{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4293bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adde4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "class PVNet2():\n",
    "    def __init__(self, board_height, board_width):\n",
    "        \n",
    "        self.board_width = board_width\n",
    "        self.board_height = board_height\n",
    "\n",
    "        # Define the tensorflow neural network\n",
    "        # 1. Input:\n",
    "        tf.reset_default_graph()\n",
    "        self.input_states = tf.placeholder(\n",
    "                tf.float32, shape=[None, 4, board_height, board_width])\n",
    "        self.input_state = tf.transpose(self.input_states, [0, 2, 3, 1])\n",
    "        # 2. Common Networks Layers\n",
    "        self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
    "                                      filters=32, kernel_size=[3, 3],\n",
    "                                      padding=\"same\", data_format=\"channels_last\",\n",
    "                                      activation=tf.nn.relu)\n",
    "        self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
    "                                      kernel_size=[3, 3], padding=\"same\",\n",
    "                                      data_format=\"channels_last\",\n",
    "                                      activation=tf.nn.relu)\n",
    "        self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
    "                                      kernel_size=[3, 3], padding=\"same\",\n",
    "                                      data_format=\"channels_last\",\n",
    "                                      activation=tf.nn.relu)\n",
    "        # 3-1 Action Networks\n",
    "        self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
    "                                            kernel_size=[1, 1], padding=\"same\",\n",
    "                                            data_format=\"channels_last\",\n",
    "                                            activation=tf.nn.relu)\n",
    "        # Flatten the tensor\n",
    "        self.action_conv_flat = tf.reshape(\n",
    "                self.action_conv, [-1, 4 * board_height * board_width])\n",
    "        # 3-2 Full connected layer, the output is the log probability of moves\n",
    "        # on each slot on the board\n",
    "        self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
    "                                         units=board_height * board_width,\n",
    "                                         activation=tf.nn.log_softmax)\n",
    "        # 4 Evaluation Networks\n",
    "        self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
    "                                                kernel_size=[1, 1],\n",
    "                                                padding=\"same\",\n",
    "                                                data_format=\"channels_last\",\n",
    "                                                activation=tf.nn.relu)\n",
    "        self.evaluation_conv_flat = tf.reshape(\n",
    "                self.evaluation_conv, [-1, 2 * board_height * board_width])\n",
    "        self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
    "                                              units=64, activation=tf.nn.relu)\n",
    "        # output the score of evaluation on current state\n",
    "        self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
    "                                              units=1, activation=tf.nn.tanh)\n",
    "\n",
    "        # Define the Loss function\n",
    "        # 1. Label: the array containing if the game wins or not for each state\n",
    "        self.labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        # 2. Predictions: the array containing the evaluation score of each state\n",
    "        # which is self.evaluation_fc2\n",
    "        # 3-1. Value Loss function\n",
    "        self.value_loss = tf.losses.mean_squared_error(self.labels,\n",
    "                                                       self.evaluation_fc2)\n",
    "        # 3-2. Policy Loss function\n",
    "        self.mcts_probs = tf.placeholder(\n",
    "                tf.float32, shape=[None, board_height * board_width])\n",
    "        self.policy_loss = tf.negative(tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.multiply(self.mcts_probs, self.action_fc), 1)))\n",
    "        # 3-3. L2 penalty (regularization)\n",
    "        l2_penalty_beta = 1e-4\n",
    "        vars = tf.trainable_variables()\n",
    "        l2_penalty = l2_penalty_beta * tf.add_n(\n",
    "            [tf.nn.l2_loss(v) for v in vars if 'bias' not in v.name.lower()])\n",
    "        # 3-4 Add up to be the Loss function\n",
    "        self.loss = self.value_loss + self.policy_loss + l2_penalty\n",
    "\n",
    "        # Define the optimizer we use for training\n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "                learning_rate=self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        # Make a session\n",
    "        self.session = tf.Session()\n",
    "\n",
    "        # calc policy entropy, for monitoring only\n",
    "        self.entropy = tf.negative(tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.exp(self.action_fc) * self.action_fc, 1)))\n",
    "\n",
    "        # Initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session.run(init)\n",
    "        self.saver = tf.train.Saver()\n",
    "        '''\n",
    "        \n",
    "        self.board_width = board_width\n",
    "        self.board_height = board_height\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        # Define the tensorflow neural network\n",
    "        # 1. Input:\n",
    "        #tf.reset_default_graph()\n",
    "        self.input_states = tf.placeholder(\n",
    "                tf.float32, shape=[None, 4, board_height, board_width])\n",
    "        self.input_state = tf.transpose(self.input_states, [0, 2, 3, 1])\n",
    "        \n",
    "        # Conv layer followed by relu activation and batchnormalization\n",
    "        self.x = tf.layers.conv2d(inputs=self.input_state, filters=64, kernel_size=[3, 3],padding=\"same\", activation=tf.nn.relu)\n",
    "        self.x = tf.layers.batch_normalization(inputs=self.x)\n",
    "        self.x = tf.layers.conv2d(inputs=self.x, filters=128,kernel_size=[3, 3], padding=\"same\",activation=tf.nn.relu)\n",
    "        self.x = tf.layers.batch_normalization(inputs=self.x)\n",
    "        self.x = tf.layers.conv2d(inputs=self.x, filters=256,kernel_size=[3, 3], padding=\"same\",activation=tf.nn.relu)\n",
    "        self.x = tf.layers.batch_normalization(inputs=self.x)\n",
    "        #print(self.x.shape)\n",
    "        # Policy Net\n",
    "        self.p = tf.layers.conv2d(inputs=self.x, filters=2,kernel_size=[1, 1], padding=\"same\",activation=tf.nn.relu)\n",
    "        self.p = tf.layers.batch_normalization(inputs=self.p)\n",
    "        #print(self.p.shape)\n",
    "        self.p = tf.reshape(self.p, [-1, 2 * board_height * board_width])\n",
    "        #print(self.p.shape)\n",
    "        self.action_fc = tf.layers.dense(inputs=self.p, units=board_height * board_width, activation=tf.nn.log_softmax)\n",
    "        \n",
    "        # Value net\n",
    "        self.v = tf.layers.conv2d(inputs=self.x, filters=1, kernel_size=[1, 1], padding=\"same\", activation=tf.nn.relu)\n",
    "        self.v = tf.layers.batch_normalization(inputs=self.v)\n",
    "        self.v = tf.reshape(self.v, [-1,  board_height * board_width])\n",
    "        self.v = tf.layers.dense(inputs=self.v, units=64, activation=tf.nn.relu)\n",
    "        self.evaluation_fc = tf.layers.dense(inputs=self.v, units=1, activation=tf.nn.tanh)\n",
    "\n",
    "        \n",
    "        # Define the Loss function\n",
    "        # 1. Label: the array containing if the game wins or not for each state\n",
    "        self.labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        # 2. Predictions: the array containing the evaluation score of each state\n",
    "        # which is self.evaluation_fc2\n",
    "        # 3-1. Value Loss function\n",
    "        self.value_loss = tf.losses.mean_squared_error(self.labels,\n",
    "                                                       self.evaluation_fc)\n",
    "        # 3-2. Policy Loss function\n",
    "        self.mcts_probs = tf.placeholder(\n",
    "                tf.float32, shape=[None, board_height * board_width])\n",
    "        self.policy_loss = tf.negative(tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.multiply(self.mcts_probs, self.action_fc), 1)))\n",
    "        # 3-3. L2 penalty (regularization)\n",
    "        l2_penalty_beta = 1e-4\n",
    "        vars = tf.trainable_variables()\n",
    "        l2_penalty = l2_penalty_beta * tf.add_n(\n",
    "            [tf.nn.l2_loss(v) for v in vars if 'bias' not in v.name.lower()])\n",
    "        # 3-4 Add up to be the Loss function\n",
    "        self.loss = self.value_loss + self.policy_loss + l2_penalty\n",
    "\n",
    "        # Define the optimizer we use for training\n",
    "        self.learning_rate = tf.placeholder(tf.float32)\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "                learning_rate=self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        # Make a session\n",
    "        self.session = tf.Session()\n",
    "\n",
    "        # calc policy entropy, for monitoring only\n",
    "        self.entropy = tf.negative(tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.exp(self.action_fc) * self.action_fc, 1)))\n",
    "\n",
    "        # Initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session.run(init)\n",
    "\n",
    "        # For saving and restoring\n",
    "        self.saver = tf.train.Saver()\n",
    "        '''\n",
    "    def predict(self, state, v=True):\n",
    "        #state.get_state().reshape(-1, 1, 8, 8)\n",
    "        log_act_probs, value = self.session.run(\n",
    "            [self.action_fc, self.evaluation_fc2],\n",
    "            feed_dict={self.input_states: state}\n",
    "            )\n",
    "        act_probs = np.exp(log_act_probs)\n",
    "        #print(\"predict\", act_probs, value[0][0])\n",
    "        if v:\n",
    "            return act_probs[0], value[0][0]\n",
    "        else:\n",
    "            return act_probs, value\n",
    "       \n",
    "    \n",
    "    def train(self, state_batch, mcts_probs, winner_batch, lr):\n",
    "        winner_batch = np.reshape(winner_batch, (-1, 1))\n",
    "        loss, entropy, _ = self.session.run(\n",
    "                [self.loss, self.entropy, self.optimizer],\n",
    "                feed_dict={self.input_states: state_batch,\n",
    "                           self.mcts_probs: mcts_probs,\n",
    "                           self.labels: winner_batch,\n",
    "                           self.learning_rate: lr})\n",
    "        return loss, entropy\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.saver.save(self.session, path)\n",
    "        \n",
    "    def restore(self, path):\n",
    "        self.saver.restore(self.session, path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9134f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "class PVNet():\n",
    "    '''Policy Value Neural Network'''\n",
    "    def __init__(self, dimension):\n",
    "        self.dimension = dimension\n",
    "        self.l2_const = 1e-4\n",
    "        self.initialize()\n",
    "        \n",
    "        \n",
    "    def initialize2(self):\n",
    "        in_x = network = Input((1, 8, 8))\n",
    "\n",
    "        # conv layers\n",
    "        network = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=l2(self.l2_const))(network)\n",
    "        network = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=l2(self.l2_const))(network)\n",
    "        network = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=l2(self.l2_const))(network)\n",
    "        # action policy layers\n",
    "        policy_net = Conv2D(filters=4, kernel_size=(1, 1), data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=l2(self.l2_const))(network)\n",
    "        policy_net = Flatten()(policy_net)\n",
    "        self.policy_net = Dense(64, activation=\"softmax\", kernel_regularizer=l2(self.l2_const))(policy_net)\n",
    "        # state value layers\n",
    "        value_net = Conv2D(filters=2, kernel_size=(1, 1), data_format=\"channels_first\", activation=\"relu\", kernel_regularizer=l2(self.l2_const))(network)\n",
    "        value_net = Flatten()(value_net)\n",
    "        value_net = Dense(64, kernel_regularizer=l2(self.l2_const))(value_net)\n",
    "        self.value_net = Dense(1, activation=\"tanh\", kernel_regularizer=l2(self.l2_const))(value_net)\n",
    "\n",
    "        self.model = Model(in_x, [self.policy_net, self.value_net])\n",
    "        \n",
    "    def initialize(self):\n",
    "        # Conv layers\n",
    "        weight_decay=1e-4\n",
    "        input = Input((1, self.dimension, self.dimension))\n",
    "        x = input\n",
    "        x = Conv2D(32, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        #print(x.shape)\n",
    "        \n",
    "        # policy net\n",
    "        p = Conv2D(2, (1,1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        p = BatchNormalization()(p)\n",
    "        p = Flatten()(p)\n",
    "        p = Dense(self.dimension * self.dimension, activation='softmax')(p)\n",
    "        #print(p.shape)\n",
    "        \n",
    "        # value net\n",
    "        v = Conv2D(2, (1,1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "        v = BatchNormalization()(v)\n",
    "        v = Flatten()(v)\n",
    "        v = Dense(self.dimension * self.dimension, activation='relu')(v)\n",
    "        v = Dense(self.dimension * self.dimension, activation='tanh')(v)\n",
    "        \n",
    "        self.model = Model(inputs=input, outputs=[p, v])\n",
    "        self.model.compile(optimizer=Adam(), loss=['categorical_crossentropy', 'mean_squared_error'])\n",
    "        \n",
    "    def train(self, x, y):\n",
    "        self.model.fit(x, y)\n",
    "        \n",
    "    def predict(self, state):\n",
    "        probs, value = self.model.predict_on_batch(state)\n",
    "        return probs[0], value[0][0]\n",
    "    def predict2(self, state):\n",
    "        probs, value = self.model.predict_on_batch(state)\n",
    "        return probs[0], value[0][0]\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977fd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, parent, p):\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        self.Q = 0\n",
    "        self.c = 5\n",
    "        self.visits = 0\n",
    "        self.P = p\n",
    "    \n",
    "    # get the value Q + U\n",
    "    def get_value(self):\n",
    "        return self.Q + self.c * self.P * np.sqrt(self.parent.visits) / (1 + self.visits)\n",
    "    \n",
    "    # expand the leaf node \n",
    "    def expand(self, actions, probs):\n",
    "        #print(actions, probs)\n",
    "        for i in range(len(actions)):\n",
    "            if actions[i] not in self.children:\n",
    "                self.children[actions[i]] = Node(self, probs[i])\n",
    "          \n",
    "    # back propagate the value from leaf to root\n",
    "    def update(self, value):\n",
    "        self.visits += 1\n",
    "        self.Q += 1.0 * (value - self.Q) / self.visits\n",
    "        if self.parent:\n",
    "            self.parent.update(-value)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    probs = np.exp(x - np.max(x))\n",
    "    probs /= np.sum(probs)\n",
    "    return probs\n",
    "            \n",
    "import copy, time\n",
    "# Monte Carlo Tree Search\n",
    "class MCTS():\n",
    "    def __init__(self, pv_net, c, n_simulations):\n",
    "        self.root = Node(None, 1.0)\n",
    "     \n",
    "        self.pv_net = pv_net\n",
    "        self.c = c\n",
    "        self.n_simulations = n_simulations\n",
    "    \n",
    "    # run n simulations of mcts\n",
    "    def run(self, board, temp=1):\n",
    "        #visits = [self.root.children[c].visits for c in self.root.children]\n",
    "        #print(\"visits b\", visits)\n",
    "        for i in range(self.n_simulations):\n",
    "            #if i % 100 == 0:\n",
    "               # print(i, \" simulations\")\n",
    "            self.traverse(self.root, copy.deepcopy(board))\n",
    "            \n",
    "        #print(\"time\", time.time() - start)\n",
    "        visits = [self.root.children[c].visits for c in self.root.children]\n",
    "        actions = [a for a in self.root.children]\n",
    "        #print(\"actions\", actions)\n",
    "        #print(\"visits\", visits, len(visits))\n",
    "        actions_p = softmax(1.0/temp * np.log(np.array(visits) + 1e-10))\n",
    "        #print(\"visits\", visits, np.array(visits).shape)\n",
    "        #print(\"actions\", actions_p)\n",
    "        return actions, actions_p\n",
    "    \n",
    "    # perform one simulation fo mcts\n",
    "    def traverse2(self, root, board, start):\n",
    "        ptr = self.root\n",
    "        while True:\n",
    "            if len(ptr.children) == 0: break\n",
    "            action, ptr = max(ptr.children.items(), key=lambda n: n[1].get_value())\n",
    "            board.make_move(action)\n",
    "        # base case, at leaf node\n",
    "        #print(\"t before\", time.time() - start)\n",
    "        probs, value = self.pv_net.predict(board.get_state().reshape(-1, 4, 6, 6))\n",
    "        #print(\"t after\", time.time() - start)   \n",
    "            \n",
    "        if board.has_ended():\n",
    "            #print(\"2\")\n",
    "            # use the true reward if game has ended\n",
    "            if len(board.availables) == 0: value = 0\n",
    "            else: value = board.player\n",
    "        else:\n",
    "            #print(\"3\")\n",
    "            #print(\"probs\", probs.shape)\n",
    "            ptr.expand(board.availables, probs[board.availables]) # expand the tree\n",
    "\n",
    "        # backpropagate the value from leaf to root\n",
    "        #print(\"value\", value)\n",
    "        ptr.update(-value)\n",
    "    \n",
    "         \n",
    "    # perform one simulation fo mcts\n",
    "    def traverse(self, root, board):\n",
    "        # base case, at leaf node\n",
    "        if len(root.children) == 0:\n",
    "            #print(\"1\")\n",
    "            start = time.time()\n",
    "            probs, value = self.pv_net.predict(board.get_state().reshape(-1, 4, 6, 6))\n",
    "            #print(value)\n",
    "            #print(\"t\", time.time() - start)\n",
    "            #print(\"p\", probs)\n",
    "            if board.has_ended():\n",
    "                #print(\"2\")\n",
    "                #print(board.board)\n",
    "                # use the true reward if game has ended\n",
    "                if len(board.availables) == 0: value = 0\n",
    "                else: value = -1\n",
    "            else:\n",
    "                #print(\"3\")\n",
    "                #print(\"probs\", probs.shape)\n",
    "                root.expand(board.availables, probs[board.availables]) # expand the tree\n",
    "                \n",
    "            # backpropagate the value from leaf to root\n",
    "            #print(\"value\", value)\n",
    "            root.update(-value)\n",
    "            return\n",
    "            \n",
    "        # Greedily select the children node with the max(Q + U) until leaf \n",
    "        #      where Q is the average of all values of nodes in the subtree and \n",
    "        #      U = c * p * sqrt(parent.visits) / (1 + visits)\n",
    "        action, child = max(root.children.items(), key=lambda n: n[1].get_value())\n",
    "        board.make_move(action)\n",
    "        self.traverse(child, board)\n",
    "    \n",
    "        \n",
    "    def forward(self, move):\n",
    "        if move in self.root.children:\n",
    "            self.root = self.root.children[move]\n",
    "            self.root.parent = None\n",
    "        else:\n",
    "            self.root = Node(None, 1.0)\n",
    "        \n",
    "        \n",
    "class Player():\n",
    "    def __init__(self, pv_net, n_simulations=400):\n",
    "        #print(\"p\", pv_net)\n",
    "        self.mcts = MCTS(pv_net, 1, n_simulations)\n",
    "        self.n_simulations = n_simulations\n",
    "        self.pv_net = pv_net\n",
    "        \n",
    "    def get_move(self, board, self_play=True):\n",
    "        actions, actions_p = self.mcts.run(board)\n",
    "        \n",
    "        move = np.random.choice(\n",
    "                    actions,\n",
    "                    p=0.75*actions_p + 0.25*np.random.dirichlet(0.3*np.ones(len(actions_p)))\n",
    "                )\n",
    "                # update the root node and reuse the search tree\n",
    "            \n",
    "        if not self_play:\n",
    "            move = actions[np.argmax(actions_p)]\n",
    "            \n",
    "        move_p = np.zeros(board.dimension**2)\n",
    "        move_p[list(actions)] = actions_p\n",
    "        if self_play:\n",
    "            self.mcts.forward(move)\n",
    "        else:\n",
    "            self.mcts.forward(-1)\n",
    "        return move, move_p\n",
    "        \n",
    "class Game():\n",
    "    '''A Single Game of Gomoku'''\n",
    "    def __init__(self, player, dimension, win_l, show):\n",
    "        self.board = Board(dimension, win_l)\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.players = []\n",
    "        self.opponent = {}\n",
    "        self.player = player\n",
    "        self.show = show\n",
    "        \n",
    "    # start game\n",
    "    def start(self):\n",
    "        i = 0\n",
    "        #s = time.time()\n",
    "        while True:\n",
    "            move, p = self.player.get_move(self.board)\n",
    "            i += 1\n",
    "            #print(\"move\", i, \"time\", time.time() - s)\n",
    "            \n",
    "            # before each move, save the the board state, probabilities of next actions and the current player at the turn\n",
    "            #print(\"state after one move:\\n\", self.board.get_state())\n",
    "            self.states.append(self.board.get_state())\n",
    "            #print(\"current states\", self.board.get_state())\n",
    "            self.probs.append(p)\n",
    "            #print(\"probs\", p)\n",
    "            self.players.append(self.board.player)\n",
    "            #print(\"current player\", self.board.player)\n",
    "            \n",
    "            self.board.make_move(move)\n",
    "            if self.show:\n",
    "                print(self.board.board)\n",
    "            \n",
    "            if self.board.has_ended():\n",
    "                #print(\"1\", self.board.board)\n",
    "                winners = np.zeros(len(self.players))\n",
    "                # someone wins\n",
    "                if len(self.board.availables) > 0:\n",
    "                    winner = -self.board.player\n",
    "                    winners[np.array(self.players) == winner] = 1.0\n",
    "                    winners[np.array(self.players) != winner] = -1.0\n",
    "                '''\n",
    "                for i in winners:\n",
    "                    print(\"winner\", i)\n",
    "                for i in self.states:\n",
    "                    print(\"s\", i)\n",
    "                for i in self.probs:\n",
    "                    print(\"p\", i)\n",
    "                '''\n",
    "                #print(\"winners\", winners)\n",
    "                return zip(self.states, self.probs, winners)\n",
    "            \n",
    "        \n",
    "    def ended(self):\n",
    "        return self.board.has_ended()\n",
    "    \n",
    "                \n",
    "    \n",
    "\n",
    "# run through the training pipeline\n",
    "class Train():\n",
    "    \n",
    "    \n",
    "    def __init__(self, dimension=6, win_l=4):\n",
    "        self.dimension = dimension\n",
    "        self.win_l = win_l\n",
    "        self.pv_net = PVNet2(dimension, dimension)\n",
    "        self.data_collection = deque(maxlen=10000)\n",
    "        self.n_games = 300\n",
    "        self.batch_size = 512\n",
    "        self.epochs = 5\n",
    "        self.lr_multiplier = 1.0\n",
    "        self.kl_targ = 0.02\n",
    "        self.data_len = []\n",
    "        self.game_len = 0\n",
    "        \n",
    "    # collect data through self play\n",
    "    def collect_data_self_play(self, show=False, n_rounds=1):\n",
    "        # perform n rounds of self play\n",
    "        for i in range(n_rounds):\n",
    "            #print(\"collect\", self.pv_net)\n",
    "            player = Player(self.pv_net)\n",
    "            game = Game(player, self.dimension, self.win_l, show)\n",
    "            data = list(game.start())[:]\n",
    "            #print(len(data))\n",
    "            #self.data_len += len(data)\n",
    "            #print(data)\n",
    "            self.game_len = len(data)\n",
    "            data = self.get_equi_data(data)\n",
    "            self.data_len.append(len(data))\n",
    "            #print(\"datalen\", len(data))\n",
    "            self.data_collection.extend(data)\n",
    "      \n",
    "    def get_equi_data(self, play_data):\n",
    "        \"\"\"augment the data set by rotation and flipping\n",
    "        play_data: [(state, mcts_prob, winner_z), ..., ...]\n",
    "        \"\"\"\n",
    "        extend_data = []\n",
    "        for state, mcts_porb, winner in play_data:\n",
    "            for i in [1, 2, 3, 4]:\n",
    "                # rotate counterclockwise\n",
    "                equi_state = np.array([np.rot90(s, i) for s in state])\n",
    "                equi_mcts_prob = np.rot90(np.flipud(\n",
    "                    mcts_porb.reshape(self.dimension, self.dimension)), i)\n",
    "                extend_data.append((equi_state,\n",
    "                                    np.flipud(equi_mcts_prob).flatten(),\n",
    "                                    winner))\n",
    "                # flip horizontally\n",
    "                equi_state = np.array([np.fliplr(s) for s in equi_state])\n",
    "                equi_mcts_prob = np.fliplr(equi_mcts_prob)\n",
    "                extend_data.append((equi_state,\n",
    "                                    np.flipud(equi_mcts_prob).flatten(),\n",
    "                                    winner))\n",
    "        return extend_data\n",
    "    # run the training process\n",
    "    def run(self, n_games= 300, display_games=50, l_rate_m=1.0):\n",
    "        #self.lr_multiplier /= l_rate_m\n",
    "        start = time.time()\n",
    "        self.n_games = n_games\n",
    "        for i in range(self.n_games):\n",
    "            s = time.time() \n",
    "            self.collect_data_self_play()\n",
    "            if ((i + 1) % display_games == 0):\n",
    "                player = Player(self.pv_net, n_simulations=800)\n",
    "                board = Board(self.dimension, self.win_l)\n",
    "                while True:\n",
    "                    move, p = player.get_move(board, self_play=False)\n",
    "                    board.make_move(move)\n",
    "                    pred = self.pv_net.predict(board.get_state().reshape(-1, 4, 6, 6))\n",
    "                    print(\"prediction:\\n\", pred[0], \"\\n\", pred[1])\n",
    "                    print(\"p\", p.reshape(-1, self.dimension))\n",
    "                    print(\"move\", move)\n",
    "                    print(\"board\\n\", board.board)\n",
    "                    if board.has_ended():\n",
    "                        print(-board.player, \"won\")\n",
    "                        break\n",
    " \n",
    "            #print(time.time() - s)\n",
    "            #if (len(self.data_collection)) > self.batch_size:\n",
    "            print(\"game\", i, \"completed in\", time.time() - s, \"s\", self.game_len, \"steps\")\n",
    "            if (i >= 300):\n",
    "                l = self.data_len.pop(0)\n",
    "                #print(\"length\", l, \"data l\", len(self.data_collection))\n",
    "                for i in range(l):\n",
    "                    self.data_collection.popleft()\n",
    "                    \n",
    "                print(\"data l after\", len(self.data_collection))\n",
    "            #print(self.data_collection[0])\n",
    "            #print(states[0].shape)\n",
    "            #print(probs[0].reshape(-1, self.dimension**2).shape)\n",
    "            #print(winners[0].reshape(1, 1).shape, winners)\n",
    "            #print(len(self.data_collection))\n",
    "            if len(self.data_collection) > self.batch_size:\n",
    "                s = time.time()\n",
    "                # train neural network\n",
    "                \n",
    "                batch = random.sample(self.data_collection, self.batch_size)\n",
    "                #s = np.array([d[0] for d in batch])\n",
    "                #print(\"s1 shape\", s.shape)\n",
    "                states = np.array([d[0] for d in batch])\n",
    "                #print(\"s shape\", states.shape)\n",
    "                probs = np.array([d[1] for d in batch])\n",
    "                #print(\"p shape\", probs.shape)\n",
    "                winners = np.array([d[2] for d in batch]).reshape(-1, 1)\n",
    "                #print(\"w shape\", winners.shape)\n",
    "                old_probs, old_v = self.pv_net.predict(states, v=False)\n",
    "                #print(np.array(old_probs).shape, np.array(old_v).shape)\n",
    "                for j in range(self.epochs):\n",
    "                    #print(batch.shape)\n",
    "                    \n",
    "                    #print(states.shape, probs.shape, winners.shape)\n",
    "                    loss, entropy = self.pv_net.train(states, probs, winners, 2e-3 * self.lr_multiplier)\n",
    "                    \n",
    "                    new_probs, new_v = self.pv_net.predict(states, v=False)\n",
    "                    print(\"training\", j, \"lr_mult\", self.lr_multiplier, \"loss\", loss, \"entropy\", entropy)\n",
    "                    \n",
    "                    kl = np.mean(np.sum(old_probs * (\n",
    "                        np.log(old_probs + 1e-10) - np.log(new_probs + 1e-10)),\n",
    "                        axis=1))\n",
    "                    \n",
    "                    if kl > self.kl_targ * 4:  # early stopping if D_KL diverges badly\n",
    "                        break\n",
    "                # adaptively adjust the learning rate\n",
    "                print(\"kl\", kl)\n",
    "                \n",
    "                if kl > self.kl_targ * 2 and self.lr_multiplier > 0.1:\n",
    "                    self.lr_multiplier /= 1.5\n",
    "                elif kl < self.kl_targ / 2 and self.lr_multiplier < 10:\n",
    "                    self.lr_multiplier *= 1.5\n",
    "                \n",
    "                \n",
    "                    \n",
    "                print(\"completed in\", time.time() - s, \"s\")\n",
    "            \n",
    "        print(\"training pipeline completed in\", time.time() - start, \"s\")\n",
    "    def save(self, path):\n",
    "        self.pv_net.save(path)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17f0c80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 µs, sys: 2 µs, total: 54 µs\n",
      "Wall time: 58.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import groupby\n",
    "class Board():\n",
    "    '''Board used in the Gomoku'''\n",
    "    def __init__(self, dimension, win_l):\n",
    "        self.dimension = dimension\n",
    "        self.board = np.zeros((dimension, dimension))\n",
    "        self.win_l = win_l         \n",
    "        self.prev_move = -1\n",
    "        self.player = 1\n",
    "        self.availables = list(range(dimension * dimension))\n",
    "        \n",
    "    \n",
    "    def make_move(self, pos):\n",
    "        self.board[pos // self.dimension][pos % self.dimension] = self.player\n",
    "        self.prev_move = pos\n",
    "        self.player = -self.player\n",
    "        self.availables.remove(pos)\n",
    "        \n",
    "    def has_won(self):\n",
    "        def check(a):\n",
    "            length = max(sum(1 for i in g) for k, g in groupby(a))\n",
    "            #print(\"length\", length)\n",
    "            return length >= 4 and a[a.shape[0] // 2] != 0\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        i = self.prev_move // self.dimension\n",
    "        j = self.prev_move % self.dimension\n",
    "        \n",
    "        # horizontal\n",
    "        #print(\"i\", i, \"j\", j)\n",
    "        #print(\"l\", self.board[i, :])\n",
    "        if check(self.board[i, :]): return True\n",
    "        # vertical\n",
    "        #print(\"2\", self.board[:, j])\n",
    "        if check(self.board[:, j]): return True\n",
    "        # diagonal \\\n",
    "        #print(\"3\", self.board.diagonal(j - i))\n",
    "        if check(self.board.diagonal(j - i)): return True\n",
    "        # diagonal /\n",
    "        #print(\"4\", np.fliplr(self.board).diagonal(self.dimension - j - i - 1))\n",
    "        return check(np.fliplr(self.board).diagonal(self.dimension - j - i - 1))\n",
    "    \n",
    "    def has_ended(self):\n",
    "        return len(self.availables) != self.dimension**2 and (self.has_won() or (len(self.availables) == 0))\n",
    "    \n",
    "    def get_state(self):\n",
    "        #print(self.board.shape)\n",
    "        state = np.zeros((4, self.board.shape[0], self.board.shape[1]))\n",
    "        state[0] = (self.board == self.player).astype(int)\n",
    "        state[1] = (self.board == -self.player).astype(int)\n",
    "        last = np.zeros(self.board.shape)\n",
    "        if self.prev_move != -1:\n",
    "            last[self.prev_move // self.dimension][self.prev_move % self.dimension] = 1\n",
    "        state[2] = last\n",
    "        if self.player == 1:\n",
    "            state[3] = np.ones(self.board.shape)\n",
    "        else:\n",
    "            state[3] = np.zeros(self.board.shape)\n",
    "        \n",
    "        return state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5124ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:18: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
      "/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/keras/legacy_tf_layers/convolutional.py:563: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:22: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:26: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:31: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:40: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
      "/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:44: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:51: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19454/3538894304.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
      "2022-10-12 18:47:25.949730: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-12 18:47:25.949879: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-10-12 18:47:25.958165: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-12 18:47:25.958295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    }
   ],
   "source": [
    "k = Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff05b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 18:44:09.389119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 28.175297021865845 s 29 steps\n",
      "game 1 completed in 15.836066007614136 s 17 steps\n",
      "game 2 completed in 19.57217812538147 s 20 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 18:45:13.761487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0 lr_mult 1.0 loss 4.6010046 entropy 3.5826356\n",
      "training 1 lr_mult 1.0 loss 4.590211 entropy 3.5829363\n",
      "training 2 lr_mult 1.0 loss 4.5560665 entropy 3.580771\n",
      "training 3 lr_mult 1.0 loss 4.497539 entropy 3.5761766\n",
      "training 4 lr_mult 1.0 loss 4.4725895 entropy 3.568336\n",
      "kl 0.0190255\n",
      "completed in 4.596683025360107 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/1968526124.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_games, display_games, l_rate_m)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_data_self_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_games\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpv_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_simulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mcollect_data_self_play\u001b[0;34m(self, show, n_rounds)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpv_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwin_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;31m#print(len(data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;31m#self.data_len += len(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m#s = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m#print(\"move\", i, \"time\", time.time() - s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mget_move\u001b[0;34m(self, board, self_play)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_play\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         move = np.random.choice(\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, board, temp)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#if i % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                \u001b[0;31m# print(i, \" simulations\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m#print(\"time\", time.time() - start)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(self, root, board)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/4291231227.py\u001b[0m in \u001b[0;36mtraverse\u001b[0;34m(self, root, board)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m#print(\"1\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;31m#print(value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m#print(\"t\", time.time() - start)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_19010/3538894304.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state, v)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#state.get_state().reshape(-1, 1, 8, 8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         log_act_probs, value = self.session.run(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_fc2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                            run_metadata)\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1378\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1454\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1455\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1456\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05270a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.save('n2-300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15eb1307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 6.848814964294434 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2140422 entropy 2.545452\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.188348 entropy 2.5524023\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1409156 entropy 2.5579104\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0911727 entropy 2.5611782\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0505993 entropy 2.5619135\n",
      "kl 0.03351944\n",
      "completed in 0.151777982711792 s\n",
      "game 1 completed in 7.0047972202301025 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1716425 entropy 2.536679\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1491623 entropy 2.5413976\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1175377 entropy 2.5499616\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0847592 entropy 2.561005\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0524225 entropy 2.5725088\n",
      "kl 0.0228841\n",
      "completed in 0.17209982872009277 s\n",
      "game 2 completed in 11.82697319984436 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2179058 entropy 2.5811682\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.2004795 entropy 2.5890882\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1673627 entropy 2.5934126\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1300797 entropy 2.5923705\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0943558 entropy 2.586342\n",
      "kl 0.025204275\n",
      "completed in 0.19991183280944824 s\n",
      "game 3 completed in 10.537827014923096 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.176377 entropy 2.605629\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1471426 entropy 2.592877\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1110473 entropy 2.580114\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0762703 entropy 2.5692196\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0421069 entropy 2.561507\n",
      "kl 0.033706814\n",
      "completed in 0.16519594192504883 s\n",
      "game 4 completed in 7.398576974868774 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1483989 entropy 2.5276337\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1135616 entropy 2.528666\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0583973 entropy 2.5305736\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0104923 entropy 2.5290437\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9703317 entropy 2.5221\n",
      "kl 0.026926916\n",
      "completed in 0.160477876663208 s\n",
      "game 5 completed in 8.967549085617065 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1746447 entropy 2.508225\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.148569 entropy 2.4966912\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1031787 entropy 2.486243\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0519447 entropy 2.476214\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.001745 entropy 2.4664783\n",
      "kl 0.03243643\n",
      "completed in 0.21013212203979492 s\n",
      "game 6 completed in 11.093472003936768 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1153264 entropy 2.419649\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0882819 entropy 2.4136937\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.043446 entropy 2.4112623\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9951694 entropy 2.4129176\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9552186 entropy 2.418356\n",
      "kl 0.027672749\n",
      "completed in 0.20433902740478516 s\n",
      "game 7 completed in 10.75722074508667 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1633296 entropy 2.4390087\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.137086 entropy 2.4494047\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0935 entropy 2.4593964\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0462563 entropy 2.4683332\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0035257 entropy 2.4755442\n",
      "kl 0.021859452\n",
      "completed in 0.2278139591217041 s\n",
      "game 8 completed in 7.449582099914551 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1955822 entropy 2.4887037\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1675692 entropy 2.500701\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1219447 entropy 2.5140977\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0756357 entropy 2.5249276\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0340505 entropy 2.5315297\n",
      "kl 0.032525457\n",
      "completed in 0.16882920265197754 s\n",
      "game 9 completed in 6.665975093841553 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2140422 entropy 2.6069157\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1886296 entropy 2.6014252\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.146482 entropy 2.5895035\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1029327 entropy 2.5736313\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0646296 entropy 2.556829\n",
      "kl 0.04881796\n",
      "completed in 0.16734790802001953 s\n",
      "game 10 completed in 8.949705123901367 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1019807 entropy 2.5051694\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.0811331 entropy 2.5034165\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.04662 entropy 2.506313\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0106833 entropy 2.5121727\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.9789307 entropy 2.5190368\n",
      "kl 0.013598716\n",
      "completed in 0.1689450740814209 s\n",
      "game 11 completed in 6.496670246124268 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1849024 entropy 2.5380545\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1694694 entropy 2.54629\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.1396937 entropy 2.553825\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.1018045 entropy 2.5591846\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.0645516 entropy 2.5616944\n",
      "kl 0.013618639\n",
      "completed in 0.17542624473571777 s\n",
      "game 12 completed in 5.887395143508911 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.221531 entropy 2.6165051\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.2009423 entropy 2.6117935\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.1680074 entropy 2.6026864\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.1314616 entropy 2.590795\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.097122 entropy 2.5771937\n",
      "kl 0.017478392\n",
      "completed in 0.20334196090698242 s\n",
      "game 13 completed in 5.946300745010376 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1554842 entropy 2.5336008\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1299982 entropy 2.526401\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0956829 entropy 2.5219288\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0589254 entropy 2.5189772\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.0247746 entropy 2.5165615\n",
      "kl 0.014316147\n",
      "completed in 0.16441798210144043 s\n",
      "game 14 completed in 5.809474229812622 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.0837607 entropy 2.4756417\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.067121 entropy 2.4757102\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0401657 entropy 2.4758987\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0085196 entropy 2.4753656\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.9797754 entropy 2.4736748\n",
      "kl 0.017643087\n",
      "completed in 0.16695713996887207 s\n",
      "game 15 completed in 6.6824951171875 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1624582 entropy 2.5055203\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1513073 entropy 2.5063663\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.1263516 entropy 2.5074935\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0943022 entropy 2.5083108\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.062362 entropy 2.5079992\n",
      "kl 0.014370769\n",
      "completed in 0.16680335998535156 s\n",
      "game 16 completed in 9.170589923858643 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1434848 entropy 2.499228\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1280217 entropy 2.4975986\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0975578 entropy 2.4947462\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.060015 entropy 2.4912348\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.0227144 entropy 2.4872863\n",
      "kl 0.015702108\n",
      "completed in 0.2134418487548828 s\n",
      "game 17 completed in 8.163161993026733 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1675828 entropy 2.496468\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1486044 entropy 2.4955792\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.1205337 entropy 2.4965725\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0912821 entropy 2.4990683\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.0628693 entropy 2.502753\n",
      "kl 0.0101196375\n",
      "completed in 0.16686010360717773 s\n",
      "game 18 completed in 10.568639993667603 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.0656419 entropy 2.5032861\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.0508077 entropy 2.5078673\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0253463 entropy 2.5123482\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.9954674 entropy 2.5161464\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.9655857 entropy 2.5186946\n",
      "kl 0.012939346\n",
      "completed in 0.17236089706420898 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 19 completed in 13.88631796836853 s 17 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.2230155 entropy 2.5521882\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.2061694 entropy 2.5523074\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.1794603 entropy 2.5498433\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.149455 entropy 2.545089\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.1208944 entropy 2.538546\n",
      "kl 0.0075266855\n",
      "completed in 0.1719820499420166 s\n",
      "game 20 completed in 9.879530906677246 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.160883 entropy 2.5153112\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1274328 entropy 2.5052285\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0808964 entropy 2.496113\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0353274 entropy 2.489786\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.996563 entropy 2.4861484\n",
      "kl 0.022934835\n",
      "completed in 0.1714632511138916 s\n",
      "game 21 completed in 7.308928966522217 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.080794 entropy 2.4247935\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0596166 entropy 2.4282272\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0227554 entropy 2.4352946\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9870934 entropy 2.4431696\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9509032 entropy 2.4492207\n",
      "kl 0.021676239\n",
      "completed in 0.19373011589050293 s\n",
      "game 22 completed in 5.813287019729614 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1432176 entropy 2.524221\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.129822 entropy 2.5203383\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.10094 entropy 2.5131235\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0655713 entropy 2.5034347\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0292237 entropy 2.4930665\n",
      "kl 0.028207423\n",
      "completed in 0.16685199737548828 s\n",
      "game 23 completed in 5.785764217376709 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1644022 entropy 2.4536626\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1312582 entropy 2.4530053\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0832987 entropy 2.461524\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0358412 entropy 2.4772062\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9987059 entropy 2.4959097\n",
      "kl 0.022559706\n",
      "completed in 0.16694021224975586 s\n",
      "game 24 completed in 11.028931856155396 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1917892 entropy 2.5175245\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1690679 entropy 2.5327373\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1292512 entropy 2.5400894\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0873744 entropy 2.5380871\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0495338 entropy 2.5262969\n",
      "kl 0.02007421\n",
      "completed in 0.1728971004486084 s\n",
      "game 25 completed in 9.163611888885498 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.15623 entropy 2.540501\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1376593 entropy 2.5241418\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1082604 entropy 2.5140758\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.072119 entropy 2.5119762\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0337923 entropy 2.517013\n",
      "kl 0.019374432\n",
      "completed in 0.17167901992797852 s\n",
      "game 26 completed in 7.488976001739502 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1188874 entropy 2.4680295\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0985227 entropy 2.4758534\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.05855 entropy 2.4826374\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0110722 entropy 2.4880023\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9679844 entropy 2.4921215\n",
      "kl 0.016830929\n",
      "completed in 0.20599985122680664 s\n",
      "game 27 completed in 9.026297092437744 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1824317 entropy 2.5104527\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1528394 entropy 2.5146713\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1062095 entropy 2.5192657\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0608516 entropy 2.521265\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0214014 entropy 2.5194216\n",
      "kl 0.02187116\n",
      "completed in 0.1696150302886963 s\n",
      "game 28 completed in 6.625849962234497 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.065958 entropy 2.4921474\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0445695 entropy 2.4870503\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0118363 entropy 2.48249\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.979144 entropy 2.4778469\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9499514 entropy 2.4719799\n",
      "kl 0.016790152\n",
      "completed in 0.17532110214233398 s\n",
      "game 29 completed in 5.707635879516602 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0516403 entropy 2.516877\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0260794 entropy 2.509562\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9855769 entropy 2.501458\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9454865 entropy 2.4920301\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9083338 entropy 2.4808197\n",
      "kl 0.025496526\n",
      "completed in 0.17478013038635254 s\n",
      "game 30 completed in 7.573613882064819 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.184902 entropy 2.4488192\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.168232 entropy 2.4484618\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1292815 entropy 2.4555278\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0811653 entropy 2.4662395\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0323546 entropy 2.4779902\n",
      "kl 0.03989183\n",
      "completed in 0.1639399528503418 s\n",
      "game 31 completed in 7.4611427783966064 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1032548 entropy 2.478738\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0777645 entropy 2.4919376\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.037106 entropy 2.5061347\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9948003 entropy 2.5181615\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9575086 entropy 2.5247388\n",
      "kl 0.048042346\n",
      "completed in 0.20153594017028809 s\n",
      "game 32 completed in 5.819112062454224 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.1238415 entropy 2.5243716\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1106465 entropy 2.5243487\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0850592 entropy 2.521927\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0549796 entropy 2.5163236\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.025141 entropy 2.5077624\n",
      "kl 0.02787308\n",
      "completed in 0.17724275588989258 s\n",
      "game 33 completed in 7.59628701210022 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.0420523 entropy 2.4966826\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.0295358 entropy 2.4835067\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0064354 entropy 2.4703155\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.976686 entropy 2.4580154\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.9429276 entropy 2.4468398\n",
      "kl 0.0125970645\n",
      "completed in 0.17131400108337402 s\n",
      "game 34 completed in 8.843152284622192 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.130376 entropy 2.439912\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.1138833 entropy 2.431912\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0861948 entropy 2.427476\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0533597 entropy 2.4268613\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.0191648 entropy 2.4294624\n",
      "kl 0.015912667\n",
      "completed in 0.17258429527282715 s\n",
      "game 35 completed in 7.419949054718018 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.097604 entropy 2.4286523\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.0787704 entropy 2.435177\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0482726 entropy 2.4434066\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.0169048 entropy 2.451539\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.9855788 entropy 2.457777\n",
      "kl 0.013320767\n",
      "completed in 0.16846489906311035 s\n",
      "game 36 completed in 8.945977926254272 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.0868483 entropy 2.4422557\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.0675662 entropy 2.442245\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.0395603 entropy 2.4397922\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.013681 entropy 2.4360108\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.9907928 entropy 2.4321654\n",
      "kl 0.009461397\n",
      "completed in 0.17111611366271973 s\n",
      "game 37 completed in 7.427998304367065 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0618992 entropy 2.4501772\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0488436 entropy 2.446694\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0248601 entropy 2.4478226\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9940803 entropy 2.4526358\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9646099 entropy 2.458696\n",
      "kl 0.02006727\n",
      "completed in 0.18453097343444824 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 38 completed in 8.226725101470947 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0386565 entropy 2.451143\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0134397 entropy 2.459196\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.982628 entropy 2.4690008\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9575484 entropy 2.4763017\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9350567 entropy 2.4785008\n",
      "kl 0.019155473\n",
      "completed in 0.16772913932800293 s\n",
      "game 39 completed in 7.974160671234131 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.040987 entropy 2.4938424\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0128357 entropy 2.4851193\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9712257 entropy 2.4724226\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9347405 entropy 2.4578528\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.906094 entropy 2.4440284\n",
      "kl 0.027115189\n",
      "completed in 0.20631098747253418 s\n",
      "game 40 completed in 8.095203876495361 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0861328 entropy 2.4498496\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0644162 entropy 2.4438257\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0283568 entropy 2.4415793\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.992119 entropy 2.442021\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9593105 entropy 2.4433408\n",
      "kl 0.020885032\n",
      "completed in 0.17154884338378906 s\n",
      "game 41 completed in 8.852006912231445 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1318226 entropy 2.4600704\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0981247 entropy 2.4633741\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.058741 entropy 2.4660437\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0259254 entropy 2.4679375\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.994456 entropy 2.4688268\n",
      "kl 0.02519318\n",
      "completed in 0.168701171875 s\n",
      "game 42 completed in 9.23543095588684 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0281103 entropy 2.3252213\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9957156 entropy 2.3266149\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.945079 entropy 2.3288918\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8975391 entropy 2.3289366\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8620973 entropy 2.325107\n",
      "kl 0.021483026\n",
      "completed in 0.18077993392944336 s\n",
      "game 43 completed in 6.742354869842529 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.114064 entropy 2.398866\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0884979 entropy 2.3896074\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0419168 entropy 2.3812613\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0048475 entropy 2.3759036\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9765642 entropy 2.3741894\n",
      "kl 0.022756912\n",
      "completed in 0.20678210258483887 s\n",
      "game 44 completed in 11.371968984603882 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0703144 entropy 2.3823736\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0460567 entropy 2.3869662\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0052154 entropy 2.393174\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9619856 entropy 2.3987663\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9218943 entropy 2.4016125\n",
      "kl 0.019210342\n",
      "completed in 0.16396689414978027 s\n",
      "game 45 completed in 9.712900876998901 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.313719 entropy 2.4447596\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.2805789 entropy 2.4490802\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.2341619 entropy 2.4567542\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1907876 entropy 2.4646778\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1474967 entropy 2.4719758\n",
      "kl 0.02045694\n",
      "completed in 0.1927497386932373 s\n",
      "game 46 completed in 7.36102819442749 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0847642 entropy 2.4101257\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0572166 entropy 2.4117498\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.015277 entropy 2.4110522\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.971313 entropy 2.408192\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9349802 entropy 2.4048796\n",
      "kl 0.027696759\n",
      "completed in 0.17093300819396973 s\n",
      "game 47 completed in 8.84712028503418 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0272408 entropy 2.427822\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.010955 entropy 2.4266384\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9813826 entropy 2.4268863\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9456756 entropy 2.4273267\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9089835 entropy 2.4276357\n",
      "kl 0.022281056\n",
      "completed in 0.19013500213623047 s\n",
      "game 48 completed in 17.578362226486206 s 22 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1446097 entropy 2.4124737\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1243129 entropy 2.4167113\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0894506 entropy 2.42449\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0498505 entropy 2.4329262\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0055223 entropy 2.4398003\n",
      "kl 0.02280823\n",
      "completed in 0.16034197807312012 s\n",
      "prediction:\n",
      " [0.0051056  0.00536047 0.00507301 0.00446831 0.00562408 0.00252883\n",
      " 0.00382001 0.11365167 0.08002777 0.08146625 0.01500366 0.00597339\n",
      " 0.00452003 0.08748398 0.00628599 0.02473218 0.0850288  0.00523101\n",
      " 0.00622408 0.06233663 0.02972929 0.00671732 0.05911804 0.00288974\n",
      " 0.00791429 0.01412928 0.07797766 0.07612323 0.08292216 0.00493629\n",
      " 0.00178235 0.00845761 0.00396999 0.00462704 0.00430307 0.00445708] \n",
      " -0.4950061\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 3.16645807e-01 1.36420526e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 2.72841051e-01 2.62828536e-01\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.008312   0.00710277 0.006905   0.00191057 0.00213848 0.00427112\n",
      " 0.00479313 0.00622122 0.01436267 0.00806547 0.00220187 0.00306978\n",
      " 0.01414301 0.01150457 0.0930885  0.12169494 0.01091474 0.00247263\n",
      " 0.00357489 0.01395639 0.44286525 0.10500491 0.01836981 0.00729198\n",
      " 0.00394566 0.00389021 0.02614591 0.00805447 0.00510159 0.0055107\n",
      " 0.00442589 0.00403384 0.00347051 0.01044597 0.00434862 0.0063911 ] \n",
      " 0.13857858\n",
      "p [[0.00250313 0.00250313 0.00375469 0.00375469 0.00375469 0.00250313]\n",
      " [0.01501877 0.3028786  0.04630788 0.04130163 0.01877347 0.00250313]\n",
      " [0.00750939 0.04630788 0.         0.00625782 0.04505632 0.00250313]\n",
      " [0.00500626 0.05882353 0.05131414 0.00250313 0.05256571 0.00250313]\n",
      " [0.01126408 0.01376721 0.03254068 0.11389237 0.06883605 0.00250313]\n",
      " [0.00125156 0.00250313 0.00125156 0.01877347 0.00500626 0.00250313]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01867986 0.01000926 0.00385974 0.00599431 0.00935197 0.00277364\n",
      " 0.00556076 0.07275422 0.08726631 0.04714835 0.00826368 0.01016328\n",
      " 0.00753666 0.14117585 0.00092913 0.01794394 0.05214081 0.00729588\n",
      " 0.00895227 0.07782064 0.01720217 0.00093758 0.07074091 0.00373249\n",
      " 0.00965602 0.02615694 0.06174688 0.11219355 0.04158961 0.00482138\n",
      " 0.00319685 0.01324439 0.00912572 0.00454754 0.00895146 0.01653619] \n",
      " -0.848271\n",
      "p [[1.25156446e-03 1.37672090e-02 2.50312891e-03 1.25156446e-13\n",
      "  1.25156446e-13 2.50312891e-03]\n",
      " [4.25531915e-02 0.00000000e+00 2.62828536e-01 8.76095119e-03\n",
      "  1.25156446e-13 3.75469337e-03]\n",
      " [3.75469337e-03 3.75469337e-03 0.00000000e+00 3.37922403e-02\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 5.00625782e-03 1.50187735e-01 4.18022528e-01\n",
      "  2.50312891e-03 5.00625782e-03]\n",
      " [5.00625782e-03 1.25156446e-03 5.00625782e-03 1.25156446e-03\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [2.50312891e-03 2.50312891e-03 2.50312891e-03 2.50312891e-03\n",
      "  5.00625782e-03 2.50312891e-03]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.0403441  0.01247142 0.00184208 0.00218243 0.00398805 0.00117222\n",
      " 0.00654725 0.00970546 0.00591712 0.0071807  0.00151678 0.00359957\n",
      " 0.00912337 0.0133544  0.00414293 0.21045648 0.01877537 0.00155742\n",
      " 0.00204013 0.02541258 0.52184975 0.00188024 0.00916663 0.00366919\n",
      " 0.00228239 0.00135598 0.00771423 0.00643575 0.0077242  0.00662646\n",
      " 0.00083813 0.00464689 0.00230741 0.00276547 0.00816356 0.03124397] \n",
      " 0.26942465\n",
      "p [[0.0350438  0.00375469 0.00125156 0.00250313 0.00250313 0.00125156]\n",
      " [0.00125156 0.         0.0738423  0.04630788 0.00375469 0.02252816]\n",
      " [0.00250313 0.08760951 0.         0.00625782 0.04505632 0.00250313]\n",
      " [0.00750939 0.0563204  0.01251564 0.         0.04881101 0.00125156]\n",
      " [0.00250313 0.01501877 0.02252816 0.08010013 0.36545682 0.00125156]\n",
      " [0.00250313 0.02002503 0.00250313 0.01627034 0.00250313 0.00500626]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.03357682 0.01158513 0.00593304 0.00334774 0.00678812 0.00676098\n",
      " 0.00561437 0.00186653 0.213653   0.04096953 0.02080062 0.00725965\n",
      " 0.00878358 0.15277219 0.00181781 0.00197182 0.04694217 0.00471502\n",
      " 0.00457291 0.0583617  0.00176252 0.00098813 0.12069465 0.00573391\n",
      " 0.00646506 0.03909404 0.03625131 0.08443286 0.00140934 0.00739001\n",
      " 0.00533429 0.0055821  0.00548525 0.00657011 0.01790202 0.01681189] \n",
      " -0.88954467\n",
      "p [[2.62828536e-02 4.88110138e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.87734668e-02 1.25156446e-13]\n",
      " [3.12891114e-02 0.00000000e+00 2.50312891e-03 5.00625782e-03\n",
      "  1.25156446e-13 3.75469337e-03]\n",
      " [7.50938673e-03 3.75469337e-03 0.00000000e+00 5.25657071e-01\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.50187735e-02 1.75219024e-01 0.00000000e+00\n",
      "  1.37672090e-02 3.75469337e-03]\n",
      " [1.25156446e-13 1.25156446e-13 5.00625782e-03 2.12765957e-02\n",
      "  0.00000000e+00 7.50938673e-03]\n",
      " [1.25156446e-13 1.00125156e-02 1.25156446e-13 1.25156446e-13\n",
      "  5.63204005e-02 1.25156446e-02]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02574918 0.02829416 0.00510569 0.00368829 0.00344388 0.00587635\n",
      " 0.0124495  0.00312892 0.00651134 0.13423312 0.00315577 0.0049581\n",
      " 0.01884791 0.08879018 0.00314236 0.01106757 0.14342056 0.00378557\n",
      " 0.00535954 0.15455317 0.03365063 0.00243076 0.06696893 0.00898567\n",
      " 0.0041934  0.01410487 0.11139617 0.00750385 0.00750772 0.0172723\n",
      " 0.00698863 0.00283316 0.00428407 0.01330975 0.01403141 0.01897771] \n",
      " -0.05076053\n",
      "p [[0.04255319 0.00876095 0.00125156 0.00125156 0.00250313 0.00375469]\n",
      " [0.00500626 0.         0.09136421 0.02252816 0.01126408 0.00500626]\n",
      " [0.00125156 0.15018773 0.         0.         0.0212766  0.00125156]\n",
      " [0.03128911 0.03379224 0.00125156 0.         0.19274093 0.00125156]\n",
      " [0.00625782 0.02002503 0.01126408 0.29411765 0.         0.00625782]\n",
      " [0.00375469 0.00375469 0.00375469 0.00125156 0.00750939 0.01251564]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02203126 0.02075029 0.00552991 0.00730169 0.00871978 0.00528417\n",
      " 0.03085717 0.00258159 0.00437362 0.1823203  0.02304372 0.00480737\n",
      " 0.01955444 0.08246818 0.00188253 0.0026298  0.00551472 0.0148355\n",
      " 0.02642966 0.00715033 0.00260598 0.00161957 0.13464516 0.00382067\n",
      " 0.00690199 0.09415064 0.17137538 0.00541964 0.00078596 0.03113908\n",
      " 0.00829785 0.00675161 0.00856415 0.00890465 0.02901964 0.00793223] \n",
      " -0.7322422\n",
      "p [[6.25782228e-03 8.76095119e-03 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [7.50938673e-03 0.00000000e+00 3.75469337e-03 5.88235294e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-03 3.12891114e-02 0.00000000e+00 0.00000000e+00\n",
      "  7.68460576e-01 1.25156446e-13]\n",
      " [1.25156446e-03 1.87734668e-02 7.50938673e-03 0.00000000e+00\n",
      "  1.75219024e-02 5.00625782e-03]\n",
      " [1.25156446e-13 1.12640801e-02 2.37797247e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.37672090e-02]\n",
      " [1.25156446e-03 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  5.00625782e-03 5.00625782e-03]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.5424188e-03 2.4344581e-03 4.2195545e-04 1.3070724e-03 1.9288522e-03\n",
      " 5.0784135e-04 3.1151790e-03 1.9234626e-04 8.4641238e-04 2.9877680e-03\n",
      " 2.1044051e-03 2.8663555e-03 3.2966011e-03 3.7657651e-01 4.4646375e-03\n",
      " 5.3230248e-04 5.9880293e-04 5.9482496e-02 1.4073016e-01 1.8607288e-03\n",
      " 1.4667232e-03 2.7093268e-03 3.4681284e-01 6.9477328e-04 1.9795308e-03\n",
      " 1.9889237e-02 1.9183718e-03 1.0940215e-03 4.5067145e-04 5.2315686e-03\n",
      " 7.8943151e-04 1.4333391e-03 9.4436371e-04 1.1707154e-03 5.1141111e-04\n",
      " 2.1064600e-03] \n",
      " -0.760113\n",
      "p [[0.03254068 0.03754693 0.01126408 0.00750939 0.00750939 0.03254068]\n",
      " [0.0387985  0.         0.01376721 0.09136421 0.03003755 0.02753442]\n",
      " [0.01877347 0.09887359 0.         0.         0.         0.01877347]\n",
      " [0.03003755 0.04630788 0.00750939 0.         0.05506884 0.00125156]\n",
      " [0.00500626 0.09887359 0.11764706 0.         0.         0.07634543]\n",
      " [0.00750939 0.00876095 0.00375469 0.03254068 0.02503129 0.0175219 ]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.4017983e-03 2.7155997e-03 7.2620943e-04 4.2693852e-03 2.0544375e-03\n",
      " 6.6354586e-04 1.1014281e-01 7.1370736e-04 2.4734710e-03 7.9940045e-03\n",
      " 1.3502382e-01 4.3107769e-03 6.6376645e-03 3.2712619e-03 4.1464399e-04\n",
      " 2.6582187e-04 2.2187671e-03 5.1712943e-03 2.2489359e-03 4.4987770e-03\n",
      " 2.1921073e-04 2.0080603e-04 2.5493188e-03 1.1379957e-03 1.0148094e-02\n",
      " 3.1406161e-01 7.2412575e-03 8.9724474e-03 4.0496889e-04 3.3015028e-01\n",
      " 8.9321198e-04 1.7255198e-03 9.7567346e-03 1.4505681e-03 1.1366595e-02\n",
      " 1.5046878e-03] \n",
      " 0.95207876\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 8.28535670e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.30162703e-01]\n",
      " [1.12640801e-02 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  2.87859825e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 49 completed in 20.745371103286743 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1930003 entropy 2.4934874\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1633613 entropy 2.4955134\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.116398 entropy 2.496564\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0660572 entropy 2.4968371\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0191514 entropy 2.4963648\n",
      "kl 0.016909922\n",
      "completed in 0.16390204429626465 s\n",
      "game 50 completed in 7.397937059402466 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0768266 entropy 2.4603276\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0519686 entropy 2.4593072\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0200825 entropy 2.4589643\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9883544 entropy 2.4587998\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9610188 entropy 2.4565032\n",
      "kl 0.014732151\n",
      "completed in 0.18035197257995605 s\n",
      "game 51 completed in 7.483536243438721 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1032598 entropy 2.471921\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0818224 entropy 2.469905\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0486605 entropy 2.4696095\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0167003 entropy 2.469459\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9870842 entropy 2.467791\n",
      "kl 0.023033746\n",
      "completed in 0.16500496864318848 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 52 completed in 9.110831022262573 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0357974 entropy 2.449979\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0133162 entropy 2.4405642\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.973337 entropy 2.427888\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9264007 entropy 2.4127903\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8779933 entropy 2.395927\n",
      "kl 0.024657821\n",
      "completed in 0.2037949562072754 s\n",
      "game 53 completed in 9.152209043502808 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1022792 entropy 2.3927412\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0789633 entropy 2.3824441\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0335555 entropy 2.3755898\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.986228 entropy 2.3713956\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9469419 entropy 2.3688996\n",
      "kl 0.031923838\n",
      "completed in 0.19950008392333984 s\n",
      "game 54 completed in 9.933630228042603 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0823984 entropy 2.3760293\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0655172 entropy 2.3786583\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.034078 entropy 2.3810933\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9960475 entropy 2.3847065\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9570918 entropy 2.3873596\n",
      "kl 0.019488668\n",
      "completed in 0.1961050033569336 s\n",
      "game 55 completed in 12.871448993682861 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1901429 entropy 2.4072957\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1561224 entropy 2.4142952\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1123087 entropy 2.4245872\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0699236 entropy 2.4360547\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.025162 entropy 2.4467697\n",
      "kl 0.034214698\n",
      "completed in 0.16614317893981934 s\n",
      "game 56 completed in 8.856601238250732 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.008849 entropy 2.3645384\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9804935 entropy 2.3721633\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9436202 entropy 2.3798711\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9067712 entropy 2.3859696\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8725634 entropy 2.3889732\n",
      "kl 0.017419891\n",
      "completed in 0.17269206047058105 s\n",
      "game 57 completed in 10.806343078613281 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1255078 entropy 2.3947453\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1064322 entropy 2.3923273\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0723681 entropy 2.3889186\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0311284 entropy 2.3858345\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.989319 entropy 2.3832126\n",
      "kl 0.020071559\n",
      "completed in 0.1880340576171875 s\n",
      "game 58 completed in 12.185633897781372 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0404787 entropy 2.4462073\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.011789 entropy 2.444079\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9707646 entropy 2.442596\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9320028 entropy 2.4401193\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8990152 entropy 2.435915\n",
      "kl 0.020153496\n",
      "completed in 0.18872714042663574 s\n",
      "game 59 completed in 5.680450916290283 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9809887 entropy 2.37969\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.955343 entropy 2.3710122\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9182186 entropy 2.3617055\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8784811 entropy 2.3530486\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8397522 entropy 2.3458862\n",
      "kl 0.018744439\n",
      "completed in 0.17547392845153809 s\n",
      "game 60 completed in 7.567610025405884 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9917512 entropy 2.3611968\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9756885 entropy 2.3614187\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9514654 entropy 2.364467\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9236279 entropy 2.3689091\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8946028 entropy 2.3732462\n",
      "kl 0.021374974\n",
      "completed in 0.16685700416564941 s\n",
      "game 61 completed in 7.486846923828125 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9363856 entropy 2.387467\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.914462 entropy 2.3871903\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.878652 entropy 2.3829556\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.83818 entropy 2.3743882\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8035107 entropy 2.3625128\n",
      "kl 0.03747654\n",
      "completed in 0.19602513313293457 s\n",
      "game 62 completed in 8.643874883651733 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.043807 entropy 2.376576\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0219254 entropy 2.373354\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.984512 entropy 2.3775306\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9415054 entropy 2.3871076\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.897909 entropy 2.3990593\n",
      "kl 0.034127515\n",
      "completed in 0.19914793968200684 s\n",
      "game 63 completed in 6.2132227420806885 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0842943 entropy 2.408217\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0696898 entropy 2.4174738\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.040981 entropy 2.4225974\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0053003 entropy 2.4228015\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.967359 entropy 2.4183283\n",
      "kl 0.031515673\n",
      "completed in 0.18238401412963867 s\n",
      "game 64 completed in 11.713216066360474 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0054207 entropy 2.4124184\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9757326 entropy 2.4021115\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9355915 entropy 2.3926969\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8943956 entropy 2.385007\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8563855 entropy 2.3785686\n",
      "kl 0.027368238\n",
      "completed in 0.17214393615722656 s\n",
      "game 65 completed in 7.93594217300415 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.040992 entropy 2.3880134\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0137393 entropy 2.3906825\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9701219 entropy 2.3983884\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.928921 entropy 2.4087315\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.889719 entropy 2.41811\n",
      "kl 0.024271918\n",
      "completed in 0.17212605476379395 s\n",
      "game 66 completed in 6.892824172973633 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9773335 entropy 2.3710723\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9496906 entropy 2.3707561\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9109125 entropy 2.3651586\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.87321 entropy 2.355899\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8366692 entropy 2.3456464\n",
      "kl 0.016906494\n",
      "completed in 0.1915431022644043 s\n",
      "game 67 completed in 5.906986951828003 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9866118 entropy 2.3407009\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9565034 entropy 2.3402457\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.916413 entropy 2.3457832\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.882889 entropy 2.3532262\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8550577 entropy 2.3598132\n",
      "kl 0.034032308\n",
      "completed in 0.2095637321472168 s\n",
      "game 68 completed in 9.824978828430176 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0399716 entropy 2.3883064\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0169358 entropy 2.391272\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9817514 entropy 2.392665\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9454372 entropy 2.3935332\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9111497 entropy 2.3953764\n",
      "kl 0.032025743\n",
      "completed in 0.16939687728881836 s\n",
      "game 69 completed in 8.933133840560913 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0102324 entropy 2.406383\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9788284 entropy 2.414672\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9276187 entropy 2.4255342\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8785167 entropy 2.4360619\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.840598 entropy 2.4437966\n",
      "kl 0.029145373\n",
      "completed in 0.16806912422180176 s\n",
      "game 70 completed in 5.810657024383545 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9477787 entropy 2.4226613\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9215674 entropy 2.4239097\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.887011 entropy 2.420012\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8530834 entropy 2.4117076\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.822886 entropy 2.3990798\n",
      "kl 0.018056303\n",
      "completed in 0.16684603691101074 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 71 completed in 5.871106863021851 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0353932 entropy 2.4213908\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0196846 entropy 2.409989\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9852393 entropy 2.4010344\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9430912 entropy 2.393374\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.900418 entropy 2.3858023\n",
      "kl 0.036760118\n",
      "completed in 0.1631181240081787 s\n",
      "game 72 completed in 5.876597166061401 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0437474 entropy 2.3732805\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0300713 entropy 2.3702161\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0021243 entropy 2.3714268\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.967845 entropy 2.3761053\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.932319 entropy 2.3819993\n",
      "kl 0.015193825\n",
      "completed in 0.18801593780517578 s\n",
      "game 73 completed in 11.342127084732056 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9700956 entropy 2.3957753\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.952382 entropy 2.3995903\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9198043 entropy 2.39849\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.882702 entropy 2.3932922\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.847354 entropy 2.3854525\n",
      "kl 0.021049902\n",
      "completed in 0.17224502563476562 s\n",
      "game 74 completed in 7.459100961685181 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9747481 entropy 2.352376\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9439974 entropy 2.3447301\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.907749 entropy 2.3390088\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8725615 entropy 2.3346028\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8384578 entropy 2.330924\n",
      "kl 0.026289238\n",
      "completed in 0.1713581085205078 s\n",
      "game 75 completed in 5.760117053985596 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.996408 entropy 2.3419106\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9773502 entropy 2.3405085\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9495668 entropy 2.3413963\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9202302 entropy 2.3423657\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8874848 entropy 2.3417559\n",
      "kl 0.020334743\n",
      "completed in 0.1715247631072998 s\n",
      "game 76 completed in 9.10677719116211 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9856074 entropy 2.3095021\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.950112 entropy 2.3078566\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9092977 entropy 2.3084726\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8711207 entropy 2.311049\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8363228 entropy 2.314986\n",
      "kl 0.027763072\n",
      "completed in 0.17043209075927734 s\n",
      "game 77 completed in 7.511689901351929 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0626824 entropy 2.3934891\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0401826 entropy 2.4036987\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9966555 entropy 2.4178514\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9523919 entropy 2.4327958\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9168947 entropy 2.4450126\n",
      "kl 0.024984233\n",
      "completed in 0.16405892372131348 s\n",
      "game 78 completed in 10.435420036315918 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9806466 entropy 2.401928\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9603388 entropy 2.4066484\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9272895 entropy 2.4070225\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.892073 entropy 2.4028883\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8549988 entropy 2.3942375\n",
      "kl 0.021033896\n",
      "completed in 0.18154406547546387 s\n",
      "game 79 completed in 8.293641090393066 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.060362 entropy 2.3913279\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0473776 entropy 2.380739\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0207148 entropy 2.371121\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.985526 entropy 2.3636322\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.94473 entropy 2.3596263\n",
      "kl 0.02513669\n",
      "completed in 0.18015003204345703 s\n",
      "game 80 completed in 5.791985034942627 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1006205 entropy 2.380084\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0740943 entropy 2.3836203\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0334516 entropy 2.3891814\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9898188 entropy 2.3952124\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.947165 entropy 2.4006214\n",
      "kl 0.0225842\n",
      "completed in 0.19318890571594238 s\n",
      "game 81 completed in 5.876116037368774 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9445176 entropy 2.3594701\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9217973 entropy 2.3652074\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.885594 entropy 2.3688397\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8530433 entropy 2.369773\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8253798 entropy 2.368032\n",
      "kl 0.02201311\n",
      "completed in 0.19288301467895508 s\n",
      "game 82 completed in 12.355311155319214 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0621002 entropy 2.399898\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0257213 entropy 2.4057422\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9665315 entropy 2.4158387\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9138405 entropy 2.4260786\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8713064 entropy 2.4340324\n",
      "kl 0.030073665\n",
      "completed in 0.19814586639404297 s\n",
      "game 83 completed in 6.759274005889893 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.978021 entropy 2.4113913\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9636614 entropy 2.4097648\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9337296 entropy 2.402792\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9060888 entropy 2.3925908\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.879405 entropy 2.380467\n",
      "kl 0.019535393\n",
      "completed in 0.19854497909545898 s\n",
      "game 84 completed in 9.092465162277222 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0105078 entropy 2.348382\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.983468 entropy 2.337832\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9463024 entropy 2.328533\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9094932 entropy 2.3205605\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8766525 entropy 2.313335\n",
      "kl 0.02349136\n",
      "completed in 0.16337084770202637 s\n",
      "game 85 completed in 13.287275075912476 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0457094 entropy 2.3223133\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0155761 entropy 2.3165817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.974186 entropy 2.3140502\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9327002 entropy 2.3136837\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9002428 entropy 2.3135343\n",
      "kl 0.02973922\n",
      "completed in 0.2180919647216797 s\n",
      "game 86 completed in 7.532576084136963 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0697513 entropy 2.366261\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0441697 entropy 2.372503\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0107691 entropy 2.3811316\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9762485 entropy 2.3903368\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9436402 entropy 2.398446\n",
      "kl 0.029642835\n",
      "completed in 0.1633319854736328 s\n",
      "game 87 completed in 9.798546314239502 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.041788 entropy 2.4190946\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0168185 entropy 2.4243534\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9743536 entropy 2.424585\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9342158 entropy 2.421398\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8980668 entropy 2.415079\n",
      "kl 0.021281766\n",
      "completed in 0.19504880905151367 s\n",
      "game 88 completed in 7.504195690155029 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.00562 entropy 2.3817787\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.980577 entropy 2.372653\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9454417 entropy 2.3644526\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9091196 entropy 2.3577552\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8698568 entropy 2.353129\n",
      "kl 0.017961677\n",
      "completed in 0.17096710205078125 s\n",
      "game 89 completed in 8.198474884033203 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.993529 entropy 2.325153\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9628966 entropy 2.3234181\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9236364 entropy 2.3202913\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8933876 entropy 2.315627\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.865811 entropy 2.3092356\n",
      "kl 0.025846435\n",
      "completed in 0.16738033294677734 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 90 completed in 11.12441873550415 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9051843 entropy 2.2741818\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8749876 entropy 2.270029\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.836234 entropy 2.2679102\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8009393 entropy 2.2681344\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7685637 entropy 2.270842\n",
      "kl 0.018309042\n",
      "completed in 0.16436076164245605 s\n",
      "game 91 completed in 7.323698043823242 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9722395 entropy 2.3030424\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9490528 entropy 2.310531\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9104404 entropy 2.3176055\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.873811 entropy 2.3230164\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8434036 entropy 2.3259091\n",
      "kl 0.026446449\n",
      "completed in 0.18376898765563965 s\n",
      "game 92 completed in 11.270411968231201 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9727166 entropy 2.3479776\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9530113 entropy 2.351505\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.922232 entropy 2.356275\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8912103 entropy 2.3609257\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.859822 entropy 2.3644445\n",
      "kl 0.017486285\n",
      "completed in 0.2246541976928711 s\n",
      "game 93 completed in 7.466398239135742 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0551746 entropy 2.4090972\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.024247 entropy 2.410759\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9824665 entropy 2.41086\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.942217 entropy 2.4087086\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9032135 entropy 2.4045937\n",
      "kl 0.032225147\n",
      "completed in 0.18484187126159668 s\n",
      "game 94 completed in 9.084967851638794 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9971652 entropy 2.347027\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.977925 entropy 2.3387904\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.941052 entropy 2.3292089\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8953495 entropy 2.3192184\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.847176 entropy 2.309733\n",
      "kl 0.02916858\n",
      "completed in 0.16880106925964355 s\n",
      "game 95 completed in 8.292953968048096 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9169536 entropy 2.2839608\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.898583 entropy 2.281842\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8687627 entropy 2.2837877\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8337333 entropy 2.2877538\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8004189 entropy 2.291872\n",
      "kl 0.033550285\n",
      "completed in 0.16838288307189941 s\n",
      "game 96 completed in 7.1639978885650635 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9386144 entropy 2.3048558\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9223356 entropy 2.3096836\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8888726 entropy 2.3148835\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8529027 entropy 2.3197637\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8166964 entropy 2.3231034\n",
      "kl 0.027923014\n",
      "completed in 0.2155780792236328 s\n",
      "game 97 completed in 7.664083242416382 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9490387 entropy 2.3623838\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.925705 entropy 2.3631234\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.889552 entropy 2.3636546\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.852215 entropy 2.3630047\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.818475 entropy 2.3600085\n",
      "kl 0.026423771\n",
      "completed in 0.15769386291503906 s\n",
      "game 98 completed in 8.390148878097534 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.883072 entropy 2.3462315\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.865681 entropy 2.3411903\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8386707 entropy 2.3373733\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.809521 entropy 2.3354058\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7811327 entropy 2.3351007\n",
      "kl 0.028129835\n",
      "completed in 0.1929171085357666 s\n",
      "prediction:\n",
      " [0.00493582 0.00555745 0.00607211 0.00306937 0.00422899 0.00199314\n",
      " 0.00261251 0.10206689 0.07758766 0.07474377 0.01611712 0.00600229\n",
      " 0.00212042 0.07477735 0.00999369 0.03364483 0.06875279 0.00499225\n",
      " 0.00428833 0.04403944 0.05168345 0.00940189 0.09617621 0.00249559\n",
      " 0.00485269 0.01722656 0.06958184 0.06990948 0.10151419 0.00514287\n",
      " 0.00120017 0.00690819 0.00483483 0.0030718  0.00336095 0.00504306] \n",
      " -0.5591726\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.39299124e-01 2.17772215e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.90237797e-01 1.52690864e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.0161223  0.00206762 0.00987638 0.00223013 0.00617216 0.00083566\n",
      " 0.00162679 0.10214952 0.01482139 0.03218985 0.00072948 0.00624939\n",
      " 0.00238407 0.01532941 0.00705169 0.14619946 0.0510616  0.00494409\n",
      " 0.00305789 0.0164442  0.26995924 0.00748986 0.02211726 0.00252207\n",
      " 0.0038004  0.00095186 0.0437395  0.01791384 0.15109639 0.00457377\n",
      " 0.00114203 0.00834062 0.00194405 0.00990248 0.00162068 0.01134297] \n",
      " 0.15438673\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.03379224 0.02878598 0.02377972 0.00500626 0.00125156]\n",
      " [0.00125156 0.02878598 0.         0.01001252 0.02377972 0.00625782]\n",
      " [0.00125156 0.01376721 0.02628285 0.54693367 0.03254068 0.00250313]\n",
      " [0.00250313 0.00750939 0.05006258 0.10262829 0.03254068 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01205414 0.00967554 0.01028809 0.00326599 0.01331661 0.00312221\n",
      " 0.00470491 0.09305806 0.12683292 0.06765632 0.0084274  0.010404\n",
      " 0.00547599 0.0437001  0.00117367 0.01864963 0.07821827 0.00271184\n",
      " 0.00348387 0.06696297 0.02979004 0.00089842 0.05895542 0.00606525\n",
      " 0.00912442 0.01157239 0.08412356 0.09150242 0.07081857 0.0050902\n",
      " 0.00207065 0.01684825 0.00450255 0.00623831 0.00442746 0.01478993] \n",
      " -0.60935074\n",
      "p [[2.50312891e-03 1.25156446e-03 1.25156446e-03 1.25156446e-03\n",
      "  2.50312891e-03 1.25156446e-03]\n",
      " [1.25156446e-03 2.37797247e-02 3.75469337e-03 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-03 3.75469337e-03 0.00000000e+00 3.74217772e-01\n",
      "  1.37672090e-02 1.25156446e-03]\n",
      " [1.25156446e-03 2.50312891e-03 4.59324155e-01 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-03]\n",
      " [1.25156446e-03 1.25156446e-03 3.25406758e-02 2.50312891e-03\n",
      "  4.13016270e-02 1.25156446e-03]\n",
      " [1.25156446e-03 2.50312891e-03 2.50312891e-03 1.25156446e-03\n",
      "  1.25156446e-03 3.75469337e-03]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01234672 0.01085206 0.05117462 0.00572449 0.00771802 0.00280225\n",
      " 0.00293819 0.04982249 0.20356454 0.00877362 0.00227067 0.01291537\n",
      " 0.00185753 0.008846   0.0030567  0.03182669 0.05587457 0.00437201\n",
      " 0.00150845 0.02262442 0.03011217 0.00260715 0.00861729 0.0020946\n",
      " 0.01424566 0.00737541 0.01933727 0.20592913 0.10893963 0.01275399\n",
      " 0.00217266 0.01455576 0.00976668 0.04324404 0.0045371  0.01284225] \n",
      " -0.6861658\n",
      "p [[0.00375469 0.00250313 0.00250313 0.00125156 0.00375469 0.00125156]\n",
      " [0.00250313 0.02878598 0.0387985  0.02002503 0.00125156 0.00250313]\n",
      " [0.00125156 0.01627034 0.         0.02628285 0.02503129 0.00125156]\n",
      " [0.00125156 0.02252816 0.         0.         0.01627034 0.00125156]\n",
      " [0.00250313 0.00375469 0.70337922 0.02878598 0.02252816 0.00250313]\n",
      " [0.00125156 0.00625782 0.00250313 0.00125156 0.00125156 0.00375469]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.01367511 0.00646557 0.00462567 0.00322296 0.06913074 0.00317418\n",
      " 0.00513619 0.04360828 0.11396526 0.00276975 0.00597473 0.03021741\n",
      " 0.005927   0.00826571 0.0011372  0.00460015 0.20770137 0.00123038\n",
      " 0.00084484 0.19466814 0.00817755 0.0005966  0.00537504 0.00630448\n",
      " 0.01786644 0.01313706 0.00407617 0.10899996 0.03673136 0.01245508\n",
      " 0.00225641 0.02690424 0.00561976 0.00287418 0.00333448 0.01895066] \n",
      " 0.16633432\n",
      "p [[0.00125156 0.00125156 0.69211514 0.00250313 0.00250313 0.00250313]\n",
      " [0.00250313 0.00750939 0.17146433 0.00250313 0.00125156 0.00375469]\n",
      " [0.00125156 0.00375469 0.         0.00876095 0.00750939 0.00125156]\n",
      " [0.00375469 0.00500626 0.         0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.03128911 0.0212766  0.00125156]\n",
      " [0.00125156 0.00375469 0.00250313 0.00625782 0.00125156 0.00375469]]\n",
      "move 2\n",
      "board\n",
      " [[ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02251963 0.04441683 0.00779141 0.02537869 0.02249534 0.00526203\n",
      " 0.0049776  0.11295467 0.03695793 0.0309648  0.01574115 0.01996501\n",
      " 0.00494383 0.01812352 0.00296917 0.02842097 0.12006281 0.00456908\n",
      " 0.00211498 0.05396079 0.04506115 0.00618461 0.01380129 0.00314722\n",
      " 0.02218697 0.02717469 0.03368257 0.03243263 0.11558452 0.02700428\n",
      " 0.0063121  0.02510736 0.02139938 0.00489383 0.02008555 0.01135162] \n",
      " 0.80743486\n",
      "p [[0.01251564 0.00750939 0.         0.00750939 0.03128911 0.00500626]\n",
      " [0.00500626 0.02377972 0.54317897 0.00250313 0.00750939 0.01877347]\n",
      " [0.00625782 0.01376721 0.         0.01001252 0.08635795 0.00625782]\n",
      " [0.00125156 0.06007509 0.         0.         0.00750939 0.00500626]\n",
      " [0.0175219  0.01126408 0.         0.02377972 0.0175219  0.01126408]\n",
      " [0.00500626 0.01376721 0.00500626 0.01251564 0.00500626 0.01627034]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0116261  0.00666137 0.00782651 0.00269917 0.19970988 0.00180842\n",
      " 0.00439001 0.12021384 0.00749497 0.02039615 0.00855945 0.07330788\n",
      " 0.00635894 0.06510436 0.00433365 0.02541707 0.01945718 0.00524709\n",
      " 0.00178908 0.01120274 0.03964107 0.00227026 0.0323642  0.00659479\n",
      " 0.02646875 0.01357232 0.02928817 0.0052601  0.14256717 0.0181813\n",
      " 0.00168027 0.04685438 0.00651689 0.00266166 0.00486537 0.01760964] \n",
      " -0.12801194\n",
      "p [[0.05882353 0.03003755 0.         0.01376721 0.01627034 0.01877347]\n",
      " [0.01376721 0.05131414 0.         0.03128911 0.08135169 0.01627034]\n",
      " [0.01126408 0.0175219  0.         0.09386733 0.08510638 0.01501877]\n",
      " [0.00625782 0.12015019 0.         0.         0.0175219  0.00125156]\n",
      " [0.01001252 0.00625782 0.         0.02628285 0.0738423  0.02753442]\n",
      " [0.02503129 0.03003755 0.0350438  0.00125156 0.03003755 0.0350438 ]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.04523125 0.00914739 0.00517504 0.01744808 0.11273029 0.00193475\n",
      " 0.00259793 0.04965719 0.00894386 0.06277607 0.0075934  0.04624189\n",
      " 0.0058458  0.02913259 0.00664238 0.00418889 0.00076847 0.02376116\n",
      " 0.01038571 0.00045103 0.01463141 0.00500243 0.01730348 0.00493746\n",
      " 0.15552218 0.01360559 0.118885   0.0068477  0.03223103 0.00837912\n",
      " 0.00232727 0.12091064 0.01752937 0.00200897 0.00533473 0.02389066] \n",
      " 0.9274534\n",
      "p [[0.00125156 0.00125156 0.         0.00125156 0.06883605 0.00125156]\n",
      " [0.00125156 0.02252816 0.         0.01126408 0.00125156 0.01501877]\n",
      " [0.00125156 0.06883605 0.         0.10513141 0.44680851 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.00500626 0.00125156]\n",
      " [0.04005006 0.00125156 0.         0.16770964 0.0212766  0.00125156]\n",
      " [0.00125156 0.00625782 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0. -1.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.1266623e-03 4.4162413e-03 1.1467625e-03 1.8277181e-03 4.5532665e-01\n",
      " 2.4967082e-04 2.7044234e-03 1.0886540e-01 1.7353876e-03 2.0051105e-02\n",
      " 3.4691389e-03 9.3520194e-02 3.7930368e-03 2.1456519e-02 2.7841572e-03\n",
      " 1.2127588e-02 7.7431835e-04 2.5210208e-03 2.1046277e-03 1.0013751e-03\n",
      " 1.1046971e-02 3.7624713e-03 9.2672845e-03 4.6951771e-03 1.7100494e-02\n",
      " 8.7620812e-03 3.2036487e-02 1.7417578e-03 7.5320527e-02 5.3609461e-03\n",
      " 2.6801610e-04 6.9900505e-02 2.0082949e-03 6.4056262e-04 1.3219381e-03\n",
      " 1.0764519e-02] \n",
      " 0.8797013\n",
      "p [[0.04630788 0.01501877 0.         0.01501877 0.07008761 0.00125156]\n",
      " [0.00876095 0.03128911 0.         0.17271589 0.00750939 0.05757196]\n",
      " [0.01001252 0.02503129 0.         0.00625782 0.         0.03754693]\n",
      " [0.01126408 0.         0.         0.         0.01501877 0.00125156]\n",
      " [0.21276596 0.00876095 0.         0.00625782 0.02628285 0.01126408]\n",
      " [0.00125156 0.13516896 0.01376721 0.00125156 0.00876095 0.04255319]]\n",
      "move 24\n",
      "board\n",
      " [[ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0. -1.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 1.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.06401605 0.01763342 0.0105963  0.0380915  0.09760914 0.00665493\n",
      " 0.00355294 0.04926794 0.01173525 0.06419361 0.01108847 0.00316476\n",
      " 0.01085764 0.03820993 0.01038302 0.00442274 0.00101238 0.08748033\n",
      " 0.04436443 0.00075127 0.01434461 0.01222407 0.01732933 0.01145179\n",
      " 0.01454655 0.02082043 0.11079869 0.01033853 0.02863426 0.01150252\n",
      " 0.01249982 0.0898421  0.02173243 0.00420829 0.00952911 0.03511159] \n",
      " 0.960446\n",
      "p [[1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  4.63078849e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.12640801e-02 0.00000000e+00 1.25156446e-03\n",
      "  1.25156446e-13 5.23153942e-01]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 3.75469337e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [0.00000000e+00 1.25156446e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.75219024e-02 1.25156446e-13]\n",
      " [1.25156446e-13 3.91739675e-01 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-03]]\n",
      "move 11\n",
      "board\n",
      " [[ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0. -1.]\n",
      " [ 0.  0.  1.  0. -1.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 1.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "-1 won\n",
      "game 99 completed in 27.085023880004883 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9799085 entropy 2.3587117\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9577746 entropy 2.3633332\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9251332 entropy 2.368159\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8899467 entropy 2.3715081\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8562527 entropy 2.371736\n",
      "kl 0.023089621\n",
      "completed in 0.1756269931793213 s\n",
      "game 100 completed in 5.8845555782318115 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9613435 entropy 2.3380225\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9439812 entropy 2.3352156\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9178946 entropy 2.3316991\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8891623 entropy 2.3276234\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8617833 entropy 2.3234456\n",
      "kl 0.024798604\n",
      "completed in 0.16673994064331055 s\n",
      "game 101 completed in 5.798527002334595 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9438572 entropy 2.278038\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9200995 entropy 2.2768817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.880173 entropy 2.2784607\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.834876 entropy 2.281693\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7935798 entropy 2.2847042\n",
      "kl 0.031667717\n",
      "completed in 0.21755695343017578 s\n",
      "game 102 completed in 8.057658195495605 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.90967 entropy 2.2897048\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8985653 entropy 2.2904112\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8728256 entropy 2.2903647\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8398886 entropy 2.289185\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8064322 entropy 2.2867403\n",
      "kl 0.029827002\n",
      "completed in 0.16558623313903809 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 103 completed in 5.615324258804321 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.924709 entropy 2.2324333\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9096963 entropy 2.2309139\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8809776 entropy 2.2313695\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8445325 entropy 2.2333128\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8090477 entropy 2.2358005\n",
      "kl 0.015229848\n",
      "completed in 0.16972899436950684 s\n",
      "game 104 completed in 8.680601119995117 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9742138 entropy 2.2930932\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9476645 entropy 2.2976801\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9052136 entropy 2.2999573\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8615935 entropy 2.297913\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8247123 entropy 2.29221\n",
      "kl 0.037946623\n",
      "completed in 0.18635225296020508 s\n",
      "game 105 completed in 10.43818998336792 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9179442 entropy 2.308175\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8960788 entropy 2.3048368\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8593123 entropy 2.3034954\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8201828 entropy 2.3018417\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.787767 entropy 2.2981188\n",
      "kl 0.04138034\n",
      "completed in 0.16866087913513184 s\n",
      "game 106 completed in 7.97066330909729 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.8242316 entropy 2.3004007\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.8124688 entropy 2.298448\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7897441 entropy 2.2976012\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7616584 entropy 2.2975678\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.7345636 entropy 2.2980962\n",
      "kl 0.019782461\n",
      "completed in 0.18170690536499023 s\n",
      "game 107 completed in 6.537487030029297 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.8625047 entropy 2.2945282\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.854986 entropy 2.294982\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.8384054 entropy 2.2967167\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.8154004 entropy 2.3005521\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.7883391 entropy 2.3063002\n",
      "kl 0.008620012\n",
      "completed in 0.1732771396636963 s\n",
      "game 108 completed in 8.934858083724976 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9115627 entropy 2.3527768\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.888023 entropy 2.3612738\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8583179 entropy 2.369988\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8254302 entropy 2.3759816\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7902615 entropy 2.3766851\n",
      "kl 0.018345084\n",
      "completed in 0.18886232376098633 s\n",
      "game 109 completed in 7.2638280391693115 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.834717 entropy 2.3002298\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8185194 entropy 2.2899098\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.789294 entropy 2.2770398\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7513852 entropy 2.262973\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7086112 entropy 2.2489638\n",
      "kl 0.01643517\n",
      "completed in 0.17220711708068848 s\n",
      "game 110 completed in 7.284576177597046 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.880897 entropy 2.2815537\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8565333 entropy 2.270731\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.828888 entropy 2.2602181\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8007479 entropy 2.250709\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7703443 entropy 2.2422054\n",
      "kl 0.027400529\n",
      "completed in 0.1669759750366211 s\n",
      "game 111 completed in 7.1645002365112305 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8302155 entropy 2.2403839\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8080683 entropy 2.23558\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.779186 entropy 2.232726\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.750739 entropy 2.23124\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.72202 entropy 2.2304451\n",
      "kl 0.017430862\n",
      "completed in 0.16793203353881836 s\n",
      "game 112 completed in 5.6887547969818115 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.902573 entropy 2.260927\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8784738 entropy 2.26402\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8417943 entropy 2.268795\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8053603 entropy 2.2754278\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7661312 entropy 2.2832956\n",
      "kl 0.013703156\n",
      "completed in 0.17008686065673828 s\n",
      "game 113 completed in 5.696876049041748 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8961692 entropy 2.2348237\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8787167 entropy 2.244234\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8468783 entropy 2.2525802\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.806851 entropy 2.2578926\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7648256 entropy 2.258993\n",
      "kl 0.0200925\n",
      "completed in 0.18660807609558105 s\n",
      "game 114 completed in 9.329096794128418 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8878286 entropy 2.298926\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8678763 entropy 2.2925038\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8325713 entropy 2.2842944\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7942975 entropy 2.2752445\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7569737 entropy 2.2665522\n",
      "kl 0.019732961\n",
      "completed in 0.18102502822875977 s\n",
      "game 115 completed in 5.687987804412842 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8940802 entropy 2.2473574\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.879187 entropy 2.2457361\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8526616 entropy 2.2480862\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8215015 entropy 2.253393\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7873347 entropy 2.2593498\n",
      "kl 0.015642758\n",
      "completed in 0.20145320892333984 s\n",
      "game 116 completed in 5.707374811172485 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8430643 entropy 2.2695203\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8210907 entropy 2.2706919\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7861824 entropy 2.2717175\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7504017 entropy 2.272891\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7183707 entropy 2.273646\n",
      "kl 0.019408967\n",
      "completed in 0.16307902336120605 s\n",
      "game 117 completed in 8.757660865783691 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.960082 entropy 2.265146\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9400296 entropy 2.2631042\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.903925 entropy 2.259223\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8648305 entropy 2.2546859\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8288717 entropy 2.249663\n",
      "kl 0.01791739\n",
      "completed in 0.16126799583435059 s\n",
      "game 118 completed in 8.10362982749939 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8398252 entropy 2.2388353\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8252149 entropy 2.2352083\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8024666 entropy 2.2341218\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.776219 entropy 2.2354136\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7490633 entropy 2.238604\n",
      "kl 0.029571086\n",
      "completed in 0.18903303146362305 s\n",
      "game 119 completed in 7.290373086929321 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.053289 entropy 2.2916234\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0215688 entropy 2.3018079\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9744916 entropy 2.314784\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.934994 entropy 2.3248377\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.900315 entropy 2.3298178\n",
      "kl 0.030861586\n",
      "completed in 0.17258024215698242 s\n",
      "game 120 completed in 5.770626068115234 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.807973 entropy 2.2956223\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7897477 entropy 2.2918043\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7624874 entropy 2.285159\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7312994 entropy 2.2781534\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.694697 entropy 2.272181\n",
      "kl 0.0242589\n",
      "completed in 0.19403696060180664 s\n",
      "game 121 completed in 11.282992124557495 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9493308 entropy 2.2752857\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9253805 entropy 2.273168\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8857613 entropy 2.2738461\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.844267 entropy 2.27664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.8066533 entropy 2.2798758\n",
      "kl 0.019842286\n",
      "completed in 0.20328783988952637 s\n",
      "game 122 completed in 7.679657936096191 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.787718 entropy 2.2333817\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7640364 entropy 2.2402987\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7313092 entropy 2.2480564\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7047997 entropy 2.2516031\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6764832 entropy 2.2467687\n",
      "kl 0.020981025\n",
      "completed in 0.17209410667419434 s\n",
      "game 123 completed in 6.118185043334961 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0249705 entropy 2.3022676\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9966712 entropy 2.2922053\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9540854 entropy 2.284402\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.90812 entropy 2.278349\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8652315 entropy 2.2741942\n",
      "kl 0.03305391\n",
      "completed in 0.16639304161071777 s\n",
      "game 124 completed in 6.003050088882446 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8321323 entropy 2.2095876\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.816354 entropy 2.2161026\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7886684 entropy 2.229538\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7589056 entropy 2.2449305\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7301261 entropy 2.2574716\n",
      "kl 0.035044454\n",
      "completed in 0.1905357837677002 s\n",
      "game 125 completed in 11.655331134796143 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9528809 entropy 2.3177714\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.938137 entropy 2.3189113\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.907099 entropy 2.316192\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.864378 entropy 2.310499\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8197217 entropy 2.3026097\n",
      "kl 0.022205848\n",
      "completed in 0.17751812934875488 s\n",
      "game 126 completed in 8.210242986679077 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8086476 entropy 2.2666674\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7917678 entropy 2.2587602\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7662337 entropy 2.2529116\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7359848 entropy 2.249361\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7042234 entropy 2.247453\n",
      "kl 0.01729803\n",
      "completed in 0.17065715789794922 s\n",
      "game 127 completed in 5.865218639373779 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8449252 entropy 2.2240443\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8288655 entropy 2.2264888\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7971573 entropy 2.2289996\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.762115 entropy 2.2304146\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7291613 entropy 2.2292829\n",
      "kl 0.023077726\n",
      "completed in 0.1683058738708496 s\n",
      "game 128 completed in 12.950937032699585 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9285705 entropy 2.324394\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9137108 entropy 2.3195133\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8868294 entropy 2.3151464\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8526807 entropy 2.3119755\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8153818 entropy 2.3095527\n",
      "kl 0.018167615\n",
      "completed in 0.1862800121307373 s\n",
      "game 129 completed in 5.849671125411987 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.916375 entropy 2.288957\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8887427 entropy 2.2856364\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8491626 entropy 2.2809\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8065584 entropy 2.2763627\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.766699 entropy 2.2726774\n",
      "kl 0.019422797\n",
      "completed in 0.16361498832702637 s\n",
      "game 130 completed in 11.398894786834717 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.973898 entropy 2.278419\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9508328 entropy 2.2805524\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.916259 entropy 2.2854676\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8782477 entropy 2.2919383\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8456335 entropy 2.297648\n",
      "kl 0.019450393\n",
      "completed in 0.1918470859527588 s\n",
      "game 131 completed in 6.747234106063843 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8458526 entropy 2.2345366\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.820251 entropy 2.2400858\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7886243 entropy 2.2458987\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.752395 entropy 2.2505472\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.713704 entropy 2.253275\n",
      "kl 0.014660688\n",
      "completed in 0.17058038711547852 s\n",
      "game 132 completed in 9.182711124420166 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8809855 entropy 2.2791035\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.857711 entropy 2.278976\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8343637 entropy 2.2784193\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.807832 entropy 2.2773857\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7730374 entropy 2.2754855\n",
      "kl 0.025996499\n",
      "completed in 0.20286321640014648 s\n",
      "game 133 completed in 8.898146152496338 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8296404 entropy 2.2664165\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8124707 entropy 2.262948\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7898717 entropy 2.255225\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7670405 entropy 2.2429004\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7421484 entropy 2.2262619\n",
      "kl 0.018505365\n",
      "completed in 0.18565988540649414 s\n",
      "game 134 completed in 7.340256929397583 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8937705 entropy 2.2504795\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8549528 entropy 2.2329333\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8144214 entropy 2.2196684\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.786884 entropy 2.2146041\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7599096 entropy 2.2193308\n",
      "kl 0.021032434\n",
      "completed in 0.19787192344665527 s\n",
      "game 135 completed in 5.851727247238159 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7741117 entropy 2.2104745\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7449033 entropy 2.224668\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7138214 entropy 2.2383928\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6893446 entropy 2.2481713\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6623182 entropy 2.2518895\n",
      "kl 0.017136984\n",
      "completed in 0.1739969253540039 s\n",
      "game 136 completed in 6.66026496887207 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8399491 entropy 2.2022285\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8218615 entropy 2.2016032\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7934203 entropy 2.201492\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7616463 entropy 2.2026718\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7268572 entropy 2.2058022\n",
      "kl 0.025467515\n",
      "completed in 0.19671893119812012 s\n",
      "game 137 completed in 14.60384202003479 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7970934 entropy 2.2763004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7791948 entropy 2.2820718\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7478774 entropy 2.2879782\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7153146 entropy 2.293032\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6888063 entropy 2.29603\n",
      "kl 0.018837074\n",
      "completed in 0.18833398818969727 s\n",
      "game 138 completed in 8.2448890209198 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8083942 entropy 2.3311315\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7919407 entropy 2.327567\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7609072 entropy 2.31869\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.725504 entropy 2.3056037\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.691494 entropy 2.2902322\n",
      "kl 0.029026061\n",
      "completed in 0.17181110382080078 s\n",
      "game 139 completed in 7.561628103256226 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7748551 entropy 2.209931\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7638116 entropy 2.2018757\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.740284 entropy 2.2009914\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.709094 entropy 2.2048042\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.67377 entropy 2.2105742\n",
      "kl 0.020850418\n",
      "completed in 0.1660900115966797 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 140 completed in 8.401784181594849 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.848697 entropy 2.2811608\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8308156 entropy 2.281561\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8031855 entropy 2.2776704\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.772697 entropy 2.2693949\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7439578 entropy 2.2583709\n",
      "kl 0.025725778\n",
      "completed in 0.1692197322845459 s\n",
      "game 141 completed in 10.417690992355347 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8234572 entropy 2.2173045\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7992868 entropy 2.2076576\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.768959 entropy 2.201013\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7376049 entropy 2.198526\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7093182 entropy 2.1998358\n",
      "kl 0.026342649\n",
      "completed in 0.16823983192443848 s\n",
      "game 142 completed in 10.603014945983887 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.779932 entropy 2.1913986\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.762225 entropy 2.201345\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7379296 entropy 2.2133198\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7139356 entropy 2.223675\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.692421 entropy 2.2297225\n",
      "kl 0.02947735\n",
      "completed in 0.1685330867767334 s\n",
      "game 143 completed in 13.083908081054688 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8438878 entropy 2.237969\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8261077 entropy 2.2320719\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7953165 entropy 2.224298\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7559903 entropy 2.2153401\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7143598 entropy 2.207057\n",
      "kl 0.027595077\n",
      "completed in 0.16622209548950195 s\n",
      "game 144 completed in 6.528789043426514 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9158924 entropy 2.240292\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8989604 entropy 2.2416563\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8655586 entropy 2.2493682\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8257236 entropy 2.259891\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.786784 entropy 2.2693162\n",
      "kl 0.032435637\n",
      "completed in 0.17167401313781738 s\n",
      "game 145 completed in 9.310855865478516 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8704102 entropy 2.2784863\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.857454 entropy 2.2820623\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8290157 entropy 2.2805302\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7947624 entropy 2.2747493\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7600985 entropy 2.266097\n",
      "kl 0.014929967\n",
      "completed in 0.1735210418701172 s\n",
      "game 146 completed in 7.465222120285034 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9040868 entropy 2.3130383\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8875148 entropy 2.3031497\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.860418 entropy 2.295799\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.828915 entropy 2.2914052\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7980723 entropy 2.2894182\n",
      "kl 0.02939136\n",
      "completed in 0.18906497955322266 s\n",
      "game 147 completed in 8.93870496749878 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.751595 entropy 2.1754808\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7306218 entropy 2.178933\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6990767 entropy 2.1829724\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.667479 entropy 2.1854606\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6400201 entropy 2.184986\n",
      "kl 0.029350365\n",
      "completed in 0.1867070198059082 s\n",
      "game 148 completed in 9.271612882614136 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7838953 entropy 2.2309399\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.763666 entropy 2.2235775\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7334118 entropy 2.2137456\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7015967 entropy 2.2032511\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6733637 entropy 2.1937785\n",
      "kl 0.042310055\n",
      "completed in 0.16736507415771484 s\n",
      "prediction:\n",
      " [0.00328098 0.00235562 0.00260886 0.00442642 0.00487497 0.00125976\n",
      " 0.00267639 0.08812606 0.07573298 0.05198694 0.01473242 0.00585291\n",
      " 0.00306183 0.09369177 0.01341139 0.08145767 0.05429476 0.00974751\n",
      " 0.0060425  0.06755301 0.04834053 0.01537528 0.08086697 0.00418394\n",
      " 0.00312142 0.01273605 0.05342609 0.11000448 0.06428915 0.00256909\n",
      " 0.00135759 0.0035667  0.00342235 0.00334121 0.00311507 0.00310936] \n",
      " -0.3372358\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.45306633e-01 2.29036295e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.51564456e-01 2.74092616e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.14345700e-03 7.03623693e-04 2.02905945e-03 1.11292815e-03\n",
      " 5.91345178e-03 4.22431971e-04 1.12925656e-03 7.71103203e-02\n",
      " 3.94351361e-03 1.55275166e-02 1.56257965e-03 3.91017646e-03\n",
      " 1.78435014e-03 1.13918856e-02 2.23009855e-01 2.49956608e-01\n",
      " 4.79556341e-03 1.90864888e-03 8.99659644e-04 2.78163725e-03\n",
      " 1.12057291e-01 1.24736793e-01 6.28347974e-03 4.74935817e-03\n",
      " 1.88798003e-03 5.59412409e-04 1.20063638e-02 6.95090741e-03\n",
      " 1.04206264e-01 1.08385470e-03 2.45608360e-04 3.71593935e-03\n",
      " 8.34149425e-04 2.42325035e-03 1.56303425e-03 3.65977548e-03] \n",
      " -0.1049683\n",
      "p [[0.00375469 0.00375469 0.00375469 0.00876095 0.00375469 0.00250313]\n",
      " [0.00375469 0.04255319 0.10012516 0.077597   0.01501877 0.00375469]\n",
      " [0.00500626 0.07634543 0.0563204  0.09386733 0.03003755 0.00500626]\n",
      " [0.00625782 0.12891114 0.04881101 0.         0.05256571 0.00250313]\n",
      " [0.00375469 0.01001252 0.06883605 0.07634543 0.03754693 0.00500626]\n",
      " [0.00375469 0.00250313 0.00625782 0.00125156 0.00625782 0.00375469]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00824561 0.00215219 0.00373135 0.00156749 0.01070539 0.00076954\n",
      " 0.00172081 0.39965022 0.01324826 0.02364722 0.00948733 0.00516189\n",
      " 0.00423329 0.04185848 0.00108733 0.03142512 0.0087676  0.00820434\n",
      " 0.00525753 0.00858877 0.02945825 0.00084562 0.06236951 0.00559607\n",
      " 0.01082925 0.00878833 0.02402565 0.01301669 0.23024063 0.002793\n",
      " 0.0010981  0.00625718 0.00206632 0.00318088 0.00398948 0.00593545] \n",
      " -0.79779005\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.62703379e-02 1.25156446e-13 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 5.50688360e-01 3.50438048e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 4.38047559e-02 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-03\n",
      "  3.00375469e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.2159772e-02 9.8974793e-04 8.1910880e-04 2.7916295e-04 8.2601001e-03\n",
      " 2.5719020e-04 1.0720930e-03 3.1057510e-01 6.2831710e-03 1.1005461e-02\n",
      " 7.6644175e-04 2.0275970e-03 1.0134820e-03 8.0923364e-02 1.5294746e-03\n",
      " 1.2046489e-01 3.7466271e-03 2.9433453e-03 1.2451676e-03 2.9252511e-03\n",
      " 9.8188318e-02 5.1105110e-04 4.8930250e-02 2.6852973e-03 2.3733943e-03\n",
      " 6.1555498e-04 1.1635153e-02 5.8713872e-03 2.0402910e-01 1.1833333e-03\n",
      " 3.5937515e-04 6.4038518e-03 4.2752174e-04 7.8481645e-04 1.4312560e-03\n",
      " 2.5283970e-02] \n",
      " -0.5162451\n",
      "p [[0.00500626 0.00250313 0.00375469 0.00250313 0.00500626 0.00250313]\n",
      " [0.00625782 0.61326658 0.01001252 0.01376721 0.00375469 0.00250313]\n",
      " [0.00500626 0.07884856 0.         0.01251564 0.00375469 0.00375469]\n",
      " [0.00375469 0.         0.0175219  0.         0.02628285 0.00250313]\n",
      " [0.00625782 0.00625782 0.01251564 0.01376721 0.11013767 0.00250313]\n",
      " [0.00375469 0.00750939 0.00125156 0.00250313 0.00500626 0.00375469]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.02948796 0.00521649 0.00770716 0.00174765 0.02082646 0.00076775\n",
      " 0.00134597 0.01039662 0.01571696 0.00785654 0.02372942 0.00839706\n",
      " 0.00574794 0.24868223 0.00071911 0.02164563 0.00280553 0.01465114\n",
      " 0.00601058 0.00353142 0.02536622 0.00081721 0.3799211  0.00582418\n",
      " 0.01527017 0.05348916 0.00989606 0.01369933 0.00440202 0.003318\n",
      " 0.00100158 0.01340008 0.00383502 0.00300302 0.01184427 0.01792301] \n",
      " -0.7723465\n",
      "p [[5.00625782e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 2.50312891e-03 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 5.88235294e-02 0.00000000e+00 2.62828536e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.50187735e-02 0.00000000e+00\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.00625782e-03 1.25156446e-03\n",
      "  5.41927409e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 3.31664581e-01]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.06660359 0.00908997 0.00128513 0.00076628 0.01503493 0.00136529\n",
      " 0.00344051 0.07056663 0.02421125 0.04683496 0.0031072  0.00761576\n",
      " 0.00674084 0.08958769 0.00465731 0.2731551  0.00843979 0.02472577\n",
      " 0.00582519 0.00894621 0.05034849 0.00237253 0.06517244 0.01460045\n",
      " 0.00384279 0.00259584 0.03785643 0.02103294 0.02913284 0.00489465\n",
      " 0.0012373  0.01155109 0.00109563 0.00214375 0.00568121 0.07444222] \n",
      " 0.7700527\n",
      "p [[0.00750939 0.00125156 0.00125156 0.00125156 0.00625782 0.00125156]\n",
      " [0.00125156 0.         0.00500626 0.00250313 0.00625782 0.00250313]\n",
      " [0.00125156 0.09136421 0.         0.00625782 0.00250313 0.00375469]\n",
      " [0.00250313 0.         0.00876095 0.         0.10888611 0.00250313]\n",
      " [0.00500626 0.02753442 0.00625782 0.00625782 0.         0.00125156]\n",
      " [0.00125156 0.00750939 0.00125156 0.00125156 0.00625782 0.67209011]]\n",
      "move 35\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n",
      "prediction:\n",
      " [0.01050278 0.02672252 0.01046553 0.00238005 0.03720985 0.00167646\n",
      " 0.01548509 0.03045541 0.04134158 0.02301033 0.02949309 0.01161961\n",
      " 0.06036329 0.00997034 0.00179197 0.19635145 0.00851399 0.02627774\n",
      " 0.01244541 0.01129377 0.12041005 0.00313086 0.01337782 0.07754491\n",
      " 0.01263973 0.02378006 0.02170111 0.02405102 0.01795618 0.02357365\n",
      " 0.00096755 0.0242765  0.00676208 0.0070874  0.04662744 0.00874355] \n",
      " -0.32652053\n",
      "p [[1.62703379e-02 5.00625782e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.12640801e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 6.25782228e-03 4.38047559e-02\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-03 7.19649562e-01 0.00000000e+00 6.63329161e-02\n",
      "  1.12640801e-02 1.12640801e-02]\n",
      " [7.50938673e-03 0.00000000e+00 1.25156446e-02 0.00000000e+00\n",
      "  2.00250313e-02 1.50187735e-02]\n",
      " [1.25156446e-03 1.25156446e-13 2.25281602e-02 1.50187735e-02\n",
      "  0.00000000e+00 1.00125156e-02]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 0.00000000e+00]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n",
      "prediction:\n",
      " [2.3512196e-02 9.2807189e-03 6.1728916e-04 3.8616225e-04 8.8607129e-03\n",
      " 2.1871093e-03 2.0020914e-03 1.2346373e-02 2.1615047e-02 2.8991643e-02\n",
      " 2.3379424e-03 3.0585409e-03 3.4182869e-02 6.6576758e-03 2.0213109e-03\n",
      " 4.8221907e-01 5.1213326e-03 2.7457677e-02 4.4638477e-03 6.0060825e-03\n",
      " 1.1061103e-01 4.4159149e-04 6.8982425e-03 1.0384931e-01 1.7343784e-03\n",
      " 1.9429461e-03 3.1746075e-02 1.6262233e-02 6.7685097e-03 3.3667879e-03\n",
      " 7.9646806e-04 3.9138943e-03 5.4351037e-04 6.7687163e-04 1.0805177e-02\n",
      " 1.6317407e-02] \n",
      " 0.43167722\n",
      "p [[0.00375469 0.00876095 0.00375469 0.00250313 0.01376721 0.00125156]\n",
      " [0.02002503 0.         0.10137672 0.01877347 0.01126408 0.00500626]\n",
      " [0.02252816 0.         0.         0.5456821  0.00375469 0.00876095]\n",
      " [0.00500626 0.         0.10262829 0.         0.00375469 0.02878598]\n",
      " [0.00375469 0.01251564 0.00876095 0.01126408 0.         0.00750939]\n",
      " [0.00250313 0.00876095 0.00250313 0.00375469 0.02753442 0.        ]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n",
      "prediction:\n",
      " [0.00530564 0.02586902 0.00709583 0.00565342 0.01082963 0.00750015\n",
      " 0.02584978 0.00512571 0.09940181 0.03128405 0.06059704 0.01178534\n",
      " 0.04254003 0.05149324 0.00469352 0.00317004 0.01929139 0.06736853\n",
      " 0.02246594 0.00887887 0.0014048  0.01788235 0.06025131 0.04131082\n",
      " 0.00664545 0.04554445 0.07843513 0.07512735 0.00457776 0.03800419\n",
      " 0.00533548 0.03115913 0.01426676 0.01609812 0.04296316 0.00479508] \n",
      " -0.105515905\n",
      "p [[7.50938673e-03 6.25782228e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 8.76095119e-03 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [5.00625782e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 3.75469337e-03]\n",
      " [1.25156446e-03 0.00000000e+00 9.29912390e-01 0.00000000e+00\n",
      "  2.50312891e-03 1.87734668e-02]\n",
      " [1.25156446e-13 1.25156446e-13 8.76095119e-03 1.25156446e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 0.00000000e+00]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n",
      "prediction:\n",
      " [5.7205106e-03 4.4485573e-02 1.4289654e-03 3.6833913e-03 1.3051659e-02\n",
      " 8.1574507e-03 2.6264086e-02 2.7838254e-03 9.8342383e-03 9.6845895e-02\n",
      " 4.7698617e-03 1.6173887e-03 7.3004358e-02 1.2809872e-02 6.3386402e-04\n",
      " 1.9998825e-03 1.6321826e-03 1.5680486e-02 6.9965078e-03 7.0961621e-03\n",
      " 5.5164262e-04 3.1694456e-04 1.3932342e-02 3.5250473e-01 5.7945057e-04\n",
      " 4.2013670e-03 1.7519358e-01 2.0843726e-02 7.1995117e-04 4.1295510e-02\n",
      " 2.4368935e-03 5.8144145e-03 1.6070105e-03 2.0168896e-03 3.0509418e-02\n",
      " 8.9801131e-03] \n",
      " 0.7651728\n",
      "p [[0.00125156 0.01376721 0.00125156 0.00876095 0.01376721 0.00625782]\n",
      " [0.02377972 0.         0.49561952 0.03128911 0.02377972 0.02252816]\n",
      " [0.01501877 0.         0.         0.         0.00876095 0.05256571]\n",
      " [0.01251564 0.         0.         0.         0.02753442 0.02878598]\n",
      " [0.00125156 0.04255319 0.04380476 0.02878598 0.         0.01627034]\n",
      " [0.00125156 0.01126408 0.00500626 0.01251564 0.05006258 0.        ]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n",
      "prediction:\n",
      " [0.00253812 0.02799776 0.00652927 0.00760163 0.01720482 0.00419012\n",
      " 0.12060249 0.0010201  0.00476438 0.01757003 0.08339679 0.00798485\n",
      " 0.01021474 0.04757979 0.00033384 0.00346353 0.00252396 0.03990855\n",
      " 0.02519069 0.00109215 0.00223947 0.00137705 0.03452432 0.00889798\n",
      " 0.00495816 0.08176307 0.02282408 0.00742853 0.00110307 0.26273113\n",
      " 0.00360186 0.0266552  0.01377224 0.00447365 0.08770843 0.00423427] \n",
      " 0.80357206\n",
      "p [[1.25156446e-03 1.12640801e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [2.00250313e-02 0.00000000e+00 0.00000000e+00 1.50187735e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.12765957e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 4.75594493e-02]\n",
      " [1.25156446e-13 1.25156446e-13 8.49812265e-01 1.25156446e-03\n",
      "  0.00000000e+00 1.00125156e-02]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.50187735e-02 0.00000000e+00]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n",
      "prediction:\n",
      " [8.8308443e-04 3.3362971e-03 3.2330194e-05 1.4102913e-01 7.7763706e-02\n",
      " 4.3101457e-04 4.7825903e-04 2.6339502e-04 1.7371917e-02 4.9715850e-04\n",
      " 3.6721851e-03 7.2260601e-03 1.5543576e-02 3.2405066e-03 8.9091964e-06\n",
      " 2.6656315e-04 3.6721185e-04 1.3637520e-02 1.8619554e-03 5.4737083e-03\n",
      " 2.1647251e-05 2.3291950e-06 1.0819854e-03 1.4051409e-01 7.4641866e-04\n",
      " 2.3161285e-03 3.9834305e-04 1.9232370e-01 4.7989350e-05 2.3606617e-03\n",
      " 1.0250995e-04 5.7830424e-03 3.3894524e-01 5.2710915e-05 5.8282660e-03\n",
      " 1.6090479e-02] \n",
      " 0.98251325\n",
      "p [[0.00125156 0.0175219  0.00876095 0.04505632 0.0175219  0.04255319]\n",
      " [0.09762203 0.         0.         0.0212766  0.10012516 0.01001252]\n",
      " [0.00375469 0.         0.         0.         0.00125156 0.0387985 ]\n",
      " [0.02252816 0.         0.         0.         0.07008761 0.00375469]\n",
      " [0.00125156 0.09887359 0.         0.00250313 0.         0.17521902]\n",
      " [0.00125156 0.0212766  0.12640801 0.00125156 0.07008761 0.        ]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0. -1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00254652 0.02089228 0.00277979 0.00217221 0.01503183 0.00551829\n",
      " 0.020858   0.00146862 0.00444382 0.02685596 0.08595232 0.00666183\n",
      " 0.05007225 0.1436839  0.00034668 0.00834172 0.00508467 0.04370596\n",
      " 0.02696594 0.00159488 0.00295539 0.00142711 0.17545666 0.04814761\n",
      " 0.00334489 0.09001133 0.04269593 0.00423759 0.00120612 0.05372872\n",
      " 0.007516   0.02986929 0.0048987  0.00252144 0.04424786 0.01275805] \n",
      " 0.9560883\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.37672090e-02\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.37672090e-02]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 2.00250313e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 9.42428035e-01 1.25156446e-13\n",
      "  1.25156446e-13 0.00000000e+00]]\n",
      "move 32\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1. -1.]\n",
      " [ 0.  0.  1.  0.  0. -1.]]\n",
      "1 won\n",
      "game 149 completed in 27.503636837005615 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7516139 entropy 2.15943\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7447286 entropy 2.1611938\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7277195 entropy 2.1668777\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7047815 entropy 2.175072\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6804867 entropy 2.1837745\n",
      "kl 0.011614478\n",
      "completed in 0.16503596305847168 s\n",
      "game 150 completed in 5.8276190757751465 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7762003 entropy 2.2159781\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7543535 entropy 2.2224388\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.724769 entropy 2.227831\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6996682 entropy 2.2306125\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6815014 entropy 2.2301226\n",
      "kl 0.023321623\n",
      "completed in 0.1708829402923584 s\n",
      "game 151 completed in 5.831883907318115 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.8478954 entropy 2.2829573\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.839862 entropy 2.2802494\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.8211823 entropy 2.2783682\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.796111 entropy 2.2768483\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.7695358 entropy 2.275303\n",
      "kl 0.012268619\n",
      "completed in 0.19660210609436035 s\n",
      "game 152 completed in 7.399787902832031 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7572472 entropy 2.214952\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7305436 entropy 2.2098901\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7009788 entropy 2.2010498\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.676623 entropy 2.1899023\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.65821 entropy 2.1788125\n",
      "kl 0.014479401\n",
      "completed in 0.17094802856445312 s\n",
      "game 153 completed in 6.633420944213867 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7215757 entropy 2.1572633\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7155197 entropy 2.1507502\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6971357 entropy 2.1468766\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6713872 entropy 2.145551\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6428845 entropy 2.1463852\n",
      "kl 0.016343843\n",
      "completed in 0.17445826530456543 s\n",
      "game 154 completed in 8.309288024902344 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7858553 entropy 2.1306176\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.770277 entropy 2.1366935\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7507489 entropy 2.1460419\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7302203 entropy 2.156836\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.7063267 entropy 2.167355\n",
      "kl 0.014648303\n",
      "completed in 0.17586994171142578 s\n",
      "game 155 completed in 7.5052149295806885 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7417157 entropy 2.1968083\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7303488 entropy 2.204243\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7132423 entropy 2.2078505\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6913686 entropy 2.207934\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6667182 entropy 2.2049153\n",
      "kl 0.010920582\n",
      "completed in 0.1939840316772461 s\n",
      "game 156 completed in 10.844443082809448 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7018204 entropy 2.1801794\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6939783 entropy 2.1784468\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6778686 entropy 2.178801\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6571887 entropy 2.1807668\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6352613 entropy 2.18358\n",
      "kl 0.009582348\n",
      "completed in 0.17007899284362793 s\n",
      "game 157 completed in 8.886597871780396 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8690467 entropy 2.2242785\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8498676 entropy 2.2304356\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8242805 entropy 2.2367325\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7973533 entropy 2.240893\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7695456 entropy 2.241788\n",
      "kl 0.018627413\n",
      "completed in 0.18777203559875488 s\n",
      "game 158 completed in 7.45292067527771 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8893104 entropy 2.2781281\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8629851 entropy 2.2747922\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8260777 entropy 2.2699957\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7924716 entropy 2.2655845\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7593894 entropy 2.2643523\n",
      "kl 0.030111188\n",
      "completed in 0.16716599464416504 s\n",
      "game 159 completed in 10.90121603012085 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6863139 entropy 2.1818259\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6671152 entropy 2.187823\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.631751 entropy 2.1917238\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5915217 entropy 2.190609\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.55313 entropy 2.1826963\n",
      "kl 0.02955518\n",
      "completed in 0.22098708152770996 s\n",
      "game 160 completed in 14.331103086471558 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8188472 entropy 2.2555456\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7965033 entropy 2.243157\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7653804 entropy 2.2307553\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.733583 entropy 2.2185836\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7023754 entropy 2.2065701\n",
      "kl 0.022529693\n",
      "completed in 0.1863420009613037 s\n",
      "game 161 completed in 6.853955030441284 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7085216 entropy 2.1687503\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6834292 entropy 2.1618476\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6431503 entropy 2.158199\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6024914 entropy 2.1567233\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5674982 entropy 2.156621\n",
      "kl 0.035510942\n",
      "completed in 0.16420912742614746 s\n",
      "game 162 completed in 8.242016077041626 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7919393 entropy 2.1366782\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.772788 entropy 2.13561\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7420957 entropy 2.137306\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7095203 entropy 2.1418269\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6808243 entropy 2.1481347\n",
      "kl 0.027094651\n",
      "completed in 0.1965007781982422 s\n",
      "game 163 completed in 9.114253044128418 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7745686 entropy 2.1989403\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7519886 entropy 2.202314\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.720606 entropy 2.2044604\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.688917 entropy 2.2071295\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6595414 entropy 2.2113507\n",
      "kl 0.017913237\n",
      "completed in 0.19721603393554688 s\n",
      "game 164 completed in 11.796515226364136 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8112051 entropy 2.2131436\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7895706 entropy 2.2233214\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.75658 entropy 2.234888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.7212653 entropy 2.2449074\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.687818 entropy 2.2510567\n",
      "kl 0.026449712\n",
      "completed in 0.2824549674987793 s\n",
      "game 165 completed in 7.350776672363281 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8365788 entropy 2.2675185\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.800494 entropy 2.2679548\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7615445 entropy 2.2650352\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7359526 entropy 2.2587037\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7088387 entropy 2.24915\n",
      "kl 0.021328751\n",
      "completed in 0.16767001152038574 s\n",
      "game 166 completed in 5.867126226425171 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7079356 entropy 2.2225733\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6906075 entropy 2.2110279\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6686091 entropy 2.2003226\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.642182 entropy 2.1918497\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.611508 entropy 2.1855304\n",
      "kl 0.019219587\n",
      "completed in 0.164564847946167 s\n",
      "game 167 completed in 6.519669055938721 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.795979 entropy 2.194676\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.776127 entropy 2.190245\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.73953 entropy 2.1860304\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6984277 entropy 2.1810465\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6650252 entropy 2.174432\n",
      "kl 0.0229499\n",
      "completed in 0.17408990859985352 s\n",
      "game 168 completed in 9.7694411277771 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7296472 entropy 2.1363404\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7224674 entropy 2.1300263\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6996999 entropy 2.127124\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6671987 entropy 2.1276023\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.632826 entropy 2.1303637\n",
      "kl 0.015822504\n",
      "completed in 0.19180727005004883 s\n",
      "game 169 completed in 7.457081079483032 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8780117 entropy 2.1740494\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8547518 entropy 2.1785393\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8207436 entropy 2.182863\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7834477 entropy 2.1857657\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7502725 entropy 2.1863117\n",
      "kl 0.028038027\n",
      "completed in 0.16702699661254883 s\n",
      "game 170 completed in 5.9073638916015625 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.745615 entropy 2.1454139\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7248528 entropy 2.1458197\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6926486 entropy 2.1481934\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6620712 entropy 2.1513357\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.63651 entropy 2.1536512\n",
      "kl 0.024034906\n",
      "completed in 0.1649947166442871 s\n",
      "game 171 completed in 10.495031118392944 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7377632 entropy 2.1652687\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.728829 entropy 2.164591\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7027118 entropy 2.1635227\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6672611 entropy 2.163189\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.630679 entropy 2.1632564\n",
      "kl 0.020939257\n",
      "completed in 0.17137503623962402 s\n",
      "game 172 completed in 7.628392934799194 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.681925 entropy 2.14074\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6650386 entropy 2.1412258\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6383765 entropy 2.1425054\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.608814 entropy 2.1438706\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5804405 entropy 2.144617\n",
      "kl 0.022318682\n",
      "completed in 0.18272686004638672 s\n",
      "game 173 completed in 13.553425788879395 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.667088 entropy 2.118609\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6416585 entropy 2.1187863\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6039014 entropy 2.1183991\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5700502 entropy 2.1177163\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.543526 entropy 2.1161132\n",
      "kl 0.027806906\n",
      "completed in 0.20613598823547363 s\n",
      "game 174 completed in 7.443385124206543 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7805777 entropy 2.2103384\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7681108 entropy 2.210628\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7463179 entropy 2.2124658\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7159965 entropy 2.2156792\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6836257 entropy 2.219129\n",
      "kl 0.016698785\n",
      "completed in 0.1749560832977295 s\n",
      "game 175 completed in 12.365813970565796 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.683408 entropy 2.1855497\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.660804 entropy 2.1910236\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6307979 entropy 2.1959448\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.599824 entropy 2.198093\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5723732 entropy 2.1959858\n",
      "kl 0.025357679\n",
      "completed in 0.18199396133422852 s\n",
      "game 176 completed in 9.261158227920532 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.730583 entropy 2.1421168\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7074182 entropy 2.1369383\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6676877 entropy 2.1351423\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6283703 entropy 2.136557\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5907276 entropy 2.1407213\n",
      "kl 0.024500482\n",
      "completed in 0.17896294593811035 s\n",
      "game 177 completed in 5.878199100494385 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.744074 entropy 2.1948597\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.724993 entropy 2.2029428\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6933563 entropy 2.2093835\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6574645 entropy 2.2114847\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6235607 entropy 2.208204\n",
      "kl 0.023659363\n",
      "completed in 0.18632173538208008 s\n",
      "game 178 completed in 10.946523904800415 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7580752 entropy 2.2191482\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.729588 entropy 2.2089877\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6893554 entropy 2.1975455\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6490037 entropy 2.1853373\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6112463 entropy 2.173613\n",
      "kl 0.031683102\n",
      "completed in 0.1676921844482422 s\n",
      "game 179 completed in 13.917054176330566 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7573092 entropy 2.1650052\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7349453 entropy 2.154869\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6990705 entropy 2.1473086\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.661741 entropy 2.142552\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6271162 entropy 2.1398454\n",
      "kl 0.030006908\n",
      "completed in 0.1890430450439453 s\n",
      "game 180 completed in 14.238620281219482 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7866445 entropy 2.1104755\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7635205 entropy 2.1114597\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7275224 entropy 2.1150079\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6874475 entropy 2.1204312\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6487484 entropy 2.1267638\n",
      "kl 0.024961425\n",
      "completed in 0.1711869239807129 s\n",
      "game 181 completed in 8.91745400428772 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8205202 entropy 2.1992674\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.803343 entropy 2.2081153\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7727375 entropy 2.2190578\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7381184 entropy 2.2307568\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7005363 entropy 2.241192\n",
      "kl 0.018026654\n",
      "completed in 0.17028307914733887 s\n",
      "game 182 completed in 5.822094202041626 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6860647 entropy 2.161592\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6512344 entropy 2.1668844\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6059144 entropy 2.1718657\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5653622 entropy 2.1762247\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5288029 entropy 2.1790128\n",
      "kl 0.024870735\n",
      "completed in 0.17243099212646484 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 183 completed in 11.464640855789185 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7624028 entropy 2.2032332\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7494423 entropy 2.1991982\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7199492 entropy 2.1915917\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.679951 entropy 2.1808593\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6427882 entropy 2.16828\n",
      "kl 0.024542924\n",
      "completed in 0.16975998878479004 s\n",
      "game 184 completed in 13.958964824676514 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8363416 entropy 2.1924021\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.806463 entropy 2.188004\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.761681 entropy 2.1888394\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.713924 entropy 2.1917162\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6680143 entropy 2.1929681\n",
      "kl 0.028979972\n",
      "completed in 0.17224884033203125 s\n",
      "game 185 completed in 5.778605937957764 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7616217 entropy 2.1637876\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7333746 entropy 2.160931\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.685152 entropy 2.157062\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.635291 entropy 2.15238\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5959046 entropy 2.1472776\n",
      "kl 0.033434495\n",
      "completed in 0.16787099838256836 s\n",
      "game 186 completed in 7.496288061141968 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6752458 entropy 2.1992216\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6591792 entropy 2.2005694\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6265905 entropy 2.203341\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5909705 entropy 2.2072\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5579658 entropy 2.2112963\n",
      "kl 0.028193165\n",
      "completed in 0.16471409797668457 s\n",
      "game 187 completed in 15.59738302230835 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7347615 entropy 2.1859148\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7132611 entropy 2.1944094\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6804445 entropy 2.2048006\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.64989 entropy 2.2135606\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6256778 entropy 2.217584\n",
      "kl 0.026400696\n",
      "completed in 0.1715409755706787 s\n",
      "game 188 completed in 12.642084121704102 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.728794 entropy 2.225681\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7078414 entropy 2.2152672\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.673665 entropy 2.1997333\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6355898 entropy 2.1828074\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5999608 entropy 2.1680198\n",
      "kl 0.035212424\n",
      "completed in 0.20519185066223145 s\n",
      "game 189 completed in 8.945189952850342 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6985788 entropy 2.1461802\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.673205 entropy 2.1456623\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6299925 entropy 2.1509657\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5908926 entropy 2.1586685\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5601456 entropy 2.164534\n",
      "kl 0.045294784\n",
      "completed in 0.20025897026062012 s\n",
      "game 190 completed in 5.8363330364227295 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7881052 entropy 2.246691\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7712975 entropy 2.246758\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7439916 entropy 2.2441585\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7143393 entropy 2.239871\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6860616 entropy 2.234874\n",
      "kl 0.010329077\n",
      "completed in 0.1634819507598877 s\n",
      "game 191 completed in 7.3989269733428955 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6664858 entropy 2.164908\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6533678 entropy 2.1599326\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6356761 entropy 2.154591\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6156578 entropy 2.1507792\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5933313 entropy 2.1494045\n",
      "kl 0.01511236\n",
      "completed in 0.19767189025878906 s\n",
      "game 192 completed in 9.965697765350342 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7887695 entropy 2.194501\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7674003 entropy 2.1977468\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7325559 entropy 2.2025392\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6955974 entropy 2.2071865\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.66202 entropy 2.2098951\n",
      "kl 0.01686864\n",
      "completed in 0.18589997291564941 s\n",
      "game 193 completed in 6.65907096862793 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7502947 entropy 2.2013097\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.739168 entropy 2.1994724\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7192457 entropy 2.1966298\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6952925 entropy 2.1931996\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6714253 entropy 2.1894097\n",
      "kl 0.008936672\n",
      "completed in 0.17197299003601074 s\n",
      "game 194 completed in 6.718914985656738 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7471962 entropy 2.1663508\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7273483 entropy 2.1619773\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6999002 entropy 2.1589475\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6663916 entropy 2.15716\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6304884 entropy 2.1562796\n",
      "kl 0.028737744\n",
      "completed in 0.17365717887878418 s\n",
      "game 195 completed in 13.072041034698486 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.671303 entropy 2.110445\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.656265 entropy 2.1140175\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6239603 entropy 2.1204374\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5861514 entropy 2.1269927\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5511787 entropy 2.1321316\n",
      "kl 0.023881553\n",
      "completed in 0.17825102806091309 s\n",
      "game 196 completed in 13.563340187072754 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6886485 entropy 2.184865\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6706161 entropy 2.1883981\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.640148 entropy 2.1915007\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6090503 entropy 2.193949\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5808146 entropy 2.195027\n",
      "kl 0.021599282\n",
      "completed in 0.1846599578857422 s\n",
      "game 197 completed in 5.788934707641602 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.810292 entropy 2.2126698\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7782345 entropy 2.2156472\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.734042 entropy 2.2193785\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6917093 entropy 2.2226458\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6551175 entropy 2.2242074\n",
      "kl 0.035564877\n",
      "completed in 0.1702098846435547 s\n",
      "game 198 completed in 5.937274932861328 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.727382 entropy 2.1944852\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7078836 entropy 2.1933174\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.676303 entropy 2.1912122\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.643885 entropy 2.1867332\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.615285 entropy 2.1795158\n",
      "kl 0.030663742\n",
      "completed in 0.1678006649017334 s\n",
      "prediction:\n",
      " [0.00285161 0.00336323 0.00361262 0.00344452 0.0042595  0.00460726\n",
      " 0.00371686 0.01219486 0.061503   0.08522099 0.05426812 0.00373434\n",
      " 0.00377828 0.06124413 0.06114138 0.03335688 0.09941478 0.00493319\n",
      " 0.00427018 0.08622156 0.02221699 0.086341   0.05169145 0.00553173\n",
      " 0.002855   0.06078657 0.06730021 0.06529448 0.0116603  0.00418689\n",
      " 0.00384193 0.00344281 0.00486987 0.00554758 0.00548108 0.00181495] \n",
      " -0.25264633\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.21526909e-01 4.98122653e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.62703379e-01 1.17647059e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [8.02645169e-04 1.21152296e-03 2.13434236e-04 1.19526114e-03\n",
      " 3.27164540e-04 1.05193409e-03 7.51596992e-04 5.94804937e-04\n",
      " 3.32994293e-03 7.86844082e-03 2.38665212e-02 6.26082998e-04\n",
      " 2.78347085e-04 1.00022601e-02 1.09552972e-01 3.85098308e-01\n",
      " 5.22318343e-03 1.97906909e-03 2.14721868e-03 3.11412453e-03\n",
      " 2.65843213e-01 1.15240484e-01 9.26336553e-03 7.30788510e-04\n",
      " 2.94802536e-04 3.53705883e-02 3.90447141e-03 3.15292808e-03\n",
      " 9.67511733e-04 1.26402429e-03 7.20018812e-04 3.57394863e-04\n",
      " 1.38422300e-03 5.02262614e-04 1.28644484e-03 4.82834963e-04] \n",
      " -0.13167061\n",
      "p [[0.00500626 0.00375469 0.00750939 0.00250313 0.02503129 0.00625782]\n",
      " [0.00250313 0.00876095 0.05256571 0.07133917 0.04881101 0.01376721]\n",
      " [0.01126408 0.08510638 0.04380476 0.         0.10513141 0.00250313]\n",
      " [0.00500626 0.07008761 0.03003755 0.05006258 0.05757196 0.00500626]\n",
      " [0.00375469 0.0387985  0.08886108 0.11013767 0.00876095 0.00625782]\n",
      " [0.00500626 0.00375469 0.00375469 0.00625782 0.00750939 0.00375469]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00231039 0.0130512  0.00516634 0.01170073 0.00331719 0.00671114\n",
      " 0.00780419 0.00587906 0.00380683 0.05046552 0.23057619 0.00407857\n",
      " 0.00315859 0.01371195 0.03938986 0.00362156 0.01866558 0.00460508\n",
      " 0.00375069 0.00815247 0.00366181 0.02440096 0.02271728 0.00271442\n",
      " 0.0047746  0.34637204 0.07793993 0.00578902 0.01282743 0.008281\n",
      " 0.00742654 0.0044088  0.02446423 0.00515293 0.00716071 0.00198537] \n",
      " -0.6484436\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.37672090e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 7.34668335e-01 1.07634543e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.00125156e-02 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00217862 0.00329089 0.00066825 0.00354493 0.00094859 0.04889508\n",
      " 0.00272872 0.00197995 0.00392099 0.04517581 0.14823866 0.00235171\n",
      " 0.00249438 0.01110241 0.14686573 0.00495381 0.0129387  0.00237807\n",
      " 0.00254966 0.00423987 0.00392713 0.14714806 0.01618587 0.00120523\n",
      " 0.00120083 0.2658767  0.06616654 0.00208294 0.00127578 0.00347694\n",
      " 0.03104491 0.00119885 0.00431601 0.00079444 0.00211214 0.00054292] \n",
      " 0.6305705\n",
      "p [[0.00250313 0.00876095 0.00375469 0.00750939 0.00876095 0.00500626]\n",
      " [0.00500626 0.00375469 0.00375469 0.03128911 0.18147685 0.00375469]\n",
      " [0.00375469 0.01001252 0.02377972 0.         0.01251564 0.00250313]\n",
      " [0.00250313 0.00500626 0.         0.01376721 0.01501877 0.00125156]\n",
      " [0.00876095 0.51314143 0.07008761 0.         0.00750939 0.00625782]\n",
      " [0.00625782 0.00250313 0.01877347 0.00375469 0.00625782 0.00125156]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0063362  0.00706732 0.00884098 0.00652666 0.00770631 0.02665857\n",
      " 0.00744977 0.02721759 0.00468554 0.18723889 0.00426134 0.00944538\n",
      " 0.00278823 0.01590328 0.01797754 0.00339418 0.01989564 0.00511672\n",
      " 0.00433903 0.01246075 0.0044605  0.01710267 0.02688065 0.00325756\n",
      " 0.01082676 0.00853025 0.4201747  0.00401266 0.03702975 0.00935701\n",
      " 0.04528382 0.00706573 0.00906983 0.00496656 0.00291545 0.0037562 ] \n",
      " -0.9549675\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 2.66583229e-01]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 7.50938673e-03\n",
      "  5.49436796e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 2.12765957e-02 0.00000000e+00\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.75219024e-02\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.18898623e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.50312891e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.6800731e-04 8.9482596e-04 1.8866625e-04 3.2813885e-04 4.9479515e-04\n",
      " 5.8576018e-01 1.1526669e-03 8.6397066e-04 2.6118546e-03 2.4148898e-04\n",
      " 1.5696188e-02 1.3178289e-03 5.6945957e-04 1.7820500e-03 6.2500890e-03\n",
      " 3.0296235e-04 1.5934125e-03 6.4038055e-04 2.9551104e-04 9.7709394e-04\n",
      " 2.8855598e-04 7.5891851e-03 1.5489261e-03 4.2297458e-04 6.3739868e-04\n",
      " 1.9625602e-02 2.6843793e-04 2.0638832e-03 8.2226022e-04 3.9659012e-03\n",
      " 3.3629230e-01 4.6533017e-04 7.3772966e-04 4.8067860e-04 1.4124670e-03\n",
      " 4.4887912e-04] \n",
      " 0.9799686\n",
      "p [[0.00375469 0.00375469 0.00500626 0.00375469 0.00625782 0.26157697]\n",
      " [0.00375469 0.01627034 0.00250313 0.11889862 0.         0.00500626]\n",
      " [0.00125156 0.01001252 0.01126408 0.         0.01251564 0.00250313]\n",
      " [0.00250313 0.00750939 0.         0.01001252 0.0175219  0.00125156]\n",
      " [0.01627034 0.         0.37546934 0.         0.05256571 0.00750939]\n",
      " [0.02753442 0.00375469 0.00500626 0.00250313 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.1693370e-04 2.2721202e-03 7.8146905e-04 3.7181264e-04 2.2138867e-03\n",
      " 1.6260829e-03 2.1932188e-03 1.4037153e-01 2.7965365e-03 5.0693797e-04\n",
      " 1.3100679e-03 1.5074883e-01 1.0188142e-04 4.2761554e-04 8.7273668e-04\n",
      " 1.7819828e-05 4.4233416e-04 2.3227224e-04 6.6284949e-05 7.0450734e-04\n",
      " 5.7004227e-06 3.7118909e-04 2.0224937e-04 1.6574928e-04 3.3407587e-01\n",
      " 1.4575488e-03 4.5869799e-04 1.8792381e-03 3.3602980e-01 7.8112595e-03\n",
      " 1.4949066e-03 3.7818307e-03 4.6918044e-04 1.1300010e-03 7.0895499e-04\n",
      " 9.8317664e-04] \n",
      " 0.58826274\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 9.69962453e-01]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [3.00375469e-02 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 5\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 199 completed in 18.46367311477661 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6805441 entropy 2.1535523\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6580713 entropy 2.1375024\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6251473 entropy 2.1206214\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5923734 entropy 2.1068435\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5612938 entropy 2.097592\n",
      "kl 0.036092818\n",
      "completed in 0.17539358139038086 s\n",
      "game 200 completed in 7.587619066238403 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6509905 entropy 2.0829382\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6328342 entropy 2.0886114\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6030374 entropy 2.099687\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5715792 entropy 2.112759\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5425742 entropy 2.123619\n",
      "kl 0.035199486\n",
      "completed in 0.19017410278320312 s\n",
      "game 201 completed in 6.75122594833374 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7292886 entropy 2.2119534\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7065046 entropy 2.2210667\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.675455 entropy 2.230684\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.643332 entropy 2.2374063\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.610313 entropy 2.240223\n",
      "kl 0.027389381\n",
      "completed in 0.18758702278137207 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 202 completed in 8.458799839019775 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7381077 entropy 2.1774368\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7145078 entropy 2.1730118\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6768153 entropy 2.1658976\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6369865 entropy 2.1574574\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6008408 entropy 2.1491532\n",
      "kl 0.02197706\n",
      "completed in 0.1738433837890625 s\n",
      "game 203 completed in 9.104942798614502 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7567031 entropy 2.1525865\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.734539 entropy 2.144506\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6979468 entropy 2.1366854\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6579423 entropy 2.1299338\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6215148 entropy 2.1252894\n",
      "kl 0.027147718\n",
      "completed in 0.1692500114440918 s\n",
      "game 204 completed in 5.903442859649658 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7066295 entropy 2.1220214\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6920068 entropy 2.1227717\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6634333 entropy 2.1240497\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.625774 entropy 2.1247778\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5873723 entropy 2.124742\n",
      "kl 0.022116035\n",
      "completed in 0.1903820037841797 s\n",
      "game 205 completed in 7.519881963729858 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7526233 entropy 2.1840718\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7325563 entropy 2.1851246\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.703828 entropy 2.1871374\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.673395 entropy 2.1896667\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6472578 entropy 2.190322\n",
      "kl 0.035753123\n",
      "completed in 0.17020487785339355 s\n",
      "game 206 completed in 5.906970262527466 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7350738 entropy 2.1404886\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7189608 entropy 2.1429899\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6934319 entropy 2.1484613\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6612902 entropy 2.1553535\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6264126 entropy 2.1620245\n",
      "kl 0.022742843\n",
      "completed in 0.2005312442779541 s\n",
      "game 207 completed in 6.7136149406433105 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.687276 entropy 2.1639597\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6704974 entropy 2.1633964\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6411276 entropy 2.1591542\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6109738 entropy 2.1530066\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5829256 entropy 2.1463878\n",
      "kl 0.023247097\n",
      "completed in 0.1728529930114746 s\n",
      "game 208 completed in 5.926788806915283 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7103086 entropy 2.1626627\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6929898 entropy 2.1567013\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6662316 entropy 2.1519275\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6332977 entropy 2.1493144\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5985541 entropy 2.1493063\n",
      "kl 0.021950636\n",
      "completed in 0.1903238296508789 s\n",
      "game 209 completed in 7.642913103103638 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6808457 entropy 2.137403\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6644125 entropy 2.144919\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6382709 entropy 2.154652\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.611176 entropy 2.16425\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5864592 entropy 2.1715436\n",
      "kl 0.02939646\n",
      "completed in 0.17179274559020996 s\n",
      "game 210 completed in 7.4646689891815186 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6340673 entropy 2.159524\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6167872 entropy 2.1602926\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5844963 entropy 2.1589944\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5511186 entropy 2.1556218\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5211782 entropy 2.150414\n",
      "kl 0.020144397\n",
      "completed in 0.17295503616333008 s\n",
      "game 211 completed in 10.165302038192749 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7151437 entropy 2.1455865\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.691204 entropy 2.138499\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6543536 entropy 2.1319602\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6189656 entropy 2.1259515\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5884988 entropy 2.1206856\n",
      "kl 0.031828273\n",
      "completed in 0.17832589149475098 s\n",
      "game 212 completed in 8.466040134429932 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7599647 entropy 2.1631594\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7392015 entropy 2.1613379\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6954322 entropy 2.162406\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6559722 entropy 2.166514\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.622925 entropy 2.1727958\n",
      "kl 0.03516557\n",
      "completed in 0.1679821014404297 s\n",
      "game 213 completed in 7.461266994476318 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.807159 entropy 2.1339352\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7869143 entropy 2.1420722\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7498925 entropy 2.1487508\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7154675 entropy 2.1518385\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6833925 entropy 2.149427\n",
      "kl 0.027458584\n",
      "completed in 0.2087860107421875 s\n",
      "game 214 completed in 9.214915037155151 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6556914 entropy 2.177604\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.631978 entropy 2.170201\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5993714 entropy 2.1603498\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5642438 entropy 2.1505513\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5300038 entropy 2.1420143\n",
      "kl 0.036412627\n",
      "completed in 0.18799614906311035 s\n",
      "game 215 completed in 12.659473896026611 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.687662 entropy 2.109702\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6745875 entropy 2.1093817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.650103 entropy 2.1140785\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.61803 entropy 2.121683\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5832694 entropy 2.1309285\n",
      "kl 0.025504522\n",
      "completed in 0.182481050491333 s\n",
      "game 216 completed in 6.027935266494751 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.707886 entropy 2.1259594\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6856377 entropy 2.1353388\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.652816 entropy 2.1424956\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6222243 entropy 2.1457014\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5961747 entropy 2.1441565\n",
      "kl 0.03197396\n",
      "completed in 0.16498303413391113 s\n",
      "game 217 completed in 8.35091781616211 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.777152 entropy 2.1931329\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.753911 entropy 2.1814907\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7184694 entropy 2.1673636\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6812134 entropy 2.1542296\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6492403 entropy 2.1440797\n",
      "kl 0.0329537\n",
      "completed in 0.16646099090576172 s\n",
      "game 218 completed in 12.588064908981323 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7876241 entropy 2.1293917\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7597384 entropy 2.1285212\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7146478 entropy 2.1341906\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.666317 entropy 2.1440682\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6217442 entropy 2.154698\n",
      "kl 0.04073237\n",
      "completed in 0.16876888275146484 s\n",
      "game 219 completed in 11.535640001296997 s 14 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7910001 entropy 2.1577187\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7799642 entropy 2.1577113\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7582343 entropy 2.154633\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7320156 entropy 2.1492915\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.705199 entropy 2.1432118\n",
      "kl 0.012216095\n",
      "completed in 0.1702721118927002 s\n",
      "game 220 completed in 7.721069097518921 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7376497 entropy 2.1272254\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7240767 entropy 2.1235907\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6988955 entropy 2.124031\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.666257 entropy 2.1277552\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6336396 entropy 2.1337461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl 0.019287664\n",
      "completed in 0.20084905624389648 s\n",
      "game 221 completed in 5.945451736450195 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.64454 entropy 2.1074667\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6279006 entropy 2.1194553\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6042259 entropy 2.132233\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5797155 entropy 2.1438181\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5552611 entropy 2.1518526\n",
      "kl 0.012984119\n",
      "completed in 0.169602632522583 s\n",
      "game 222 completed in 6.652241945266724 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6788568 entropy 2.197113\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.664599 entropy 2.1971006\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6390572 entropy 2.1928668\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.609338 entropy 2.1853046\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.581788 entropy 2.1754084\n",
      "kl 0.013933263\n",
      "completed in 0.18059706687927246 s\n",
      "game 223 completed in 8.486839771270752 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6760063 entropy 2.1566823\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.659306 entropy 2.1478877\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6244786 entropy 2.13982\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5832355 entropy 2.1328492\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5512495 entropy 2.1263742\n",
      "kl 0.013985937\n",
      "completed in 0.16813397407531738 s\n",
      "game 224 completed in 6.035659074783325 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7766454 entropy 2.1792026\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7605727 entropy 2.1731505\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7324343 entropy 2.1660771\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.699923 entropy 2.1586676\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6683984 entropy 2.1514912\n",
      "kl 0.01894476\n",
      "completed in 0.1875920295715332 s\n",
      "game 225 completed in 9.003103971481323 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7031431 entropy 2.0938723\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6819167 entropy 2.0911102\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6550908 entropy 2.0917087\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.626204 entropy 2.0956414\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5950937 entropy 2.1013987\n",
      "kl 0.027287148\n",
      "completed in 0.18721294403076172 s\n",
      "game 226 completed in 6.217376947402954 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6658409 entropy 2.0803742\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6513104 entropy 2.0866432\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6254284 entropy 2.093514\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.592899 entropy 2.0995607\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.559501 entropy 2.1032372\n",
      "kl 0.028105624\n",
      "completed in 0.1706371307373047 s\n",
      "game 227 completed in 9.87737488746643 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.678714 entropy 2.0933008\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6611717 entropy 2.096397\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6310866 entropy 2.0987856\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6022642 entropy 2.0991654\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5757508 entropy 2.0971098\n",
      "kl 0.021955637\n",
      "completed in 0.19055795669555664 s\n",
      "game 228 completed in 9.258478164672852 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5914812 entropy 2.1293676\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5750017 entropy 2.1228848\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.550064 entropy 2.114933\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5244918 entropy 2.1069813\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.501129 entropy 2.1002624\n",
      "kl 0.01886972\n",
      "completed in 0.20104002952575684 s\n",
      "game 229 completed in 6.082674026489258 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.622566 entropy 2.0731778\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.61378 entropy 2.0729237\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.598247 entropy 2.075566\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5769038 entropy 2.0796137\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.551397 entropy 2.0835283\n",
      "kl 0.018464325\n",
      "completed in 0.16759800910949707 s\n",
      "game 230 completed in 14.720415830612183 s 18 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7333415 entropy 2.1113052\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7100334 entropy 2.110313\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6783674 entropy 2.1049075\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.64323 entropy 2.0957947\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6123314 entropy 2.0841599\n",
      "kl 0.027662545\n",
      "completed in 0.17028212547302246 s\n",
      "game 231 completed in 5.88368821144104 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.729381 entropy 2.0883536\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7139592 entropy 2.0815892\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6850471 entropy 2.0795622\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6501791 entropy 2.08156\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6171782 entropy 2.0867262\n",
      "kl 0.029304603\n",
      "completed in 0.1893599033355713 s\n",
      "game 232 completed in 6.72680401802063 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7642756 entropy 2.1118956\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7525492 entropy 2.1229057\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7293305 entropy 2.1348963\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6971705 entropy 2.1458209\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6607645 entropy 2.1540413\n",
      "kl 0.019206066\n",
      "completed in 0.17171931266784668 s\n",
      "game 233 completed in 11.42925500869751 s 14 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7790744 entropy 2.1374693\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7495468 entropy 2.13935\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7107344 entropy 2.1363509\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6752062 entropy 2.1294181\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.644062 entropy 2.120512\n",
      "kl 0.034553047\n",
      "completed in 0.19774675369262695 s\n",
      "game 234 completed in 15.625373125076294 s 19 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7384717 entropy 2.170634\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7232535 entropy 2.1635628\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.696707 entropy 2.15912\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6657922 entropy 2.157887\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6340287 entropy 2.159524\n",
      "kl 0.012674041\n",
      "completed in 0.20506501197814941 s\n",
      "game 235 completed in 8.406054019927979 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6748602 entropy 2.0967276\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.660709 entropy 2.1054864\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.637078 entropy 2.114741\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6098235 entropy 2.1232948\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5835247 entropy 2.1299624\n",
      "kl 0.021827705\n",
      "completed in 0.16605710983276367 s\n",
      "game 236 completed in 5.937566041946411 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7172456 entropy 2.1566086\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7033827 entropy 2.1556797\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6786635 entropy 2.15055\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.648536 entropy 2.1424117\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6205041 entropy 2.1325624\n",
      "kl 0.012530652\n",
      "completed in 0.20918798446655273 s\n",
      "game 237 completed in 6.0861639976501465 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.8134263 entropy 2.1346302\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7935524 entropy 2.1285923\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.756062 entropy 2.1279655\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7190945 entropy 2.1309614\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6866415 entropy 2.1350286\n",
      "kl 0.015998546\n",
      "completed in 0.1974201202392578 s\n",
      "game 238 completed in 9.184015035629272 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7012634 entropy 2.0952835\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.688163 entropy 2.0982606\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6619034 entropy 2.101395\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6292143 entropy 2.1044438\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5972283 entropy 2.1070986\n",
      "kl 0.014352122\n",
      "completed in 0.1906421184539795 s\n",
      "game 239 completed in 7.5483667850494385 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6718519 entropy 2.1293802\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6515124 entropy 2.132701\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6252248 entropy 2.1373677\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5976543 entropy 2.143398\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5685084 entropy 2.1493087\n",
      "kl 0.015645746\n",
      "completed in 0.16609406471252441 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 240 completed in 11.917919158935547 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7159512 entropy 2.1573594\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.698544 entropy 2.158558\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.671169 entropy 2.154995\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6377447 entropy 2.146733\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6044464 entropy 2.1345503\n",
      "kl 0.016689464\n",
      "completed in 0.16828417778015137 s\n",
      "game 241 completed in 7.512660980224609 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.686256 entropy 2.1783652\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.673952 entropy 2.1649423\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6523576 entropy 2.1517665\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.625353 entropy 2.140182\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5971746 entropy 2.1307678\n",
      "kl 0.014464202\n",
      "completed in 0.17714309692382812 s\n",
      "game 242 completed in 10.921900033950806 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7657752 entropy 2.1310413\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7500339 entropy 2.1282954\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7246768 entropy 2.1279027\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6920855 entropy 2.1294985\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.657868 entropy 2.132234\n",
      "kl 0.015257139\n",
      "completed in 0.20021772384643555 s\n",
      "game 243 completed in 8.285599946975708 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6436503 entropy 2.0879312\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6206455 entropy 2.0890236\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5886123 entropy 2.0903049\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5559926 entropy 2.089993\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5214906 entropy 2.0871189\n",
      "kl 0.013345566\n",
      "completed in 0.19344520568847656 s\n",
      "game 244 completed in 14.763613939285278 s 18 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6774507 entropy 2.127775\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6650028 entropy 2.1242988\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6429174 entropy 2.1221943\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6175044 entropy 2.121004\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5934858 entropy 2.1208568\n",
      "kl 0.01335674\n",
      "completed in 0.17235422134399414 s\n",
      "game 245 completed in 12.358518123626709 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.757376 entropy 2.1159024\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7376385 entropy 2.1174462\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7082472 entropy 2.1183448\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.677563 entropy 2.1187568\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6467152 entropy 2.1185126\n",
      "kl 0.01040538\n",
      "completed in 0.21326708793640137 s\n",
      "game 246 completed in 6.140154123306274 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7323172 entropy 2.0559177\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7081926 entropy 2.0557675\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.674472 entropy 2.0563111\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6352663 entropy 2.0578911\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5947173 entropy 2.0599341\n",
      "kl 0.020247642\n",
      "completed in 0.18997907638549805 s\n",
      "game 247 completed in 5.916147232055664 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.690415 entropy 2.0841327\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6817832 entropy 2.0880342\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6626658 entropy 2.0929039\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6369019 entropy 2.0981238\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6071863 entropy 2.103056\n",
      "kl 0.012371359\n",
      "completed in 0.19351696968078613 s\n",
      "game 248 completed in 9.697758913040161 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.675354 entropy 2.12151\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6617315 entropy 2.129039\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6392696 entropy 2.1378517\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6125307 entropy 2.1471224\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5858405 entropy 2.1558347\n",
      "kl 0.012553059\n",
      "completed in 0.164780855178833 s\n",
      "prediction:\n",
      " [0.00429207 0.00652268 0.0049056  0.00693712 0.00367585 0.00339984\n",
      " 0.0065914  0.04182491 0.07917944 0.05804027 0.01074594 0.00590854\n",
      " 0.0048249  0.07259233 0.06649497 0.06833889 0.05881861 0.00781595\n",
      " 0.00554814 0.06500355 0.0442499  0.06093149 0.06508188 0.00671546\n",
      " 0.00408015 0.01211767 0.06947949 0.07844462 0.04504603 0.00552247\n",
      " 0.00279734 0.00468006 0.00555579 0.00583046 0.00435536 0.00365119] \n",
      " -0.48528937\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.66583229e-01 1.35168961e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.57697121e-01 4.40550688e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [5.6218758e-04 4.9925926e-05 5.7798281e-04 1.7435850e-04 2.4802549e-04\n",
      " 5.0210747e-05 9.6842006e-05 6.8137548e-03 7.7976985e-04 4.4595310e-03\n",
      " 8.1040016e-05 2.0715244e-04 1.7726664e-04 9.5308200e-04 2.7025297e-01\n",
      " 1.9612622e-01 5.6599714e-03 8.1209837e-05 4.6231566e-05 6.2693176e-03\n",
      " 5.8075361e-02 4.3147197e-01 6.2431517e-04 2.8548212e-04 2.6003137e-04\n",
      " 1.1589597e-04 5.7733827e-03 1.3780337e-03 6.5101185e-03 1.2719739e-04\n",
      " 3.5477071e-05 2.5227873e-04 9.5268988e-05 9.0273953e-04 3.4401004e-05\n",
      " 3.9102789e-04] \n",
      " -0.36881843\n",
      "p [[0.00250313 0.0212766  0.00375469 0.00750939 0.00375469 0.00250313]\n",
      " [0.00750939 0.02002503 0.05757196 0.03003755 0.00375469 0.00625782]\n",
      " [0.00375469 0.03629537 0.21777222 0.02377972 0.03754693 0.00375469]\n",
      " [0.00375469 0.03128911 0.01501877 0.         0.02878598 0.00375469]\n",
      " [0.00375469 0.00500626 0.07008761 0.04130163 0.01627034 0.00876095]\n",
      " [0.00250313 0.00375469 0.00625782 0.00250313 0.2640801  0.00375469]]\n",
      "move 34\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [0.01837274 0.00216816 0.01521516 0.00560944 0.00657397 0.00212051\n",
      " 0.00641015 0.36520135 0.02038985 0.02356235 0.00280663 0.00850025\n",
      " 0.00411303 0.02050716 0.00128083 0.0194537  0.02908303 0.00463442\n",
      " 0.00426158 0.02109914 0.02175947 0.00097271 0.02348928 0.00279692\n",
      " 0.00827158 0.00372722 0.02966784 0.02220629 0.25696036 0.00494472\n",
      " 0.00185668 0.00867826 0.00424891 0.01710921 0.00152618 0.01042096] \n",
      " -0.7528586\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.24780976e-01 9.88735920e-02\n",
      "  5.25657071e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.50187735e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-13\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [8.5525438e-02 2.0743256e-04 1.9141739e-03 7.1426772e-04 1.5676889e-03\n",
      " 3.1981873e-04 9.0697478e-04 2.5105590e-01 3.0944655e-03 2.0076927e-02\n",
      " 6.6486020e-05 8.4742840e-04 1.3382582e-03 5.4962691e-03 2.9071574e-03\n",
      " 9.6411258e-02 3.1882856e-02 2.7847535e-04 2.1385803e-04 3.0748969e-02\n",
      " 7.5531699e-02 3.4925020e-03 6.9307717e-03 1.1552360e-03 1.4212180e-03\n",
      " 1.4819094e-04 2.0691205e-02 3.7865115e-03 3.0129135e-01 8.3484343e-04\n",
      " 2.0445319e-04 3.9297338e-03 5.5666739e-04 3.3124213e-03 1.2878576e-04\n",
      " 4.1010465e-02] \n",
      " -0.70408887\n",
      "p [[0.04130163 0.0563204  0.01251564 0.04630788 0.02753442 0.0951189 ]\n",
      " [0.04630788 0.2077597  0.01501877 0.01251564 0.00125156 0.02878598]\n",
      " [0.00500626 0.0212766  0.         0.00750939 0.01251564 0.01001252]\n",
      " [0.01001252 0.02628285 0.00750939 0.         0.00876095 0.00500626]\n",
      " [0.02503129 0.00500626 0.02377972 0.01251564 0.1339174  0.01126408]\n",
      " [0.01501877 0.0175219  0.01126408 0.0212766  0.         0.01877347]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.22578923 0.00329077 0.0175977  0.01397604 0.01071472 0.00343284\n",
      " 0.0158055  0.01176243 0.06174073 0.03392082 0.00387888 0.01121868\n",
      " 0.01385056 0.02739163 0.00046936 0.03688572 0.05636164 0.00533303\n",
      " 0.00475153 0.04681677 0.02843176 0.00035526 0.04979936 0.00620879\n",
      " 0.01644295 0.01191079 0.03867355 0.05912279 0.00977497 0.00901673\n",
      " 0.00432498 0.01433708 0.01545575 0.01791135 0.00241291 0.11083261] \n",
      " -0.98294246\n",
      "p [[6.38297872e-02 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 3.62953692e-02\n",
      "  8.88610763e-02 1.25156446e-13]\n",
      " [1.25156446e-13 7.50938673e-03 1.50187735e-02 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.62703379e-02 1.25156446e-13\n",
      "  7.45932416e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.75219024e-02]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [3.1184942e-01 7.0776133e-04 4.1772635e-03 2.6999780e-03 3.2626705e-03\n",
      " 1.0333025e-03 4.0680054e-03 7.0503280e-02 1.1991883e-02 5.6503609e-02\n",
      " 1.3141040e-04 2.6881208e-03 5.5567529e-03 4.9863211e-03 4.3755602e-03\n",
      " 1.0202465e-01 4.5369897e-02 6.1367347e-04 4.1612933e-04 5.8978453e-02\n",
      " 2.7790422e-02 1.0122436e-02 6.0846568e-03 3.0526239e-03 1.6146355e-03\n",
      " 3.0721223e-04 6.8767890e-02 1.6142020e-02 4.8449911e-02 2.2700627e-03\n",
      " 6.6462916e-04 5.5248789e-03 9.1915054e-04 1.5796311e-02 2.7826772e-04\n",
      " 1.0027685e-01] \n",
      " 0.66660005\n",
      "p [[0.15269086 0.00750939 0.01001252 0.01376721 0.00750939 0.00750939]\n",
      " [0.0175219  0.         0.04755945 0.0212766  0.00250313 0.01001252]\n",
      " [0.00876095 0.0175219  0.         0.02252816 0.0387985  0.00500626]\n",
      " [0.00500626 0.03254068 0.0175219  0.         0.02878598 0.00625782]\n",
      " [0.01126408 0.00750939 0.02377972 0.0350438  0.         0.00625782]\n",
      " [0.00500626 0.01126408 0.01126408 0.01251564 0.         0.39549437]]\n",
      "move 35\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1. -1.]]\n",
      "prediction:\n",
      " [0.04791272 0.00491577 0.00388171 0.02178866 0.0093657  0.00390456\n",
      " 0.01293926 0.00459321 0.13157968 0.04889217 0.00568168 0.00606846\n",
      " 0.05130112 0.04719957 0.00046494 0.08853123 0.09096359 0.00956169\n",
      " 0.00675233 0.04477598 0.04272512 0.00057756 0.05624963 0.02010942\n",
      " 0.0137526  0.00842347 0.03211826 0.08469409 0.00616426 0.00902116\n",
      " 0.00776451 0.01764794 0.02324883 0.00398109 0.00244266 0.03000549] \n",
      " -0.9628928\n",
      "p [[1.12640801e-01 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.50187735e-02 8.01001252e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 5.38172716e-02\n",
      "  5.88235294e-02 1.25156446e-13]\n",
      " [1.25156446e-13 6.13266583e-02 1.25156446e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.25657071e-02 5.00625782e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 5.48185232e-01\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n",
      "prediction:\n",
      " [3.43916804e-01 6.30009745e-04 1.14776034e-04 5.18096751e-03\n",
      " 5.59845241e-03 1.27159304e-03 1.99123565e-03 1.09652476e-02\n",
      " 5.21526933e-02 4.57992516e-02 5.00472030e-04 2.85381405e-03\n",
      " 2.60178857e-02 2.62016859e-02 2.14304542e-03 1.29956290e-01\n",
      " 9.39480681e-03 9.94791160e-04 4.85841709e-04 6.75263302e-03\n",
      " 4.14453074e-02 3.20182508e-03 2.55147144e-02 2.59769019e-02\n",
      " 2.03120266e-03 9.97302704e-04 3.14084999e-02 3.46498936e-02\n",
      " 9.19053704e-03 1.11656287e-03 7.84298347e-04 1.89273953e-02\n",
      " 3.26299248e-03 2.97836727e-04 5.14637039e-04 1.27757847e-01] \n",
      " 0.943946\n",
      "p [[0.04755945 0.00500626 0.00125156 0.01251564 0.00375469 0.00250313]\n",
      " [0.00876095 0.         0.18272841 0.07884856 0.00250313 0.00250313]\n",
      " [0.02753442 0.02252816 0.         0.04630788 0.06132666 0.00500626]\n",
      " [0.00500626 0.27909887 0.02503129 0.         0.02753442 0.01251564]\n",
      " [0.00750939 0.00375469 0.03128911 0.06382979 0.         0.00375469]\n",
      " [0.00375469 0.01001252 0.01627034 0.         0.         0.        ]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n",
      "prediction:\n",
      " [0.07828293 0.017384   0.01462953 0.00459597 0.01237551 0.00177238\n",
      " 0.02376174 0.0023961  0.02098384 0.07791938 0.01169895 0.00829947\n",
      " 0.02057439 0.08906817 0.00034886 0.05384983 0.01023971 0.01327967\n",
      " 0.0065187  0.00305288 0.04033962 0.00026365 0.21389581 0.00643919\n",
      " 0.03881837 0.02754748 0.04899435 0.00389782 0.00472019 0.04679532\n",
      " 0.00542169 0.03312901 0.00632326 0.00782956 0.00972132 0.0348314 ] \n",
      " -0.7265168\n",
      "p [[6.50813517e-02 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.50187735e-02 1.12640801e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-02 7.75969962e-02 0.00000000e+00 3.27909887e-01\n",
      "  3.12891114e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 7.50938673e-03 0.00000000e+00\n",
      "  2.62828536e-02 2.12765957e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.12640801e-02 3.55444305e-01\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 3.75469337e-02 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n",
      "prediction:\n",
      " [3.0799353e-02 4.4585597e-03 5.9672246e-05 8.8789454e-04 3.3686298e-03\n",
      " 1.2389353e-03 3.7744902e-02 2.7765487e-03 3.5342216e-03 5.1716679e-01\n",
      " 1.0149797e-03 2.6509354e-03 2.1163236e-02 3.7213813e-03 3.3706301e-04\n",
      " 2.0696402e-01 8.7072735e-04 1.7929668e-04 1.7534869e-04 5.1695883e-04\n",
      " 1.2294047e-02 2.5525226e-04 4.3845098e-03 1.2397887e-02 2.2270263e-03\n",
      " 9.8315836e-04 6.5112673e-02 5.0199660e-04 2.1381010e-03 2.5580760e-02\n",
      " 2.0060504e-03 1.6590815e-02 1.9050973e-03 2.2539773e-04 2.2269508e-03\n",
      " 1.1540848e-02] \n",
      " 0.9254908\n",
      "p [[0.03629537 0.00750939 0.01001252 0.00250313 0.00500626 0.00125156]\n",
      " [0.01251564 0.         0.01501877 0.0350438  0.00500626 0.00625782]\n",
      " [0.01001252 0.04630788 0.         0.56070088 0.00375469 0.00876095]\n",
      " [0.00250313 0.         0.0175219  0.         0.10262829 0.00250313]\n",
      " [0.02002503 0.0212766  0.0212766  0.         0.         0.02252816]\n",
      " [0.00250313 0.01877347 0.00250313 0.         0.         0.        ]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n",
      "prediction:\n",
      " [2.6532674e-02 5.2072010e-03 1.8703360e-03 2.4087441e-03 7.6516448e-03\n",
      " 6.9116725e-04 2.7465101e-02 5.5541669e-04 1.4363186e-02 7.9460097e-03\n",
      " 4.4260543e-02 5.2286508e-03 1.3320089e-02 6.5949567e-02 2.7472095e-04\n",
      " 5.3935662e-02 1.5255793e-02 3.4686162e-03 2.9021879e-03 3.9976579e-03\n",
      " 3.8069513e-02 1.5401706e-04 3.0235332e-01 4.2379042e-03 2.9638162e-02\n",
      " 1.2908457e-01 4.9234489e-03 9.1791234e-04 7.9565763e-04 1.0998235e-01\n",
      " 4.6011708e-03 4.0057506e-02 1.0557593e-02 2.1063064e-03 8.7194350e-03\n",
      " 1.0516327e-02] \n",
      " -0.9902353\n",
      "p [[4.63078849e-02 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [5.25657071e-02 0.00000000e+00 1.25156446e-13 7.63454318e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.00250313e-02 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 7.50938673e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.00125156e-02]\n",
      " [1.25156446e-13 1.25156446e-13 7.13391740e-01 0.00000000e+00\n",
      "  0.00000000e+00 2.00250313e-02]\n",
      " [1.25156446e-13 5.38172716e-02 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [5.08788833e-03 3.99620412e-03 2.23839434e-05 2.13010376e-03\n",
      " 5.86315384e-03 9.59804820e-05 1.96743861e-01 3.78849596e-04\n",
      " 3.47968340e-02 9.05145146e-03 4.10207324e-02 7.29242293e-03\n",
      " 1.53676607e-03 1.61784366e-04 8.62597790e-06 1.19164184e-01\n",
      " 3.49118462e-04 1.60447002e-04 1.01009653e-04 8.36777544e-05\n",
      " 3.52091459e-03 3.45687454e-06 1.10850888e-04 8.31249286e-04\n",
      " 9.93443094e-03 1.16052590e-02 5.21849084e-04 3.44810169e-03\n",
      " 3.73771938e-04 5.04638731e-01 1.97322879e-04 2.34410372e-02\n",
      " 6.56809891e-03 6.06233334e-05 5.25184395e-03 1.44713733e-03] \n",
      " 0.8479192\n",
      "p [[0.0212766  0.00500626 0.00250313 0.00500626 0.00500626 0.00625782]\n",
      " [0.02002503 0.         0.01627034 0.00500626 0.03754693 0.01001252]\n",
      " [0.00876095 0.06257822 0.         0.         0.01251564 0.00250313]\n",
      " [0.00500626 0.         0.0563204  0.         0.25782228 0.00375469]\n",
      " [0.01877347 0.12765957 0.         0.         0.         0.25031289]\n",
      " [0.00375469 0.05006258 0.00625782 0.         0.         0.        ]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n",
      "prediction:\n",
      " [0.0198663  0.0132691  0.00208079 0.00287284 0.00783511 0.00061577\n",
      " 0.01513236 0.00245517 0.07837578 0.01219146 0.05625421 0.00722967\n",
      " 0.00986993 0.00933458 0.00150464 0.12183893 0.05529723 0.0139788\n",
      " 0.00959994 0.01163456 0.04412889 0.00212163 0.07081364 0.00238431\n",
      " 0.06909444 0.1127801  0.00858735 0.00433335 0.00366042 0.0581569\n",
      " 0.0064211  0.12849799 0.007261   0.00461283 0.01762495 0.00828409] \n",
      " -0.9815484\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [9.76220275e-02 0.00000000e+00 3.37922403e-02 5.00625782e-03\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [5.00625782e-03 1.87734668e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.19774718e-01]\n",
      " [1.25156446e-13 1.00125156e-02 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1. -1. -1.]]\n",
      "1 won\n",
      "game 249 completed in 27.137872219085693 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7208617 entropy 2.2075431\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.705695 entropy 2.2108185\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6795619 entropy 2.2110746\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6506104 entropy 2.2089953\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6225054 entropy 2.2054033\n",
      "kl 0.014501753\n",
      "completed in 0.1768510341644287 s\n",
      "game 250 completed in 7.336590051651001 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.708736 entropy 2.1711829\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6909401 entropy 2.166833\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.665658 entropy 2.1609507\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6379821 entropy 2.1540744\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6114545 entropy 2.1471443\n",
      "kl 0.014354074\n",
      "completed in 0.20946192741394043 s\n",
      "game 251 completed in 5.863489151000977 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7685 entropy 2.182086\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7450538 entropy 2.1766946\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7159095 entropy 2.1721814\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6889672 entropy 2.1696348\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6587172 entropy 2.168832\n",
      "kl 0.015912972\n",
      "completed in 0.16933584213256836 s\n",
      "game 252 completed in 5.900773048400879 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6924703 entropy 2.0935597\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6608477 entropy 2.0966501\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6164868 entropy 2.1019278\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5781884 entropy 2.1060293\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.545505 entropy 2.106359\n",
      "kl 0.019439355\n",
      "completed in 0.1939849853515625 s\n",
      "game 253 completed in 8.850069999694824 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.760694 entropy 2.1130562\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7410543 entropy 2.1071498\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.706931 entropy 2.1020374\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.667174 entropy 2.098999\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.631736 entropy 2.098834\n",
      "kl 0.013995122\n",
      "completed in 0.21088004112243652 s\n",
      "game 254 completed in 14.862706899642944 s 18 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.8147044 entropy 2.1759517\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.8023806 entropy 2.181739\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7782767 entropy 2.1889608\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.750302 entropy 2.196193\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.7227132 entropy 2.202309\n",
      "kl 0.017863765\n",
      "completed in 0.17251825332641602 s\n",
      "game 255 completed in 5.872922897338867 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6774046 entropy 2.0839891\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6675653 entropy 2.0880814\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6475773 entropy 2.0921803\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6190867 entropy 2.0960302\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5861006 entropy 2.0991786\n",
      "kl 0.013610674\n",
      "completed in 0.1698780059814453 s\n",
      "game 256 completed in 10.306074857711792 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6368184 entropy 2.1282034\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6256692 entropy 2.1263618\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6020432 entropy 2.1222153\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5727346 entropy 2.1163483\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5434556 entropy 2.109582\n",
      "kl 0.014749399\n",
      "completed in 0.18094706535339355 s\n",
      "game 257 completed in 9.123114109039307 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7093637 entropy 2.1549907\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7018757 entropy 2.1519594\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6841173 entropy 2.152897\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6601465 entropy 2.1567972\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6348753 entropy 2.1615136\n",
      "kl 0.015509672\n",
      "completed in 0.16743183135986328 s\n",
      "game 258 completed in 8.9113187789917 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7684379 entropy 2.1587222\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7568076 entropy 2.1625133\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7354963 entropy 2.1648972\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.7091758 entropy 2.1659398\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6823175 entropy 2.1659818\n",
      "kl 0.013628095\n",
      "completed in 0.17211389541625977 s\n",
      "game 259 completed in 12.080806970596313 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7120664 entropy 2.1855645\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6944933 entropy 2.1853044\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6674104 entropy 2.1842852\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6369383 entropy 2.1827493\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.60619 entropy 2.1810546\n",
      "kl 0.013946184\n",
      "completed in 0.17053890228271484 s\n",
      "game 260 completed in 8.956876993179321 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6434176 entropy 2.0850155\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6308343 entropy 2.0862274\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6048033 entropy 2.0888214\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5751336 entropy 2.0920587\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5465739 entropy 2.0945852\n",
      "kl 0.0131975375\n",
      "completed in 0.17454195022583008 s\n",
      "game 261 completed in 5.975123882293701 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5590186 entropy 2.130683\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5506325 entropy 2.1298733\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5348153 entropy 2.126131\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.512686 entropy 2.1197908\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4845467 entropy 2.1112223\n",
      "kl 0.007479633\n",
      "completed in 0.1706540584564209 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 262 completed in 9.32127594947815 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5856566 entropy 2.1084619\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5669909 entropy 2.0955787\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5377288 entropy 2.0841186\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5082974 entropy 2.07591\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.477091 entropy 2.0709355\n",
      "kl 0.0265444\n",
      "completed in 0.16678404808044434 s\n",
      "game 263 completed in 13.857203960418701 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6282432 entropy 2.0875502\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6045766 entropy 2.0907617\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5723045 entropy 2.0970197\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5362947 entropy 2.1022553\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.498373 entropy 2.1046157\n",
      "kl 0.017068835\n",
      "completed in 0.16910696029663086 s\n",
      "game 264 completed in 6.022594690322876 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5725777 entropy 2.0785737\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5450716 entropy 2.0802217\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.508952 entropy 2.0839102\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4680338 entropy 2.0903928\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4323087 entropy 2.098304\n",
      "kl 0.025663195\n",
      "completed in 0.17047500610351562 s\n",
      "game 265 completed in 10.746092081069946 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6043792 entropy 2.138039\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5671928 entropy 2.14009\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5286582 entropy 2.1389065\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4914994 entropy 2.1364179\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4538155 entropy 2.1318378\n",
      "kl 0.024928669\n",
      "completed in 0.16824769973754883 s\n",
      "game 266 completed in 6.773988723754883 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.696392 entropy 2.1141105\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6786602 entropy 2.1098468\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6398406 entropy 2.1058795\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5959384 entropy 2.1012735\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.553714 entropy 2.096983\n",
      "kl 0.030396817\n",
      "completed in 0.15937519073486328 s\n",
      "game 267 completed in 7.911448955535889 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.555583 entropy 2.060761\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5388691 entropy 2.0575626\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5123625 entropy 2.0574813\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4792223 entropy 2.060286\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.447095 entropy 2.0646133\n",
      "kl 0.023505393\n",
      "completed in 0.17681002616882324 s\n",
      "game 268 completed in 7.662718772888184 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6561964 entropy 2.0837975\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.627341 entropy 2.0952811\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.589468 entropy 2.1080103\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5473056 entropy 2.1171362\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5067139 entropy 2.1195297\n",
      "kl 0.030487943\n",
      "completed in 0.17225098609924316 s\n",
      "game 269 completed in 7.415974140167236 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.622994 entropy 2.1474435\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6028895 entropy 2.1375995\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5767183 entropy 2.1240206\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5488052 entropy 2.110548\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5172036 entropy 2.0995393\n",
      "kl 0.025736675\n",
      "completed in 0.20110392570495605 s\n",
      "game 270 completed in 7.374885082244873 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6055083 entropy 2.0864916\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.578937 entropy 2.08884\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5443447 entropy 2.097124\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5102615 entropy 2.1074948\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.478071 entropy 2.116156\n",
      "kl 0.02313349\n",
      "completed in 0.1907649040222168 s\n",
      "game 271 completed in 9.968987941741943 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.528438 entropy 2.1083448\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5106595 entropy 2.1123471\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4856298 entropy 2.1156197\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4577732 entropy 2.1178703\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4282408 entropy 2.1175275\n",
      "kl 0.026417995\n",
      "completed in 0.1639118194580078 s\n",
      "game 272 completed in 9.874898910522461 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5645094 entropy 2.1302297\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.546713 entropy 2.120023\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5213733 entropy 2.1051254\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4953365 entropy 2.0884564\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4707382 entropy 2.0728803\n",
      "kl 0.027793165\n",
      "completed in 0.1921529769897461 s\n",
      "game 273 completed in 10.817490816116333 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6875727 entropy 2.082723\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.669076 entropy 2.0784533\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6310873 entropy 2.08258\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5867147 entropy 2.0921881\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5497541 entropy 2.1026993\n",
      "kl 0.023522219\n",
      "completed in 0.18485808372497559 s\n",
      "game 274 completed in 5.9320948123931885 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6068048 entropy 2.0547297\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.586126 entropy 2.0650034\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5520902 entropy 2.0753446\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5132277 entropy 2.0832825\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.480422 entropy 2.0860682\n",
      "kl 0.025855677\n",
      "completed in 0.22847795486450195 s\n",
      "game 275 completed in 10.74577784538269 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7156792 entropy 2.1363223\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.697345 entropy 2.132483\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6686642 entropy 2.1297824\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.634665 entropy 2.1288953\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6001139 entropy 2.129055\n",
      "kl 0.01619305\n",
      "completed in 0.18496489524841309 s\n",
      "game 276 completed in 8.423850059509277 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6628957 entropy 2.110102\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6245553 entropy 2.1092997\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5856082 entropy 2.1090498\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5451193 entropy 2.1098223\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5015867 entropy 2.1104736\n",
      "kl 0.038536638\n",
      "completed in 0.16984295845031738 s\n",
      "game 277 completed in 8.17136836051941 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6756072 entropy 2.1433651\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6514049 entropy 2.1472106\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6190403 entropy 2.152701\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5862985 entropy 2.1580982\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.550432 entropy 2.1618915\n",
      "kl 0.028441831\n",
      "completed in 0.18999791145324707 s\n",
      "game 278 completed in 9.754729986190796 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6972902 entropy 2.1838157\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6690855 entropy 2.1876798\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6228936 entropy 2.1925812\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.576046 entropy 2.1990938\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5369384 entropy 2.2051995\n",
      "kl 0.033690993\n",
      "completed in 0.16457772254943848 s\n",
      "game 279 completed in 6.106151103973389 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7279673 entropy 2.1895149\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.691387 entropy 2.18504\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6349583 entropy 2.1739597\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5903347 entropy 2.161574\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5598915 entropy 2.15205\n",
      "kl 0.042535365\n",
      "completed in 0.2002561092376709 s\n",
      "game 280 completed in 7.549367666244507 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6256316 entropy 2.1018848\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6093829 entropy 2.1027203\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5836282 entropy 2.1045856\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5521073 entropy 2.1065893\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5189633 entropy 2.1079473\n",
      "kl 0.012452077\n",
      "completed in 0.16424798965454102 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 281 completed in 11.031743049621582 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6013415 entropy 2.1233885\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5847204 entropy 2.1251657\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.55741 entropy 2.1267004\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5261445 entropy 2.1269054\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4936347 entropy 2.1248481\n",
      "kl 0.015336077\n",
      "completed in 0.20610427856445312 s\n",
      "game 282 completed in 8.3087899684906 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.631807 entropy 2.0763586\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6116664 entropy 2.072174\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5789921 entropy 2.0685287\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5413744 entropy 2.0658119\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5056136 entropy 2.0641174\n",
      "kl 0.026286768\n",
      "completed in 0.1688098907470703 s\n",
      "game 283 completed in 5.951807975769043 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6737008 entropy 2.1092672\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6612983 entropy 2.1119645\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6390564 entropy 2.116568\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6110482 entropy 2.1226041\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5810905 entropy 2.1292207\n",
      "kl 0.013451697\n",
      "completed in 0.1565382480621338 s\n",
      "game 284 completed in 12.397695302963257 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.673795 entropy 2.1501324\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6529024 entropy 2.1551733\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6237924 entropy 2.1586964\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.593194 entropy 2.1599097\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5640469 entropy 2.1585464\n",
      "kl 0.019475073\n",
      "completed in 0.16820287704467773 s\n",
      "game 285 completed in 7.542988061904907 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.64791 entropy 2.147048\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6305418 entropy 2.1420894\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6059835 entropy 2.135669\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5788505 entropy 2.1290026\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5506988 entropy 2.122812\n",
      "kl 0.016102465\n",
      "completed in 0.18666601181030273 s\n",
      "game 286 completed in 8.06600284576416 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6217082 entropy 2.0877056\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6081848 entropy 2.083516\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5864832 entropy 2.0805967\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5622003 entropy 2.0785475\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5345838 entropy 2.0765662\n",
      "kl 0.009212563\n",
      "completed in 0.1703498363494873 s\n",
      "game 287 completed in 10.470333814620972 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.61734 entropy 2.0965781\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5972133 entropy 2.096254\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5623345 entropy 2.0970142\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5245218 entropy 2.0984392\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4898136 entropy 2.0999274\n",
      "kl 0.025504176\n",
      "completed in 0.1705610752105713 s\n",
      "game 288 completed in 9.84748911857605 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6862085 entropy 2.1497765\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.664777 entropy 2.1509666\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.63342 entropy 2.1528826\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5972872 entropy 2.1550188\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5611207 entropy 2.1567786\n",
      "kl 0.014898339\n",
      "completed in 0.22084975242614746 s\n",
      "game 289 completed in 13.788679838180542 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.63537 entropy 2.1297436\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6080637 entropy 2.1252444\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5700703 entropy 2.116219\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5339355 entropy 2.1063995\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.50111 entropy 2.0969088\n",
      "kl 0.02653995\n",
      "completed in 0.17094802856445312 s\n",
      "game 290 completed in 5.96744966506958 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.651146 entropy 2.088615\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6291857 entropy 2.083057\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5987346 entropy 2.081159\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5663745 entropy 2.081645\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.532265 entropy 2.082902\n",
      "kl 0.029055275\n",
      "completed in 0.17137479782104492 s\n",
      "game 291 completed in 5.914278984069824 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6764793 entropy 2.0937738\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6597545 entropy 2.0998526\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.625598 entropy 2.1095743\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5791476 entropy 2.1190023\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5302265 entropy 2.1251132\n",
      "kl 0.029621819\n",
      "completed in 0.1679978370666504 s\n",
      "game 292 completed in 8.574287176132202 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6142724 entropy 2.1214914\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5890238 entropy 2.121087\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5537436 entropy 2.120077\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5184712 entropy 2.1209326\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4868083 entropy 2.123981\n",
      "kl 0.0261801\n",
      "completed in 0.17151689529418945 s\n",
      "game 293 completed in 7.550785064697266 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.661685 entropy 2.061718\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.63309 entropy 2.066999\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5856242 entropy 2.0704622\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5414193 entropy 2.071478\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5017118 entropy 2.0696597\n",
      "kl 0.023034483\n",
      "completed in 0.16517877578735352 s\n",
      "game 294 completed in 7.457120895385742 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5930724 entropy 2.1091073\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.572524 entropy 2.1061637\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5380838 entropy 2.10164\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.502106 entropy 2.0972002\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4685416 entropy 2.0935447\n",
      "kl 0.024371803\n",
      "completed in 0.19727587699890137 s\n",
      "game 295 completed in 7.418828010559082 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7002826 entropy 2.142408\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6747022 entropy 2.1413105\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.636202 entropy 2.1400437\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.592056 entropy 2.1380634\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5455375 entropy 2.1340518\n",
      "kl 0.031371396\n",
      "completed in 0.17613577842712402 s\n",
      "game 296 completed in 9.95514702796936 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6649847 entropy 2.1061263\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6327868 entropy 2.1001267\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5901124 entropy 2.0932124\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.556531 entropy 2.08509\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5292268 entropy 2.0762048\n",
      "kl 0.0371069\n",
      "completed in 0.1795651912689209 s\n",
      "game 297 completed in 6.47170877456665 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6214626 entropy 2.0366595\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6032035 entropy 2.0285997\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.571868 entropy 2.022911\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5359762 entropy 2.021041\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4975643 entropy 2.023366\n",
      "kl 0.024935534\n",
      "completed in 0.2117140293121338 s\n",
      "game 298 completed in 9.142079830169678 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6867754 entropy 2.106493\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.663593 entropy 2.1147532\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6315322 entropy 2.1246538\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6011012 entropy 2.1340454\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5728889 entropy 2.1412075\n",
      "kl 0.042049147\n",
      "completed in 0.18171405792236328 s\n",
      "prediction:\n",
      " [0.00275111 0.01644262 0.00394445 0.00903908 0.00418257 0.00305436\n",
      " 0.01419006 0.04369417 0.07049675 0.06479533 0.01043853 0.00843944\n",
      " 0.00651883 0.05020381 0.07910464 0.04256816 0.0569437  0.0076146\n",
      " 0.00739452 0.06790984 0.02353785 0.08325102 0.05156133 0.00738632\n",
      " 0.0054375  0.00947623 0.05729128 0.09418562 0.03937317 0.01647517\n",
      " 0.00431462 0.0061632  0.00896749 0.00458949 0.01353632 0.00472692] \n",
      " -0.53829193\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.81476846e-01 1.53942428e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.67709637e-01 4.96871089e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [4.9202732e-04 5.2733999e-04 1.6968186e-03 7.0656795e-04 1.1985108e-03\n",
      " 1.8096420e-04 4.7400911e-04 6.7983097e-03 3.6661613e-03 3.7877053e-02\n",
      " 1.9623837e-04 7.0427795e-04 1.8165377e-03 2.1478762e-03 1.0774465e-02\n",
      " 3.5906377e-01 4.6420481e-02 2.7092596e-04 4.7018312e-04 8.5663453e-02\n",
      " 3.4369740e-01 8.3138691e-03 3.2637394e-03 1.3117720e-03 5.0965056e-04\n",
      " 2.3012228e-04 6.5718897e-02 4.0166206e-03 5.2905721e-03 4.9803592e-04\n",
      " 4.4111945e-04 1.0997974e-03 1.3481042e-03 1.4853830e-03 4.8096839e-04\n",
      " 1.1480899e-03] \n",
      " 0.51708883\n",
      "p [[0.00250313 0.01501877 0.00375469 0.00876095 0.00375469 0.00250313]\n",
      " [0.12891114 0.07634543 0.04630788 0.03754693 0.00500626 0.00500626]\n",
      " [0.00375469 0.04380476 0.23404255 0.02252816 0.03379224 0.00625782]\n",
      " [0.00625782 0.04380476 0.01126408 0.         0.05131414 0.00625782]\n",
      " [0.00375469 0.00500626 0.02628285 0.08760951 0.02503129 0.01501877]\n",
      " [0.00500626 0.00375469 0.00625782 0.00250313 0.01627034 0.00500626]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00229059 0.00127774 0.00153948 0.00062714 0.00244576 0.00069908\n",
      " 0.00254966 0.00520671 0.00359883 0.02725783 0.00077289 0.00301436\n",
      " 0.00690431 0.0389677  0.00099589 0.03764441 0.37631172 0.0036734\n",
      " 0.00364565 0.34890524 0.03091917 0.00053488 0.03368684 0.00456185\n",
      " 0.00378705 0.00073342 0.02837301 0.00560384 0.00648618 0.00177144\n",
      " 0.00148495 0.00363161 0.00065694 0.00187009 0.0021421  0.00542839] \n",
      " -0.8916674\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.12640801e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 2.22778473e-01\n",
      "  1.12640801e-02 1.25156446e-13]\n",
      " [1.25156446e-13 2.62828536e-02 7.04630788e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.00250313e-02 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00445621 0.00328424 0.00520629 0.00550717 0.00878631 0.00643479\n",
      " 0.00372684 0.00749388 0.00955985 0.13561173 0.00751141 0.0048308\n",
      " 0.02707769 0.14136976 0.00295285 0.01501546 0.00947253 0.00187915\n",
      " 0.00145342 0.00918179 0.0102428  0.00060953 0.27766025 0.02239502\n",
      " 0.00621935 0.00565285 0.17349972 0.01000076 0.01573264 0.0150147\n",
      " 0.00506463 0.01141629 0.00834408 0.00559294 0.0040704  0.01767199] \n",
      " 0.33527234\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.01877347 0.00125156 0.00125156]\n",
      " [0.00125156 0.0175219  0.         0.01126408 0.15644556 0.00125156]\n",
      " [0.00125156 0.74092616 0.         0.         0.01376721 0.00125156]\n",
      " [0.00250313 0.00125156 0.00750939 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.26967428e-03 2.04760605e-03 8.26994481e-04 4.72184329e-04\n",
      " 1.05835255e-02 3.84806626e-04 5.31373313e-04 7.51643628e-03\n",
      " 1.04132737e-03 1.51291355e-01 3.20654304e-04 1.60617251e-02\n",
      " 2.78759569e-01 5.01960516e-03 4.79162962e-04 6.55750325e-03\n",
      " 3.50171514e-03 8.67341761e-04 1.34500477e-03 1.21652405e-03\n",
      " 6.24649320e-03 2.50016543e-04 3.16491956e-03 2.71449208e-01\n",
      " 3.82574573e-02 4.52544715e-04 1.42254949e-01 1.10666733e-03\n",
      " 1.18877739e-02 1.46815833e-03 9.56673583e-04 2.47653462e-02\n",
      " 3.11978132e-04 1.58634235e-03 1.36353215e-03 4.38399334e-03] \n",
      " -0.1794225\n",
      "p [[2.50312891e-03 1.25156446e-13 3.75469337e-03 2.50312891e-03\n",
      "  3.75469337e-03 2.50312891e-03]\n",
      " [1.62703379e-02 1.50187735e-02 6.25782228e-03 2.49061327e-01\n",
      "  2.50312891e-03 2.50312891e-03]\n",
      " [7.50938673e-03 3.25406758e-02 0.00000000e+00 2.50312891e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.09261577e-01 1.66458073e-01]\n",
      " [2.50312891e-03 1.25156446e-03 4.25531915e-02 1.25156446e-03\n",
      "  3.75469337e-03 2.50312891e-03]\n",
      " [2.50312891e-03 2.50312891e-03 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-03 8.76095119e-03]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00521276 0.02024924 0.01244252 0.01221864 0.00675543 0.00553194\n",
      " 0.01215371 0.02748673 0.01798782 0.08740534 0.01290947 0.0045536\n",
      " 0.03073426 0.00733117 0.00323574 0.01097067 0.08366892 0.03907444\n",
      " 0.05161057 0.05816276 0.00419818 0.002037   0.02181839 0.01694469\n",
      " 0.01090878 0.01139548 0.18300362 0.02844042 0.02779712 0.07022841\n",
      " 0.00929247 0.01755776 0.02400384 0.02597927 0.01733705 0.01936193] \n",
      " -0.5916269\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.04881101 0.00125156 0.00125156]\n",
      " [0.0387985  0.00125156 0.         0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.83479349]\n",
      " [0.02252816 0.00125156 0.01877347 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00500626 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00368241 0.01767383 0.00979412 0.00275617 0.01570779 0.00236822\n",
      " 0.00949579 0.04283764 0.0081436  0.13550054 0.00167452 0.06664535\n",
      " 0.02852945 0.04032364 0.00098179 0.04131015 0.03218071 0.01355126\n",
      " 0.03377726 0.01130757 0.02665353 0.00078139 0.0274602  0.02493289\n",
      " 0.10948101 0.0020083  0.11848365 0.0056005  0.05087755 0.02007688\n",
      " 0.00617221 0.04683819 0.00271912 0.01595331 0.0143637  0.00935597] \n",
      " -0.66390836\n",
      "p [[0.00876095 0.01126408 0.00750939 0.00375469 0.00625782 0.00375469]\n",
      " [0.04130163 0.03003755 0.01251564 0.56445557 0.00250313 0.00250313]\n",
      " [0.01376721 0.00876095 0.         0.00250313 0.03128911 0.01376721]\n",
      " [0.01501877 0.         0.         0.         0.         0.        ]\n",
      " [0.00750939 0.00625782 0.10513141 0.01126408 0.00876095 0.02628285]\n",
      " [0.00876095 0.00876095 0.00876095 0.01001252 0.00876095 0.01001252]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.42312658e-03 2.83391271e-02 2.71022227e-02 1.73011962e-02\n",
      " 4.33912734e-03 4.26478870e-03 7.83231389e-03 2.83713061e-02\n",
      " 1.70238558e-02 5.38967131e-03 8.66733678e-03 6.33715978e-03\n",
      " 5.95103391e-02 1.80225093e-02 2.23448806e-04 6.54318486e-04\n",
      " 1.75431684e-01 4.70392592e-02 1.06035143e-01 1.27311051e-01\n",
      " 3.02209781e-04 1.33988186e-04 3.64120603e-02 3.22743282e-02\n",
      " 1.23517253e-02 7.27715623e-03 1.32031972e-02 2.39635650e-02\n",
      " 1.92186106e-02 3.56153995e-02 9.62177664e-03 1.19982995e-02\n",
      " 2.62557771e-02 4.58558500e-02 1.76934004e-02 1.42038604e-02] \n",
      " 0.933297\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00125156 0.00375469 0.00125156]\n",
      " [0.00125156 0.01001252 0.00125156 0.         0.00125156 0.01376721]\n",
      " [0.00750939 0.00750939 0.         0.8660826  0.00375469 0.00125156]\n",
      " [0.00625782 0.         0.         0.         0.         0.        ]\n",
      " [0.01877347 0.00125156 0.01877347 0.00125156 0.00750939 0.00876095]\n",
      " [0.00125156 0.00625782 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00408465 0.07726264 0.00804821 0.00380452 0.01795307 0.01033723\n",
      " 0.019769   0.01743961 0.05845719 0.0594663  0.00224865 0.08584767\n",
      " 0.03348616 0.00841272 0.00102586 0.00019041 0.02324331 0.08795467\n",
      " 0.09923547 0.00846259 0.00018626 0.00054924 0.00538361 0.04349021\n",
      " 0.07391234 0.00149751 0.0434975  0.03346955 0.01811023 0.03963892\n",
      " 0.01374845 0.02680256 0.00502892 0.02201588 0.02927097 0.01666825] \n",
      " 0.04486645\n",
      "p [[0.00876095 0.02628285 0.02377972 0.01001252 0.00125156 0.00125156]\n",
      " [0.00750939 0.04630788 0.01001252 0.         0.00125156 0.00125156]\n",
      " [0.0212766  0.53566959 0.         0.         0.09011264 0.03128911]\n",
      " [0.02002503 0.         0.         0.         0.         0.        ]\n",
      " [0.00375469 0.00125156 0.01627034 0.01001252 0.02503129 0.01877347]\n",
      " [0.01251564 0.01251564 0.01627034 0.01376721 0.01251564 0.0212766 ]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [4.6840278e-03 6.4613141e-02 2.4673678e-02 4.6678139e-03 9.8886723e-03\n",
      " 1.6038894e-03 3.4164585e-02 1.6295316e-02 1.6286826e-01 1.4500647e-03\n",
      " 8.5270760e-04 7.6293293e-03 4.8943092e-03 3.3613160e-04 2.0679575e-04\n",
      " 3.9806582e-05 4.1325178e-02 1.2872241e-02 2.7558448e-02 5.1297635e-02\n",
      " 4.1584270e-05 4.7892925e-05 7.9474418e-04 5.2581285e-03 1.0574269e-02\n",
      " 1.5348181e-03 1.5248243e-03 2.6604185e-01 1.1944242e-02 8.4615499e-02\n",
      " 5.3542270e-03 6.5473113e-03 7.4419640e-03 8.3574958e-02 3.2712925e-02\n",
      " 1.0068717e-02] \n",
      " -0.18350689\n",
      "p [[1.25156446e-03 2.12765957e-02 7.50938673e-03 2.25281602e-02\n",
      "  2.12765957e-02 1.50187735e-02]\n",
      " [1.12640801e-02 1.62703379e-02 1.37672090e-02 0.00000000e+00\n",
      "  3.75469337e-03 3.87984981e-02]\n",
      " [1.37672090e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.00625782e-03 6.42052566e-01]\n",
      " [2.25281602e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.25281602e-02 1.25156446e-13 5.00625782e-03 6.25782228e-03\n",
      "  7.50938673e-03 2.75344180e-02]\n",
      " [5.00625782e-03 1.50187735e-02 1.25156446e-03 7.50938673e-03\n",
      "  1.75219024e-02 2.87859825e-02]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1. -1.  0. -1.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.05698316e-03 4.87852581e-02 7.29849003e-03 8.73476092e-04\n",
      " 1.13021228e-02 2.99197971e-03 7.39089698e-02 1.01584112e-02\n",
      " 7.71894492e-03 1.34941684e-02 1.08692585e-03 3.47323984e-01\n",
      " 1.59424935e-02 4.88177640e-04 8.93403630e-05 3.23300701e-05\n",
      " 1.58162540e-04 4.66313504e-04 3.07519594e-03 7.60415933e-05\n",
      " 2.64518367e-05 9.45758366e-05 4.79513110e-04 4.67432663e-03\n",
      " 2.93134719e-01 1.45370071e-03 1.14509054e-02 3.23336478e-03\n",
      " 4.71969368e-03 7.35046640e-02 7.88204558e-03 1.37429405e-02\n",
      " 1.41887111e-03 1.00221299e-02 1.47278057e-02 1.01066027e-02] \n",
      " -0.9060367\n",
      "p [[0.00625782 0.05256571 0.02002503 0.00125156 0.00625782 0.00375469]\n",
      " [0.04881101 0.03629537 0.10888611 0.         0.00125156 0.00250313]\n",
      " [0.00125156 0.         0.         0.         0.281602   0.        ]\n",
      " [0.0175219  0.         0.         0.         0.         0.        ]\n",
      " [0.00500626 0.02377972 0.01001252 0.17396746 0.01001252 0.05256571]\n",
      " [0.0175219  0.01376721 0.00125156 0.06382979 0.03254068 0.00750939]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.9379623e-03 9.3351021e-02 5.4627467e-02 6.7925747e-03 2.2553304e-02\n",
      " 1.5832108e-03 3.0243043e-02 4.9513988e-02 7.7555403e-02 9.6545722e-03\n",
      " 2.9560223e-03 3.0314603e-03 5.5125214e-02 2.2424251e-04 8.4376443e-05\n",
      " 4.2220159e-05 2.6915414e-04 1.6608348e-02 4.7918081e-02 5.1286415e-04\n",
      " 4.3634962e-05 2.9304600e-05 3.3668021e-04 4.3393064e-02 5.2953069e-03\n",
      " 3.3670159e-03 5.8490299e-03 1.2251455e-01 3.0150514e-02 5.0590180e-02\n",
      " 4.0878300e-03 3.7424188e-02 8.2798647e-03 1.7028877e-01 3.6970973e-02\n",
      " 5.7946965e-03] \n",
      " 0.22755177\n",
      "p [[1.25156446e-13 5.00625782e-03 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [8.76095119e-03 1.25156446e-03 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 9.26157697e-01]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.00375469e-02 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.62703379e-02]\n",
      " [1.25156446e-03 1.25156446e-03 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-03]]\n",
      "move 11\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [7.4145449e-03 4.6737805e-02 2.6521783e-03 2.6159366e-03 9.0019563e-03\n",
      " 4.1653603e-02 2.9762658e-01 2.4452126e-02 1.0730823e-02 3.6055472e-02\n",
      " 3.4140099e-03 3.9521467e-02 3.4271173e-02 9.1768824e-04 7.1207702e-05\n",
      " 5.7093373e-05 2.0280622e-04 8.8144792e-04 7.7611487e-03 4.2410593e-05\n",
      " 3.6254951e-05 1.1111422e-04 6.1660813e-04 5.7674916e-03 3.0739352e-02\n",
      " 4.6030781e-03 1.0355716e-02 7.5240815e-03 1.2102643e-02 2.3810428e-01\n",
      " 5.4244380e-02 1.1839808e-02 2.4955501e-03 3.0073659e-03 3.7904643e-02\n",
      " 1.4466268e-02] \n",
      " 0.9280117\n",
      "p [[0.00750939 0.09386733 0.06132666 0.01001252 0.03003755 0.01001252]\n",
      " [0.02753442 0.05381727 0.06007509 0.         0.00125156 0.        ]\n",
      " [0.03629537 0.         0.         0.         0.         0.        ]\n",
      " [0.02878598 0.         0.         0.         0.         0.        ]\n",
      " [0.01627034 0.02878598 0.01877347 0.11639549 0.07259074 0.09762203]\n",
      " [0.01126408 0.04005006 0.00375469 0.14142678 0.02878598 0.00375469]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]]\n",
      "prediction:\n",
      " [6.9498769e-03 1.0016290e-01 1.4357065e-02 8.6191529e-03 3.3509351e-02\n",
      " 3.1042846e-03 5.2304859e-03 2.8598012e-02 1.4374129e-01 1.1216800e-02\n",
      " 3.2791533e-03 3.4519809e-03 7.8855984e-02 1.5650978e-04 5.3873919e-05\n",
      " 5.3402237e-05 2.6794148e-04 1.9382548e-02 6.4787574e-02 5.5691641e-04\n",
      " 3.2515996e-05 1.9816252e-05 2.0523186e-04 5.9836999e-02 5.6984988e-03\n",
      " 3.2440424e-03 5.0655110e-03 1.7370267e-01 1.7071320e-02 8.1955930e-03\n",
      " 4.8890100e-03 5.4292306e-02 1.1361328e-02 5.3304143e-02 5.5988692e-02\n",
      " 2.0757386e-02] \n",
      " 0.9567039\n",
      "p [[1.25156446e-13 1.37672090e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.11389237e-01]\n",
      " [1.82728411e-01 1.25156446e-03 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 0.00000000e+00]\n",
      " [1.00125156e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.75469337e-03 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-03 6.43304130e-01]\n",
      " [1.87734668e-02 1.25156446e-03 1.25156446e-13 0.00000000e+00\n",
      "  6.25782228e-03 1.25156446e-03]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]]\n",
      "-1 won\n",
      "game 299 completed in 30.41400980949402 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6673079 entropy 2.1216578\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6494594 entropy 2.1236918\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6212885 entropy 2.1224983\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.587522 entropy 2.1189642\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5520554 entropy 2.1136966\n",
      "kl 0.020125374\n",
      "completed in 0.16574716567993164 s\n",
      "training pipeline completed in 2720.5574028491974 s\n"
     ]
    }
   ],
   "source": [
    "k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "700781b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.save('n2-600.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d706f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 12.800676107406616 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6192636 entropy 2.073866\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6081326 entropy 2.0686808\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.584226 entropy 2.0655746\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5533473 entropy 2.0644102\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.52252 entropy 2.0648923\n",
      "kl 0.01311289\n",
      "completed in 0.1706070899963379 s\n",
      "game 1 completed in 8.838735103607178 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.764078 entropy 2.1017222\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7409296 entropy 2.1060333\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.7062967 entropy 2.11161\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6672606 entropy 2.1171317\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.630884 entropy 2.1217299\n",
      "kl 0.021925766\n",
      "completed in 0.17171502113342285 s\n",
      "game 2 completed in 6.216421127319336 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.640523 entropy 2.0735102\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.62565 entropy 2.0770202\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6016734 entropy 2.0790594\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5732734 entropy 2.0793383\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5430577 entropy 2.0778306\n",
      "kl 0.013457821\n",
      "completed in 0.16638803482055664 s\n",
      "game 3 completed in 6.087604284286499 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5764582 entropy 2.1116133\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5591755 entropy 2.106345\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.53211 entropy 2.0993268\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5001974 entropy 2.0912797\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4739552 entropy 2.0830882\n",
      "kl 0.018375829\n",
      "completed in 0.18265080451965332 s\n",
      "game 4 completed in 6.098304033279419 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6499915 entropy 2.1075027\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6389055 entropy 2.1047854\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6178873 entropy 2.1061459\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.590765 entropy 2.1108735\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5598388 entropy 2.117858\n",
      "kl 0.011032304\n",
      "completed in 0.1739037036895752 s\n",
      "game 5 completed in 11.641924142837524 s 14 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5837462 entropy 2.0726404\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5670161 entropy 2.0796494\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.539869 entropy 2.0832107\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.509416 entropy 2.082742\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4766781 entropy 2.0787234\n",
      "kl 0.012423761\n",
      "completed in 0.18358206748962402 s\n",
      "game 6 completed in 14.970607995986938 s 17 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.590118 entropy 2.0757737\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5750382 entropy 2.0685322\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5526078 entropy 2.0608525\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5302567 entropy 2.0544586\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5097983 entropy 2.0508997\n",
      "kl 0.010996617\n",
      "completed in 0.17148494720458984 s\n",
      "game 7 completed in 10.00208592414856 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7061882 entropy 2.0979207\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6865451 entropy 2.098728\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6553855 entropy 2.101811\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6207066 entropy 2.1058342\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5873034 entropy 2.1090844\n",
      "kl 0.014168756\n",
      "completed in 0.1775212287902832 s\n",
      "game 8 completed in 7.89171576499939 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6082356 entropy 2.0577502\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5979738 entropy 2.0599322\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5774117 entropy 2.0610929\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.552327 entropy 2.0601573\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5255082 entropy 2.0567384\n",
      "kl 0.00996275\n",
      "completed in 0.16655325889587402 s\n",
      "game 9 completed in 8.852528810501099 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.546785 entropy 2.0670114\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5257869 entropy 2.0581307\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5053194 entropy 2.048253\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4835 entropy 2.0401416\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.457055 entropy 2.035079\n",
      "kl 0.027108878\n",
      "completed in 0.16767477989196777 s\n",
      "game 10 completed in 7.841086149215698 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7089782 entropy 2.0949655\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6911428 entropy 2.0981874\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6608727 entropy 2.1076126\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6274807 entropy 2.1199002\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5968726 entropy 2.1317077\n",
      "kl 0.024617648\n",
      "completed in 0.1914970874786377 s\n",
      "game 11 completed in 10.551389932632446 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7319684 entropy 2.1034238\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6985116 entropy 2.1077113\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6574197 entropy 2.1070237\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6179068 entropy 2.1044934\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5792322 entropy 2.1009512\n",
      "kl 0.034323692\n",
      "completed in 0.17456674575805664 s\n",
      "game 12 completed in 9.618155002593994 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6262586 entropy 2.1071749\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6069283 entropy 2.1109188\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.576122 entropy 2.1195846\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5435753 entropy 2.130761\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5133655 entropy 2.1416306\n",
      "kl 0.025446141\n",
      "completed in 0.1991109848022461 s\n",
      "game 13 completed in 15.52420711517334 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5769215 entropy 2.10845\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5596073 entropy 2.1139917\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5286384 entropy 2.114028\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.493097 entropy 2.1090152\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4622202 entropy 2.1000514\n",
      "kl 0.021732906\n",
      "completed in 0.18787407875061035 s\n",
      "game 14 completed in 8.787497758865356 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5998223 entropy 2.0905857\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.57496 entropy 2.0875518\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5339618 entropy 2.0895786\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4915836 entropy 2.093899\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4532514 entropy 2.0971599\n",
      "kl 0.035850573\n",
      "completed in 0.18814492225646973 s\n",
      "game 15 completed in 6.47668719291687 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6957326 entropy 2.1589723\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6714892 entropy 2.1570652\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.636609 entropy 2.150888\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6022377 entropy 2.1408987\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5704024 entropy 2.1290283\n",
      "kl 0.022172688\n",
      "completed in 0.18113207817077637 s\n",
      "game 16 completed in 11.903226852416992 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6437979 entropy 2.0672617\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6179044 entropy 2.0533056\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5823233 entropy 2.0407772\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.551497 entropy 2.0324216\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.518625 entropy 2.0289376\n",
      "kl 0.02399813\n",
      "completed in 0.1759941577911377 s\n",
      "game 17 completed in 11.27458381652832 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6852922 entropy 2.053348\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.66725 entropy 2.0544538\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6364427 entropy 2.0575101\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6029658 entropy 2.0615911\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.572113 entropy 2.0649214\n",
      "kl 0.026120454\n",
      "completed in 0.18174958229064941 s\n",
      "game 18 completed in 6.2759411334991455 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6067305 entropy 2.0833964\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.578024 entropy 2.0866752\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5445116 entropy 2.0889196\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5166838 entropy 2.0878294\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4907384 entropy 2.0819755\n",
      "kl 0.024469858\n",
      "completed in 0.17007184028625488 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 19 completed in 7.328654050827026 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.644983 entropy 2.0547194\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6225383 entropy 2.0510793\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5867107 entropy 2.0500941\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5459042 entropy 2.0513134\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5083132 entropy 2.0539665\n",
      "kl 0.027985599\n",
      "completed in 0.1754591464996338 s\n",
      "game 20 completed in 6.297815799713135 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5295963 entropy 2.0494068\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.513777 entropy 2.0502753\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4842877 entropy 2.0504818\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4467196 entropy 2.0501657\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4078069 entropy 2.048974\n",
      "kl 0.023629313\n",
      "completed in 0.22082996368408203 s\n",
      "game 21 completed in 10.829740047454834 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6831396 entropy 2.0793242\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6651165 entropy 2.0815845\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6287766 entropy 2.0855877\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5902324 entropy 2.090148\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.555496 entropy 2.0944455\n",
      "kl 0.029294161\n",
      "completed in 0.1713118553161621 s\n",
      "game 22 completed in 8.25476598739624 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7476292 entropy 2.1227357\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7152836 entropy 2.1218462\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6755486 entropy 2.120263\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.633644 entropy 2.1203341\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.594816 entropy 2.122201\n",
      "kl 0.022178583\n",
      "completed in 0.1888580322265625 s\n",
      "game 23 completed in 13.706151962280273 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5928664 entropy 2.1286058\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5621357 entropy 2.1303134\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5312812 entropy 2.1276274\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.504791 entropy 2.1203146\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4738681 entropy 2.1089294\n",
      "kl 0.03214406\n",
      "completed in 0.1697070598602295 s\n",
      "game 24 completed in 7.773686170578003 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6483507 entropy 2.1003633\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6339858 entropy 2.0902987\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.606374 entropy 2.0853577\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5701737 entropy 2.0852594\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5321605 entropy 2.087712\n",
      "kl 0.020140719\n",
      "completed in 0.1817760467529297 s\n",
      "game 25 completed in 9.332403182983398 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4963665 entropy 2.0479107\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4589586 entropy 2.0498695\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.414266 entropy 2.050669\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3784454 entropy 2.0482657\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.347835 entropy 2.0418134\n",
      "kl 0.030736273\n",
      "completed in 0.1860799789428711 s\n",
      "game 26 completed in 7.288043975830078 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5746815 entropy 2.0552282\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.544125 entropy 2.0477047\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5057378 entropy 2.0409596\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4770653 entropy 2.034918\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4511456 entropy 2.0292048\n",
      "kl 0.024548018\n",
      "completed in 0.16597294807434082 s\n",
      "game 27 completed in 16.284355878829956 s 20 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6942604 entropy 2.0456214\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6448033 entropy 2.0409317\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5923026 entropy 2.0358396\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5490196 entropy 2.033124\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5018337 entropy 2.032909\n",
      "kl 0.037742153\n",
      "completed in 0.16371512413024902 s\n",
      "game 28 completed in 13.749352931976318 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6648417 entropy 2.0557737\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6211782 entropy 2.068209\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5808356 entropy 2.0869024\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5504324 entropy 2.1050043\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5015314 entropy 2.1144938\n",
      "kl 0.029903028\n",
      "completed in 0.17717599868774414 s\n",
      "game 29 completed in 12.411518812179565 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7219555 entropy 2.1050968\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6938276 entropy 2.1029088\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.652335 entropy 2.0975246\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.608006 entropy 2.0939941\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5676434 entropy 2.0927463\n",
      "kl 0.033132605\n",
      "completed in 0.18552112579345703 s\n",
      "game 30 completed in 12.084255933761597 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.591446 entropy 2.0262008\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5567393 entropy 2.027759\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.507008 entropy 2.0282679\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.459339 entropy 2.0280635\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4228957 entropy 2.0264773\n",
      "kl 0.027972093\n",
      "completed in 0.17723488807678223 s\n",
      "game 31 completed in 12.696544885635376 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.668732 entropy 2.08149\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6410155 entropy 2.0838382\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.596391 entropy 2.0901794\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5482173 entropy 2.0977879\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.504731 entropy 2.1029491\n",
      "kl 0.030957134\n",
      "completed in 0.1806950569152832 s\n",
      "game 32 completed in 7.822022199630737 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7034214 entropy 2.0726128\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6740677 entropy 2.068325\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6276903 entropy 2.0590353\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5863714 entropy 2.0462947\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5559042 entropy 2.0332842\n",
      "kl 0.040308967\n",
      "completed in 0.1782369613647461 s\n",
      "game 33 completed in 8.254377126693726 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6956055 entropy 2.0870333\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.672743 entropy 2.087203\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6444778 entropy 2.0912547\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6153939 entropy 2.0964339\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5824897 entropy 2.1013186\n",
      "kl 0.014053782\n",
      "completed in 0.18875622749328613 s\n",
      "game 34 completed in 9.396385192871094 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.689032 entropy 2.1179304\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6697261 entropy 2.1209745\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6405902 entropy 2.123977\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6101372 entropy 2.1271296\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5823312 entropy 2.1299467\n",
      "kl 0.01749792\n",
      "completed in 0.16671299934387207 s\n",
      "game 35 completed in 10.855844020843506 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6583772 entropy 2.064488\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6354733 entropy 2.0645125\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6020496 entropy 2.0621421\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5670555 entropy 2.057867\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5343564 entropy 2.0524497\n",
      "kl 0.013845247\n",
      "completed in 0.21110892295837402 s\n",
      "game 36 completed in 12.543884038925171 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6515281 entropy 2.0659895\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.63479 entropy 2.058784\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6102421 entropy 2.0509896\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5810611 entropy 2.0432222\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5531268 entropy 2.036157\n",
      "kl 0.016079392\n",
      "completed in 0.18039393424987793 s\n",
      "game 37 completed in 8.397741794586182 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6092434 entropy 2.0018542\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5868704 entropy 2.001042\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.556327 entropy 2.0030875\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5275211 entropy 2.007413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.2962962962962963 loss 2.5006797 entropy 2.0127861\n",
      "kl 0.01501266\n",
      "completed in 0.20415067672729492 s\n",
      "game 38 completed in 6.113832235336304 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6669228 entropy 2.0809808\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.644621 entropy 2.089387\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6141193 entropy 2.0985403\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5866559 entropy 2.1066704\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5596805 entropy 2.1116915\n",
      "kl 0.016761087\n",
      "completed in 0.17518997192382812 s\n",
      "game 39 completed in 12.777076959609985 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6759417 entropy 2.087523\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6471612 entropy 2.0870013\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6178582 entropy 2.086155\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5915282 entropy 2.086586\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5646093 entropy 2.0882015\n",
      "kl 0.01672588\n",
      "completed in 0.16903400421142578 s\n",
      "game 40 completed in 7.624507904052734 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5830083 entropy 2.063261\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5658636 entropy 2.0654478\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5394845 entropy 2.0669062\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.506669 entropy 2.0672212\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.472094 entropy 2.0659437\n",
      "kl 0.017495465\n",
      "completed in 0.18677997589111328 s\n",
      "game 41 completed in 7.5608179569244385 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6784773 entropy 2.1174383\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6639912 entropy 2.1120982\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6389835 entropy 2.1045218\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.607257 entropy 2.0958793\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5731554 entropy 2.0873559\n",
      "kl 0.016335377\n",
      "completed in 0.16586017608642578 s\n",
      "game 42 completed in 17.246160984039307 s 21 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.735715 entropy 2.0591488\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7195847 entropy 2.0599074\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6941566 entropy 2.0654893\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.665231 entropy 2.074531\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.636372 entropy 2.0854836\n",
      "kl 0.022156062\n",
      "completed in 0.17351508140563965 s\n",
      "game 43 completed in 13.820717811584473 s 17 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6103787 entropy 2.1019225\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5915823 entropy 2.110074\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5574403 entropy 2.1146643\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5174792 entropy 2.1149359\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4787798 entropy 2.1102402\n",
      "kl 0.015347528\n",
      "completed in 0.17002391815185547 s\n",
      "game 44 completed in 14.595188856124878 s 18 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.675856 entropy 2.092658\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.659287 entropy 2.084341\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6310794 entropy 2.078\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.601622 entropy 2.0729604\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5715325 entropy 2.0683904\n",
      "kl 0.01564801\n",
      "completed in 0.18740391731262207 s\n",
      "game 45 completed in 5.979345083236694 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.72687 entropy 2.0568147\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7086377 entropy 2.0579028\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6783407 entropy 2.0624623\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6434991 entropy 2.0686722\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6048775 entropy 2.0744529\n",
      "kl 0.020978576\n",
      "completed in 0.1723499298095703 s\n",
      "game 46 completed in 9.343000888824463 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6601412 entropy 2.119606\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.646223 entropy 2.121332\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6248922 entropy 2.1210306\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5978096 entropy 2.1192207\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.568755 entropy 2.1162412\n",
      "kl 0.0129878055\n",
      "completed in 0.17531800270080566 s\n",
      "game 47 completed in 6.844043016433716 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5288231 entropy 2.0806236\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5171583 entropy 2.0776646\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.497118 entropy 2.0755677\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4723215 entropy 2.0738554\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4466252 entropy 2.0720038\n",
      "kl 0.012266907\n",
      "completed in 0.17395401000976562 s\n",
      "game 48 completed in 11.09481692314148 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6299553 entropy 2.0655744\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6116984 entropy 2.0645409\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5827663 entropy 2.0630698\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5516639 entropy 2.0610304\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5235953 entropy 2.0585008\n",
      "kl 0.016754698\n",
      "completed in 0.2048959732055664 s\n",
      "prediction:\n",
      " [0.00482119 0.00699888 0.00873087 0.00353274 0.02164424 0.00399833\n",
      " 0.00623493 0.00999443 0.03979871 0.0771818  0.03380745 0.02682342\n",
      " 0.00989421 0.04507668 0.02982976 0.07722548 0.06418364 0.00552761\n",
      " 0.00468501 0.08336159 0.09239747 0.04867737 0.03939607 0.0129399\n",
      " 0.02309084 0.04756374 0.06976772 0.04037206 0.00785353 0.00670207\n",
      " 0.00281241 0.02582056 0.00272716 0.00766667 0.00608256 0.00277894] \n",
      " -0.61754346\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.04005006e-01 3.42928661e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.12765957e-01 2.40300375e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.3507735e-04 8.1069814e-04 3.5168941e-04 1.1428349e-03 4.0381518e-04\n",
      " 1.2428174e-03 2.6912027e-04 8.1757567e-04 1.5363558e-02 4.8598330e-03\n",
      " 3.3226057e-03 6.0690060e-04 3.8503954e-04 1.5960885e-02 2.3145404e-02\n",
      " 2.9934660e-01 7.4502975e-03 3.6296225e-04 3.7036961e-04 1.0256765e-02\n",
      " 5.3032726e-01 3.9097767e-02 1.8303547e-02 8.4084168e-04 2.7713107e-04\n",
      " 5.2209250e-03 2.2914053e-03 1.2551652e-02 5.9740519e-04 4.6365042e-04\n",
      " 8.2214380e-04 3.4928165e-04 6.8413652e-04 4.6830962e-04 6.6690095e-04\n",
      " 2.3287976e-04] \n",
      " 0.46217614\n",
      "p [[0.00125156 0.00250313 0.00250313 0.00125156 0.00876095 0.00125156]\n",
      " [0.00125156 0.00250313 0.01877347 0.06007509 0.03003755 0.01001252]\n",
      " [0.00375469 0.0212766  0.0387985  0.         0.21652065 0.00375469]\n",
      " [0.00125156 0.11514393 0.08135169 0.21777222 0.0175219  0.00375469]\n",
      " [0.01126408 0.03754693 0.05006258 0.01501877 0.00250313 0.00250313]\n",
      " [0.00125156 0.01251564 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00434956 0.0038399  0.00481593 0.00152953 0.00514509 0.00494522\n",
      " 0.00640355 0.00798883 0.01854092 0.05536208 0.12072162 0.00774502\n",
      " 0.00455164 0.01000199 0.1694027  0.00388868 0.02766523 0.0012385\n",
      " 0.00189354 0.03671891 0.00582838 0.16082944 0.01345773 0.00331034\n",
      " 0.01099531 0.20818944 0.03996561 0.02349553 0.00541867 0.00420927\n",
      " 0.00821782 0.00433958 0.00083532 0.00816297 0.00356649 0.00242982] \n",
      " -0.87424695\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 1.62703379e-02 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 7.50938673e-03 9.56195244e-01 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [8.6330558e-04 1.0873686e-03 2.3519606e-04 7.1719737e-04 1.5213505e-04\n",
      " 7.7657543e-02 1.3107772e-03 3.5040017e-04 5.0291931e-03 3.1605293e-04\n",
      " 2.7503937e-01 2.2080576e-04 3.0191767e-04 3.6737702e-03 7.4179785e-05\n",
      " 2.5512450e-04 3.0650609e-04 1.8309403e-04 1.6161428e-04 4.9254001e-04\n",
      " 5.3778058e-04 4.9847138e-05 3.8846529e-03 4.4316723e-04 3.3486713e-04\n",
      " 5.4119021e-01 5.0413754e-04 7.7658277e-03 4.8919127e-04 1.0457825e-03\n",
      " 7.2732016e-02 1.7406543e-04 3.3281840e-04 2.2506565e-04 1.2434452e-03\n",
      " 6.1914814e-04] \n",
      " -0.9745876\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00250313 0.00125156]\n",
      " [0.00125156 0.00250313 0.00625782 0.02753442 0.15394243 0.00250313]\n",
      " [0.00250313 0.00250313 0.41301627 0.         0.04505632 0.00125156]\n",
      " [0.00125156 0.01501877 0.         0.         0.00500626 0.00125156]\n",
      " [0.00500626 0.25031289 0.03254068 0.00750939 0.00125156 0.00125156]\n",
      " [0.00250313 0.00375469 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.6616570e-02 1.0035089e-03 4.3913811e-03 5.3598394e-04 4.3870192e-03\n",
      " 2.8103350e-02 1.7825804e-03 4.5388317e-01 2.3858340e-03 1.0647640e-02\n",
      " 1.3133561e-03 4.7033359e-03 2.8241756e-03 2.1427542e-03 2.9047381e-04\n",
      " 9.7568880e-04 3.1792648e-02 1.1432540e-03 1.1625020e-03 3.1225095e-02\n",
      " 2.3958103e-03 3.7041024e-04 5.0838967e-03 2.4578879e-03 5.5932198e-03\n",
      " 2.8545572e-03 1.4512130e-02 2.5024782e-03 3.2222944e-01 9.6934265e-04\n",
      " 1.9391662e-02 4.7081737e-03 5.0526962e-04 3.2679099e-03 5.3274818e-04\n",
      " 1.1314767e-02] \n",
      " -0.50475097\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.75219024e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.00125156e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 8.69837297e-01 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.12640801e-02 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.15270761e-03 8.97826743e-04 8.02284339e-05 3.08064249e-04\n",
      " 6.71960661e-05 5.52924752e-01 6.00297819e-04 2.37037893e-05\n",
      " 1.47845736e-03 1.06235340e-04 1.43722510e-02 1.14389746e-04\n",
      " 2.09803664e-04 2.24053883e-03 3.07217670e-05 2.15033651e-05\n",
      " 8.72725432e-05 1.22992933e-04 7.90879421e-05 1.47858489e-04\n",
      " 1.03108228e-04 5.66631934e-06 1.68577477e-03 2.81754154e-04\n",
      " 5.18198722e-05 2.16547642e-02 3.41948238e-04 7.04405189e-04\n",
      " 7.91074781e-05 1.02383632e-03 3.95218909e-01 9.51553011e-05\n",
      " 1.76256217e-04 1.04115308e-04 1.47919287e-03 1.92851655e-03] \n",
      " -0.69361794\n",
      "p [[0.05256571 0.01001252 0.01251564 0.01001252 0.0175219  0.0175219 ]\n",
      " [0.01627034 0.33917397 0.00125156 0.01376721 0.02002503 0.00876095]\n",
      " [0.00625782 0.00125156 0.         0.         0.03629537 0.00250313]\n",
      " [0.00750939 0.02252816 0.         0.         0.00250313 0.00750939]\n",
      " [0.01126408 0.         0.01501877 0.00125156 0.24155194 0.01126408]\n",
      " [0.02002503 0.02753442 0.01627034 0.00750939 0.00375469 0.0387985 ]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.9857050e-01 5.7749299e-04 9.3069894e-04 5.6814193e-04 3.8558652e-03\n",
      " 4.0980019e-03 5.9762772e-04 4.7843903e-02 2.8446217e-03 7.3147221e-03\n",
      " 5.3596322e-04 4.0290467e-03 8.6011004e-04 7.4492348e-04 1.7833473e-04\n",
      " 1.1884900e-04 2.5401490e-03 1.7524905e-03 9.4320124e-04 5.1238458e-03\n",
      " 1.0494031e-03 1.7078989e-04 2.3105338e-03 8.2589936e-04 4.0517612e-03\n",
      " 1.2441841e-03 1.0200261e-02 1.6391178e-03 5.1612329e-02 8.0673816e-04\n",
      " 9.2767499e-04 3.1757359e-03 7.6404656e-04 1.4675012e-03 3.4134206e-04\n",
      " 3.3538422e-01] \n",
      " 0.7522375\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 5.00625782e-02]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  3.25406758e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [9.17396746e-01 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 30\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 49 completed in 18.28838562965393 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.550642 entropy 2.0262213\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5391269 entropy 2.0273547\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.517578 entropy 2.029046\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4928796 entropy 2.0306249\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4692135 entropy 2.0311406\n",
      "kl 0.014782557\n",
      "completed in 0.1702132225036621 s\n",
      "game 50 completed in 12.69258189201355 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.559174 entropy 2.0695362\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5469036 entropy 2.0689237\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.526203 entropy 2.067459\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.503641 entropy 2.0651422\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.484354 entropy 2.062215\n",
      "kl 0.01680847\n",
      "completed in 0.18617701530456543 s\n",
      "game 51 completed in 13.194135904312134 s 16 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5620744 entropy 2.0988498\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5515115 entropy 2.0971525\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5328717 entropy 2.0963745\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5106661 entropy 2.0960622\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4889624 entropy 2.095389\n",
      "kl 0.016811844\n",
      "completed in 0.17020392417907715 s\n",
      "game 52 completed in 6.798059940338135 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.689775 entropy 2.1361892\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6685169 entropy 2.1320844\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6398041 entropy 2.1262746\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6125324 entropy 2.1203036\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5864785 entropy 2.1152937\n",
      "kl 0.020627748\n",
      "completed in 0.17125487327575684 s\n",
      "game 53 completed in 6.299030065536499 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5503316 entropy 2.0024903\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5333068 entropy 2.0034\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5036154 entropy 2.0094905\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4803245 entropy 2.0184445\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4596596 entropy 2.0273943\n",
      "kl 0.0145229725\n",
      "completed in 0.18276405334472656 s\n",
      "game 54 completed in 9.342865943908691 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.669157 entropy 2.132079\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6559927 entropy 2.137648\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6333494 entropy 2.1422687\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.606091 entropy 2.145523\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5789654 entropy 2.147204\n",
      "kl 0.015512547\n",
      "completed in 0.16905593872070312 s\n",
      "game 55 completed in 6.0014870166778564 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.614737 entropy 2.1118827\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.594892 entropy 2.1151567\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5707393 entropy 2.1180549\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5462556 entropy 2.1188745\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.520371 entropy 2.1170063\n",
      "kl 0.019221855\n",
      "completed in 0.17034912109375 s\n",
      "game 56 completed in 10.609512329101562 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5617535 entropy 2.1155076\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.546155 entropy 2.1086922\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5267115 entropy 2.1004467\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.504898 entropy 2.092976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.2962962962962963 loss 2.4795163 entropy 2.0865464\n",
      "kl 0.012830953\n",
      "completed in 0.20483708381652832 s\n",
      "game 57 completed in 8.495727062225342 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6137822 entropy 2.0794072\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5925682 entropy 2.0776474\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.564396 entropy 2.077855\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5355768 entropy 2.0790732\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5086987 entropy 2.0805254\n",
      "kl 0.01488098\n",
      "completed in 0.2031850814819336 s\n",
      "game 58 completed in 13.24885082244873 s 16 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.589507 entropy 2.0785818\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.570618 entropy 2.0775561\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.544101 entropy 2.0751677\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.516523 entropy 2.0725222\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4875016 entropy 2.069789\n",
      "kl 0.0120421965\n",
      "completed in 0.16742801666259766 s\n",
      "game 59 completed in 7.518669843673706 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6702707 entropy 2.1140475\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6573224 entropy 2.110808\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6368978 entropy 2.106432\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6126323 entropy 2.1019497\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5876627 entropy 2.0978146\n",
      "kl 0.012435238\n",
      "completed in 0.20688199996948242 s\n",
      "game 60 completed in 9.010411977767944 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6595347 entropy 2.0550592\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.642958 entropy 2.0526257\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6154177 entropy 2.0511174\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5861192 entropy 2.0505798\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5587847 entropy 2.0509439\n",
      "kl 0.010623161\n",
      "completed in 0.17204499244689941 s\n",
      "game 61 completed in 8.608848810195923 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6400478 entropy 2.0564303\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.625185 entropy 2.061141\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.598629 entropy 2.0666847\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5729537 entropy 2.0716581\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5501504 entropy 2.0743976\n",
      "kl 0.011656243\n",
      "completed in 0.17941880226135254 s\n",
      "game 62 completed in 9.35744309425354 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.673982 entropy 2.1274133\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6596005 entropy 2.1295004\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6389759 entropy 2.132845\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.618198 entropy 2.1365137\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5974174 entropy 2.1396606\n",
      "kl 0.010313051\n",
      "completed in 0.17183876037597656 s\n",
      "game 63 completed in 6.094796180725098 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6895814 entropy 2.0722766\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.673252 entropy 2.0678592\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6414266 entropy 2.0581334\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.608008 entropy 2.0458057\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5793884 entropy 2.033714\n",
      "kl 0.015041541\n",
      "completed in 0.16401195526123047 s\n",
      "game 64 completed in 8.426587104797363 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.57774 entropy 2.058219\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5673406 entropy 2.053341\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.545789 entropy 2.0531137\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.516342 entropy 2.0565794\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.490538 entropy 2.0620694\n",
      "kl 0.012875892\n",
      "completed in 0.17032098770141602 s\n",
      "game 65 completed in 17.93754506111145 s 22 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6973412 entropy 2.1086326\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6773171 entropy 2.113469\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6436796 entropy 2.1178925\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.610337 entropy 2.1207423\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5806985 entropy 2.1214132\n",
      "kl 0.016803881\n",
      "completed in 0.17108488082885742 s\n",
      "game 66 completed in 8.93691897392273 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5906153 entropy 2.0317042\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5752218 entropy 2.032518\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5544794 entropy 2.0333915\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5295763 entropy 2.0351572\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5020251 entropy 2.0366888\n",
      "kl 0.014004154\n",
      "completed in 0.22395110130310059 s\n",
      "game 67 completed in 7.013880968093872 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5572033 entropy 2.0480149\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5480514 entropy 2.0468013\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5293093 entropy 2.0437474\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.507747 entropy 2.0392969\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4871473 entropy 2.0340695\n",
      "kl 0.015036491\n",
      "completed in 0.16869211196899414 s\n",
      "game 68 completed in 6.00734281539917 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6000018 entropy 2.020865\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.583578 entropy 2.0158982\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5586038 entropy 2.010096\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.532311 entropy 2.0044577\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5078008 entropy 1.9996264\n",
      "kl 0.016847689\n",
      "completed in 0.2022230625152588 s\n",
      "game 69 completed in 6.1203293800354 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5318725 entropy 1.992836\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5158198 entropy 1.9904879\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4891946 entropy 1.9908775\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.462243 entropy 1.9928926\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.435441 entropy 1.9951904\n",
      "kl 0.017969765\n",
      "completed in 0.1797947883605957 s\n",
      "game 70 completed in 6.060963869094849 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7250292 entropy 2.0294785\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.69983 entropy 2.0309968\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.658831 entropy 2.0308168\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6201408 entropy 2.0307117\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5916593 entropy 2.0319965\n",
      "kl 0.01632975\n",
      "completed in 0.20258307456970215 s\n",
      "game 71 completed in 7.034667015075684 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7201219 entropy 2.0856407\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7091434 entropy 2.0912519\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.686896 entropy 2.0990076\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.661899 entropy 2.1074321\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6379747 entropy 2.114897\n",
      "kl 0.019180588\n",
      "completed in 0.1903829574584961 s\n",
      "game 72 completed in 6.019289970397949 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6081893 entropy 2.0920076\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5929432 entropy 2.0934534\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5661209 entropy 2.0910678\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5339003 entropy 2.0857224\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5070546 entropy 2.0783994\n",
      "kl 0.010817321\n",
      "completed in 0.1751267910003662 s\n",
      "game 73 completed in 6.149479866027832 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5276325 entropy 2.033011\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5182815 entropy 2.026009\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4975877 entropy 2.0194855\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4705849 entropy 2.0137427\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4426262 entropy 2.0086753\n",
      "kl 0.017396057\n",
      "completed in 0.195037841796875 s\n",
      "game 74 completed in 9.158360004425049 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.702161 entropy 2.0603814\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.693907 entropy 2.0592046\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.6741421 entropy 2.060042\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.6461608 entropy 2.0625029\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.6149464 entropy 2.0657363\n",
      "kl 0.011196151\n",
      "completed in 0.1698288917541504 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 75 completed in 5.9398181438446045 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.619097 entropy 2.026275\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6050434 entropy 2.0305142\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.581912 entropy 2.0353303\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5563502 entropy 2.0401251\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.531726 entropy 2.0442538\n",
      "kl 0.015828025\n",
      "completed in 0.1717827320098877 s\n",
      "game 76 completed in 8.112902879714966 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4550385 entropy 2.0059185\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4462342 entropy 2.0107288\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4275694 entropy 2.0147521\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4029956 entropy 2.0170913\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.375927 entropy 2.0166094\n",
      "kl 0.010800274\n",
      "completed in 0.16971707344055176 s\n",
      "game 77 completed in 10.497134923934937 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6098332 entropy 2.0831766\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5972817 entropy 2.078065\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5763521 entropy 2.072021\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.553132 entropy 2.0656428\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5297418 entropy 2.0590448\n",
      "kl 0.009433748\n",
      "completed in 0.1797327995300293 s\n",
      "game 78 completed in 6.795519113540649 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6051135 entropy 2.0088236\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5900455 entropy 2.004482\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5591283 entropy 2.0014768\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5219302 entropy 1.9991982\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4896197 entropy 1.9966263\n",
      "kl 0.024177648\n",
      "completed in 0.1709730625152588 s\n",
      "game 79 completed in 10.116307020187378 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.621817 entropy 2.026259\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.601681 entropy 2.0254958\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.57071 entropy 2.0260062\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.538463 entropy 2.0261953\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.508602 entropy 2.024915\n",
      "kl 0.020467307\n",
      "completed in 0.1663532257080078 s\n",
      "game 80 completed in 8.450861930847168 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5946822 entropy 2.0349252\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5770042 entropy 2.0292764\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.547312 entropy 2.0205293\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5135977 entropy 2.011009\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.480651 entropy 2.0028682\n",
      "kl 0.025528416\n",
      "completed in 0.16807126998901367 s\n",
      "game 81 completed in 8.308775186538696 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6371322 entropy 2.0172334\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6126723 entropy 2.0211744\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.582877 entropy 2.0293856\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.558336 entropy 2.0377922\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5348275 entropy 2.0436997\n",
      "kl 0.026931368\n",
      "completed in 0.17472100257873535 s\n",
      "game 82 completed in 9.670237064361572 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5940495 entropy 1.9938704\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5642776 entropy 1.99056\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.520878 entropy 1.9837277\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.477093 entropy 1.9753902\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4399602 entropy 1.9670283\n",
      "kl 0.03263295\n",
      "completed in 0.17088675498962402 s\n",
      "game 83 completed in 7.4836390018463135 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6375148 entropy 2.0077126\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6155794 entropy 2.0079057\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5819242 entropy 2.0111232\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5426412 entropy 2.0132706\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5063024 entropy 2.0136948\n",
      "kl 0.03422397\n",
      "completed in 0.17785382270812988 s\n",
      "game 84 completed in 10.144362926483154 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5600448 entropy 1.984578\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5313756 entropy 1.9808004\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.494847 entropy 1.9753904\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4622989 entropy 1.9698474\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4303722 entropy 1.9644392\n",
      "kl 0.026335526\n",
      "completed in 0.17676472663879395 s\n",
      "game 85 completed in 7.489322900772095 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6590652 entropy 1.9896418\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.632847 entropy 1.990838\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5929122 entropy 1.996473\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5522244 entropy 2.0048285\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5152001 entropy 2.0136929\n",
      "kl 0.026956536\n",
      "completed in 0.16935396194458008 s\n",
      "game 86 completed in 9.953895092010498 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5867171 entropy 2.0214834\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5660133 entropy 2.0274003\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5329015 entropy 2.0325963\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4981337 entropy 2.0356474\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.465544 entropy 2.036059\n",
      "kl 0.03194196\n",
      "completed in 0.1698899269104004 s\n",
      "game 87 completed in 5.9183690547943115 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6454837 entropy 2.0760946\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6277745 entropy 2.0707936\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5987306 entropy 2.065206\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5653381 entropy 2.0606275\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.527916 entropy 2.0575557\n",
      "kl 0.022104677\n",
      "completed in 0.20316696166992188 s\n",
      "game 88 completed in 9.361705780029297 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6437573 entropy 2.0329275\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6125538 entropy 2.039972\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5746193 entropy 2.0488594\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5405817 entropy 2.0542536\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5066936 entropy 2.0539155\n",
      "kl 0.026068188\n",
      "completed in 0.19410920143127441 s\n",
      "game 89 completed in 10.120880126953125 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.569437 entropy 2.0169296\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5104773 entropy 2.002557\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.475464 entropy 1.9858813\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4484205 entropy 1.972997\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4093316 entropy 1.9658253\n",
      "kl 0.02067428\n",
      "completed in 0.17060208320617676 s\n",
      "game 90 completed in 9.149778842926025 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6431625 entropy 1.959536\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6009028 entropy 1.9663169\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5619202 entropy 1.9783285\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.537154 entropy 1.9902155\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.505512 entropy 1.996084\n",
      "kl 0.024641458\n",
      "completed in 0.17900395393371582 s\n",
      "game 91 completed in 10.066423177719116 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5993629 entropy 2.0477352\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5818083 entropy 2.0481167\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5484912 entropy 2.048875\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5127304 entropy 2.0490103\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4796882 entropy 2.0479398\n",
      "kl 0.031816557\n",
      "completed in 0.19261908531188965 s\n",
      "game 92 completed in 9.565644979476929 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5716355 entropy 2.0137162\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5443153 entropy 2.0087333\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5066254 entropy 1.9991413\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4714289 entropy 1.9882731\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4446576 entropy 1.9780847\n",
      "kl 0.03392663\n",
      "completed in 0.17316389083862305 s\n",
      "game 93 completed in 10.602571964263916 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.582621 entropy 2.0118709\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.561543 entropy 2.0082095\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5311096 entropy 2.0061865\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4971287 entropy 2.0060618\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.463725 entropy 2.0062785\n",
      "kl 0.025117949\n",
      "completed in 0.18205595016479492 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 94 completed in 10.150020837783813 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6330795 entropy 1.9973469\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6108103 entropy 1.9965937\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5685246 entropy 1.9948534\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5222242 entropy 1.9925221\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4792101 entropy 1.9905009\n",
      "kl 0.020211874\n",
      "completed in 0.16849493980407715 s\n",
      "game 95 completed in 11.866533279418945 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6598375 entropy 2.0109007\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6339726 entropy 2.0187576\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5963387 entropy 2.0318696\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5589964 entropy 2.0457177\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5225523 entropy 2.0554178\n",
      "kl 0.038548727\n",
      "completed in 0.196685791015625 s\n",
      "game 96 completed in 12.430392980575562 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6235888 entropy 2.0356774\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5973642 entropy 2.0388246\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5555975 entropy 2.0385988\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5142908 entropy 2.0341907\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4768493 entropy 2.026236\n",
      "kl 0.024813803\n",
      "completed in 0.19101190567016602 s\n",
      "game 97 completed in 7.662647008895874 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5836012 entropy 1.9772089\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5549684 entropy 1.9708736\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5106294 entropy 1.9667184\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.462043 entropy 1.9647863\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.429922 entropy 1.9615142\n",
      "kl 0.039015938\n",
      "completed in 0.16966891288757324 s\n",
      "game 98 completed in 11.770286083221436 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6801846 entropy 1.9962063\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6569576 entropy 1.9935131\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.619142 entropy 1.9925166\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5773895 entropy 1.9938687\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5366929 entropy 1.9951154\n",
      "kl 0.04128518\n",
      "completed in 0.17729997634887695 s\n",
      "prediction:\n",
      " [0.00457239 0.02714887 0.00233866 0.00698761 0.00637812 0.00328182\n",
      " 0.02455234 0.04291026 0.07210908 0.03105671 0.00940836 0.00562724\n",
      " 0.00207528 0.07654624 0.06517591 0.03550584 0.03723357 0.00872539\n",
      " 0.00717976 0.06400707 0.03749847 0.0768727  0.08851703 0.00281296\n",
      " 0.00461534 0.00492452 0.04825944 0.07450759 0.0508725  0.01732615\n",
      " 0.00236736 0.00701987 0.01085079 0.00371383 0.03196666 0.00505431] \n",
      " -0.37633553\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.46808511e-01 2.47809762e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.76095119e-02 2.17772215e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [1.0388838e-03 2.5782062e-04 5.2724243e-04 6.7079923e-04 3.3232046e-04\n",
      " 1.9652172e-04 2.4262427e-04 7.7650282e-03 5.5601769e-03 7.3173039e-02\n",
      " 2.2835498e-04 3.9914637e-04 2.6666306e-04 3.6882085e-03 1.2116114e-02\n",
      " 3.1072035e-01 3.5018757e-02 2.9591544e-04 3.2911604e-04 3.8307767e-02\n",
      " 4.1103113e-01 4.7313385e-03 5.4292991e-03 6.8354077e-04 3.4115085e-04\n",
      " 1.9277653e-04 7.1431309e-02 5.3291228e-03 6.2845885e-03 2.9407808e-04\n",
      " 1.7633069e-04 6.0545508e-04 4.0603601e-04 6.6487258e-04 3.4612094e-04\n",
      " 9.1821572e-04] \n",
      " 0.53555614\n",
      "p [[0.00250313 0.01126408 0.00125156 0.00250313 0.00375469 0.00125156]\n",
      " [0.01126408 0.02503129 0.05256571 0.01376721 0.00375469 0.00250313]\n",
      " [0.00125156 0.07259074 0.         0.01501877 0.0175219  0.00500626]\n",
      " [0.00250313 0.02878598 0.0175219  0.42052566 0.12891114 0.00125156]\n",
      " [0.00250313 0.00250313 0.02878598 0.05882353 0.03003755 0.00750939]\n",
      " [0.00250313 0.00375469 0.00375469 0.00125156 0.01376721 0.00250313]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.003437   0.00406503 0.0030129  0.00094345 0.00724151 0.00165898\n",
      " 0.00283188 0.01342974 0.02928809 0.24382493 0.00147224 0.00196753\n",
      " 0.00068822 0.00632994 0.0017699  0.02540253 0.01142731 0.00130004\n",
      " 0.00169418 0.02285621 0.04179581 0.00136256 0.00919703 0.00110355\n",
      " 0.00186831 0.00069492 0.49998695 0.0222689  0.01678081 0.00122918\n",
      " 0.00161621 0.00540418 0.00114817 0.00313034 0.00385467 0.00391677] \n",
      " -0.6965866\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-03 2.75344180e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.90237797e-01\n",
      "  2.25281602e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.12640801e-02 7.28410513e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.62703379e-02 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00637904 0.00086237 0.01488349 0.00168695 0.00475951 0.00167049\n",
      " 0.00185108 0.00500799 0.11982463 0.00701627 0.00630428 0.0049884\n",
      " 0.00143543 0.01202534 0.00363223 0.05798199 0.1354683  0.00389357\n",
      " 0.00380516 0.2878908  0.031765   0.00154006 0.01195564 0.00273845\n",
      " 0.00288208 0.00392508 0.00972361 0.19935603 0.00937373 0.00258553\n",
      " 0.00171371 0.00871234 0.00184821 0.020812   0.00234682 0.00735457] \n",
      " 0.19802639\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00125156 0.00250313 0.00125156]\n",
      " [0.00250313 0.00625782 0.0175219  0.12390488 0.00250313 0.00125156]\n",
      " [0.00125156 0.00250313 0.         0.01376721 0.01001252 0.00250313]\n",
      " [0.00125156 0.01376721 0.         0.         0.00375469 0.00125156]\n",
      " [0.00125156 0.00125156 0.75093867 0.01501877 0.00750939 0.00125156]\n",
      " [0.00125156 0.00250313 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00481593 0.00226038 0.01341357 0.0013369  0.03609805 0.00196946\n",
      " 0.00531488 0.00967203 0.08487727 0.00288387 0.0031659  0.03967254\n",
      " 0.00191405 0.0176001  0.0026767  0.2539794  0.03412742 0.00320096\n",
      " 0.00271157 0.07992023 0.17156717 0.00146074 0.0144495  0.00322708\n",
      " 0.02302949 0.001435   0.00410026 0.08454347 0.02220025 0.00422348\n",
      " 0.00235776 0.02623343 0.00236563 0.02915123 0.0024338  0.00561059] \n",
      " 0.6561033\n",
      "p [[1.25156446e-03 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.62953692e-02 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.37672090e-02\n",
      "  8.59824781e-01 1.25156446e-13]\n",
      " [1.25156446e-13 3.87984981e-02 0.00000000e+00 0.00000000e+00\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 2.87859825e-02\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.25156446e-13 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-03]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [8.5105031e-04 7.6182745e-04 1.3054628e-02 8.1865391e-04 4.3779309e-03\n",
      " 6.4918783e-04 1.2157863e-03 1.7339269e-03 3.8304636e-01 3.5434444e-02\n",
      " 1.9133281e-03 4.0138117e-03 1.2873536e-03 1.1554448e-02 4.8851623e-04\n",
      " 7.5034588e-03 4.3555596e-03 3.6032523e-03 3.0037987e-03 7.0073721e-03\n",
      " 3.2691988e-03 1.7719311e-04 1.0872043e-02 2.1268842e-03 1.4023634e-03\n",
      " 1.1484759e-03 5.4653522e-02 3.8954255e-01 1.6890713e-03 1.0918493e-03\n",
      " 9.9385192e-04 5.9165484e-03 2.1145553e-03 3.3751752e-02 2.4698775e-03\n",
      " 2.1056265e-03] \n",
      " 0.6422998\n",
      "p [[0.00375469 0.00500626 0.00876095 0.00375469 0.02377972 0.00250313]\n",
      " [0.00375469 0.00500626 0.05506884 0.00250313 0.00500626 0.02252816]\n",
      " [0.00750939 0.0175219  0.         0.62578223 0.         0.00250313]\n",
      " [0.00250313 0.06007509 0.         0.         0.00625782 0.00375469]\n",
      " [0.01251564 0.00625782 0.         0.04630788 0.01627034 0.00375469]\n",
      " [0.00375469 0.01501877 0.00250313 0.02252816 0.00125156 0.00250313]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.46042963e-03 4.13056201e-04 1.88302845e-01 1.47890509e-03\n",
      " 5.42893037e-02 2.35543773e-03 2.77750730e-03 3.54943471e-03\n",
      " 4.20302711e-02 3.76044735e-02 4.03773598e-03 6.32855343e-03\n",
      " 2.76186643e-03 1.41979358e-03 3.59024707e-04 1.61606877e-04\n",
      " 6.04753383e-03 1.89822202e-03 1.96617236e-03 1.08717112e-02\n",
      " 1.75975889e-04 3.27643211e-04 3.03846621e-03 2.31816596e-03\n",
      " 6.44232286e-03 2.36894516e-03 9.79026407e-02 1.01541884e-01\n",
      " 1.73612835e-03 1.07604440e-03 4.44731442e-03 1.57625731e-02\n",
      " 1.68408442e-03 3.89568210e-01 5.43472765e-04 9.52323840e-04] \n",
      " -0.73607796\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.74843554e-01 8.76095119e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.05131414e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00318226 0.0036853  0.04175545 0.0072103  0.02643201 0.0031787\n",
      " 0.00514542 0.02347759 0.0495315  0.07262725 0.00483897 0.01052294\n",
      " 0.00990884 0.08256442 0.00246504 0.00736353 0.01186815 0.0166312\n",
      " 0.01231525 0.03596634 0.00687552 0.00149785 0.08508196 0.02302779\n",
      " 0.00638548 0.00247307 0.16576567 0.13576603 0.01825347 0.00481425\n",
      " 0.0057819  0.01455939 0.00989753 0.07554852 0.00752515 0.00607608] \n",
      " 0.8604073\n",
      "p [[0.00125156 0.00125156 0.64330413 0.00125156 0.0212766  0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.08760951 0.00125156 0.00250313]\n",
      " [0.00125156 0.00125156 0.         0.         0.         0.00125156]\n",
      " [0.00125156 0.00250313 0.         0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.08760951 0.00125156 0.00125156]\n",
      " [0.00125156 0.00625782 0.00125156 0.12265332 0.00125156 0.00125156]]\n",
      "move 2\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.1512552e-03 2.7349638e-03 9.4915181e-02 1.3537568e-03 3.1325305e-01\n",
      " 5.5992240e-03 7.3155593e-03 1.1720778e-02 2.3957355e-02 1.0241210e-03\n",
      " 2.7447728e-02 2.2256490e-02 6.7743962e-03 9.2343462e-04 2.5267361e-04\n",
      " 2.0407351e-04 3.6209162e-02 6.7392900e-03 3.0937956e-03 1.2778288e-01\n",
      " 1.2249041e-04 3.1355722e-04 2.8826157e-03 1.1077090e-02 2.0497823e-02\n",
      " 7.1083000e-03 2.5007606e-03 4.2824790e-02 3.9589200e-03 3.5949119e-03\n",
      " 5.1624742e-03 5.4227404e-02 1.0842641e-03 1.4381015e-01 1.5874001e-03\n",
      " 2.5379527e-03] \n",
      " -0.8865689\n",
      "p [[1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-03\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-03 8.76095119e-03 0.00000000e+00 5.31914894e-01\n",
      "  2.00250313e-02 2.50312891e-03]\n",
      " [5.00625782e-03 1.37672090e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.50938673e-03]\n",
      " [3.75469337e-03 5.00625782e-03 0.00000000e+00 0.00000000e+00\n",
      "  3.62953692e-02 1.12640801e-02]\n",
      " [1.25156446e-03 1.25156446e-13 0.00000000e+00 2.60325407e-01\n",
      "  3.75469337e-02 1.25156446e-03]\n",
      " [7.50938673e-03 5.00625782e-03 5.00625782e-03 1.62703379e-02\n",
      "  6.25782228e-03 1.25156446e-03]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.24291927e-03 1.17584243e-02 2.30279155e-02 2.46970891e-03\n",
      " 1.11968249e-01 2.70806369e-03 1.41529720e-02 5.28069995e-02\n",
      " 2.25574933e-02 4.17371746e-04 3.30605283e-02 3.54143009e-02\n",
      " 8.07861313e-02 1.32229365e-02 5.14195766e-04 5.15241583e-04\n",
      " 1.31443562e-02 2.31563058e-02 1.71065386e-02 5.48881032e-02\n",
      " 4.31313703e-04 1.11236048e-04 3.51008885e-02 1.57111555e-01\n",
      " 2.10310891e-02 2.45880689e-02 1.61946460e-03 8.81175026e-02\n",
      " 5.55089749e-02 6.86045317e-03 3.24229337e-03 5.12130074e-02\n",
      " 2.73929304e-03 1.38181793e-02 5.46394475e-03 1.01241255e-02] \n",
      " 0.88176614\n",
      "p [[0.00125156 0.00125156 0.         0.00125156 0.1689612  0.00375469]\n",
      " [0.00125156 0.00500626 0.         0.         0.00876095 0.02377972]\n",
      " [0.00250313 0.00125156 0.         0.         0.         0.00250313]\n",
      " [0.00125156 0.04755945 0.         0.         0.00125156 0.00375469]\n",
      " [0.00876095 0.00250313 0.         0.09011264 0.00250313 0.00125156]\n",
      " [0.00125156 0.0350438  0.00125156 0.57947434 0.00125156 0.00125156]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [1.82731729e-03 1.52471382e-02 3.24079092e-03 5.31532755e-03\n",
      " 1.25454709e-01 1.05596269e-02 1.16310865e-02 1.13649629e-02\n",
      " 1.58765225e-03 1.73121298e-04 1.25841033e-02 2.94571556e-02\n",
      " 3.88452709e-02 4.99675097e-03 4.44523437e-04 2.96678947e-04\n",
      " 8.64686146e-02 1.08051244e-02 7.20256427e-03 2.18539223e-01\n",
      " 1.62613476e-04 4.18828102e-04 2.39688214e-02 1.00205772e-01\n",
      " 4.87536415e-02 6.28358731e-03 3.07105336e-04 9.50127607e-04\n",
      " 6.47383509e-03 5.08442055e-03 9.18312464e-03 1.46152020e-01\n",
      " 2.38352679e-02 1.25830593e-02 1.66749097e-02 2.92113656e-03] \n",
      " -0.98541296\n",
      "p [[6.25782228e-03 5.00625782e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.37672090e-02 1.25156446e-13]\n",
      " [5.00625782e-03 6.25782228e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.00125156e-02 5.00625782e-03]\n",
      " [1.12640801e-02 6.25782228e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.00625782e-03]\n",
      " [6.25782228e-03 1.25156446e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.00125156e-02 2.62828536e-02]\n",
      " [7.50938673e-03 8.76095119e-03 0.00000000e+00 8.17271589e-01\n",
      "  1.00125156e-02 1.25156446e-02]\n",
      " [1.25156446e-13 6.25782228e-03 1.25156446e-13 0.00000000e+00\n",
      "  2.50312891e-03 6.25782228e-03]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [4.1291994e-04 1.0936924e-02 2.4017354e-03 4.7212131e-03 1.6564080e-02\n",
      " 2.8520834e-04 1.3897567e-02 1.3465508e-02 5.1674884e-05 1.8355699e-04\n",
      " 1.0463222e-02 3.2848231e-03 3.9532777e-02 1.4327180e-01 8.4178566e-05\n",
      " 1.1816018e-03 6.3032763e-05 7.1104220e-03 4.9348790e-03 2.7467590e-04\n",
      " 8.1571157e-04 2.9498689e-05 5.4777896e-01 1.0906786e-01 2.4654707e-03\n",
      " 5.0322083e-03 1.5307288e-03 3.8003092e-04 1.5223745e-02 9.7129894e-03\n",
      " 3.4757817e-04 1.5412007e-02 1.0472861e-02 3.1640958e-03 4.5389519e-03\n",
      " 9.0572151e-04] \n",
      " 0.9962345\n",
      "p [[0.00125156 0.00500626 0.         0.00125156 0.12265332 0.00375469]\n",
      " [0.00375469 0.00500626 0.         0.         0.01001252 0.02377972]\n",
      " [0.16020025 0.00125156 0.         0.         0.         0.00375469]\n",
      " [0.00250313 0.4543179  0.         0.         0.00876095 0.0387985 ]\n",
      " [0.01877347 0.00125156 0.         0.         0.00250313 0.00125156]\n",
      " [0.00250313 0.11013767 0.01001252 0.         0.00625782 0.00125156]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  1.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [6.8715488e-04 5.9884866e-03 2.0081436e-03 1.8592512e-03 1.7603625e-01\n",
      " 4.4425880e-03 5.2922042e-03 1.3092161e-03 3.4592079e-04 2.2680068e-05\n",
      " 1.2104086e-02 3.5475805e-02 1.9424947e-02 1.7141707e-02 1.0926373e-04\n",
      " 5.6015310e-04 4.1219620e-03 7.2707259e-03 6.3559194e-03 1.8036101e-02\n",
      " 2.1556269e-04 1.1437775e-04 6.3951991e-02 6.3752897e-02 4.6398297e-02\n",
      " 7.2193062e-03 7.5890035e-05 2.5945323e-04 8.9954940e-04 4.6205763e-03\n",
      " 3.3438224e-03 4.5843178e-01 9.4396258e-03 8.4254025e-03 1.2010160e-02\n",
      " 2.2489305e-03] \n",
      " -0.9933839\n",
      "p [[1.25156446e-13 5.00625782e-03 0.00000000e+00 1.25156446e-13\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [3.75469337e-03 6.25782228e-03 0.00000000e+00 0.00000000e+00\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [8.26032541e-01 2.37797247e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.00625782e-03]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.00876095e-02 2.37797247e-02]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  8.76095119e-03 5.00625782e-03]\n",
      " [1.25156446e-13 5.00625782e-03 5.00625782e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 12\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 1.  0.  1. -1.  1.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.5935043e-04 3.1856520e-03 4.6618146e-04 1.6923978e-03 8.2013512e-04\n",
      " 1.0158735e-04 4.6428009e-03 3.0112690e-03 2.0532083e-05 1.0796652e-05\n",
      " 2.5424198e-03 1.1944384e-03 5.5049063e-04 2.5994980e-01 7.6959122e-06\n",
      " 1.4422138e-04 9.8295632e-06 3.6219324e-03 1.1600804e-03 6.4095271e-05\n",
      " 1.8078653e-04 7.1145928e-07 7.0031232e-01 3.9134892e-03 1.1780468e-03\n",
      " 1.8826454e-03 8.6030690e-05 1.1303453e-04 2.4788184e-03 3.2006237e-03\n",
      " 6.9824157e-05 5.8783009e-04 1.4391651e-03 2.0546313e-04 8.3274976e-04\n",
      " 1.6283493e-04] \n",
      " 0.9924266\n",
      "p [[0.00125156 0.00250313 0.         0.00125156 0.16395494 0.00125156]\n",
      " [0.00250313 0.00125156 0.         0.         0.00750939 0.04005006]\n",
      " [0.         0.00876095 0.         0.         0.         0.00250313]\n",
      " [0.00250313 0.         0.         0.         0.03379224 0.0350438 ]\n",
      " [0.02628285 0.00250313 0.         0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.65331665 0.00375469 0.         0.00500626 0.00125156]]\n",
      "move 31\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 1.  0.  1. -1.  1.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [1.2022560e-03 1.5871564e-02 7.4312054e-03 1.1010107e-02 3.8026161e-02\n",
      " 1.4777547e-02 2.7336841e-02 6.4399396e-04 1.8345969e-03 3.6841797e-05\n",
      " 6.3362293e-02 6.9338314e-02 4.8069857e-02 2.2935371e-03 5.1600696e-04\n",
      " 4.6969508e-04 4.2161397e-03 2.4308795e-02 1.1050301e-02 3.9153215e-02\n",
      " 4.2160851e-04 4.0340735e-04 7.0648305e-03 2.6065457e-01 7.5638399e-02\n",
      " 3.6335953e-02 7.1437877e-05 9.5510611e-04 2.0162580e-03 4.3452341e-02\n",
      " 8.1266323e-03 5.2256897e-02 2.9790157e-02 4.0330470e-02 5.1634554e-02\n",
      " 9.8983096e-03] \n",
      " -0.96478325\n",
      "p [[1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 7.47183980e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.52816020e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 1.  1.  1. -1.  1.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [4.61466807e-05 7.85620436e-02 7.35123002e-04 3.20855752e-02\n",
      " 3.49170924e-03 3.14948382e-04 2.66244471e-01 1.84533407e-03\n",
      " 1.15927585e-04 1.72713717e-05 1.76012404e-02 1.91324968e-02\n",
      " 4.59591683e-04 1.56546663e-02 7.42519769e-05 4.39832365e-04\n",
      " 1.01904065e-04 1.71925440e-01 9.86975804e-02 3.77615070e-04\n",
      " 6.81780395e-04 1.14249369e-05 6.62872344e-02 4.52153897e-03\n",
      " 6.21788716e-03 7.22967880e-03 1.18828713e-04 4.27997817e-04\n",
      " 3.36542190e-03 1.26007542e-01 1.13316666e-04 1.61856599e-03\n",
      " 3.59863192e-02 6.96090457e-04 3.86885330e-02 1.04760518e-04] \n",
      " 0.9968855\n",
      "p [[0.00125156 0.01126408 0.         0.0212766  0.077597   0.01001252]\n",
      " [0.02252816 0.00125156 0.         0.         0.06758448 0.08385482]\n",
      " [0.         0.         0.         0.         0.         0.04005006]\n",
      " [0.00876095 0.         0.         0.         0.00500626 0.22653317]\n",
      " [0.06382979 0.03629537 0.         0.         0.00125156 0.04380476]\n",
      " [0.00500626 0.         0.10763454 0.         0.15894869 0.00625782]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 1.  1.  1. -1.  1.  0.]\n",
      " [ 0. -1.  1. -1.  0. -1.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [2.1579964e-03 6.3354797e-03 1.2034989e-02 5.9829177e-03 5.3262170e-02\n",
      " 3.1037180e-02 1.0785044e-02 1.8919228e-03 1.3116756e-03 3.1098731e-05\n",
      " 4.4848882e-02 1.9637166e-01 1.5150546e-02 5.0555379e-03 2.3926981e-03\n",
      " 8.6936366e-04 1.0872488e-03 7.0550412e-02 3.9533984e-02 9.1434512e-03\n",
      " 5.9877266e-04 1.1877575e-03 5.1005710e-02 4.2680755e-02 1.4271799e-01\n",
      " 3.5385519e-02 5.3491742e-05 7.1628654e-04 1.0390920e-02 1.6930662e-02\n",
      " 1.8314103e-02 5.7971124e-02 2.1122698e-02 3.9583310e-02 3.1377763e-02\n",
      " 2.0129083e-02] \n",
      " -0.9753435\n",
      "p [[1.25156446e-13 4.00500626e-02 0.00000000e+00 3.00375469e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [4.28035044e-01 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  2.62828536e-02 2.50312891e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.61451815e-01]\n",
      " [9.51188986e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.13016270e-02 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 5.00625782e-02]\n",
      " [1.25156446e-13 0.00000000e+00 4.13016270e-02 0.00000000e+00\n",
      "  6.13266583e-02 1.25156446e-13]]\n",
      "move 6\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 1.  0.  1.  1.  0.  0.]\n",
      " [ 1.  1.  1. -1.  1.  0.]\n",
      " [ 0. -1.  1. -1.  0. -1.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]]\n",
      "1 won\n",
      "game 99 completed in 36.34291100502014 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.515561 entropy 2.0159812\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4978206 entropy 2.016766\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4680867 entropy 2.0163474\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4362485 entropy 2.0142465\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.405151 entropy 2.0102305\n",
      "kl 0.016454112\n",
      "completed in 0.16951394081115723 s\n",
      "game 100 completed in 10.249259948730469 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.579978 entropy 1.9776522\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5656009 entropy 1.9753993\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5437138 entropy 1.975847\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5169058 entropy 1.979075\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.489143 entropy 1.9847485\n",
      "kl 0.029507477\n",
      "completed in 0.16659808158874512 s\n",
      "game 101 completed in 7.7570459842681885 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6601477 entropy 2.0498853\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.64539 entropy 2.0557032\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.618474 entropy 2.0600944\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5840397 entropy 2.062333\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5498335 entropy 2.0625033\n",
      "kl 0.011700322\n",
      "completed in 0.17650389671325684 s\n",
      "game 102 completed in 10.65037488937378 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.564086 entropy 2.0679958\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5526876 entropy 2.068848\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5337179 entropy 2.0688653\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.513118 entropy 2.0681663\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.492497 entropy 2.066588\n",
      "kl 0.011593679\n",
      "completed in 0.1690680980682373 s\n",
      "game 103 completed in 7.736111879348755 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5479302 entropy 2.0019674\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5296865 entropy 1.9996156\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5044968 entropy 1.9982557\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4773896 entropy 1.9968028\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4502664 entropy 1.9943297\n",
      "kl 0.0136926845\n",
      "completed in 0.16696500778198242 s\n",
      "game 104 completed in 7.921794176101685 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.584955 entropy 2.032352\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.565226 entropy 2.0287213\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5320442 entropy 2.024907\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4969285 entropy 2.0218658\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4615664 entropy 2.0207815\n",
      "kl 0.013352282\n",
      "completed in 0.17663192749023438 s\n",
      "game 105 completed in 12.374547958374023 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5855951 entropy 2.00669\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5702782 entropy 2.0062196\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5456433 entropy 2.0054016\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5190167 entropy 2.004365\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4957867 entropy 2.0030353\n",
      "kl 0.011703122\n",
      "completed in 0.17575287818908691 s\n",
      "game 106 completed in 10.359660148620605 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4637687 entropy 1.981205\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4438195 entropy 1.9817294\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4152257 entropy 1.983105\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3869696 entropy 1.9839246\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3570833 entropy 1.983315\n",
      "kl 0.018080385\n",
      "completed in 0.19464993476867676 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 107 completed in 7.163832187652588 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4790142 entropy 1.940565\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4686804 entropy 1.9438663\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4484363 entropy 1.9507133\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4247184 entropy 1.9595978\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.398899 entropy 1.9689877\n",
      "kl 0.012449738\n",
      "completed in 0.17252683639526367 s\n",
      "game 108 completed in 8.102572202682495 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5244977 entropy 2.042378\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5111089 entropy 2.045588\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4886405 entropy 2.0450308\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4643579 entropy 2.0420454\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4419053 entropy 2.037963\n",
      "kl 0.013158504\n",
      "completed in 0.16596508026123047 s\n",
      "game 109 completed in 7.794337749481201 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5339746 entropy 2.0413318\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.520127 entropy 2.0362937\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4957938 entropy 2.0316114\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4666805 entropy 2.0278392\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.434771 entropy 2.0251791\n",
      "kl 0.015264824\n",
      "completed in 0.17268896102905273 s\n",
      "game 110 completed in 7.789329290390015 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.578747 entropy 2.039047\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5605462 entropy 2.037509\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5340993 entropy 2.0374556\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5052361 entropy 2.038491\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4793134 entropy 2.0398967\n",
      "kl 0.017394999\n",
      "completed in 0.18763399124145508 s\n",
      "game 111 completed in 8.437166213989258 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5263224 entropy 2.0025425\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5168238 entropy 2.0057414\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4983926 entropy 2.009829\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4747345 entropy 2.0137873\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4484005 entropy 2.0166416\n",
      "kl 0.012079731\n",
      "completed in 0.18991589546203613 s\n",
      "game 112 completed in 7.582628965377808 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5762913 entropy 2.053553\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5627604 entropy 2.052475\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5396104 entropy 2.0486736\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5115833 entropy 2.0431798\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4817986 entropy 2.0372927\n",
      "kl 0.016183574\n",
      "completed in 0.18807101249694824 s\n",
      "game 113 completed in 7.4459388256073 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4232872 entropy 1.9602134\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4115777 entropy 1.9550357\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3920832 entropy 1.9500031\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3692117 entropy 1.9455793\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.345094 entropy 1.9418714\n",
      "kl 0.01171598\n",
      "completed in 0.16912198066711426 s\n",
      "game 114 completed in 8.508808851242065 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5180428 entropy 1.9983937\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.504766 entropy 1.9988502\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4851828 entropy 2.0014992\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.46268 entropy 2.0059118\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.436377 entropy 2.010981\n",
      "kl 0.01341458\n",
      "completed in 0.22665786743164062 s\n",
      "game 115 completed in 7.554877996444702 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4351583 entropy 1.9369522\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4124963 entropy 1.9339937\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3776948 entropy 1.9267572\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3525689 entropy 1.9181429\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3293617 entropy 1.9103031\n",
      "kl 0.015472243\n",
      "completed in 0.18642306327819824 s\n",
      "game 116 completed in 8.557198762893677 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4868906 entropy 1.9413419\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4745321 entropy 1.9367712\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4512236 entropy 1.9345965\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4207234 entropy 1.9352367\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3870056 entropy 1.9381821\n",
      "kl 0.008749922\n",
      "completed in 0.19466495513916016 s\n",
      "game 117 completed in 7.819343090057373 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5269766 entropy 1.9687368\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5010495 entropy 1.9784243\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4695053 entropy 1.9872236\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.438625 entropy 1.9926519\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4095411 entropy 1.9932784\n",
      "kl 0.040103674\n",
      "completed in 0.16469788551330566 s\n",
      "game 118 completed in 7.558639049530029 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4564996 entropy 1.9779458\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4405036 entropy 1.9735968\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4120848 entropy 1.9673344\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3814707 entropy 1.9601247\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.355117 entropy 1.953131\n",
      "kl 0.017183911\n",
      "completed in 0.17220783233642578 s\n",
      "game 119 completed in 12.085750102996826 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5628557 entropy 1.9862229\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5467594 entropy 1.9850581\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5285394 entropy 1.984647\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.509875 entropy 1.9843787\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4874048 entropy 1.9839842\n",
      "kl 0.0149171725\n",
      "completed in 0.1695258617401123 s\n",
      "game 120 completed in 9.345332860946655 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5450194 entropy 1.967406\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5159795 entropy 1.9655561\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4821637 entropy 1.9633958\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4515533 entropy 1.9621983\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.42162 entropy 1.9623616\n",
      "kl 0.01449633\n",
      "completed in 0.1765270233154297 s\n",
      "game 121 completed in 8.137818098068237 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5182092 entropy 1.9737417\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.507541 entropy 1.9779158\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4864686 entropy 1.9835036\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4604301 entropy 1.9892488\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4336293 entropy 1.9942354\n",
      "kl 0.010392432\n",
      "completed in 0.20512986183166504 s\n",
      "game 122 completed in 6.724261045455933 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4741464 entropy 1.9740396\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4643004 entropy 1.9764388\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.448377 entropy 1.9767668\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4295676 entropy 1.9750648\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4101639 entropy 1.971698\n",
      "kl 0.013612397\n",
      "completed in 0.16600608825683594 s\n",
      "game 123 completed in 10.720489263534546 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4122112 entropy 1.9570777\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.400166 entropy 1.9545095\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3768806 entropy 1.9521816\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3501723 entropy 1.9497647\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3236756 entropy 1.9472128\n",
      "kl 0.011857028\n",
      "completed in 0.17779898643493652 s\n",
      "game 124 completed in 11.162277221679688 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.490588 entropy 1.9605904\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4760404 entropy 1.9592276\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4524143 entropy 1.9588406\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4240084 entropy 1.9588152\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3954737 entropy 1.9589298\n",
      "kl 0.015694898\n",
      "completed in 0.17008304595947266 s\n",
      "game 125 completed in 6.032386064529419 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5374675 entropy 1.976757\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5292194 entropy 1.9782641\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5137832 entropy 1.9791217\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.493208 entropy 1.9787631\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4702432 entropy 1.977296\n",
      "kl 0.009501278\n",
      "completed in 0.16483783721923828 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 126 completed in 7.846718788146973 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.449596 entropy 1.965728\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.423836 entropy 1.9596272\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.393513 entropy 1.951415\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3657217 entropy 1.9427088\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3418365 entropy 1.934183\n",
      "kl 0.02577835\n",
      "completed in 0.1755051612854004 s\n",
      "game 127 completed in 8.21247386932373 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4782708 entropy 1.933945\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4620826 entropy 1.9317317\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4336212 entropy 1.9335895\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4022086 entropy 1.937855\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3708227 entropy 1.942591\n",
      "kl 0.022408256\n",
      "completed in 0.16080999374389648 s\n",
      "game 128 completed in 7.479552745819092 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4528096 entropy 1.94693\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4356399 entropy 1.9516661\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.415025 entropy 1.9546523\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.388359 entropy 1.9540441\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3632312 entropy 1.9501766\n",
      "kl 0.029082024\n",
      "completed in 0.1753082275390625 s\n",
      "game 129 completed in 6.740333080291748 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.480226 entropy 1.9018553\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4617467 entropy 1.896042\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4273293 entropy 1.8908114\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3908968 entropy 1.8860358\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3570054 entropy 1.8816406\n",
      "kl 0.03905223\n",
      "completed in 0.20018792152404785 s\n",
      "game 130 completed in 5.81372594833374 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5771096 entropy 1.9561253\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5565805 entropy 1.9576284\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5196755 entropy 1.9638187\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4782116 entropy 1.9726427\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.446985 entropy 1.9838412\n",
      "kl 0.020299263\n",
      "completed in 0.1959519386291504 s\n",
      "game 131 completed in 12.8421311378479 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.476708 entropy 1.9890506\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4573178 entropy 2.001667\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.428126 entropy 2.0118783\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.39848 entropy 2.0164838\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3682857 entropy 2.0146818\n",
      "kl 0.029702589\n",
      "completed in 0.1713402271270752 s\n",
      "game 132 completed in 8.334352016448975 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5835207 entropy 2.0424004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5713844 entropy 2.0373497\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5464237 entropy 2.0322785\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.516378 entropy 2.0282474\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4860125 entropy 2.0248067\n",
      "kl 0.017407205\n",
      "completed in 0.16987299919128418 s\n",
      "game 133 completed in 7.45971417427063 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.538047 entropy 1.9760761\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.522927 entropy 1.9740407\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.492288 entropy 1.9723253\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4590638 entropy 1.9701345\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4275827 entropy 1.9668198\n",
      "kl 0.018699117\n",
      "completed in 0.19474101066589355 s\n",
      "game 134 completed in 7.493207931518555 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.511226 entropy 2.0220778\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4954457 entropy 2.019763\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4739103 entropy 2.0161705\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.449601 entropy 2.0097702\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.423789 entropy 2.00034\n",
      "kl 0.019401994\n",
      "completed in 0.1666579246520996 s\n",
      "game 135 completed in 5.843675851821899 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6136155 entropy 1.9605889\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5760796 entropy 1.945962\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.542571 entropy 1.9281452\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5118 entropy 1.9137356\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4713922 entropy 1.9051809\n",
      "kl 0.027771428\n",
      "completed in 0.19442319869995117 s\n",
      "game 136 completed in 7.599634885787964 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5248682 entropy 1.9290224\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5013337 entropy 1.9391837\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4749362 entropy 1.9547722\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4522574 entropy 1.9694722\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4234383 entropy 1.9778222\n",
      "kl 0.030412842\n",
      "completed in 0.1742703914642334 s\n",
      "game 137 completed in 6.736240863800049 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4881957 entropy 1.9028708\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4632201 entropy 1.9034024\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4296544 entropy 1.9050457\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3959975 entropy 1.9087188\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3575373 entropy 1.9156661\n",
      "kl 0.027375542\n",
      "completed in 0.17182064056396484 s\n",
      "game 138 completed in 8.758126974105835 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.61731 entropy 1.9590924\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5957115 entropy 1.9609042\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5642276 entropy 1.9602122\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5310924 entropy 1.957216\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4996119 entropy 1.9525267\n",
      "kl 0.027176075\n",
      "completed in 0.19707012176513672 s\n",
      "game 139 completed in 12.508129119873047 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4773128 entropy 1.891221\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4516175 entropy 1.8889877\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4154909 entropy 1.8886564\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3810039 entropy 1.8871794\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3513572 entropy 1.882833\n",
      "kl 0.03722194\n",
      "completed in 0.1712789535522461 s\n",
      "game 140 completed in 6.132090091705322 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5137782 entropy 1.9102975\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5037313 entropy 1.9074705\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4779315 entropy 1.9063542\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4457238 entropy 1.9066377\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4099834 entropy 1.9080235\n",
      "kl 0.02861122\n",
      "completed in 0.1700601577758789 s\n",
      "game 141 completed in 6.0635011196136475 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4381685 entropy 1.8876605\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.420422 entropy 1.8922722\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3950028 entropy 1.8967787\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3651369 entropy 1.9011576\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3356526 entropy 1.9047501\n",
      "kl 0.024124578\n",
      "completed in 0.1728992462158203 s\n",
      "game 142 completed in 7.693936824798584 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5216672 entropy 1.9386947\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4948416 entropy 1.9419205\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4538894 entropy 1.9436185\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4149969 entropy 1.945918\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3793738 entropy 1.9477917\n",
      "kl 0.021130119\n",
      "completed in 0.19471192359924316 s\n",
      "game 143 completed in 5.958580017089844 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5418518 entropy 1.964464\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.520924 entropy 1.9672227\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4936194 entropy 1.9693735\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4605746 entropy 1.9689965\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4265873 entropy 1.966141\n",
      "kl 0.020261535\n",
      "completed in 0.16796302795410156 s\n",
      "game 144 completed in 7.816426992416382 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4002967 entropy 1.858125\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.377492 entropy 1.8523571\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3469563 entropy 1.8484775\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3119705 entropy 1.8489707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.2745967 entropy 1.8534704\n",
      "kl 0.01845739\n",
      "completed in 0.20178627967834473 s\n",
      "game 145 completed in 8.162363052368164 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5258794 entropy 1.9294862\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5122364 entropy 1.9324881\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.482244 entropy 1.9315361\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4518876 entropy 1.9276845\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.424164 entropy 1.92365\n",
      "kl 0.016324425\n",
      "completed in 0.19585609436035156 s\n",
      "game 146 completed in 6.699257850646973 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5277464 entropy 1.9214319\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5091565 entropy 1.9171021\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4803016 entropy 1.9114046\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4509077 entropy 1.9054205\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4224923 entropy 1.9004534\n",
      "kl 0.024514727\n",
      "completed in 0.1574089527130127 s\n",
      "game 147 completed in 12.185580253601074 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4463167 entropy 1.8620595\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.431828 entropy 1.8599168\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4055524 entropy 1.8586106\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3732898 entropy 1.8578299\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3423364 entropy 1.8573401\n",
      "kl 0.013691636\n",
      "completed in 0.185560941696167 s\n",
      "game 148 completed in 10.498433828353882 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4304297 entropy 1.8888493\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.416296 entropy 1.890296\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3886936 entropy 1.8925774\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3581586 entropy 1.8953462\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3313825 entropy 1.8985962\n",
      "kl 0.021277152\n",
      "completed in 0.16608786582946777 s\n",
      "prediction:\n",
      " [0.00201224 0.00437208 0.0043476  0.00179264 0.01387687 0.00277188\n",
      " 0.00505104 0.00515806 0.03407672 0.10706221 0.02924792 0.01410765\n",
      " 0.00520567 0.03289454 0.04116466 0.0983455  0.08626853 0.00252195\n",
      " 0.00343742 0.0874226  0.08927443 0.0396749  0.03880974 0.00751226\n",
      " 0.01595401 0.04313255 0.10225993 0.03832462 0.00373507 0.00497069\n",
      " 0.00180274 0.02219817 0.0021241  0.00350259 0.00415774 0.00142887] \n",
      " -0.30666414\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.24030038e-01 5.10638298e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 9.76220275e-02 1.67709637e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.4910598e-05 1.5809287e-04 3.9362037e-04 1.5767639e-04 9.7325305e-05\n",
      " 1.3256358e-03 1.7044120e-04 9.8393124e-05 8.1435956e-02 3.5630567e-03\n",
      " 5.0837272e-03 1.5264880e-04 2.2591335e-04 5.3168625e-02 2.9293048e-01\n",
      " 8.4076514e-03 6.1798305e-03 2.4711792e-04 4.5676899e-04 3.5782612e-03\n",
      " 5.2353316e-03 4.4508490e-01 4.1769192e-02 1.5126860e-04 1.8958411e-04\n",
      " 4.9885996e-03 3.6616835e-03 3.8120318e-02 1.1815984e-04 1.4486181e-04\n",
      " 1.6260426e-03 1.3272834e-04 1.7648311e-04 3.8827898e-04 3.0954852e-04\n",
      " 3.6944886e-05] \n",
      " 0.69682616\n",
      "p [[0.00125156 0.00500626 0.00250313 0.00250313 0.01126408 0.00375469]\n",
      " [0.00375469 0.00250313 0.03629537 0.08260325 0.09887359 0.00876095]\n",
      " [0.00625782 0.02377972 0.03128911 0.         0.10137672 0.00125156]\n",
      " [0.00250313 0.077597   0.26032541 0.02878598 0.02628285 0.00375469]\n",
      " [0.00876095 0.05006258 0.06633292 0.02753442 0.00125156 0.00500626]\n",
      " [0.00125156 0.01126408 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.2011408e-03 8.0408092e-04 4.4512414e-04 8.6966011e-04 4.7718748e-04\n",
      " 1.1435904e-03 7.2597712e-04 7.4627344e-04 5.6567336e-03 1.4847677e-03\n",
      " 2.9084261e-03 4.4295765e-04 1.8011942e-03 3.2763746e-01 5.7851495e-03\n",
      " 6.7730423e-04 1.6551606e-02 4.7102734e-03 5.1994175e-03 1.1398226e-02\n",
      " 6.8233133e-04 5.4251431e-03 5.8392531e-01 1.4941583e-03 6.0725381e-04\n",
      " 2.8205137e-03 3.1564797e-03 6.4121936e-03 3.1591431e-04 9.1414759e-04\n",
      " 8.4558781e-04 6.0965435e-04 8.2749786e-04 2.5467575e-04 6.4696901e-04\n",
      " 3.9578156e-04] \n",
      " -0.4845043\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.71589487e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.20150188e-01 2.94117647e-01 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 2.49061327e-01\n",
      "  1.25156446e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 5.13141427e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00109095 0.00058264 0.00118431 0.0006114  0.00042788 0.00231472\n",
      " 0.00213589 0.00276424 0.3052733  0.00583992 0.00219051 0.00036733\n",
      " 0.00186903 0.00842223 0.00661318 0.00082572 0.20912303 0.00443373\n",
      " 0.00735416 0.08535831 0.00041334 0.01791442 0.01047447 0.00173444\n",
      " 0.00040613 0.00187902 0.00395199 0.30491918 0.00265714 0.00152033\n",
      " 0.00171251 0.00047884 0.00058675 0.0011948  0.00094889 0.00042542] \n",
      " 0.40308163\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00250313 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.63829787 0.         0.         0.01126408 0.00125156]\n",
      " [0.00250313 0.00625782 0.         0.00375469 0.2991239  0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00500626 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.2322734e-03 2.0353083e-02 2.4306081e-04 2.3161264e-03 1.6497364e-03\n",
      " 1.7982404e-03 4.9666531e-02 1.9491960e-03 7.9689473e-03 4.1375877e-03\n",
      " 4.2341007e-03 1.4892283e-03 2.2256207e-03 4.2979158e-03 4.3950406e-01\n",
      " 8.3291176e-04 2.8023742e-02 3.3331782e-02 2.1514045e-02 3.3097167e-02\n",
      " 3.8745152e-04 2.5565013e-01 4.4942913e-03 2.5243938e-03 9.4712269e-04\n",
      " 3.6189388e-03 6.3097002e-03 1.4621480e-02 3.1170587e-03 2.8319756e-02\n",
      " 9.4870379e-04 1.8651081e-03 3.7520602e-03 5.5780995e-04 1.1868449e-02\n",
      " 1.1523477e-03] \n",
      " -0.74599814\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.25657071e-02 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.36795995e-01 1.25156446e-03]\n",
      " [1.25156446e-03 2.50312891e-02 0.00000000e+00 6.25782228e-03\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 4.69336671e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.1674656e-03 4.1688345e-03 1.3209727e-03 2.0655836e-03 3.3863322e-04\n",
      " 1.5861691e-03 3.1290378e-03 6.7619677e-03 2.5130257e-02 1.6692379e-02\n",
      " 1.3075124e-03 6.0381083e-04 1.1680881e-03 2.4127306e-02 1.0499401e-03\n",
      " 3.2690194e-04 5.8717984e-01 4.3636397e-03 6.7124721e-03 2.3031820e-01\n",
      " 4.5364161e-04 3.5531400e-03 2.0407202e-02 1.7908829e-03 6.8262615e-04\n",
      " 1.1692561e-03 1.1783930e-02 2.0705562e-02 7.1369340e-03 2.0195902e-03\n",
      " 1.0236683e-03 6.1746815e-04 1.3519395e-03 1.9042009e-03 3.7123158e-03\n",
      " 1.1686886e-03] \n",
      " -0.22098407\n",
      "p [[0.00125156 0.00375469 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.01001252 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.00750939 0.00625782]\n",
      " [0.00375469 0.00625782 0.         0.92866083 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.00125156 0.00500626]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [2.2347535e-03 3.2458017e-03 3.0235303e-04 1.4575947e-03 4.6383817e-04\n",
      " 3.7107849e-04 2.8737511e-02 9.1810321e-04 2.0487604e-03 1.3942602e-03\n",
      " 2.9335192e-03 4.3707993e-04 2.4185763e-03 2.8790276e-02 2.6969926e-03\n",
      " 2.5160814e-04 1.2510933e-01 3.6987090e-01 2.7405906e-01 7.7271223e-02\n",
      " 1.0239651e-04 1.8920671e-03 2.8399725e-02 6.7297881e-03 1.7047176e-04\n",
      " 4.4424925e-03 2.3660767e-03 6.1029424e-03 3.1248271e-03 5.3677862e-03\n",
      " 4.4087804e-04 1.3251605e-03 3.2598744e-03 9.0087409e-04 7.1525890e-03\n",
      " 3.2094419e-03] \n",
      " -0.9818696\n",
      "p [[1.25156446e-03 1.25156446e-03 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-03 1.25156446e-03 5.00625782e-03 3.75469337e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.63579474e-01 1.25156446e-03]\n",
      " [2.50312891e-03 6.75844806e-02 0.00000000e+00 0.00000000e+00\n",
      "  2.62828536e-02 2.50312891e-03]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-03 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-03 2.50312891e-03]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00685651 0.01728903 0.00300845 0.01428771 0.0027325  0.00169114\n",
      " 0.02041171 0.01373886 0.0759097  0.10959014 0.00538921 0.00379859\n",
      " 0.01842941 0.11379588 0.00095691 0.00134103 0.11365929 0.00836408\n",
      " 0.01296072 0.02527135 0.00092347 0.00326745 0.13904966 0.01414356\n",
      " 0.0034542  0.00712983 0.07137547 0.10316022 0.01971354 0.00466325\n",
      " 0.00176692 0.00829268 0.01177023 0.00496541 0.0323899  0.00445215] \n",
      " 0.6676504\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00625782 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.89236546]\n",
      " [0.04255319 0.02252816 0.         0.         0.00625782 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00856294 0.01674128 0.00206872 0.01165454 0.0063335  0.00212265\n",
      " 0.12165102 0.00707222 0.0045783  0.1220194  0.00388887 0.00887486\n",
      " 0.03064108 0.0526168  0.00065076 0.00064828 0.0040194  0.0437429\n",
      " 0.04028761 0.00270701 0.00048406 0.00085475 0.0859514  0.0410237\n",
      " 0.00632569 0.00527373 0.21241409 0.01672206 0.01149361 0.04262156\n",
      " 0.00181443 0.01676317 0.02133829 0.00255672 0.02457171 0.01890923] \n",
      " -0.97503775\n",
      "p [[0.00500626 0.00625782 0.00375469 0.00625782 0.00375469 0.00375469]\n",
      " [0.00750939 0.01501877 0.02753442 0.02628285 0.00500626 0.00375469]\n",
      " [0.00625782 0.         0.         0.         0.         0.        ]\n",
      " [0.01251564 0.62703379 0.         0.         0.14893617 0.00625782]\n",
      " [0.00375469 0.00876095 0.0175219  0.         0.01627034 0.00375469]\n",
      " [0.00375469 0.00375469 0.01126408 0.00375469 0.00750939 0.00500626]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.6894275e-04 1.8178123e-03 4.5880191e-03 5.3640786e-03 3.2743206e-03\n",
      " 2.6543138e-03 6.4625833e-03 1.7334631e-03 4.0878044e-03 4.6222648e-01\n",
      " 1.4186134e-03 1.8701809e-02 8.8282004e-03 9.1618165e-02 6.1089545e-04\n",
      " 1.6452969e-04 1.6068090e-03 9.2499336e-05 1.7074103e-04 4.1972820e-04\n",
      " 2.8931402e-04 1.2097715e-03 9.6093491e-02 3.1825167e-03 1.7591130e-02\n",
      " 2.5343960e-03 2.1608841e-01 5.2427338e-03 4.4331201e-03 4.8696036e-03\n",
      " 1.9717831e-03 1.0663803e-02 7.1898201e-03 5.4273033e-03 5.5574151e-03\n",
      " 1.1455744e-03] \n",
      " 0.5150284\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.02628285 0.00250313 0.00125156 0.0175219  0.00125156 0.00250313]\n",
      " [0.00375469 0.         0.         0.         0.         0.        ]\n",
      " [0.00500626 0.         0.         0.         0.06883605 0.78347935]\n",
      " [0.00125156 0.00125156 0.04380476 0.         0.00125156 0.02002503]\n",
      " [0.00125156 0.00250313 0.00250313 0.00125156 0.00250313 0.00250313]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  0. -1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.31977804e-03 1.57471430e-02 7.47634389e-04 7.59709300e-03\n",
      " 9.76437237e-03 1.54831249e-03 4.02871668e-01 2.27019796e-03\n",
      " 1.02540653e-03 4.11998853e-02 4.40920092e-04 1.07005527e-02\n",
      " 1.24233984e-03 6.51053735e-04 4.12865593e-05 5.91114513e-05\n",
      " 2.93533958e-04 1.03319865e-02 2.39899866e-02 2.43382776e-04\n",
      " 3.31969641e-05 1.29077787e-04 1.59127510e-03 9.19991988e-04\n",
      " 1.36098266e-02 1.75288168e-03 6.27514273e-02 1.87075697e-03\n",
      " 2.34402483e-03 3.15630138e-01 1.47914211e-03 2.99797133e-02\n",
      " 1.22577604e-02 6.70411682e-04 1.23291472e-02 5.56569453e-03] \n",
      " -0.96821773\n",
      "p [[0.00375469 0.00375469 0.01501877 0.0175219  0.00375469 0.00500626]\n",
      " [0.00625782 0.00500626 0.00625782 0.20650814 0.00500626 0.00876095]\n",
      " [0.00625782 0.         0.         0.         0.         0.        ]\n",
      " [0.00625782 0.         0.         0.         0.51564456 0.        ]\n",
      " [0.02002503 0.00500626 0.12140175 0.         0.00500626 0.00375469]\n",
      " [0.00500626 0.00500626 0.00625782 0.00500626 0.00125156 0.00750939]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.5445298e-03 5.8494259e-02 3.7896689e-03 1.0160618e-01 2.2098873e-02\n",
      " 7.5044425e-04 1.2140931e-02 2.9527964e-02 5.7113692e-02 6.7957386e-02\n",
      " 1.1482580e-02 1.7327311e-02 1.4765869e-02 1.0271639e-03 2.0815428e-04\n",
      " 1.2736842e-04 3.6778681e-03 4.0193852e-03 9.0630343e-03 5.8884680e-04\n",
      " 6.7385954e-05 4.8785232e-04 5.1130145e-03 6.5392801e-03 7.2798498e-02\n",
      " 2.4506053e-02 3.5685387e-02 7.5531416e-02 4.3808818e-02 1.2830057e-02\n",
      " 1.8319123e-03 3.3867136e-02 8.4030584e-02 5.0975438e-03 1.7267986e-01\n",
      " 3.8140190e-03] \n",
      " 0.9405535\n",
      "p [[1.25156446e-03 1.25156446e-03 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [4.25531915e-02 1.25156446e-13 1.25156446e-13 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 1.25156446e-13 6.25782228e-03 0.00000000e+00\n",
      "  1.25156446e-13 9.31163955e-01]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-03]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0.  0.  0.  1.  0. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.9700716e-01 1.1366491e-02 3.7232964e-04 6.4650895e-03 2.0068754e-02\n",
      " 2.5360899e-03 3.1909991e-02 6.1370246e-03 5.1654928e-04 4.1874968e-02\n",
      " 1.8316250e-04 4.4418234e-02 6.8091326e-03 4.1765245e-04 4.3116645e-05\n",
      " 1.6179416e-05 6.2034943e-04 7.7008978e-02 8.5881770e-02 4.4227974e-04\n",
      " 1.2496857e-05 4.3471602e-05 1.4263601e-03 1.4999541e-02 3.8732585e-02\n",
      " 3.2534890e-03 9.1016173e-02 7.6320325e-04 7.0299092e-03 2.0532066e-02\n",
      " 1.7632035e-03 8.1076473e-02 1.8185198e-02 4.5227332e-04 9.6566947e-03\n",
      " 1.7696171e-01] \n",
      " 0.33620623\n",
      "p [[0.00876095 0.06132666 0.02503129 0.08510638 0.01376721 0.00876095]\n",
      " [0.0175219  0.04380476 0.06508135 0.07133917 0.01501877 0.03254068]\n",
      " [0.02377972 0.         0.         0.         0.         0.        ]\n",
      " [0.01001252 0.         0.         0.         0.         0.        ]\n",
      " [0.05882353 0.04380476 0.05131414 0.         0.04630788 0.        ]\n",
      " [0.00876095 0.02377972 0.08635795 0.00876095 0.13141427 0.05882353]]\n",
      "move 34\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0.  0.  0.  1.  0. -1.]\n",
      " [ 0.  0.  0.  0.  1.  0.]]\n",
      "prediction:\n",
      " [2.9898901e-04 8.7980488e-03 3.8755850e-03 4.1758996e-02 8.9670280e-03\n",
      " 1.4912820e-04 3.9875451e-03 2.3032928e-01 9.7607831e-03 2.5519107e-02\n",
      " 1.6588141e-03 4.9801003e-03 7.1981903e-03 9.8744326e-04 1.0416656e-04\n",
      " 4.5786604e-05 4.9292794e-03 1.4831776e-03 1.6684787e-03 7.0190162e-04\n",
      " 9.3714862e-06 4.1923774e-04 8.1337849e-03 4.7312868e-03 5.1767349e-02\n",
      " 8.6289523e-03 1.5107139e-02 5.7862313e-03 4.6438488e-01 3.2921806e-03\n",
      " 1.4606958e-03 2.5059830e-02 2.0935416e-02 6.9217817e-03 2.5838036e-02\n",
      " 3.2212827e-04] \n",
      " 0.6352284\n",
      "p [[1.87734668e-02 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [3.75469337e-03 1.25156446e-13 1.25156446e-13 2.50312891e-03\n",
      "  1.25156446e-13 1.88986233e-01]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.50938673e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.50312891e-03 1.25156446e-13 8.76095119e-03 0.00000000e+00\n",
      "  1.25156446e-13 0.00000000e+00]\n",
      " [1.25156446e-13 7.50938673e-03 1.25156446e-03 1.25156446e-13\n",
      "  0.00000000e+00 7.55944931e-01]]\n",
      "move 35\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  1. -1.]\n",
      " [ 0.  0.  0.  1.  0. -1.]\n",
      " [ 0.  0.  0.  0.  1. -1.]]\n",
      "-1 won\n",
      "game 149 completed in 36.648905992507935 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5107083 entropy 1.9659259\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4916992 entropy 1.9671979\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4632812 entropy 1.9675667\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.435084 entropy 1.9671036\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4063547 entropy 1.9649665\n",
      "kl 0.018427126\n",
      "completed in 0.18427681922912598 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 150 completed in 9.854627132415771 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.461402 entropy 1.8885448\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.442902 entropy 1.8879023\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4096544 entropy 1.8879325\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3741002 entropy 1.8876666\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3418508 entropy 1.8865615\n",
      "kl 0.021771261\n",
      "completed in 0.1982557773590088 s\n",
      "game 151 completed in 5.871829986572266 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5183136 entropy 1.951236\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.502658 entropy 1.9484913\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4756062 entropy 1.9456465\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4468846 entropy 1.9435887\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4208608 entropy 1.9422929\n",
      "kl 0.016118694\n",
      "completed in 0.1767277717590332 s\n",
      "game 152 completed in 6.536588668823242 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.531524 entropy 1.9250104\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5119119 entropy 1.9263632\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4832897 entropy 1.9292656\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4511812 entropy 1.932302\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4193673 entropy 1.93397\n",
      "kl 0.020749774\n",
      "completed in 0.18245506286621094 s\n",
      "game 153 completed in 19.147233724594116 s 24 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4440992 entropy 1.8902881\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.419478 entropy 1.8958817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.387014 entropy 1.9038281\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3568795 entropy 1.9097664\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3256698 entropy 1.9125416\n",
      "kl 0.021581644\n",
      "completed in 0.19486522674560547 s\n",
      "game 154 completed in 7.435251951217651 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4854827 entropy 1.927651\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4687982 entropy 1.9246182\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4451907 entropy 1.9228013\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.419013 entropy 1.921974\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.393018 entropy 1.9212135\n",
      "kl 0.023379862\n",
      "completed in 0.1738290786743164 s\n",
      "game 155 completed in 8.112836837768555 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.480924 entropy 1.9162054\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4655876 entropy 1.9124479\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4419715 entropy 1.9068148\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4180374 entropy 1.9009521\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3945854 entropy 1.8952223\n",
      "kl 0.02705724\n",
      "completed in 0.1736440658569336 s\n",
      "game 156 completed in 8.109333038330078 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6031237 entropy 1.94011\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5818832 entropy 1.938081\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5500517 entropy 1.9407357\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.516958 entropy 1.9466124\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4846025 entropy 1.9531056\n",
      "kl 0.01610952\n",
      "completed in 0.18913578987121582 s\n",
      "game 157 completed in 8.866482973098755 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4126942 entropy 1.8892307\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3998928 entropy 1.8913547\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3764114 entropy 1.8929772\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.346625 entropy 1.8934194\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3174026 entropy 1.8915399\n",
      "kl 0.019468615\n",
      "completed in 0.1627650260925293 s\n",
      "game 158 completed in 5.923632860183716 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.418044 entropy 1.8880816\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4064832 entropy 1.8800747\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3850265 entropy 1.8719857\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3573606 entropy 1.8654509\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.32823 entropy 1.8605583\n",
      "kl 0.021111999\n",
      "completed in 0.20581722259521484 s\n",
      "game 159 completed in 7.701778888702393 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5249085 entropy 1.8981287\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5091295 entropy 1.899208\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4829645 entropy 1.9028841\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4494793 entropy 1.9087527\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4075084 entropy 1.9157932\n",
      "kl 0.019527748\n",
      "completed in 0.18657183647155762 s\n",
      "game 160 completed in 5.938196897506714 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.467412 entropy 1.9093938\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4480267 entropy 1.9157984\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4205885 entropy 1.9192362\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3916514 entropy 1.9192958\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3641834 entropy 1.9161625\n",
      "kl 0.016348928\n",
      "completed in 0.18331503868103027 s\n",
      "game 161 completed in 9.046565055847168 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.329612 entropy 1.8576742\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3123002 entropy 1.8515363\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2852254 entropy 1.84493\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2594476 entropy 1.8389181\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2365742 entropy 1.8349631\n",
      "kl 0.01598016\n",
      "completed in 0.1976029872894287 s\n",
      "game 162 completed in 9.684493064880371 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5516925 entropy 1.884593\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.523939 entropy 1.8874651\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.501953 entropy 1.8923631\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4801304 entropy 1.8936127\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.441609 entropy 1.8886545\n",
      "kl 0.019284744\n",
      "completed in 0.18713903427124023 s\n",
      "game 163 completed in 6.902959823608398 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5247061 entropy 1.8943323\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5030735 entropy 1.8884239\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4740858 entropy 1.8855892\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4397662 entropy 1.8874195\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4008577 entropy 1.8935809\n",
      "kl 0.015776096\n",
      "completed in 0.15765666961669922 s\n",
      "game 164 completed in 5.808307886123657 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.454072 entropy 1.8730557\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4309652 entropy 1.8829317\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3967786 entropy 1.8889651\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3609035 entropy 1.8894337\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3311765 entropy 1.8856378\n",
      "kl 0.024382899\n",
      "completed in 0.16676712036132812 s\n",
      "game 165 completed in 12.885080814361572 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4501727 entropy 1.8635669\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4366734 entropy 1.864613\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4130735 entropy 1.8736286\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3826394 entropy 1.8877726\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3511882 entropy 1.9020361\n",
      "kl 0.022550592\n",
      "completed in 0.16971588134765625 s\n",
      "game 166 completed in 13.86238431930542 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4211166 entropy 1.938005\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3988166 entropy 1.9454362\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.369501 entropy 1.9469143\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3373847 entropy 1.9424152\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.311344 entropy 1.9338698\n",
      "kl 0.017776338\n",
      "completed in 0.16708612442016602 s\n",
      "game 167 completed in 7.54143500328064 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4426773 entropy 1.9425669\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4258113 entropy 1.932379\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3997302 entropy 1.9222753\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.370736 entropy 1.9120305\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3426597 entropy 1.9016299\n",
      "kl 0.028022144\n",
      "completed in 0.17935895919799805 s\n",
      "game 168 completed in 7.536473035812378 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5247805 entropy 1.9275357\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.512953 entropy 1.9241593\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4857726 entropy 1.9246817\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.451881 entropy 1.9260596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.4214976 entropy 1.9257271\n",
      "kl 0.022710651\n",
      "completed in 0.20169496536254883 s\n",
      "game 169 completed in 7.409854888916016 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4649494 entropy 1.8937373\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4262586 entropy 1.8883581\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3968434 entropy 1.8812071\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.376724 entropy 1.8771393\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.342436 entropy 1.8768065\n",
      "kl 0.016999926\n",
      "completed in 0.1658039093017578 s\n",
      "game 170 completed in 14.560117959976196 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.496287 entropy 1.8551567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4676826 entropy 1.8612938\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4327314 entropy 1.8641512\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3923328 entropy 1.8612422\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3525765 entropy 1.8538876\n",
      "kl 0.035882927\n",
      "completed in 0.1720881462097168 s\n",
      "game 171 completed in 5.826231956481934 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.575326 entropy 1.9190242\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5506876 entropy 1.9129678\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5124805 entropy 1.9121969\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4644897 entropy 1.9178903\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4137063 entropy 1.928366\n",
      "kl 0.022133261\n",
      "completed in 0.18695807456970215 s\n",
      "game 172 completed in 7.438713788986206 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4079258 entropy 1.9031571\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3912122 entropy 1.9138219\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3668368 entropy 1.9203258\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.340962 entropy 1.9209688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3167188 entropy 1.9168019\n",
      "kl 0.029116966\n",
      "completed in 0.16903209686279297 s\n",
      "game 173 completed in 8.005697011947632 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.383512 entropy 1.8807981\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3616042 entropy 1.874052\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3310764 entropy 1.8676968\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3003786 entropy 1.8621321\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2725003 entropy 1.856451\n",
      "kl 0.023810875\n",
      "completed in 0.17557978630065918 s\n",
      "game 174 completed in 5.785038948059082 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5056422 entropy 1.8999319\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.484222 entropy 1.8963509\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4503593 entropy 1.8934824\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4191508 entropy 1.8924025\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.388864 entropy 1.8931686\n",
      "kl 0.029207177\n",
      "completed in 0.17394375801086426 s\n",
      "game 175 completed in 12.18383502960205 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4692943 entropy 1.8913919\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4499507 entropy 1.8945212\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4216526 entropy 1.899044\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3960328 entropy 1.9035517\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.373916 entropy 1.9063864\n",
      "kl 0.025005758\n",
      "completed in 0.17012500762939453 s\n",
      "game 176 completed in 9.951539993286133 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5181918 entropy 1.8719275\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4893203 entropy 1.8709679\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4516985 entropy 1.8699871\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4214702 entropy 1.8696368\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3949602 entropy 1.870018\n",
      "kl 0.034295827\n",
      "completed in 0.19874906539916992 s\n",
      "game 177 completed in 7.605628967285156 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4889612 entropy 1.8938389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.46908 entropy 1.8982182\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4378817 entropy 1.9029772\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4047484 entropy 1.9071009\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3747232 entropy 1.9105998\n",
      "kl 0.03282455\n",
      "completed in 0.1816849708557129 s\n",
      "game 178 completed in 7.628370761871338 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6495066 entropy 1.9385321\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.628104 entropy 1.9432784\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5975382 entropy 1.9483076\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5637665 entropy 1.9523717\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5280476 entropy 1.95397\n",
      "kl 0.033167753\n",
      "completed in 0.16709589958190918 s\n",
      "game 179 completed in 9.087480068206787 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4941828 entropy 1.9689488\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4647188 entropy 1.9667773\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.434649 entropy 1.9647676\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4069142 entropy 1.9627881\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3783438 entropy 1.9604666\n",
      "kl 0.030611351\n",
      "completed in 0.17255210876464844 s\n",
      "game 180 completed in 9.36959195137024 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.536603 entropy 1.9656422\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5131094 entropy 1.9653451\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4814692 entropy 1.9663312\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4526203 entropy 1.9675522\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4226832 entropy 1.9671222\n",
      "kl 0.03545444\n",
      "completed in 0.16290879249572754 s\n",
      "game 181 completed in 7.482805013656616 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5430496 entropy 1.9592756\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.524776 entropy 1.9574175\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5016003 entropy 1.9550235\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.476636 entropy 1.9506764\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4468343 entropy 1.9438539\n",
      "kl 0.035148818\n",
      "completed in 0.15981507301330566 s\n",
      "game 182 completed in 6.739745140075684 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5655203 entropy 1.9565785\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.54621 entropy 1.9574661\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5119085 entropy 1.9639236\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.476848 entropy 1.9706254\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4404242 entropy 1.9734339\n",
      "kl 0.039726146\n",
      "completed in 0.16588330268859863 s\n",
      "game 183 completed in 9.293394327163696 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5293684 entropy 1.9115889\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5000162 entropy 1.9033116\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4682808 entropy 1.89085\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.446308 entropy 1.8800347\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4184928 entropy 1.874275\n",
      "kl 0.030380284\n",
      "completed in 0.1686100959777832 s\n",
      "game 184 completed in 7.6997599601745605 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.506438 entropy 1.8955088\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4853017 entropy 1.902573\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4563425 entropy 1.9124833\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4257066 entropy 1.9218675\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.394641 entropy 1.9270418\n",
      "kl 0.03241139\n",
      "completed in 0.1741042137145996 s\n",
      "game 185 completed in 10.579915046691895 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4260077 entropy 1.9503307\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.40706 entropy 1.9472885\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3794706 entropy 1.9414203\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3471253 entropy 1.9343452\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.316041 entropy 1.9281089\n",
      "kl 0.026600365\n",
      "completed in 0.17206811904907227 s\n",
      "game 186 completed in 6.204981088638306 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4461308 entropy 1.9002843\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4256568 entropy 1.9030592\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3931863 entropy 1.9093659\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3621056 entropy 1.9158297\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3345532 entropy 1.9198768\n",
      "kl 0.03116057\n",
      "completed in 0.17171978950500488 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 187 completed in 6.118437051773071 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4058328 entropy 1.9095562\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3917165 entropy 1.9077129\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3687944 entropy 1.9048411\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.339085 entropy 1.9016659\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3063786 entropy 1.8983911\n",
      "kl 0.022540119\n",
      "completed in 0.16945266723632812 s\n",
      "game 188 completed in 10.801935195922852 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.495776 entropy 1.8714728\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4753358 entropy 1.8682041\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4457927 entropy 1.8632876\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.418106 entropy 1.8590696\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.391926 entropy 1.8565754\n",
      "kl 0.027999151\n",
      "completed in 0.17622900009155273 s\n",
      "game 189 completed in 13.983408212661743 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.466139 entropy 1.9126525\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.449782 entropy 1.9158642\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4282968 entropy 1.9221075\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4071503 entropy 1.9274112\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3823633 entropy 1.9281089\n",
      "kl 0.02310111\n",
      "completed in 0.1706380844116211 s\n",
      "game 190 completed in 10.631622076034546 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4697027 entropy 1.9295791\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4427671 entropy 1.920797\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4090047 entropy 1.9085344\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.383352 entropy 1.8959897\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3534002 entropy 1.8872788\n",
      "kl 0.026100677\n",
      "completed in 0.17536187171936035 s\n",
      "game 191 completed in 12.179487943649292 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3874607 entropy 1.849249\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3700747 entropy 1.8508582\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3508892 entropy 1.8540552\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3267562 entropy 1.8574553\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2988951 entropy 1.8593581\n",
      "kl 0.022183556\n",
      "completed in 0.17140412330627441 s\n",
      "game 192 completed in 9.845399141311646 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4060488 entropy 1.8866086\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.39583 entropy 1.8858376\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.377489 entropy 1.8858442\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3556015 entropy 1.8857963\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3316982 entropy 1.8846874\n",
      "kl 0.018578947\n",
      "completed in 0.16792583465576172 s\n",
      "game 193 completed in 7.644634008407593 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4244134 entropy 1.7968583\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.394259 entropy 1.7905114\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.356287 entropy 1.783496\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3226888 entropy 1.7782617\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2871623 entropy 1.7758045\n",
      "kl 0.021320216\n",
      "completed in 0.19230270385742188 s\n",
      "game 194 completed in 13.313049077987671 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4378984 entropy 1.8536799\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.417447 entropy 1.8585613\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.391795 entropy 1.8647163\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3621101 entropy 1.8693914\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3293571 entropy 1.8721232\n",
      "kl 0.01912025\n",
      "completed in 0.16694998741149902 s\n",
      "game 195 completed in 6.826568841934204 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4595203 entropy 1.8617659\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4408758 entropy 1.8672444\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4105632 entropy 1.8761669\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3777843 entropy 1.8862273\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.34934 entropy 1.8945539\n",
      "kl 0.026812125\n",
      "completed in 0.17183160781860352 s\n",
      "game 196 completed in 5.983694076538086 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4714043 entropy 1.8689601\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4569285 entropy 1.8696125\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4242346 entropy 1.8651146\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3852632 entropy 1.8571429\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3454475 entropy 1.8475876\n",
      "kl 0.027539749\n",
      "completed in 0.18674302101135254 s\n",
      "game 197 completed in 7.710915803909302 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.490122 entropy 1.8650539\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4735956 entropy 1.8587481\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4502277 entropy 1.8565376\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4256396 entropy 1.8574463\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4015539 entropy 1.8606162\n",
      "kl 0.020537317\n",
      "completed in 0.179426908493042 s\n",
      "game 198 completed in 11.576350927352905 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4963744 entropy 1.899816\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4708974 entropy 1.9056957\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.438476 entropy 1.9131376\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4024234 entropy 1.9217656\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3599143 entropy 1.929755\n",
      "kl 0.030829554\n",
      "completed in 0.18464994430541992 s\n",
      "prediction:\n",
      " [0.00129252 0.00343662 0.00351467 0.00162474 0.00935699 0.00173506\n",
      " 0.00330835 0.00567374 0.03009148 0.10074986 0.03437303 0.01024679\n",
      " 0.00320416 0.04217356 0.01989085 0.1492655  0.08199742 0.00302416\n",
      " 0.00301544 0.08015458 0.14510673 0.02553447 0.03563222 0.00452489\n",
      " 0.0093773  0.03257691 0.09380084 0.03459515 0.00561573 0.00396597\n",
      " 0.00138147 0.01071622 0.00165716 0.00248396 0.00379093 0.00111077] \n",
      " -0.4889981\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.88986233e-01 2.97872340e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.24030038e-01 2.89111389e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [4.02660153e-05 4.21799341e-04 3.87167645e-04 4.45044978e-04\n",
      " 1.19164513e-04 6.58168341e-04 1.94058128e-04 1.61961128e-04\n",
      " 8.33981261e-02 2.89437128e-03 5.31076966e-03 1.39584736e-04\n",
      " 1.94962442e-04 1.19759224e-01 2.88687289e-01 7.87414238e-03\n",
      " 2.77205347e-03 3.69804737e-04 4.89701459e-04 2.23489199e-03\n",
      " 6.57400209e-03 3.65477026e-01 7.30151534e-02 9.56735166e-05\n",
      " 1.15590876e-04 5.11016743e-03 2.32479116e-03 2.80375481e-02\n",
      " 1.02560211e-04 2.17450899e-04 1.14512327e-03 1.15782408e-04\n",
      " 3.37955076e-04 3.64454434e-04 3.80196754e-04 3.40398328e-05] \n",
      " 0.6367671\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00125156 0.00500626 0.00125156]\n",
      " [0.00250313 0.00250313 0.02753442 0.08635795 0.14267835 0.00500626]\n",
      " [0.00125156 0.02628285 0.01251564 0.         0.05256571 0.00125156]\n",
      " [0.00125156 0.04005006 0.35419274 0.02377972 0.03754693 0.00125156]\n",
      " [0.00375469 0.01877347 0.1126408  0.01877347 0.00250313 0.00250313]\n",
      " [0.00125156 0.00375469 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00119279 0.00150958 0.00167661 0.00919733 0.00076813 0.00118329\n",
      " 0.00104528 0.0008013  0.25122428 0.04478379 0.00354708 0.00112188\n",
      " 0.00146741 0.02765153 0.02504231 0.00063988 0.00696833 0.00223059\n",
      " 0.00239667 0.00540974 0.00103121 0.01168889 0.02822611 0.00172065\n",
      " 0.00072722 0.00397793 0.03426375 0.51484346 0.00063802 0.00088981\n",
      " 0.00188524 0.00100651 0.00526684 0.00124697 0.00218775 0.00054198] \n",
      " -0.74255455\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.25782228e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.97747184e-01 3.20400501e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 3.36670839e-01\n",
      "  4.00500626e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 4.25531915e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [3.0338188e-04 1.9362519e-03 6.0359004e-04 6.6074342e-03 2.0675060e-04\n",
      " 1.1067132e-03 6.9300609e-04 1.8520936e-03 2.9912649e-03 1.9238666e-01\n",
      " 1.3873895e-03 2.3128837e-04 9.7334123e-04 3.6715484e-01 1.2746102e-02\n",
      " 7.6882652e-04 3.0853217e-03 7.9404988e-04 7.1064965e-04 3.1354302e-03\n",
      " 8.6444948e-04 1.0703753e-02 1.8650320e-01 9.1278291e-04 3.5590664e-04\n",
      " 1.3579520e-03 1.8571645e-01 2.7918280e-03 1.5288446e-03 6.8029534e-04\n",
      " 2.1460385e-03 4.2202446e-04 2.8280215e-03 7.7590061e-04 2.3955761e-03\n",
      " 3.4265188e-04] \n",
      " 0.81698906\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00375469 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.16395494 0.0212766  0.00125156 0.00125156]\n",
      " [0.00125156 0.07884856 0.09261577 0.         0.00500626 0.00250313]\n",
      " [0.00250313 0.00250313 0.         0.         0.02252816 0.00125156]\n",
      " [0.00125156 0.00125156 0.04005006 0.53566959 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.0489679e-04 2.4969375e-02 7.1502116e-04 3.2886750e-01 2.3944820e-04\n",
      " 6.9469574e-04 1.2195965e-02 1.8459774e-03 6.5767328e-04 3.6138967e-03\n",
      " 2.5941969e-03 1.1977641e-03 8.7617425e-04 1.9803211e-01 1.7160721e-02\n",
      " 3.7147151e-05 3.0870524e-03 2.2768837e-03 1.3820749e-03 1.0326967e-03\n",
      " 2.0904232e-04 9.4609316e-03 1.9394904e-01 1.4713219e-03 2.3652711e-03\n",
      " 1.9119928e-03 2.8158668e-03 1.2887798e-03 8.1490178e-04 1.0760639e-02\n",
      " 1.9035109e-03 8.8091305e-04 1.5490526e-01 2.2034433e-03 1.3039958e-02\n",
      " 2.3787250e-04] \n",
      " 0.44559065\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 5.79474343e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.65456821e-01 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  2.37797247e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.87859825e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00139751 0.00402604 0.00600797 0.01090644 0.00187846 0.00222495\n",
      " 0.00094133 0.00942901 0.01317373 0.03829005 0.00314835 0.00213371\n",
      " 0.00505999 0.35815257 0.00099161 0.00071432 0.0067976  0.00659055\n",
      " 0.00493493 0.00842782 0.00102564 0.00174014 0.3917888  0.00819101\n",
      " 0.00738166 0.00320909 0.0340414  0.02508715 0.01391387 0.00081185\n",
      " 0.0063487  0.00535768 0.004287   0.0063095  0.00387984 0.0013999 ] \n",
      " 0.9488453\n",
      "p [[0.00125156 0.00876095 0.00125156 0.78723404 0.00125156 0.00125156]\n",
      " [0.00250313 0.00125156 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.06257822 0.00375469 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.         0.06132666 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.00125156 0.00250313]\n",
      " [0.00125156 0.00125156 0.04130163 0.00125156 0.00250313 0.00125156]]\n",
      "move 3\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.2303532e-04 1.1653281e-01 1.1975830e-02 9.7579263e-02 4.0126904e-03\n",
      " 3.4774912e-03 2.2207454e-02 3.7045688e-03 3.0626724e-03 2.2282692e-02\n",
      " 2.2518713e-02 7.2659673e-03 2.6936370e-03 5.0389834e-02 2.1009600e-01\n",
      " 9.8428980e-05 1.7891604e-02 3.1263683e-02 2.1676656e-02 1.0437624e-02\n",
      " 4.6337946e-04 8.7017864e-02 2.7918827e-02 7.2489236e-03 8.3098141e-03\n",
      " 1.2355396e-02 2.2015132e-02 6.4259763e-03 4.7848374e-03 1.9652123e-02\n",
      " 6.0551832e-03 8.4760347e-03 2.3591684e-02 2.5065107e-02 7.7866726e-02\n",
      " 2.6625979e-03] \n",
      " -0.96544695\n",
      "p [[1.25156446e-13 1.25156446e-13 5.00625782e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 5.00625782e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-03 8.82352941e-01 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-03 5.00625782e-03 0.00000000e+00 0.00000000e+00\n",
      "  7.25907384e-02 3.75469337e-03]\n",
      " [1.25156446e-03 1.25156446e-13 7.50938673e-03 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [2.50312891e-03 1.25156446e-03 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.6672786e-03 2.2639703e-02 2.0946071e-02 1.8810833e-02 1.0835865e-03\n",
      " 5.3281067e-03 2.1358705e-03 3.0198751e-02 9.2666090e-02 1.4533331e-01\n",
      " 2.5507475e-03 1.9926510e-03 1.2876545e-02 6.5451730e-03 3.3477900e-04\n",
      " 2.6529282e-04 3.1884361e-02 1.3524580e-02 1.2136427e-02 2.6807722e-02\n",
      " 9.1359630e-05 6.5668242e-04 6.7518153e-03 2.5879713e-02 4.3401988e-03\n",
      " 3.7690219e-03 2.2918484e-01 1.8879311e-01 3.4415841e-02 1.5949906e-03\n",
      " 6.2606572e-03 4.3821959e-03 7.3721940e-03 2.5174040e-02 9.4801011e-03\n",
      " 2.1254558e-03] \n",
      " 0.9480236\n",
      "p [[0.00125156 0.03379224 0.00250313 0.         0.00125156 0.00125156]\n",
      " [0.00625782 0.00125156 0.00125156 0.         0.00625782 0.00125156]\n",
      " [0.00125156 0.         0.83354193 0.         0.00500626 0.00876095]\n",
      " [0.00625782 0.00250313 0.         0.         0.00876095 0.00125156]\n",
      " [0.00125156 0.00250313 0.01251564 0.         0.00125156 0.00750939]\n",
      " [0.00125156 0.00250313 0.01251564 0.00625782 0.02753442 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00185216 0.0771372  0.02686476 0.14721274 0.00675381 0.00144839\n",
      " 0.0089229  0.00599779 0.06615596 0.00236711 0.01592606 0.00944604\n",
      " 0.00168412 0.04252063 0.00142891 0.00054014 0.07112372 0.06636185\n",
      " 0.03448591 0.0435311  0.00187169 0.00089482 0.01702331 0.00728005\n",
      " 0.01311773 0.00924251 0.0034237  0.11454138 0.00444897 0.01748662\n",
      " 0.00179058 0.01221895 0.04898087 0.07021574 0.04188275 0.0038191 ] \n",
      " -0.9740888\n",
      "p [[1.25156446e-13 3.75469337e-03 5.00625782e-03 0.00000000e+00\n",
      "  1.25156446e-13 2.50312891e-03]\n",
      " [1.25156446e-13 1.87734668e-02 8.63579474e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.50312891e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [2.50312891e-03 5.00625782e-03 0.00000000e+00 0.00000000e+00\n",
      "  3.75469337e-03 1.00125156e-02]\n",
      " [2.50312891e-03 1.25156446e-13 8.23529412e-01 0.00000000e+00\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [2.50312891e-03 2.50312891e-03 2.50312891e-03 6.25782228e-03\n",
      "  2.50312891e-03 1.25156446e-13]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.6251609e-04 4.1953069e-03 2.6208767e-01 3.6879323e-04 1.6650867e-02\n",
      " 1.2627706e-03 1.1707356e-03 3.3985148e-03 3.4284507e-04 1.7738908e-03\n",
      " 6.4985186e-04 1.3241784e-02 5.9668948e-03 1.3352598e-03 3.3059358e-04\n",
      " 9.8248536e-05 2.0265985e-01 2.1176287e-03 2.8631659e-03 1.7036815e-01\n",
      " 5.2628136e-05 8.0872019e-04 1.1074570e-03 6.8564797e-03 1.3043453e-02\n",
      " 5.1755796e-04 3.0399922e-03 3.2012266e-04 3.5880788e-03 5.4353192e-03\n",
      " 1.0417983e-03 3.2155249e-02 6.2906265e-04 2.3799457e-01 2.0909368e-03\n",
      " 1.7334681e-04] \n",
      " -0.2064945\n",
      "p [[0.00125156 0.02252816 0.09887359 0.         0.00125156 0.00125156]\n",
      " [0.00250313 0.00125156 0.51689612 0.         0.00375469 0.00250313]\n",
      " [0.00125156 0.         0.         0.         0.02252816 0.02377972]\n",
      " [0.01001252 0.03128911 0.         0.         0.1864831  0.00125156]\n",
      " [0.00375469 0.00250313 0.         0.         0.00125156 0.00500626]\n",
      " [0.00125156 0.00250313 0.01627034 0.02503129 0.01251564 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.31600157e-03 6.70409799e-02 1.12368753e-02 7.33797178e-02\n",
      " 3.47560947e-03 9.50166082e-04 2.71938294e-02 1.33691495e-02\n",
      " 4.70576528e-03 5.24989842e-03 4.61431220e-03 1.29298093e-02\n",
      " 8.10863264e-03 2.46785842e-02 3.22757434e-04 4.14637878e-04\n",
      " 2.56325513e-01 3.23222652e-02 2.74775326e-02 1.02317452e-01\n",
      " 1.38138898e-03 2.08542930e-04 2.58818660e-02 1.52899995e-02\n",
      " 7.23470701e-03 1.30768260e-03 6.34591095e-03 8.81487038e-03\n",
      " 4.72303014e-03 6.08245209e-02 7.02222344e-04 4.74502565e-03\n",
      " 3.61509621e-02 2.46868823e-02 1.15033999e-01 8.23897682e-03] \n",
      " 0.79766273\n",
      "p [[1.25156446e-13 1.25156446e-13 9.09887359e-01 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.87859825e-02 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-03 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 3.75469337e-03 1.25156446e-13 2.50312891e-02\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 2\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00148723 0.00792633 0.02970088 0.00546316 0.03641331 0.00417338\n",
      " 0.00526966 0.08736394 0.00290183 0.00711426 0.00562558 0.02387746\n",
      " 0.02929042 0.00674963 0.0002449  0.0010783  0.1721122  0.01715701\n",
      " 0.02952863 0.2309633  0.00068227 0.00066796 0.00738119 0.03664267\n",
      " 0.03349297 0.00535167 0.02635253 0.0168623  0.05639328 0.00403871\n",
      " 0.00562307 0.0657378  0.00619423 0.02482224 0.00401114 0.00130487] \n",
      " 0.8327282\n",
      "p [[0.00125156 0.02503129 0.         0.         0.00125156 0.00250313]\n",
      " [0.01126408 0.00876095 0.         0.         0.0175219  0.00375469]\n",
      " [0.00500626 0.         0.         0.         0.26783479 0.05757196]\n",
      " [0.00876095 0.09136421 0.         0.         0.2077597  0.00500626]\n",
      " [0.00250313 0.00375469 0.         0.         0.00125156 0.02503129]\n",
      " [0.00125156 0.00125156 0.18272841 0.01126408 0.05381727 0.00250313]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.60274492e-03 5.22175282e-02 4.72516101e-03 1.22192852e-01\n",
      " 2.97380914e-03 5.42791677e-04 2.87185870e-02 4.33034683e-03\n",
      " 5.06479619e-03 1.61642721e-03 1.15625560e-02 5.00348909e-03\n",
      " 9.26265866e-03 1.42446846e-01 2.37257045e-05 1.87493197e-03\n",
      " 1.46342930e-03 4.79689017e-02 5.98040931e-02 9.07345966e-04\n",
      " 4.46856301e-03 1.43870875e-05 1.33195490e-01 3.64562236e-02\n",
      " 2.03247857e-03 2.55786185e-03 1.67366606e-03 4.03457023e-02\n",
      " 1.99966133e-03 4.26805615e-02 3.36986181e-04 2.85419519e-03\n",
      " 8.24068189e-02 9.71513893e-03 1.24978125e-01 9.98117216e-03] \n",
      " -0.9979196\n",
      "p [[1.25156446e-13 3.75469337e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [5.00625782e-03 3.11639549e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 8.76095119e-03]\n",
      " [3.75469337e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.00125156e-02]\n",
      " [2.00250313e-02 3.92991239e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-02]\n",
      " [2.37797247e-02 4.38047559e-02 0.00000000e+00 0.00000000e+00\n",
      "  3.62953692e-02 1.25156446e-13]\n",
      " [5.00625782e-03 6.00750939e-02 8.76095119e-03 7.50938673e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [7.5823232e-04 1.8475177e-02 1.3643415e-01 1.1389147e-03 5.7932131e-02\n",
      " 5.5159262e-04 9.9653169e-04 9.7516745e-02 2.3966021e-04 1.4389695e-03\n",
      " 2.4046041e-02 2.7535198e-02 1.1530194e-01 1.0202986e-03 5.3332409e-05\n",
      " 8.1856607e-04 1.1832245e-02 3.7762403e-02 3.2500762e-02 8.5971151e-03\n",
      " 4.0747382e-04 1.4560642e-04 3.4298995e-04 2.8798679e-02 3.1529032e-02\n",
      " 1.2617420e-02 6.7675253e-03 1.8759837e-03 6.3118458e-02 2.4940441e-03\n",
      " 1.0205939e-03 2.2651559e-01 9.6896512e-04 2.6520221e-02 2.0344621e-02\n",
      " 1.5829820e-03] \n",
      " 0.5373858\n",
      "p [[0.00125156 0.02377972 0.         0.         0.00125156 0.00125156]\n",
      " [0.01251564 0.00125156 0.         0.         0.1514393  0.00250313]\n",
      " [0.00375469 0.         0.         0.         0.         0.05131414]\n",
      " [0.03128911 0.         0.         0.         0.37797247 0.02503129]\n",
      " [0.00125156 0.00125156 0.         0.         0.00125156 0.0212766 ]\n",
      " [0.00125156 0.00125156 0.19774718 0.00375469 0.08260325 0.00375469]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.5391760e-04 1.1648454e-01 1.3193524e-03 6.0709082e-02 1.5280328e-02\n",
      " 1.0795267e-04 9.3073053e-03 1.7299727e-02 5.1278272e-04 5.1439099e-04\n",
      " 1.4651393e-02 3.7485124e-03 3.1389336e-03 2.8241163e-03 2.3453540e-05\n",
      " 1.2953480e-04 5.4641819e-04 1.4219652e-01 1.0739740e-01 3.7141307e-04\n",
      " 2.7965673e-04 2.0521395e-05 2.1881922e-03 5.6395750e-03 2.9188558e-03\n",
      " 2.6645386e-03 1.0130138e-03 2.6210321e-03 1.3325140e-02 3.4720782e-02\n",
      " 2.4132253e-04 1.3156910e-02 2.9182812e-02 2.0524459e-03 3.9230776e-01\n",
      " 7.5041526e-04] \n",
      " -0.65500396\n",
      "p [[1.25156446e-13 3.75469337e-03 0.00000000e+00 0.00000000e+00\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.50688360e-02 0.00000000e+00 0.00000000e+00\n",
      "  8.76095119e-03 5.00625782e-03]\n",
      " [7.37171464e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.76095119e-03]\n",
      " [6.25782228e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.25782228e-03]\n",
      " [1.00125156e-02 1.00125156e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.75219024e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.15143930e-01 1.25156446e-13 7.50938673e-03\n",
      "  2.50312891e-03 1.25156446e-13]]\n",
      "move 12\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 1.  1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.01836650e-04 2.24395795e-03 3.75442415e-01 4.44788689e-04\n",
      " 6.00558259e-02 1.74521701e-04 2.34968960e-04 9.28209350e-02\n",
      " 1.49249419e-04 2.61328823e-04 7.31506059e-03 1.55812670e-02\n",
      " 1.78276412e-02 7.01400393e-04 2.56642961e-05 1.01459744e-04\n",
      " 2.24410254e-03 1.80091504e-02 8.36854987e-03 1.53908413e-03\n",
      " 4.80914714e-05 6.18189079e-05 1.72845626e-04 7.15605123e-03\n",
      " 2.13195272e-02 4.46991855e-03 1.29049551e-03 1.10483239e-03\n",
      " 1.56141743e-01 1.64632814e-03 2.87591160e-04 7.77942985e-02\n",
      " 1.84539909e-04 1.20308354e-01 3.16509325e-03 1.10534835e-03] \n",
      " 0.8602724\n",
      "p [[0.00125156 0.11389237 0.         0.         0.01376721 0.00125156]\n",
      " [0.00750939 0.04005006 0.         0.         0.02002503 0.00375469]\n",
      " [0.         0.         0.         0.         0.         0.15394243]\n",
      " [0.08260325 0.         0.         0.         0.         0.00375469]\n",
      " [0.01001252 0.00750939 0.         0.         0.01126408 0.02753442]\n",
      " [0.00125156 0.01001252 0.02878598 0.00625782 0.45306633 0.00250313]]\n",
      "move 34\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 1.  1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [1.3325049e-04 2.3270637e-02 1.8708488e-03 1.6069129e-01 2.8274689e-02\n",
      " 1.8825538e-04 3.1260164e-03 1.6213010e-01 6.7038159e-04 1.1320019e-03\n",
      " 5.5423887e-03 4.0837168e-03 1.0304360e-02 4.1277250e-03 1.4439452e-04\n",
      " 7.7130870e-05 2.5555929e-03 1.6835631e-01 5.3653333e-02 1.0883345e-03\n",
      " 9.8070770e-05 7.5447897e-05 8.9403782e-03 3.9177652e-02 8.7185744e-03\n",
      " 5.7813935e-03 2.4188750e-03 1.2736029e-03 1.4418410e-01 2.6243718e-02\n",
      " 2.0032469e-03 1.7910333e-02 7.7401675e-02 1.3272816e-03 3.2402206e-02\n",
      " 6.2294042e-04] \n",
      " -0.905858\n",
      "p [[1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 2.00250313e-02 0.00000000e+00 0.00000000e+00\n",
      "  3.75469337e-03 3.75469337e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [2.50312891e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [3.75469337e-03 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.12640801e-02 1.25156446e-13 8.17271589e-01\n",
      "  0.00000000e+00 1.25156446e-13]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 1.  1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1.  1. -1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]]\n",
      "1 won\n",
      "game 199 completed in 36.530917167663574 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3344092 entropy 1.893147\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3209896 entropy 1.8991016\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3037956 entropy 1.9008839\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2798107 entropy 1.8964542\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2537808 entropy 1.8869128\n",
      "kl 0.026350316\n",
      "completed in 0.19651007652282715 s\n",
      "game 200 completed in 11.490111112594604 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5096514 entropy 1.8731964\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4976609 entropy 1.8639779\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4717906 entropy 1.856677\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4376237 entropy 1.8514719\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.403304 entropy 1.8462846\n",
      "kl 0.028618162\n",
      "completed in 0.16357183456420898 s\n",
      "game 201 completed in 9.159723997116089 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3705223 entropy 1.8805301\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3477774 entropy 1.8749495\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3207872 entropy 1.8691981\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2954493 entropy 1.8638326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.2691388 entropy 1.858136\n",
      "kl 0.033699974\n",
      "completed in 0.20782995223999023 s\n",
      "game 202 completed in 13.209062099456787 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4532075 entropy 1.8517213\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.436458 entropy 1.8480617\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4057853 entropy 1.8460803\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3700066 entropy 1.8444784\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3314688 entropy 1.841948\n",
      "kl 0.029277496\n",
      "completed in 0.16560983657836914 s\n",
      "game 203 completed in 7.599971771240234 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5384903 entropy 1.8427937\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5204933 entropy 1.840108\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4888935 entropy 1.8396685\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.45294 entropy 1.8416464\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.41853 entropy 1.8465683\n",
      "kl 0.02782575\n",
      "completed in 0.208909273147583 s\n",
      "game 204 completed in 6.833067178726196 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4536893 entropy 1.8586746\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4369082 entropy 1.8672063\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.410236 entropy 1.8768378\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3816085 entropy 1.8845748\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3501906 entropy 1.8884498\n",
      "kl 0.023573577\n",
      "completed in 0.17540526390075684 s\n",
      "game 205 completed in 7.673852920532227 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4677029 entropy 1.8865377\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.445457 entropy 1.8839834\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4088595 entropy 1.8802967\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3666365 entropy 1.8765891\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3277733 entropy 1.8733531\n",
      "kl 0.025605856\n",
      "completed in 0.1670551300048828 s\n",
      "game 206 completed in 8.497895956039429 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.461103 entropy 1.8956453\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.436691 entropy 1.897822\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4014442 entropy 1.9035386\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3692038 entropy 1.9094317\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.340044 entropy 1.9138243\n",
      "kl 0.024000293\n",
      "completed in 0.18367695808410645 s\n",
      "game 207 completed in 20.42766284942627 s 25 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.404342 entropy 1.8840816\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3745933 entropy 1.8849449\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3357956 entropy 1.8845588\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3021078 entropy 1.8819249\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2711701 entropy 1.8760585\n",
      "kl 0.035643574\n",
      "completed in 0.16910505294799805 s\n",
      "game 208 completed in 10.403650999069214 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4458365 entropy 1.851176\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4171789 entropy 1.8435769\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3817828 entropy 1.8373561\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3468814 entropy 1.8339553\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3166108 entropy 1.8326185\n",
      "kl 0.030081572\n",
      "completed in 0.18304800987243652 s\n",
      "game 209 completed in 14.471534013748169 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4638448 entropy 1.8902991\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.446469 entropy 1.8939006\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4143703 entropy 1.9027117\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3771865 entropy 1.9147041\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3457034 entropy 1.9260077\n",
      "kl 0.041111\n",
      "completed in 0.17145705223083496 s\n",
      "game 210 completed in 10.045228004455566 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.466448 entropy 1.9204346\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4572277 entropy 1.9252584\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4396107 entropy 1.9278544\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4177465 entropy 1.9287908\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3941622 entropy 1.9285325\n",
      "kl 0.011936485\n",
      "completed in 0.2005009651184082 s\n",
      "game 211 completed in 12.717143774032593 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.378091 entropy 1.8646781\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3635707 entropy 1.863502\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.339638 entropy 1.8621023\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3139434 entropy 1.8605101\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2883804 entropy 1.8584481\n",
      "kl 0.009833088\n",
      "completed in 0.19671869277954102 s\n",
      "game 212 completed in 8.46458101272583 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3867166 entropy 1.882021\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3671412 entropy 1.8811431\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.33556 entropy 1.8802623\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3019452 entropy 1.8784083\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2677581 entropy 1.8742821\n",
      "kl 0.022832572\n",
      "completed in 0.19250917434692383 s\n",
      "game 213 completed in 7.664960622787476 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.483179 entropy 1.8591666\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4556162 entropy 1.8540729\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4172518 entropy 1.8507946\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3859403 entropy 1.8501542\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.353995 entropy 1.8515193\n",
      "kl 0.018823344\n",
      "completed in 0.16363215446472168 s\n",
      "game 214 completed in 7.7715301513671875 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3529813 entropy 1.8788509\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.33342 entropy 1.8790436\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3069599 entropy 1.8764389\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2793746 entropy 1.8714243\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.250918 entropy 1.8650193\n",
      "kl 0.029518563\n",
      "completed in 0.15989899635314941 s\n",
      "game 215 completed in 7.667189836502075 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4259052 entropy 1.8451129\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4037867 entropy 1.8417482\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3761077 entropy 1.8403144\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3448994 entropy 1.840021\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.317175 entropy 1.8396161\n",
      "kl 0.030143607\n",
      "completed in 0.1990211009979248 s\n",
      "game 216 completed in 10.992357969284058 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3954964 entropy 1.8344929\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3779478 entropy 1.8362386\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3550026 entropy 1.8373816\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3306315 entropy 1.8374826\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.30573 entropy 1.8360908\n",
      "kl 0.026562741\n",
      "completed in 0.16853809356689453 s\n",
      "game 217 completed in 5.959419012069702 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4014606 entropy 1.8798085\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3827584 entropy 1.8827657\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3541903 entropy 1.8876295\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.322511 entropy 1.8918233\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2915943 entropy 1.8933837\n",
      "kl 0.028598301\n",
      "completed in 0.1777791976928711 s\n",
      "game 218 completed in 6.140607833862305 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3962817 entropy 1.9182143\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3783727 entropy 1.9154034\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3528965 entropy 1.9104848\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3281367 entropy 1.9048662\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3044102 entropy 1.899485\n",
      "kl 0.035051398\n",
      "completed in 0.17740702629089355 s\n",
      "game 219 completed in 7.696023225784302 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4372663 entropy 1.8564\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4252355 entropy 1.8554487\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4031405 entropy 1.8552448\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.381371 entropy 1.8565482\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3549745 entropy 1.8590727\n",
      "kl 0.025795527\n",
      "completed in 0.1717689037322998 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 220 completed in 21.775584936141968 s 26 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4208293 entropy 1.8562372\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4059558 entropy 1.8595741\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.374746 entropy 1.8610257\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3389032 entropy 1.8603033\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3030343 entropy 1.8578007\n",
      "kl 0.02310498\n",
      "completed in 0.17377424240112305 s\n",
      "game 221 completed in 10.179407119750977 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4790382 entropy 1.8252554\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4564478 entropy 1.825979\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.427534 entropy 1.827528\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.390463 entropy 1.8302357\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3537455 entropy 1.8340116\n",
      "kl 0.026551615\n",
      "completed in 0.19536614418029785 s\n",
      "game 222 completed in 9.477680921554565 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.424022 entropy 1.8587093\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4050038 entropy 1.8624586\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.370922 entropy 1.8648759\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.337829 entropy 1.86601\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3122666 entropy 1.8655243\n",
      "kl 0.031807855\n",
      "completed in 0.17936205863952637 s\n",
      "game 223 completed in 11.086965084075928 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4445164 entropy 1.850859\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4143133 entropy 1.8442063\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3752484 entropy 1.8352859\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3393269 entropy 1.8272922\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3032317 entropy 1.8220477\n",
      "kl 0.025927857\n",
      "completed in 0.1779940128326416 s\n",
      "game 224 completed in 9.216842889785767 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3107867 entropy 1.855094\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2843463 entropy 1.8556908\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2572942 entropy 1.8544807\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2295334 entropy 1.847733\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.202014 entropy 1.8346713\n",
      "kl 0.0517551\n",
      "completed in 0.17202472686767578 s\n",
      "game 225 completed in 7.645947217941284 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4242709 entropy 1.8115506\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.407823 entropy 1.8045548\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3809676 entropy 1.8018329\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3512394 entropy 1.8035427\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3200521 entropy 1.808896\n",
      "kl 0.0144821545\n",
      "completed in 0.17848515510559082 s\n",
      "game 226 completed in 9.143762826919556 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4193745 entropy 1.8774058\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.406612 entropy 1.8817298\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3836234 entropy 1.8839757\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3564184 entropy 1.8845489\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.331863 entropy 1.8842311\n",
      "kl 0.019155037\n",
      "completed in 0.19124984741210938 s\n",
      "game 227 completed in 7.797510862350464 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.365339 entropy 1.7942529\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3506038 entropy 1.7976861\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3272939 entropy 1.8015633\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3009968 entropy 1.8051822\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2722917 entropy 1.8073381\n",
      "kl 0.013127294\n",
      "completed in 0.16016316413879395 s\n",
      "game 228 completed in 7.135439872741699 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4049237 entropy 1.8762202\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3894403 entropy 1.8754262\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3686094 entropy 1.8732843\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.346638 entropy 1.8708243\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3244512 entropy 1.868829\n",
      "kl 0.017636605\n",
      "completed in 0.19399571418762207 s\n",
      "game 229 completed in 7.745869874954224 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5108058 entropy 1.8954252\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4956079 entropy 1.8984122\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.467508 entropy 1.9037479\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4351723 entropy 1.90998\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4023952 entropy 1.9156833\n",
      "kl 0.015759049\n",
      "completed in 0.19754600524902344 s\n",
      "game 230 completed in 7.692674875259399 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4788234 entropy 1.9241229\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.472272 entropy 1.9272121\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.456622 entropy 1.9295528\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4359374 entropy 1.9306548\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4117608 entropy 1.9300845\n",
      "kl 0.014842297\n",
      "completed in 0.17745399475097656 s\n",
      "game 231 completed in 10.936033010482788 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3104901 entropy 1.843996\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.2985826 entropy 1.8399825\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.2813337 entropy 1.8335547\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.26276 entropy 1.8255203\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2426124 entropy 1.8169998\n",
      "kl 0.023673631\n",
      "completed in 0.17705488204956055 s\n",
      "game 232 completed in 7.5306477546691895 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4854593 entropy 1.9199926\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.459786 entropy 1.9139308\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4319437 entropy 1.9092116\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.407038 entropy 1.9052022\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.384148 entropy 1.9014647\n",
      "kl 0.014269022\n",
      "completed in 0.1781477928161621 s\n",
      "game 233 completed in 9.456964015960693 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5126598 entropy 1.8356541\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4912663 entropy 1.8310263\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.461989 entropy 1.8262446\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.43415 entropy 1.8222787\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4054036 entropy 1.8197796\n",
      "kl 0.012478025\n",
      "completed in 0.1727161407470703 s\n",
      "game 234 completed in 6.707059860229492 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.306541 entropy 1.7954651\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.2986417 entropy 1.799815\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.2835348 entropy 1.807035\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2653463 entropy 1.8151563\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2454398 entropy 1.8222623\n",
      "kl 0.014717758\n",
      "completed in 0.1900320053100586 s\n",
      "game 235 completed in 6.041330099105835 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4700203 entropy 1.865639\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4595218 entropy 1.8716528\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4428623 entropy 1.8771049\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.420587 entropy 1.881081\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3948095 entropy 1.8831866\n",
      "kl 0.01132354\n",
      "completed in 0.1685640811920166 s\n",
      "game 236 completed in 7.904945135116577 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.416537 entropy 1.830709\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4086425 entropy 1.8304965\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.393692 entropy 1.8294945\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3732786 entropy 1.8279588\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3481731 entropy 1.8257191\n",
      "kl 0.011389932\n",
      "completed in 0.18065261840820312 s\n",
      "game 237 completed in 7.596145153045654 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4015093 entropy 1.8544459\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3873084 entropy 1.8508717\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3677647 entropy 1.8464072\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.344753 entropy 1.8422897\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3179226 entropy 1.8391032\n",
      "kl 0.008456968\n",
      "completed in 0.17760181427001953 s\n",
      "game 238 completed in 10.027836322784424 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4607387 entropy 1.8452063\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4382062 entropy 1.8457077\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.406458 entropy 1.8475032\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3726606 entropy 1.8484405\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.338489 entropy 1.8470391\n",
      "kl 0.027055416\n",
      "completed in 0.1713862419128418 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 239 completed in 7.6143388748168945 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4319272 entropy 1.8699539\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4161234 entropy 1.8636198\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3894324 entropy 1.8560448\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3619359 entropy 1.8493333\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.334848 entropy 1.8442898\n",
      "kl 0.017177746\n",
      "completed in 0.169785737991333 s\n",
      "game 240 completed in 8.359151124954224 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5123217 entropy 1.8306828\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4824638 entropy 1.8362112\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4506543 entropy 1.8450214\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4195638 entropy 1.8535129\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3858657 entropy 1.8590428\n",
      "kl 0.030612968\n",
      "completed in 0.17663216590881348 s\n",
      "game 241 completed in 9.63871693611145 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4153426 entropy 1.8544401\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3894534 entropy 1.8545554\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3595145 entropy 1.8533565\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.333422 entropy 1.8522737\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.306425 entropy 1.8504481\n",
      "kl 0.025207631\n",
      "completed in 0.17597413063049316 s\n",
      "game 242 completed in 8.501128911972046 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4369273 entropy 1.8507242\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4190183 entropy 1.851403\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.394085 entropy 1.8505354\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3691237 entropy 1.846388\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3419058 entropy 1.8388636\n",
      "kl 0.02657216\n",
      "completed in 0.1815049648284912 s\n",
      "game 243 completed in 7.478792905807495 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4662197 entropy 1.8111385\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4432712 entropy 1.8067981\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4078178 entropy 1.8065386\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3725321 entropy 1.8089471\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3388278 entropy 1.8120925\n",
      "kl 0.032664113\n",
      "completed in 0.18092799186706543 s\n",
      "game 244 completed in 10.59161901473999 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4271173 entropy 1.8460224\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4180357 entropy 1.8500093\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3983405 entropy 1.8514754\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3703895 entropy 1.8500334\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.340988 entropy 1.8460474\n",
      "kl 0.02017674\n",
      "completed in 0.1658031940460205 s\n",
      "game 245 completed in 6.8179919719696045 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3338726 entropy 1.8152242\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3096097 entropy 1.8102573\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2810113 entropy 1.8054049\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2485142 entropy 1.802662\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2116516 entropy 1.8018377\n",
      "kl 0.023313392\n",
      "completed in 0.1755051612854004 s\n",
      "game 246 completed in 6.642153978347778 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3758307 entropy 1.823753\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3604116 entropy 1.8238664\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3371773 entropy 1.8237753\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.312388 entropy 1.8231845\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2856984 entropy 1.8223462\n",
      "kl 0.018539108\n",
      "completed in 0.1877450942993164 s\n",
      "game 247 completed in 5.880454778671265 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4197924 entropy 1.7899702\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3983834 entropy 1.7902251\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3665073 entropy 1.7897706\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3318796 entropy 1.7875849\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3012881 entropy 1.7835238\n",
      "kl 0.02760571\n",
      "completed in 0.18118500709533691 s\n",
      "game 248 completed in 8.520560026168823 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3997347 entropy 1.8151548\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.378342 entropy 1.8188163\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3452148 entropy 1.8282454\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3105192 entropy 1.8399429\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2764473 entropy 1.8505654\n",
      "kl 0.03264439\n",
      "completed in 0.16527175903320312 s\n",
      "prediction:\n",
      " [0.00105441 0.00215151 0.0028025  0.00175944 0.00690161 0.00164234\n",
      " 0.00273947 0.00384624 0.02617021 0.07718503 0.04167322 0.00691148\n",
      " 0.00311445 0.02555505 0.03037953 0.17182422 0.06519917 0.00162683\n",
      " 0.00140997 0.07959796 0.21270292 0.03875199 0.02666759 0.00298225\n",
      " 0.00653779 0.04356384 0.07115223 0.02224598 0.00379524 0.00344666\n",
      " 0.00120169 0.00575515 0.00116392 0.00201777 0.00301849 0.00145207] \n",
      " -0.5223492\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-01 4.19274093e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.78973717e-01 2.76595745e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [2.9700379e-05 2.0096944e-04 2.4949657e-04 4.8933638e-04 5.2398918e-05\n",
      " 5.1342795e-04 1.2910130e-04 7.2383227e-05 8.8114671e-02 2.1377597e-03\n",
      " 2.8106966e-03 9.7966542e-05 2.3594215e-04 1.7631049e-01 2.8558540e-01\n",
      " 2.6628328e-03 1.5160778e-03 4.2900717e-04 6.9249311e-04 2.2562754e-03\n",
      " 2.9393523e-03 2.4685583e-01 1.1292257e-01 8.8017863e-05 7.4871321e-05\n",
      " 2.9455230e-03 2.0255677e-03 6.5693587e-02 7.4784191e-05 1.1036556e-04\n",
      " 8.8603911e-04 5.0987590e-05 1.9327244e-04 2.6119826e-04 2.5507342e-04\n",
      " 3.6612972e-05] \n",
      " 0.47641802\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00375469 0.00250313 0.00125156]\n",
      " [0.00125156 0.00250313 0.0350438  0.0387985  0.17647059 0.00250313]\n",
      " [0.00125156 0.01376721 0.09887359 0.         0.02753442 0.00125156]\n",
      " [0.00125156 0.04255319 0.34292866 0.0387985  0.02377972 0.00125156]\n",
      " [0.00250313 0.07008761 0.03629537 0.02002503 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00081588 0.00144918 0.0022957  0.00962975 0.00125679 0.00232571\n",
      " 0.00353511 0.00070106 0.20498529 0.01165203 0.01002632 0.00108929\n",
      " 0.00099209 0.00471198 0.09302504 0.00142076 0.0302786  0.0029107\n",
      " 0.00268722 0.02901594 0.00123181 0.11155125 0.00528439 0.00086977\n",
      " 0.00112275 0.00992085 0.01723952 0.41989654 0.00061655 0.00276698\n",
      " 0.00381247 0.00132173 0.00385049 0.00143139 0.00350489 0.00077435] \n",
      " -0.86021817\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.25406758e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.62953692e-02 1.12640801e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.12640801e-01\n",
      "  6.77096370e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 2.87859825e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.2081997e-04 3.9419223e-02 1.4769192e-03 5.5442601e-03 2.7738305e-04\n",
      " 1.8355498e-03 3.2102350e-02 3.6353872e-03 3.8483936e-01 1.3321696e-02\n",
      " 1.8114647e-02 7.6384842e-04 5.6725380e-04 4.0021900e-02 1.8438168e-02\n",
      " 1.4245724e-03 3.8042944e-03 4.7193742e-03 5.0427364e-03 4.4022705e-03\n",
      " 9.5727458e-04 1.3696498e-02 3.7513841e-02 2.6203832e-04 7.4528198e-04\n",
      " 3.1725757e-02 1.3902365e-02 2.3084618e-01 1.7695265e-03 2.2327075e-02\n",
      " 4.4924528e-03 6.3680450e-04 2.4844913e-03 1.7582652e-03 5.6331422e-02\n",
      " 3.7868670e-04] \n",
      " 0.95500386\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00375469 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.23153942 0.00500626 0.00625782 0.00125156]\n",
      " [0.00125156 0.00125156 0.14142678 0.         0.01126408 0.00125156]\n",
      " [0.00125156 0.06633292 0.         0.13642053 0.         0.00125156]\n",
      " [0.00125156 0.00375469 0.05006258 0.31664581 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [4.16748109e-04 2.36256093e-01 1.17091532e-03 2.41260529e-02\n",
      " 9.50842339e-04 1.95990643e-03 1.43972561e-01 8.47141549e-04\n",
      " 1.67341219e-04 7.03847548e-03 1.50751742e-02 1.94789330e-03\n",
      " 6.12424046e-04 6.30924255e-02 1.07912021e-02 3.74825322e-04\n",
      " 4.04543895e-03 3.80038889e-03 1.89766183e-03 3.25511512e-03\n",
      " 2.95317208e-04 1.99957117e-02 5.20622395e-02 6.12389005e-04\n",
      " 3.81700648e-03 1.44776264e-02 9.41247772e-03 2.64147413e-04\n",
      " 5.06754732e-04 1.20785415e-01 4.63498803e-03 1.04847422e-03\n",
      " 1.37432218e-02 1.05329684e-03 2.35269442e-01 2.23069816e-04] \n",
      " -0.87095934\n",
      "p [[1.25156446e-13 1.00125156e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.00125156e-02 1.25156446e-13 9.26157697e-01 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 2.12765957e-02 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  2.00250313e-02 1.25156446e-13]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.46124429e-04 2.75134966e-02 8.74997699e-04 9.06675588e-03\n",
      " 9.60475154e-05 5.97726612e-04 5.34487307e-01 1.00490660e-03\n",
      " 5.13811479e-04 2.66383868e-03 4.72671585e-03 3.94730072e-04\n",
      " 1.23119447e-04 2.53217593e-02 2.70037330e-03 1.09606990e-04\n",
      " 9.61087702e-04 1.07870915e-03 2.17708410e-03 4.64009179e-04\n",
      " 1.67766106e-04 1.14177226e-03 1.85432583e-02 2.85632286e-05\n",
      " 4.77360212e-04 6.06431998e-03 3.36516672e-03 3.63182131e-04\n",
      " 9.27511370e-04 2.42292792e-01 1.05000171e-03 2.73486861e-04\n",
      " 5.96288173e-03 2.76840496e-04 1.03821635e-01 1.21433957e-04] \n",
      " 0.99759495\n",
      "p [[0.00125156 0.2465582  0.00125156 0.01376721 0.00125156 0.00125156]\n",
      " [0.22277847 0.00125156 0.         0.00375469 0.01877347 0.00125156]\n",
      " [0.00125156 0.1339174  0.00625782 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.02628285 0.         0.00125156]\n",
      " [0.00125156 0.01501877 0.01126408 0.         0.00125156 0.077597  ]\n",
      " [0.00250313 0.00125156 0.00750939 0.00125156 0.19274093 0.00125156]]\n",
      "move 1\n",
      "board\n",
      " [[ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00355264 0.03730711 0.0142486  0.14854303 0.00335199 0.0029067\n",
      " 0.02186633 0.00503504 0.00044778 0.03729072 0.01286408 0.00751494\n",
      " 0.00262245 0.16088182 0.0262687  0.00043163 0.00891651 0.02929761\n",
      " 0.01090984 0.00683334 0.00068476 0.02634931 0.1624494  0.00423834\n",
      " 0.00711298 0.00996056 0.03276604 0.00043878 0.00390688 0.02794257\n",
      " 0.00770145 0.00496737 0.109859   0.01860186 0.03833339 0.00359642] \n",
      " -0.8412906\n",
      "p [[1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.56570713e-01 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.75219024e-02 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 6.37046308e-01]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  8.76095119e-02 1.25156446e-13]]\n",
      "move 29\n",
      "board\n",
      " [[ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 249 completed in 20.615146160125732 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.365465 entropy 1.8037131\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.338662 entropy 1.8047915\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2978303 entropy 1.803295\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.259553 entropy 1.8016382\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2245576 entropy 1.8000741\n",
      "kl 0.028923051\n",
      "completed in 0.16888189315795898 s\n",
      "game 250 completed in 7.7628819942474365 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3873918 entropy 1.8384715\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3698862 entropy 1.8393619\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3486533 entropy 1.8387058\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3231137 entropy 1.8366454\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2959087 entropy 1.8345346\n",
      "kl 0.022300024\n",
      "completed in 0.20166301727294922 s\n",
      "game 251 completed in 6.131587743759155 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3946974 entropy 1.8471348\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3753726 entropy 1.8466266\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3467064 entropy 1.846412\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3186278 entropy 1.8464322\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2902718 entropy 1.8458505\n",
      "kl 0.027081449\n",
      "completed in 0.16988897323608398 s\n",
      "game 252 completed in 6.121323823928833 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4888477 entropy 1.8463004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.453612 entropy 1.8471143\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4175615 entropy 1.8484763\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.392107 entropy 1.847466\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3544872 entropy 1.8404372\n",
      "kl 0.033384226\n",
      "completed in 0.1716909408569336 s\n",
      "game 253 completed in 11.731664180755615 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.489499 entropy 1.8267558\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4736865 entropy 1.8166163\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4527383 entropy 1.8083761\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.426038 entropy 1.804815\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3947594 entropy 1.8073932\n",
      "kl 0.028257834\n",
      "completed in 0.1593327522277832 s\n",
      "game 254 completed in 6.773300409317017 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4763858 entropy 1.8309729\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4612677 entropy 1.8459389\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4337475 entropy 1.8619853\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4036186 entropy 1.8743503\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3746424 entropy 1.8805985\n",
      "kl 0.04360853\n",
      "completed in 0.17227816581726074 s\n",
      "game 255 completed in 10.463330745697021 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4365873 entropy 1.8179921\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4282954 entropy 1.8175099\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4102468 entropy 1.816318\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3846905 entropy 1.8150424\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3563416 entropy 1.8137789\n",
      "kl 0.010379905\n",
      "completed in 0.18718433380126953 s\n",
      "game 256 completed in 6.0145180225372314 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4032385 entropy 1.8668146\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3785543 entropy 1.8670053\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3534138 entropy 1.8672692\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.331253 entropy 1.8660686\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3085027 entropy 1.8629646\n",
      "kl 0.018697225\n",
      "completed in 0.17249774932861328 s\n",
      "game 257 completed in 18.275881052017212 s 22 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.445021 entropy 1.8783414\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4305117 entropy 1.8753816\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4050171 entropy 1.8722928\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3765657 entropy 1.8689021\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3485525 entropy 1.865522\n",
      "kl 0.014857282\n",
      "completed in 0.1659986972808838 s\n",
      "game 258 completed in 6.800763845443726 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3787084 entropy 1.8004553\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3663793 entropy 1.7978255\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.344808 entropy 1.794723\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3182192 entropy 1.7906901\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2906742 entropy 1.7852371\n",
      "kl 0.01581207\n",
      "completed in 0.1666707992553711 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 259 completed in 7.553842782974243 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4484456 entropy 1.8591423\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4379423 entropy 1.8558104\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4216151 entropy 1.8537865\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4009483 entropy 1.8526502\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3773348 entropy 1.851801\n",
      "kl 0.014970458\n",
      "completed in 0.17533111572265625 s\n",
      "game 260 completed in 14.013243913650513 s 17 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4130576 entropy 1.8318286\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4048588 entropy 1.8305337\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3890696 entropy 1.8297215\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3679774 entropy 1.829123\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3455453 entropy 1.8283862\n",
      "kl 0.01264745\n",
      "completed in 0.17491507530212402 s\n",
      "game 261 completed in 9.165637016296387 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3269022 entropy 1.7893249\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3121293 entropy 1.7878395\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.2917767 entropy 1.7855837\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2701597 entropy 1.7832171\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2476895 entropy 1.7815213\n",
      "kl 0.012839781\n",
      "completed in 0.1908721923828125 s\n",
      "game 262 completed in 15.652955055236816 s 19 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4121912 entropy 1.8053267\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.399074 entropy 1.8061801\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3807292 entropy 1.8082684\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.358447 entropy 1.8107626\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3356771 entropy 1.8128983\n",
      "kl 0.01580454\n",
      "completed in 0.19187688827514648 s\n",
      "game 263 completed in 6.739102125167847 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4056897 entropy 1.7978095\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3991287 entropy 1.7986145\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3820314 entropy 1.8003763\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3576486 entropy 1.8029115\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3302665 entropy 1.8056295\n",
      "kl 0.0121700615\n",
      "completed in 0.21187996864318848 s\n",
      "game 264 completed in 8.302356958389282 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.376919 entropy 1.8009033\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3626492 entropy 1.8067304\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3379712 entropy 1.813385\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3059561 entropy 1.8197279\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2772207 entropy 1.8247653\n",
      "kl 0.013039153\n",
      "completed in 0.16288399696350098 s\n",
      "game 265 completed in 5.845500946044922 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.408225 entropy 1.8070729\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.392211 entropy 1.8073459\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.359346 entropy 1.8050106\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3267362 entropy 1.8016899\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.296745 entropy 1.7979312\n",
      "kl 0.015618026\n",
      "completed in 0.1706230640411377 s\n",
      "game 266 completed in 9.0865797996521 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4113011 entropy 1.8761338\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3953745 entropy 1.8704883\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3729668 entropy 1.8652048\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3441644 entropy 1.8612987\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3116808 entropy 1.8588753\n",
      "kl 0.015022056\n",
      "completed in 0.1749708652496338 s\n",
      "game 267 completed in 9.162328004837036 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4133167 entropy 1.7995269\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3920386 entropy 1.8051008\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3661675 entropy 1.8146508\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3433106 entropy 1.825798\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3209875 entropy 1.835828\n",
      "kl 0.019224584\n",
      "completed in 0.17597007751464844 s\n",
      "game 268 completed in 6.722218990325928 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4431477 entropy 1.8814559\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.429902 entropy 1.8885038\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4092581 entropy 1.8924234\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3866525 entropy 1.8926036\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3632023 entropy 1.889138\n",
      "kl 0.01788618\n",
      "completed in 0.16584110260009766 s\n",
      "game 269 completed in 9.115074157714844 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.405239 entropy 1.8526301\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3868475 entropy 1.8452752\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3589118 entropy 1.8381512\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3295527 entropy 1.8321015\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.303151 entropy 1.8276799\n",
      "kl 0.009854697\n",
      "completed in 0.16756916046142578 s\n",
      "game 270 completed in 6.025818824768066 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4467735 entropy 1.8626527\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.420101 entropy 1.8591561\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3883991 entropy 1.8535635\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.35672 entropy 1.8453474\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3262868 entropy 1.8353608\n",
      "kl 0.042662114\n",
      "completed in 0.17722511291503906 s\n",
      "game 271 completed in 8.32654094696045 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4963024 entropy 1.8314395\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4867122 entropy 1.8272829\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4643216 entropy 1.8247714\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4319673 entropy 1.8243527\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4002876 entropy 1.825906\n",
      "kl 0.010209869\n",
      "completed in 0.23161816596984863 s\n",
      "game 272 completed in 5.894239902496338 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3228765 entropy 1.8018152\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3086884 entropy 1.8077952\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.2853224 entropy 1.8146749\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2596905 entropy 1.8207331\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2357736 entropy 1.8245865\n",
      "kl 0.02347945\n",
      "completed in 0.16595005989074707 s\n",
      "game 273 completed in 7.485144853591919 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4628778 entropy 1.8684855\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4434671 entropy 1.8728601\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.421256 entropy 1.8771071\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4002252 entropy 1.8802223\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3791451 entropy 1.8816605\n",
      "kl 0.013564359\n",
      "completed in 0.1621541976928711 s\n",
      "game 274 completed in 9.249927043914795 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.505199 entropy 1.851917\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4897013 entropy 1.8483921\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4578354 entropy 1.8419843\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4236674 entropy 1.833455\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3999407 entropy 1.8248351\n",
      "kl 0.023849474\n",
      "completed in 0.17079997062683105 s\n",
      "game 275 completed in 6.003141164779663 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3830104 entropy 1.7895758\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3654172 entropy 1.7887642\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3394897 entropy 1.7921802\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3152757 entropy 1.7982991\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2920012 entropy 1.8052162\n",
      "kl 0.014970809\n",
      "completed in 0.18212270736694336 s\n",
      "game 276 completed in 11.005805015563965 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4773343 entropy 1.8050517\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4648836 entropy 1.811112\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.443373 entropy 1.8147914\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4165285 entropy 1.8160145\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3916948 entropy 1.8152599\n",
      "kl 0.016818449\n",
      "completed in 0.17264509201049805 s\n",
      "game 277 completed in 9.123808145523071 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4449475 entropy 1.8673003\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4316497 entropy 1.8663833\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4107502 entropy 1.8656545\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3861976 entropy 1.8645735\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3602738 entropy 1.8628199\n",
      "kl 0.017968915\n",
      "completed in 0.17429804801940918 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 278 completed in 11.522608280181885 s 14 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4861364 entropy 1.8723001\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4726708 entropy 1.8696587\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.449905 entropy 1.8671069\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4236958 entropy 1.8645048\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.397246 entropy 1.8616632\n",
      "kl 0.020304183\n",
      "completed in 0.1767590045928955 s\n",
      "game 279 completed in 7.421741962432861 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3679345 entropy 1.8232608\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.357092 entropy 1.8212087\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3376746 entropy 1.8212744\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3114414 entropy 1.8234628\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2833836 entropy 1.82704\n",
      "kl 0.01575468\n",
      "completed in 0.1732630729675293 s\n",
      "game 280 completed in 7.324859857559204 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.34487 entropy 1.8542707\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3312616 entropy 1.8566489\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3125658 entropy 1.8581774\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2901137 entropy 1.858573\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2676048 entropy 1.8577276\n",
      "kl 0.014065038\n",
      "completed in 0.17711782455444336 s\n",
      "game 281 completed in 6.053950786590576 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3373792 entropy 1.836454\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3243902 entropy 1.8358355\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.30458 entropy 1.8346674\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2804124 entropy 1.8324542\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.254143 entropy 1.8289332\n",
      "kl 0.012615772\n",
      "completed in 0.19075369834899902 s\n",
      "game 282 completed in 9.639714002609253 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4326637 entropy 1.821223\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4205291 entropy 1.817596\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.400291 entropy 1.8148022\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3789601 entropy 1.8129302\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3575065 entropy 1.8117707\n",
      "kl 0.01104632\n",
      "completed in 0.1581270694732666 s\n",
      "game 283 completed in 6.010301828384399 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4517672 entropy 1.7883847\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.441462 entropy 1.7869377\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4212954 entropy 1.7854964\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3944392 entropy 1.7842232\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3635917 entropy 1.7831869\n",
      "kl 0.015464899\n",
      "completed in 0.1770029067993164 s\n",
      "game 284 completed in 7.698627948760986 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.421916 entropy 1.7684119\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4080727 entropy 1.7711556\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3817053 entropy 1.7760617\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3497493 entropy 1.7827421\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.320649 entropy 1.7898381\n",
      "kl 0.009899678\n",
      "completed in 0.16704106330871582 s\n",
      "game 285 completed in 9.353879690170288 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4080033 entropy 1.8112943\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3924253 entropy 1.8164355\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3660665 entropy 1.8180455\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.335753 entropy 1.814618\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.304301 entropy 1.8064303\n",
      "kl 0.035164926\n",
      "completed in 0.1799018383026123 s\n",
      "game 286 completed in 12.460409879684448 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.423347 entropy 1.8218299\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4187615 entropy 1.8136213\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4008179 entropy 1.8076907\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3712025 entropy 1.8048422\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.336246 entropy 1.8052225\n",
      "kl 0.016721863\n",
      "completed in 0.15773296356201172 s\n",
      "game 287 completed in 9.107431173324585 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3897405 entropy 1.8392292\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3746405 entropy 1.8474681\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3520014 entropy 1.8553447\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3273687 entropy 1.860299\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3034825 entropy 1.8613881\n",
      "kl 0.024114605\n",
      "completed in 0.17127203941345215 s\n",
      "game 288 completed in 9.368031978607178 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4573238 entropy 1.8507469\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4262185 entropy 1.8464499\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3819022 entropy 1.8400575\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3384562 entropy 1.8335022\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.297652 entropy 1.8278348\n",
      "kl 0.029302001\n",
      "completed in 0.2147810459136963 s\n",
      "game 289 completed in 11.682704210281372 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.2886825 entropy 1.8007966\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2732625 entropy 1.7983875\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.245734 entropy 1.7972208\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.212593 entropy 1.796212\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1785054 entropy 1.7943071\n",
      "kl 0.021120252\n",
      "completed in 0.18427681922912598 s\n",
      "game 290 completed in 10.988510131835938 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.324779 entropy 1.8141347\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3063002 entropy 1.8120624\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2729168 entropy 1.810508\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.239507 entropy 1.8091681\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.209333 entropy 1.8082483\n",
      "kl 0.034235835\n",
      "completed in 0.1730360984802246 s\n",
      "game 291 completed in 6.003774881362915 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.32023 entropy 1.8070536\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2987032 entropy 1.8091195\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2718518 entropy 1.8130432\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2452838 entropy 1.8157096\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2154462 entropy 1.8154275\n",
      "kl 0.023243088\n",
      "completed in 0.17579197883605957 s\n",
      "game 292 completed in 10.838380098342896 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.397186 entropy 1.8243771\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3817697 entropy 1.8184493\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3608806 entropy 1.8114824\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.331101 entropy 1.8057687\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2970285 entropy 1.8015165\n",
      "kl 0.022565339\n",
      "completed in 0.19040775299072266 s\n",
      "game 293 completed in 11.507261991500854 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4143581 entropy 1.8160998\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3929496 entropy 1.8142124\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3587258 entropy 1.8127997\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3307245 entropy 1.8137115\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3018878 entropy 1.817467\n",
      "kl 0.026833981\n",
      "completed in 0.17461013793945312 s\n",
      "game 294 completed in 7.404244899749756 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4050033 entropy 1.7817785\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3888206 entropy 1.787916\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3586278 entropy 1.7932501\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.327204 entropy 1.7973111\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3029575 entropy 1.7991855\n",
      "kl 0.026250536\n",
      "completed in 0.1657259464263916 s\n",
      "game 295 completed in 6.97176194190979 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.455495 entropy 1.811372\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.435415 entropy 1.813057\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4046483 entropy 1.8161522\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.372137 entropy 1.8203106\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3416173 entropy 1.8240448\n",
      "kl 0.022779824\n",
      "completed in 0.17825102806091309 s\n",
      "game 296 completed in 8.561243295669556 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.465042 entropy 1.8253617\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4516995 entropy 1.8243912\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4290094 entropy 1.8237666\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.399329 entropy 1.8232827\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3680296 entropy 1.8222355\n",
      "kl 0.021886144\n",
      "completed in 0.18839287757873535 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 297 completed in 8.315414905548096 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.547793 entropy 1.8993032\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5234718 entropy 1.902842\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4843943 entropy 1.9080468\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4477575 entropy 1.9127032\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4148774 entropy 1.9142312\n",
      "kl 0.03033007\n",
      "completed in 0.1517329216003418 s\n",
      "game 298 completed in 6.024514675140381 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.548251 entropy 1.875042\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.508288 entropy 1.8650866\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4690595 entropy 1.8523148\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4358635 entropy 1.8401423\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4015388 entropy 1.8306931\n",
      "kl 0.035730496\n",
      "completed in 0.17676711082458496 s\n",
      "prediction:\n",
      " [0.0015619  0.00303395 0.00192983 0.00096292 0.00366698 0.00147191\n",
      " 0.00282058 0.00379937 0.03283241 0.05076155 0.04733489 0.00317513\n",
      " 0.00148994 0.02623056 0.03368153 0.19902778 0.05146068 0.0014166\n",
      " 0.00130251 0.05480007 0.28039202 0.03092838 0.0278111  0.00136681\n",
      " 0.00434528 0.0466866  0.03764256 0.02731976 0.00413132 0.00325695\n",
      " 0.00166237 0.00356618 0.00101837 0.00166767 0.00397824 0.0014654 ] \n",
      " -0.2734348\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.57822278e-01 2.80350438e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.46558198e-01 2.15269086e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.6314403e-05 1.5301946e-04 1.7921856e-04 1.9564973e-04 2.9102515e-05\n",
      " 4.7343265e-04 1.1245949e-04 4.2994532e-05 1.1735705e-01 1.0996502e-03\n",
      " 1.5898385e-03 4.6558362e-05 6.6087319e-05 1.1895980e-01 2.9928792e-01\n",
      " 8.9420751e-03 4.1290144e-03 2.8728825e-04 4.6204394e-04 2.3729156e-03\n",
      " 1.0780849e-02 2.3650585e-01 1.1989573e-01 3.1398555e-05 3.8857215e-05\n",
      " 1.2907035e-03 7.7884342e-04 7.3526993e-02 5.8364254e-05 9.9313991e-05\n",
      " 6.3463039e-04 3.2117227e-05 1.5712250e-04 1.7753920e-04 1.4405533e-04\n",
      " 2.5349895e-05] \n",
      " 0.4303474\n",
      "p [[0.00250313 0.00250313 0.00250313 0.00250313 0.00250313 0.00250313]\n",
      " [0.00250313 0.00625782 0.04005006 0.04130163 0.16020025 0.00876095]\n",
      " [0.00250313 0.02628285 0.02252816 0.         0.03379224 0.00125156]\n",
      " [0.00125156 0.03254068 0.44555695 0.03003755 0.0175219  0.00125156]\n",
      " [0.00375469 0.03254068 0.03379224 0.02252816 0.00625782 0.00250313]\n",
      " [0.00250313 0.00125156 0.00125156 0.00125156 0.00250313 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.5300846e-04 1.3012628e-03 6.9805817e-04 2.5368445e-03 4.1746651e-04\n",
      " 5.7048170e-04 5.2328035e-04 7.2174333e-04 3.4967709e-01 2.8557062e-02\n",
      " 2.9072892e-03 3.7334746e-04 3.2948880e-04 1.3660533e-02 3.7457161e-02\n",
      " 2.1856853e-03 3.8281819e-03 5.3753878e-04 6.5406144e-04 1.8216050e-03\n",
      " 2.1312344e-03 2.7571809e-02 3.0968718e-02 3.6335865e-04 3.9851500e-04\n",
      " 1.7527738e-03 2.6301777e-02 4.5455483e-01 8.8421541e-04 3.8138789e-04\n",
      " 8.5610704e-04 4.5044630e-04 1.8348357e-03 5.9947715e-04 1.3218183e-03\n",
      " 4.1752821e-04] \n",
      " -0.8835538\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.08886108e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.62953692e-02 8.51063830e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 4.94367960e-01\n",
      "  2.26533166e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 4.88110138e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.3927288e-04 6.9587142e-04 6.8126631e-04 1.3721462e-03 8.0361446e-05\n",
      " 1.2907392e-03 3.0831760e-04 1.1643911e-03 4.8340284e-03 2.1263160e-01\n",
      " 7.8942173e-04 1.3633189e-04 1.5478113e-04 2.4819498e-01 4.3270245e-02\n",
      " 3.6901102e-04 8.8996561e-03 3.3383531e-04 3.7783140e-04 4.7698980e-03\n",
      " 4.5034147e-04 3.4610022e-02 2.1714769e-01 2.1351139e-04 1.8167264e-04\n",
      " 1.1280521e-03 2.0301779e-01 3.3897979e-03 1.8931014e-03 2.4682019e-04\n",
      " 2.9066431e-03 2.0072733e-04 2.1128056e-03 9.1373530e-04 7.9348625e-04\n",
      " 1.9993390e-04] \n",
      " 0.4805212\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.15018773 0.01001252 0.00125156 0.00125156]\n",
      " [0.00125156 0.01877347 0.03754693 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00375469 0.         0.         0.01126408 0.00125156]\n",
      " [0.00125156 0.00125156 0.01126408 0.72590738 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.3472876e-04 3.6962636e-02 4.8562838e-04 3.1870109e-01 1.9416846e-04\n",
      " 8.7329536e-04 6.7283055e-03 2.8810531e-03 5.4332823e-03 1.6903291e-03\n",
      " 2.8051361e-03 6.8991899e-04 1.9344247e-04 1.4274432e-01 3.7421314e-03\n",
      " 1.3875404e-04 1.4548657e-03 2.1627990e-03 1.5917015e-03 6.2936655e-04\n",
      " 2.1393983e-04 4.5976248e-03 1.1252908e-01 5.0002901e-04 1.8697003e-03\n",
      " 5.3204419e-03 1.7853203e-03 7.9507511e-03 1.8776160e-03 5.4692626e-03\n",
      " 3.9695166e-03 6.7398330e-04 2.8821927e-01 1.5932203e-03 3.2201573e-02\n",
      " 4.9180968e-04] \n",
      " -0.65835905\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 8.16020025e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.15143930e-01 6.25782228e-03 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  2.50312891e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.12891114e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.0753470e-04 6.7882158e-04 2.8351427e-03 1.9845285e-03 3.8621252e-04\n",
      " 4.7239082e-04 2.8079358e-04 2.1635892e-03 1.0013140e-02 1.8302988e-02\n",
      " 8.7708840e-04 5.1801099e-04 3.9801782e-04 5.7548600e-01 1.2003971e-02\n",
      " 9.2384376e-04 5.1046051e-03 1.9113566e-03 7.9336332e-04 4.5737182e-03\n",
      " 1.5524873e-03 1.2693964e-02 2.9247800e-01 1.1421245e-03 8.4472378e-04\n",
      " 1.6052666e-03 2.6517484e-02 1.2437090e-02 3.1352462e-03 2.5010813e-04\n",
      " 1.4600147e-03 1.3383494e-03 1.3094671e-03 2.5715013e-03 4.1115267e-04\n",
      " 2.3805292e-04] \n",
      " 0.89124584\n",
      "p [[0.00125156 0.0175219  0.00125156 0.75594493 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.0563204  0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.         0.03629537 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.09011264 0.00125156 0.01251564 0.00125156]]\n",
      "move 3\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00389015 0.15355796 0.0118856  0.01068307 0.00399916 0.00156846\n",
      " 0.01709437 0.01204842 0.01432191 0.01123309 0.02724526 0.00368409\n",
      " 0.00099242 0.05334943 0.11046692 0.00190469 0.01755163 0.06008045\n",
      " 0.02874438 0.01070564 0.00242664 0.10334758 0.02851637 0.00398741\n",
      " 0.00630668 0.02060464 0.01824705 0.0176518  0.01241023 0.02076548\n",
      " 0.00535078 0.00491758 0.00948168 0.02672415 0.15983516 0.00441989] \n",
      " -0.8771166\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.76095119e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 9.24906133e-01 6.25782228e-03 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  4.63078849e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.76095119e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00376171 0.0031222  0.01884435 0.00525628 0.00133204 0.00210119\n",
      " 0.00160429 0.0262796  0.07854544 0.19585618 0.00293264 0.00247549\n",
      " 0.00281622 0.02431492 0.00498453 0.00184975 0.0456234  0.01143369\n",
      " 0.0087272  0.03632573 0.00293147 0.00321283 0.01128192 0.00625665\n",
      " 0.00323898 0.0071169  0.3460487  0.05876701 0.02327903 0.00156174\n",
      " 0.00195236 0.00351024 0.01022099 0.03792804 0.0016058  0.00290056] \n",
      " 0.86176074\n",
      "p [[0.00125156 0.05506884 0.00250313 0.         0.00125156 0.00125156]\n",
      " [0.00500626 0.00250313 0.00375469 0.         0.00750939 0.00125156]\n",
      " [0.00125156 0.         0.78598248 0.         0.00500626 0.0175219 ]\n",
      " [0.00876095 0.00250313 0.         0.         0.00750939 0.00125156]\n",
      " [0.00125156 0.00625782 0.00876095 0.         0.00375469 0.00625782]\n",
      " [0.00125156 0.00125156 0.00250313 0.00750939 0.04881101 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00361726 0.12455091 0.01568289 0.02361077 0.01297538 0.00130481\n",
      " 0.01295377 0.01653797 0.10774399 0.00272594 0.01712317 0.00680324\n",
      " 0.00121997 0.05503792 0.01800805 0.00701712 0.08202372 0.02755057\n",
      " 0.01398408 0.06030329 0.00800319 0.02289172 0.02495916 0.00474937\n",
      " 0.00944059 0.01686241 0.00256723 0.06301387 0.01260353 0.01594106\n",
      " 0.00431126 0.01042905 0.031259   0.04810856 0.10662674 0.00745853] \n",
      " -0.80055845\n",
      "p [[1.25156446e-13 1.25156446e-13 2.50312891e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 8.76095119e-03 1.62703379e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.25782228e-03 1.25156446e-03]\n",
      " [2.50312891e-03 5.00625782e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 2.50312891e-03]\n",
      " [1.25156446e-13 3.75469337e-03 9.36170213e-01 0.00000000e+00\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.40794538e-04 1.03306212e-03 1.72174037e-01 4.41731099e-05\n",
      " 1.27019752e-02 6.34269789e-04 7.88758742e-04 1.08218670e-03\n",
      " 2.33677987e-04 1.99797424e-03 5.89497446e-04 9.69305262e-03\n",
      " 2.41688406e-03 1.01120593e-02 5.70175529e-04 4.47718776e-05\n",
      " 3.78390163e-01 4.00689867e-04 7.29495136e-04 1.34644419e-01\n",
      " 1.05850646e-04 8.66593968e-04 1.61647890e-03 1.84374733e-03\n",
      " 6.24356000e-03 5.19932539e-04 2.23698164e-03 9.89631299e-05\n",
      " 3.47659085e-03 1.53108279e-03 4.28968720e-04 2.20807772e-02\n",
      " 1.66955462e-04 2.29639396e-01 5.50475379e-04 1.71600826e-04] \n",
      " -0.13376865\n",
      "p [[0.00125156 0.03754693 0.00375469 0.         0.00375469 0.00125156]\n",
      " [0.00375469 0.00375469 0.80100125 0.         0.00500626 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.02252816 0.00750939]\n",
      " [0.00375469 0.02252816 0.         0.         0.00625782 0.00125156]\n",
      " [0.00250313 0.00375469 0.         0.         0.00250313 0.00375469]\n",
      " [0.00125156 0.00250313 0.00876095 0.01501877 0.03128911 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00302262 0.16960669 0.00522015 0.04613735 0.0109804  0.00036373\n",
      " 0.03363127 0.01761606 0.00915648 0.00431088 0.0028167  0.00684738\n",
      " 0.00772748 0.02382271 0.00720268 0.00527491 0.1693781  0.02968477\n",
      " 0.02192872 0.09158942 0.00424146 0.00706379 0.02732868 0.00605132\n",
      " 0.00394188 0.00133779 0.0059502  0.00730424 0.01741141 0.03333808\n",
      " 0.00068993 0.00532902 0.02815782 0.01180804 0.16510919 0.0086187 ] \n",
      " 0.07687309\n",
      "p [[1.25156446e-13 1.25156446e-13 8.92365457e-01 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.38172716e-02 1.25156446e-13]\n",
      " [1.25156446e-13 2.25281602e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-03 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 2.50312891e-02\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 2\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.8707403e-05 1.0525758e-05 2.0207721e-04 1.6836178e-05 1.3317091e-03\n",
      " 2.7869597e-05 4.7326470e-05 3.8378907e-04 4.8684697e-06 4.0443123e-05\n",
      " 2.0026067e-05 7.2777562e-04 1.3420950e-03 3.9403877e-04 1.4405210e-05\n",
      " 1.7869606e-05 6.5014303e-01 1.3197456e-04 2.6823755e-04 3.4145623e-01\n",
      " 1.9438346e-05 5.0740782e-05 8.6029620e-05 3.9663815e-04 8.0744707e-04\n",
      " 1.7372737e-05 9.4623116e-05 9.6988169e-06 7.8041671e-04 3.1714306e-05\n",
      " 2.7505557e-05 7.0246612e-04 1.0584282e-05 2.6264580e-04 3.2745577e-06\n",
      " 5.9601833e-05] \n",
      " -0.18441184\n",
      "p [[0.00125156 0.10387985 0.         0.         0.0175219  0.00500626]\n",
      " [0.05757196 0.00876095 0.         0.         0.00250313 0.00250313]\n",
      " [0.01877347 0.         0.         0.         0.07634543 0.21902378]\n",
      " [0.02878598 0.0738423  0.         0.         0.01877347 0.00250313]\n",
      " [0.00125156 0.00125156 0.         0.         0.02878598 0.02002503]\n",
      " [0.00125156 0.00250313 0.04005006 0.01251564 0.25156446 0.00375469]]\n",
      "move 34\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [0.007339   0.0244894  0.02080613 0.11694928 0.10517927 0.00071379\n",
      " 0.02517596 0.01385163 0.00158626 0.00703145 0.00257907 0.01905955\n",
      " 0.07353948 0.02487926 0.01040479 0.00446179 0.01741626 0.1221493\n",
      " 0.02595288 0.011174   0.00458862 0.01682265 0.04393446 0.08483993\n",
      " 0.02746625 0.00365487 0.01075472 0.00164564 0.01011881 0.03669853\n",
      " 0.00221975 0.01900553 0.07687023 0.00870389 0.00956595 0.00837161] \n",
      " -0.6088397\n",
      "p [[1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.17146433e-01 1.25156446e-13]\n",
      " [1.25156446e-13 2.82853567e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [1.8273460e-03 7.6698873e-04 6.4986772e-03 3.9675922e-04 1.6017927e-01\n",
      " 1.8438563e-04 7.3382963e-04 1.6823933e-03 9.0524351e-05 8.2958542e-04\n",
      " 5.9766305e-04 1.1163487e-01 3.5237759e-01 1.6106376e-02 1.6734122e-04\n",
      " 8.6990600e-05 1.1767304e-02 7.0499058e-04 9.2020654e-04 5.8662076e-03\n",
      " 1.3473253e-04 7.6584407e-04 5.5155503e-03 5.4171592e-02 1.2683325e-01\n",
      " 9.4850024e-04 1.1974751e-03 1.6143806e-04 1.5132971e-03 2.9671632e-04\n",
      " 4.7973360e-04 1.2246178e-01 1.0533832e-03 1.0218916e-02 2.2905183e-04\n",
      " 5.9947948e-04] \n",
      " -0.93992114\n",
      "p [[0.01001252 0.0350438  0.         0.         0.13642053 0.01501877]\n",
      " [0.04005006 0.01251564 0.         0.         0.00500626 0.01877347]\n",
      " [0.06007509 0.         0.         0.         0.         0.15394243]\n",
      " [0.05757196 0.03128911 0.         0.         0.05882353 0.05381727]\n",
      " [0.03254068 0.00750939 0.         0.         0.03128911 0.04255319]\n",
      " [0.01126408 0.0387985  0.10513141 0.02753442 0.         0.01501877]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [0.01033945 0.01757443 0.01406448 0.10033783 0.00843764 0.0004861\n",
      " 0.06150448 0.00897468 0.00106364 0.00652927 0.00965248 0.01459717\n",
      " 0.0527585  0.05044872 0.00432471 0.0123874  0.0306381  0.01409361\n",
      " 0.00285287 0.01534582 0.01133743 0.00795596 0.20119753 0.08158953\n",
      " 0.03089484 0.00846322 0.005908   0.00110608 0.00726824 0.07270501\n",
      " 0.0013172  0.0013398  0.10996638 0.0058816  0.00802067 0.0086373 ] \n",
      " -0.9832526\n",
      "p [[1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  3.37922403e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 3.29161452e-01]\n",
      " [9.63704631e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.58948686e-01]\n",
      " [1.75219024e-02 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.61702128e-01 1.25156446e-13 2.50312891e-03\n",
      "  0.00000000e+00 1.25156446e-13]]\n",
      "move 31\n",
      "board\n",
      " [[ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.]]\n",
      "1 won\n",
      "game 299 completed in 32.68021821975708 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4768019 entropy 1.8020151\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4564002 entropy 1.8023281\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4282527 entropy 1.8058345\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3950098 entropy 1.8098059\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3620837 entropy 1.8118374\n",
      "kl 0.036166366\n",
      "completed in 0.1650400161743164 s\n",
      "training pipeline completed in 2887.993057012558 s\n"
     ]
    }
   ],
   "source": [
    "k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "607ee139",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.save('n2-900.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b53ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 7.701918363571167 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4605017 entropy 1.7951505\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4431546 entropy 1.7925993\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.420861 entropy 1.7913243\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3939025 entropy 1.7927802\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3565302 entropy 1.797054\n",
      "kl 0.01848074\n",
      "completed in 0.17058610916137695 s\n",
      "game 1 completed in 7.923114061355591 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5128202 entropy 1.8340323\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4929202 entropy 1.8421507\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4605138 entropy 1.8501991\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4220643 entropy 1.8573993\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.382882 entropy 1.8633251\n",
      "kl 0.026909605\n",
      "completed in 0.1872708797454834 s\n",
      "game 2 completed in 7.686304807662964 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3798645 entropy 1.7976141\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3604817 entropy 1.7988431\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3363051 entropy 1.8000653\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.30864 entropy 1.802892\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2753556 entropy 1.8062223\n",
      "kl 0.019537304\n",
      "completed in 0.20482802391052246 s\n",
      "game 3 completed in 13.22714376449585 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4360383 entropy 1.9106296\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.418568 entropy 1.9100952\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3937929 entropy 1.9063549\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3666446 entropy 1.8989313\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3384583 entropy 1.8873416\n",
      "kl 0.027993044\n",
      "completed in 0.16591095924377441 s\n",
      "game 4 completed in 7.470192909240723 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5553966 entropy 1.8710021\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5418382 entropy 1.8566761\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.515478 entropy 1.8427716\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.482148 entropy 1.8303905\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4467728 entropy 1.8211359\n",
      "kl 0.027331194\n",
      "completed in 0.1942431926727295 s\n",
      "game 5 completed in 8.926262617111206 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.455342 entropy 1.8276275\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4408143 entropy 1.8255925\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4141343 entropy 1.8275481\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.381159 entropy 1.8315878\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.347462 entropy 1.8358047\n",
      "kl 0.024647936\n",
      "completed in 0.20264983177185059 s\n",
      "game 6 completed in 10.685379981994629 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4339278 entropy 1.7871951\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4061 entropy 1.7902808\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.377979 entropy 1.7913021\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3459854 entropy 1.7886416\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3129601 entropy 1.7829962\n",
      "kl 0.018680716\n",
      "completed in 0.16800594329833984 s\n",
      "game 7 completed in 7.338138103485107 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5043323 entropy 1.7945094\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4830883 entropy 1.7913618\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4557698 entropy 1.7933013\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4259295 entropy 1.7997719\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3980107 entropy 1.8090448\n",
      "kl 0.031770386\n",
      "completed in 0.17998504638671875 s\n",
      "game 8 completed in 8.893373012542725 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5523217 entropy 1.8349539\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5351121 entropy 1.8451923\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5018911 entropy 1.8553407\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4609914 entropy 1.8635948\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4262826 entropy 1.8694551\n",
      "kl 0.02043681\n",
      "completed in 0.17331480979919434 s\n",
      "game 9 completed in 11.657090902328491 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.446255 entropy 1.8271534\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4241056 entropy 1.8271186\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3934357 entropy 1.8224971\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3644903 entropy 1.8160484\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3364532 entropy 1.8086565\n",
      "kl 0.044812515\n",
      "completed in 0.1702573299407959 s\n",
      "game 10 completed in 8.291089057922363 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5426357 entropy 1.8473376\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5257316 entropy 1.8485947\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4974577 entropy 1.853163\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4657238 entropy 1.8601229\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4329133 entropy 1.8681457\n",
      "kl 0.019996995\n",
      "completed in 0.17922091484069824 s\n",
      "game 11 completed in 7.26083517074585 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4173114 entropy 1.8556142\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4017131 entropy 1.8657765\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3792198 entropy 1.8747593\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3568754 entropy 1.8811214\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3333852 entropy 1.8833661\n",
      "kl 0.016045831\n",
      "completed in 0.17961597442626953 s\n",
      "game 12 completed in 11.5334951877594 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4088137 entropy 1.8578084\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3939366 entropy 1.8535271\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3681464 entropy 1.8474262\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3370554 entropy 1.8394617\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3016293 entropy 1.8299398\n",
      "kl 0.013009215\n",
      "completed in 0.198289155960083 s\n",
      "game 13 completed in 10.419872045516968 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3721864 entropy 1.8304136\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3542118 entropy 1.8173625\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3298404 entropy 1.8041668\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3048172 entropy 1.7930005\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2794514 entropy 1.7846577\n",
      "kl 0.013440596\n",
      "completed in 0.16623783111572266 s\n",
      "game 14 completed in 7.794885873794556 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.457772 entropy 1.806976\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4398224 entropy 1.8032568\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4169302 entropy 1.801527\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.392822 entropy 1.8009968\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3680477 entropy 1.8006418\n",
      "kl 0.018066805\n",
      "completed in 0.195389986038208 s\n",
      "game 15 completed in 10.229705095291138 s 12 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5369587 entropy 1.844196\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.523516 entropy 1.8470806\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5033538 entropy 1.8497968\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4777772 entropy 1.8515111\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4475498 entropy 1.8515241\n",
      "kl 0.010868285\n",
      "completed in 0.21209406852722168 s\n",
      "game 16 completed in 7.480320930480957 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4850323 entropy 1.827752\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4653404 entropy 1.8261874\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4393601 entropy 1.8242636\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.412604 entropy 1.8223964\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3877184 entropy 1.8210167\n",
      "kl 0.020455636\n",
      "completed in 0.16712188720703125 s\n",
      "game 17 completed in 5.967044115066528 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3018813 entropy 1.7244706\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.2890525 entropy 1.726387\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.267407 entropy 1.729294\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2414956 entropy 1.7328811\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2151835 entropy 1.7366498\n",
      "kl 0.015423834\n",
      "completed in 0.16414475440979004 s\n",
      "game 18 completed in 10.6453378200531 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.454112 entropy 1.7705733\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4396875 entropy 1.775105\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4148717 entropy 1.7802938\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3895252 entropy 1.7852906\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.363533 entropy 1.7890754\n",
      "kl 0.011225479\n",
      "completed in 0.18162298202514648 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 19 completed in 13.625030040740967 s 17 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4233267 entropy 1.8278303\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4086506 entropy 1.8279686\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3897223 entropy 1.826648\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3715432 entropy 1.8248178\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3517694 entropy 1.8231778\n",
      "kl 0.010999002\n",
      "completed in 0.17678093910217285 s\n",
      "game 20 completed in 12.126585006713867 s 15 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.413467 entropy 1.8140309\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.39737 entropy 1.814783\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3751683 entropy 1.8165462\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3563766 entropy 1.8183714\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3379447 entropy 1.8194184\n",
      "kl 0.008822982\n",
      "completed in 0.16971683502197266 s\n",
      "game 21 completed in 9.933645009994507 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4070446 entropy 1.8393979\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3881707 entropy 1.8353925\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3655531 entropy 1.8277092\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3364894 entropy 1.8174686\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3018084 entropy 1.80617\n",
      "kl 0.02558114\n",
      "completed in 0.1695559024810791 s\n",
      "game 22 completed in 8.23785400390625 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4058564 entropy 1.8241273\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3832161 entropy 1.8163123\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3513918 entropy 1.81045\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3129594 entropy 1.8061106\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.272759 entropy 1.802836\n",
      "kl 0.025328841\n",
      "completed in 0.17336511611938477 s\n",
      "game 23 completed in 6.699296951293945 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5002363 entropy 1.757562\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.478899 entropy 1.7590969\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4409924 entropy 1.762914\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3984349 entropy 1.7676039\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.357735 entropy 1.7716643\n",
      "kl 0.02731213\n",
      "completed in 0.1893320083618164 s\n",
      "game 24 completed in 8.581730127334595 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4702528 entropy 1.7818598\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4394886 entropy 1.7881902\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3923635 entropy 1.7945142\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.345918 entropy 1.8008208\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.307717 entropy 1.8058989\n",
      "kl 0.03765987\n",
      "completed in 0.16817712783813477 s\n",
      "game 25 completed in 7.7111899852752686 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.475007 entropy 1.853266\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.457016 entropy 1.8561494\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.433125 entropy 1.8590051\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4084454 entropy 1.861155\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.384176 entropy 1.8621356\n",
      "kl 0.02856966\n",
      "completed in 0.16300225257873535 s\n",
      "game 26 completed in 11.59054183959961 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.545097 entropy 1.8494334\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5125642 entropy 1.8514328\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4623811 entropy 1.8530204\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4148476 entropy 1.8541218\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3792381 entropy 1.8545742\n",
      "kl 0.027005125\n",
      "completed in 0.16564011573791504 s\n",
      "game 27 completed in 6.908766984939575 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4162602 entropy 1.7877979\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4025524 entropy 1.7885733\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.37645 entropy 1.7900565\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3452153 entropy 1.7911392\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3158028 entropy 1.7899811\n",
      "kl 0.031045957\n",
      "completed in 0.16274094581604004 s\n",
      "game 28 completed in 15.716255903244019 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5328987 entropy 1.8651004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.51129 entropy 1.8650959\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.477402 entropy 1.8643489\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4446564 entropy 1.8626189\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4143398 entropy 1.8606955\n",
      "kl 0.03463438\n",
      "completed in 0.15972304344177246 s\n",
      "game 29 completed in 6.36753511428833 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4316328 entropy 1.8322731\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4120247 entropy 1.8303158\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.380116 entropy 1.8296138\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.345791 entropy 1.8294141\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3097785 entropy 1.8288479\n",
      "kl 0.020487178\n",
      "completed in 0.19121599197387695 s\n",
      "game 30 completed in 11.207893133163452 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.440758 entropy 1.8140339\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3953805 entropy 1.8072784\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3588655 entropy 1.8005154\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3316321 entropy 1.79742\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2890882 entropy 1.7988786\n",
      "kl 0.031679418\n",
      "completed in 0.1720738410949707 s\n",
      "game 31 completed in 12.246288061141968 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4808614 entropy 1.8332552\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4577696 entropy 1.8397872\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.426901 entropy 1.8458012\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.39432 entropy 1.8483789\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3554518 entropy 1.846596\n",
      "kl 0.028601538\n",
      "completed in 0.17513585090637207 s\n",
      "game 32 completed in 7.1591010093688965 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5234942 entropy 1.8400896\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5013766 entropy 1.8343143\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4661891 entropy 1.8285308\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.427497 entropy 1.8245616\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3896708 entropy 1.821972\n",
      "kl 0.022812495\n",
      "completed in 0.18149924278259277 s\n",
      "game 33 completed in 6.664121866226196 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.441043 entropy 1.797992\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4210744 entropy 1.804251\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3937283 entropy 1.8134544\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3645074 entropy 1.8224521\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3323917 entropy 1.8277261\n",
      "kl 0.026696963\n",
      "completed in 0.18369507789611816 s\n",
      "game 34 completed in 7.330704927444458 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.684761 entropy 1.8460766\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.648244 entropy 1.8403959\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5979743 entropy 1.8320069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5500457 entropy 1.8252575\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5048225 entropy 1.8212736\n",
      "kl 0.024584644\n",
      "completed in 0.18188786506652832 s\n",
      "game 35 completed in 6.219353199005127 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4464273 entropy 1.8065658\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4173386 entropy 1.8079665\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3773854 entropy 1.8101442\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3448293 entropy 1.8113215\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3137426 entropy 1.8103044\n",
      "kl 0.033850566\n",
      "completed in 0.20433521270751953 s\n",
      "game 36 completed in 9.509405851364136 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5781066 entropy 1.8272946\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5608006 entropy 1.8256955\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5215924 entropy 1.8257191\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4700425 entropy 1.827111\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.418873 entropy 1.8298593\n",
      "kl 0.019458575\n",
      "completed in 0.19336390495300293 s\n",
      "game 37 completed in 8.730211019515991 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.477134 entropy 1.7773292\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4599254 entropy 1.781048\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4312603 entropy 1.7846903\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3961828 entropy 1.7878006\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3607516 entropy 1.7890501\n",
      "kl 0.031225162\n",
      "completed in 0.17532062530517578 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 38 completed in 8.694772958755493 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5337675 entropy 1.8675046\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.515778 entropy 1.8659246\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4849231 entropy 1.8619754\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4476476 entropy 1.856627\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.409038 entropy 1.8508387\n",
      "kl 0.031949487\n",
      "completed in 0.1884140968322754 s\n",
      "game 39 completed in 7.775240898132324 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5009592 entropy 1.798028\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4865723 entropy 1.7970889\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4621897 entropy 1.8001863\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4342747 entropy 1.8056802\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4057322 entropy 1.8117385\n",
      "kl 0.03216619\n",
      "completed in 0.16372919082641602 s\n",
      "game 40 completed in 6.354335784912109 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.493741 entropy 1.807055\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4756184 entropy 1.8117733\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.446082 entropy 1.8146689\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4124024 entropy 1.8154068\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3787918 entropy 1.8136835\n",
      "kl 0.027869742\n",
      "completed in 0.18954706192016602 s\n",
      "game 41 completed in 9.05109691619873 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.537555 entropy 1.8452284\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.515869 entropy 1.84482\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4803078 entropy 1.8468041\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.445786 entropy 1.8499814\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4093206 entropy 1.8521028\n",
      "kl 0.023441002\n",
      "completed in 0.18241500854492188 s\n",
      "game 42 completed in 7.970227003097534 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.441436 entropy 1.8099858\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4111326 entropy 1.8068979\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3763561 entropy 1.801477\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3488624 entropy 1.797081\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3174295 entropy 1.7946217\n",
      "kl 0.020946542\n",
      "completed in 0.167083740234375 s\n",
      "game 43 completed in 11.858049869537354 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5336454 entropy 1.8235757\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5154655 entropy 1.8264186\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4852939 entropy 1.8295107\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4489913 entropy 1.8306446\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4107504 entropy 1.8276695\n",
      "kl 0.027645195\n",
      "completed in 0.195573091506958 s\n",
      "game 44 completed in 7.993648290634155 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4969182 entropy 1.8127954\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4855452 entropy 1.8060255\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.462353 entropy 1.8002768\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4330251 entropy 1.7960017\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.400973 entropy 1.7938032\n",
      "kl 0.018403206\n",
      "completed in 0.17479586601257324 s\n",
      "game 45 completed in 7.993770122528076 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5399716 entropy 1.7898068\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5180378 entropy 1.7930546\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4832265 entropy 1.7985508\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.450385 entropy 1.8042827\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4177606 entropy 1.8091497\n",
      "kl 0.026570268\n",
      "completed in 0.17716288566589355 s\n",
      "game 46 completed in 8.545382022857666 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4805608 entropy 1.7873995\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4606733 entropy 1.7912266\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.426735 entropy 1.7954949\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3890064 entropy 1.7997277\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3553226 entropy 1.8034422\n",
      "kl 0.027113777\n",
      "completed in 0.17176294326782227 s\n",
      "game 47 completed in 11.783719778060913 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4766378 entropy 1.8490684\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4584916 entropy 1.852255\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.429288 entropy 1.8542542\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3957133 entropy 1.8550909\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3634415 entropy 1.854338\n",
      "kl 0.017366054\n",
      "completed in 0.1819310188293457 s\n",
      "game 48 completed in 9.426378011703491 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4837077 entropy 1.8447791\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4647276 entropy 1.8364514\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4295044 entropy 1.8257987\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3894727 entropy 1.8154538\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3532128 entropy 1.8069835\n",
      "kl 0.025786517\n",
      "completed in 0.18921113014221191 s\n",
      "prediction:\n",
      " [0.00192013 0.00226231 0.00173942 0.00115813 0.00277974 0.00175813\n",
      " 0.00241508 0.0057246  0.02737132 0.04279815 0.06775892 0.00263221\n",
      " 0.00170296 0.03128395 0.03899958 0.23010741 0.05045724 0.00159058\n",
      " 0.00101728 0.05215384 0.18466736 0.03158186 0.02551267 0.00125862\n",
      " 0.00371498 0.08064571 0.0606234  0.02365915 0.00524722 0.00282911\n",
      " 0.00236812 0.0037923  0.00151081 0.00156159 0.00201515 0.00138116] \n",
      " -0.2929361\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.46433041e-01 4.75594493e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.57697121e-01 2.20275344e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.9245839e-05 1.3633344e-04 1.9859720e-04 5.2024133e-04 1.9792664e-05\n",
      " 3.8846084e-04 1.1075674e-04 7.3049727e-05 1.2403315e-01 1.9492629e-03\n",
      " 4.2012506e-03 5.7920995e-05 1.5331715e-04 1.4013550e-01 1.7126243e-01\n",
      " 7.6226932e-03 2.3075575e-03 4.0612993e-04 4.6702535e-04 1.9498309e-03\n",
      " 5.9491610e-03 3.2953507e-01 9.9226803e-02 6.1713523e-05 3.3381602e-05\n",
      " 2.8205083e-03 1.9238350e-03 1.0240663e-01 6.6376611e-05 1.1471858e-04\n",
      " 6.7961897e-04 4.7451973e-05 6.5828196e-04 2.9827814e-04 1.2342382e-04\n",
      " 2.2216804e-05] \n",
      " 0.25526735\n",
      "p [[0.00375469 0.00250313 0.00250313 0.00250313 0.00250313 0.00250313]\n",
      " [0.00250313 0.0212766  0.01627034 0.04630788 0.05006258 0.00250313]\n",
      " [0.00250313 0.02377972 0.0738423  0.         0.04380476 0.00125156]\n",
      " [0.00125156 0.08635795 0.35294118 0.04881101 0.01126408 0.00125156]\n",
      " [0.00250313 0.06883605 0.077597   0.01877347 0.01627034 0.00375469]\n",
      " [0.00250313 0.00125156 0.00125156 0.00125156 0.00250313 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.6313882e-04 9.0673135e-04 7.6341839e-04 2.0599014e-03 4.1864743e-04\n",
      " 1.6152137e-03 1.0989058e-03 3.0823867e-03 7.9284860e-03 2.7140942e-03\n",
      " 2.8427844e-03 5.2187819e-04 2.5389392e-03 4.5388490e-01 6.9656195e-03\n",
      " 3.9400496e-03 2.3147518e-02 5.3314408e-03 3.0359824e-03 1.8939773e-02\n",
      " 3.3895958e-03 6.8430197e-03 4.1175124e-01 2.6169221e-03 5.0334324e-04\n",
      " 5.6902850e-03 5.9912167e-03 1.1296018e-02 3.6229377e-03 8.8865147e-04\n",
      " 1.1530760e-03 4.5872686e-04 1.5500204e-03 4.2087617e-04 4.3807458e-04\n",
      " 6.8626617e-04] \n",
      " -0.46196663\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.25657071e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.25406758e-02 5.93241552e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 2.40300375e-01\n",
      "  5.25657071e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 2.87859825e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [9.90694156e-04 1.83853772e-04 5.39206667e-04 1.41540857e-03\n",
      " 9.23795305e-05 8.19403795e-04 6.01707550e-04 2.68912339e-03\n",
      " 2.17719853e-01 1.10398298e-02 3.38875386e-03 1.75051435e-04\n",
      " 1.10835826e-03 1.06492182e-02 1.76037848e-02 8.44308175e-04\n",
      " 2.34664366e-01 1.00944899e-02 1.03248255e-02 2.43452951e-01\n",
      " 5.98985120e-04 1.90795865e-02 1.14367716e-02 9.88710206e-04\n",
      " 1.40985605e-04 1.17694749e-03 1.31106600e-02 1.77028447e-01\n",
      " 3.21494066e-03 7.08193402e-04 5.90688782e-04 1.51356187e-04\n",
      " 2.41584936e-03 5.73077297e-04 1.26779327e-04 2.60585715e-04] \n",
      " 0.7794943\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00250313 0.00250313 0.00250313 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.7008761  0.         0.         0.00876095 0.00125156]\n",
      " [0.00125156 0.00876095 0.         0.00250313 0.23153942 0.00125156]\n",
      " [0.00125156 0.00250313 0.00250313 0.00625782 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.0950972e-03 1.6359773e-02 1.8144168e-04 1.1013193e-03 1.7302985e-03\n",
      " 1.0574330e-03 6.7584477e-02 2.6921732e-03 1.5673810e-01 8.4062479e-04\n",
      " 3.0485815e-03 6.7687710e-04 1.9923516e-04 4.6961377e-03 5.6123300e-03\n",
      " 1.0547368e-03 2.0983438e-03 1.2854987e-01 1.0855166e-01 3.8794642e-03\n",
      " 8.2818116e-04 7.9272352e-03 7.0648273e-03 1.1089318e-03 4.0082802e-04\n",
      " 1.0740954e-03 2.7405014e-03 4.1458574e-01 2.9587850e-03 4.3544084e-02\n",
      " 8.0176804e-04 1.1041641e-03 2.8631070e-03 7.4632716e-04 4.0499573e-03\n",
      " 4.5357173e-04] \n",
      " -0.94711196\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.37922403e-02 3.75469337e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.42052566e-01 2.50312891e-03]\n",
      " [2.50312891e-03 4.00500626e-02 0.00000000e+00 3.75469337e-03\n",
      "  1.12640801e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 2.54067584e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.4515513e-03 1.4906059e-03 8.9878496e-04 2.5169814e-03 6.9429405e-04\n",
      " 1.1596463e-03 8.1008259e-04 5.2543716e-03 4.2535707e-01 9.7551486e-03\n",
      " 1.2412711e-02 1.7015000e-03 8.2033537e-03 2.7826702e-02 1.0955709e-02\n",
      " 1.8365138e-03 2.3005335e-02 1.0390141e-02 1.1783564e-02 1.0325008e-02\n",
      " 1.2652050e-03 2.0874253e-02 3.5458833e-02 7.8462046e-03 9.6776040e-04\n",
      " 5.5545936e-03 1.3923628e-02 3.2339478e-01 5.8274269e-03 1.0835886e-03\n",
      " 7.2602526e-04 8.8785728e-04 1.0024644e-02 1.1441146e-03 3.7374502e-04\n",
      " 8.1829529e-04] \n",
      " 0.9427793\n",
      "p [[0.00125156 0.00375469 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.04630788 0.00125156 0.03003755 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.74593242]\n",
      " [0.02002503 0.00125156 0.         0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.11514393 0.00125156 0.00876095]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00266207 0.05126221 0.00048035 0.01495603 0.00427105 0.00205424\n",
      " 0.20318429 0.01079537 0.02777996 0.00591711 0.02505382 0.00546304\n",
      " 0.00598145 0.02258425 0.07742169 0.00237164 0.00274894 0.02784333\n",
      " 0.01398162 0.00641887 0.00239053 0.14334144 0.02227568 0.01710429\n",
      " 0.00475946 0.02582756 0.01377378 0.08402113 0.00660192 0.10194781\n",
      " 0.0019186  0.0035249  0.03397501 0.0030368  0.02066057 0.00160941] \n",
      " -0.9527539\n",
      "p [[0.00750939 0.00375469 0.00750939 0.00500626 0.00375469 0.00375469]\n",
      " [0.00750939 0.00750939 0.12390488 0.03754693 0.01251564 0.00500626]\n",
      " [0.01376721 0.         0.         0.         0.         0.        ]\n",
      " [0.00750939 0.00750939 0.         0.02252816 0.06132666 0.02252816]\n",
      " [0.00876095 0.01001252 0.00375469 0.4931164  0.02002503 0.04255319]\n",
      " [0.00750939 0.00375469 0.00500626 0.00500626 0.01877347 0.0212766 ]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00194902 0.00209145 0.00134217 0.00589957 0.00041246 0.00045388\n",
      " 0.00338869 0.00788749 0.0202552  0.0820343  0.00477147 0.00228837\n",
      " 0.02335357 0.11025348 0.01725935 0.00144547 0.21820831 0.00426904\n",
      " 0.00427184 0.18268228 0.00075843 0.03047555 0.08985727 0.01246155\n",
      " 0.00160227 0.00280278 0.11673353 0.01874844 0.00455651 0.00296878\n",
      " 0.00051678 0.00099477 0.0195988  0.00142906 0.00118241 0.00079583] \n",
      " 0.8651859\n",
      "p [[0.00125156 0.00750939 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.03379224 0.00250313 0.00375469 0.00125156 0.00375469 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.00125156 0.00250313 0.         0.8873592  0.00250313 0.00250313]\n",
      " [0.00125156 0.00375469 0.00125156 0.         0.00125156 0.02002503]\n",
      " [0.00125156 0.00125156 0.00750939 0.00125156 0.00250313 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00760383 0.00576694 0.0005482  0.0083553  0.00220945 0.003361\n",
      " 0.13569212 0.00560331 0.01458076 0.06265481 0.01309798 0.00334547\n",
      " 0.0126008  0.08902738 0.0003927  0.00104202 0.00568544 0.05822529\n",
      " 0.03676439 0.01112733 0.0008626  0.00239479 0.19610111 0.06400943\n",
      " 0.00338523 0.0088628  0.09655806 0.0520601  0.00322136 0.05157674\n",
      " 0.00250843 0.00335916 0.02436239 0.00231322 0.0064046  0.00433566] \n",
      " -0.3492699\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00375469 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.0175219  0.00500626 0.00375469]\n",
      " [0.00750939 0.         0.         0.         0.         0.        ]\n",
      " [0.00125156 0.79974969 0.         0.         0.07634543 0.00500626]\n",
      " [0.00375469 0.00375469 0.02252816 0.         0.00876095 0.00375469]\n",
      " [0.00375469 0.00375469 0.01001252 0.00375469 0.00125156 0.00250313]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.8584717e-04 8.0315053e-04 2.4208841e-03 7.4214567e-03 2.3686797e-03\n",
      " 2.8435176e-04 8.3447091e-04 2.4832524e-03 3.0488460e-03 8.6371325e-02\n",
      " 3.7316146e-04 6.0079344e-02 3.0235103e-01 1.5066435e-03 5.1747652e-04\n",
      " 1.2371382e-04 8.1803696e-04 4.3676200e-04 3.1754543e-04 7.0336845e-04\n",
      " 9.0768044e-05 2.6785870e-04 5.8227463e-04 1.6024220e-01 2.9290212e-02\n",
      " 9.7649172e-04 3.1243509e-01 4.9450668e-03 1.9185537e-03 6.7884004e-04\n",
      " 5.8747252e-04 6.7591434e-03 5.4484466e-03 1.3764221e-03 6.3074799e-04\n",
      " 2.2124102e-04] \n",
      " -0.8580979\n",
      "p [[3.75469337e-03 2.50312891e-03 1.25156446e-13 7.50938673e-03\n",
      "  2.50312891e-03 2.50312891e-03]\n",
      " [4.50563204e-02 5.00625782e-03 6.25782228e-03 1.37672090e-02\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [5.00625782e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.76095119e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.92115144e-01 1.15143930e-01]\n",
      " [2.50312891e-03 7.50938673e-03 2.12765957e-02 0.00000000e+00\n",
      "  3.75469337e-03 3.87984981e-02]\n",
      " [1.25156446e-03 1.25156446e-03 6.25782228e-03 1.25156446e-03\n",
      "  1.25156446e-03 2.50312891e-03]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.6994592e-03 3.7914872e-02 4.0143933e-03 8.0364551e-03 1.2799455e-03\n",
      " 9.5075753e-04 3.0622298e-01 7.4611693e-03 2.4638794e-02 3.5904836e-02\n",
      " 9.1525717e-03 2.7523362e-03 3.9979746e-03 5.8544427e-04 3.9354307e-03\n",
      " 2.6055242e-04 9.2651853e-03 2.5483429e-02 1.9095009e-02 5.3724414e-03\n",
      " 5.3736247e-04 2.5427192e-03 3.7929302e-03 1.0367732e-02 3.5725208e-03\n",
      " 9.0570813e-03 1.5160798e-01 3.2062266e-02 9.4924551e-03 2.1160194e-01\n",
      " 4.5390865e-03 5.5180574e-03 1.6161082e-02 4.7387104e-03 2.1544822e-02\n",
      " 3.8393440e-03] \n",
      " 0.77595705\n",
      "p [[1.25156446e-13 1.25156446e-03 1.25156446e-03 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 1.25156446e-03 1.25156446e-03 1.50187735e-02\n",
      "  1.25156446e-13 8.76095119e-03]\n",
      " [4.50563204e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.61076345e-01]\n",
      " [3.75469337e-03 2.50312891e-03 4.88110138e-02 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-03 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.0016976  0.02556029 0.049605   0.02061562 0.01150292 0.00114167\n",
      " 0.02129089 0.02901284 0.04904469 0.06275816 0.0067971  0.16155466\n",
      " 0.02793477 0.00525004 0.00509142 0.00063975 0.00750336 0.01020333\n",
      " 0.00563619 0.0089444  0.00058607 0.00300326 0.00306572 0.01655204\n",
      " 0.09978965 0.01344152 0.19597146 0.05271645 0.02242895 0.01386849\n",
      " 0.00331929 0.02847089 0.00816632 0.01587864 0.00912145 0.00183508] \n",
      " -0.85191244\n",
      "p [[0.01501877 0.0350438  0.00500626 0.05381727 0.00250313 0.00125156]\n",
      " [0.13266583 0.10763454 0.04755945 0.27534418 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.02002503 0.         0.         0.         0.         0.        ]\n",
      " [0.00250313 0.04255319 0.03003755 0.         0.02252816 0.16520651]\n",
      " [0.00125156 0.00250313 0.00375469 0.00125156 0.02252816 0.00625782]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00258786 0.03095094 0.00485912 0.0187417  0.01179967 0.00205184\n",
      " 0.2542094  0.031076   0.07623591 0.005835   0.00662683 0.00763816\n",
      " 0.00262826 0.00055562 0.00029576 0.00138136 0.01237885 0.01062832\n",
      " 0.00438298 0.00783658 0.00438985 0.0003668  0.00271408 0.00428088\n",
      " 0.01193334 0.01355971 0.02125111 0.02448275 0.03162035 0.2722528\n",
      " 0.01055778 0.05015502 0.03767504 0.00620786 0.0139379  0.00191473] \n",
      " -0.8223411\n",
      "p [[1.25156446e-13 2.50312891e-03 6.25782228e-03 2.50312891e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [2.50312891e-03 8.76095119e-03 6.25782228e-03 0.00000000e+00\n",
      "  1.25156446e-03 3.00375469e-02]\n",
      " [3.75469337e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.37797247e-02 8.03504380e-01 8.26032541e-02 0.00000000e+00\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [1.25156446e-03 3.75469337e-03 1.25156446e-03 7.50938673e-03\n",
      "  1.25156446e-03 1.25156446e-13]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00107647 0.03113243 0.00672154 0.01300726 0.06916323 0.00072164\n",
      " 0.01725775 0.04644316 0.09839337 0.00605481 0.00164043 0.08620045\n",
      " 0.03143902 0.01195154 0.06832469 0.00239516 0.01099238 0.01650856\n",
      " 0.0166346  0.01057529 0.00239597 0.06393789 0.0102627  0.00910614\n",
      " 0.06158944 0.00611143 0.01330747 0.03498158 0.02833255 0.0092774\n",
      " 0.00268944 0.18696997 0.01137921 0.00243874 0.00980833 0.00077808] \n",
      " -0.035585586\n",
      "p [[0.00500626 0.01126408 0.00500626 0.00876095 0.00500626 0.00500626]\n",
      " [0.10888611 0.01251564 0.03754693 0.         0.00250313 0.00250313]\n",
      " [0.00500626 0.         0.         0.         0.         0.        ]\n",
      " [0.00750939 0.         0.         0.         0.         0.        ]\n",
      " [0.00625782 0.         0.61201502 0.         0.01501877 0.10262829]\n",
      " [0.00625782 0.01501877 0.01251564 0.00375469 0.00500626 0.00500626]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.93089731e-04 2.71407235e-02 3.82717792e-03 1.57862529e-02\n",
      " 2.16462426e-02 2.72933947e-04 2.35712513e-01 2.62576551e-03\n",
      " 1.69260904e-01 1.43405749e-04 4.43921238e-03 1.55398045e-02\n",
      " 2.26381258e-03 2.06522789e-04 1.19305514e-04 9.75944276e-04\n",
      " 3.36009683e-03 6.55993633e-03 4.19367524e-03 2.84961239e-03\n",
      " 3.50753404e-03 1.88299193e-04 8.31996789e-04 2.19666655e-03\n",
      " 2.02123374e-02 7.23268557e-03 2.00520502e-04 3.68894935e-02\n",
      " 3.87781626e-03 2.97204256e-01 1.98753714e-03 5.37337400e-02\n",
      " 2.76240930e-02 1.80145018e-02 8.05972703e-03 7.22136116e-04] \n",
      " -0.9639624\n",
      "p [[1.25156446e-13 8.76095119e-03 2.50312891e-03 6.25782228e-03\n",
      "  2.25281602e-02 1.25156446e-13]\n",
      " [6.25782228e-03 1.87734668e-02 2.12765957e-02 0.00000000e+00\n",
      "  1.25156446e-13 6.13266583e-02]\n",
      " [1.62703379e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.50938673e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.03379224e-01 2.50312891e-03]\n",
      " [1.25156446e-13 9.63704631e-02 6.25782228e-03 1.25156446e-13\n",
      "  7.50938673e-03 1.25156446e-13]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00175735 0.0281336  0.02804081 0.03133072 0.07970885 0.00046193\n",
      " 0.01640475 0.0051382  0.23865256 0.01282748 0.00166284 0.07201758\n",
      " 0.00701539 0.00880406 0.00800079 0.00150121 0.00349125 0.00625037\n",
      " 0.00655645 0.00115061 0.00630841 0.00942205 0.01809552 0.00376663\n",
      " 0.09238476 0.00720406 0.03881402 0.10225888 0.00167545 0.00864995\n",
      " 0.00126163 0.13148244 0.00940006 0.00472043 0.00474091 0.00090817] \n",
      " 0.92020166\n",
      "p [[0.00125156 0.01376721 0.00125156 0.00750939 0.01126408 0.00250313]\n",
      " [0.34543179 0.00125156 0.10387985 0.         0.00125156 0.00876095]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.1864831  0.         0.         0.         0.         0.        ]\n",
      " [0.01251564 0.         0.         0.         0.         0.19274093]\n",
      " [0.00125156 0.08635795 0.01376721 0.00375469 0.00250313 0.00125156]]\n",
      "move 6\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.9811294e-03 9.6164057e-03 1.1186019e-02 7.8560546e-02 1.1489650e-02\n",
      " 9.1335678e-04 3.8937338e-02 5.2707251e-03 3.4114373e-01 4.1672724e-04\n",
      " 9.9652559e-03 1.9052027e-02 3.0751666e-03 2.3516959e-04 3.6663252e-05\n",
      " 1.3066274e-03 6.5598362e-03 1.5260573e-02 8.9865001e-03 8.6922897e-03\n",
      " 1.0028966e-02 4.5842924e-05 1.1123265e-03 3.3100909e-03 3.0830365e-02\n",
      " 6.3444981e-03 1.0980871e-03 9.4556980e-02 5.0590299e-03 5.0102383e-02\n",
      " 3.8186905e-03 1.4974022e-02 1.8067184e-01 1.8009992e-02 5.5072326e-03\n",
      " 1.8439566e-03] \n",
      " -0.9937014\n",
      "p [[1.25156446e-13 1.50187735e-02 6.00750939e-02 4.50563204e-02\n",
      "  4.50563204e-02 1.25156446e-13]\n",
      " [0.00000000e+00 2.50312891e-03 6.63329161e-02 0.00000000e+00\n",
      "  1.25156446e-13 5.75719650e-02]\n",
      " [2.27784731e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.75344180e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.00625782e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.76220275e-02]\n",
      " [1.25156446e-13 2.91614518e-01 7.50938673e-03 2.50312891e-03\n",
      "  3.75469337e-03 1.25156446e-13]]\n",
      "move 31\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00321224 0.02106228 0.1053155  0.2791267  0.01077345 0.00133045\n",
      " 0.02089447 0.05410481 0.07321524 0.01692383 0.01223688 0.05007912\n",
      " 0.00217722 0.02269345 0.00061634 0.00056104 0.00038694 0.01168986\n",
      " 0.00674051 0.00045014 0.00255234 0.00076476 0.01659087 0.00111217\n",
      " 0.06773188 0.02431597 0.03922968 0.04100651 0.0125173  0.01530392\n",
      " 0.00445606 0.01257087 0.03902446 0.01846252 0.00488795 0.00588251] \n",
      " 0.7835942\n",
      "p [[0.00125156 0.00125156 0.00125156 0.04505632 0.00125156 0.17521902]\n",
      " [0.         0.00250313 0.66082603 0.         0.00125156 0.00250313]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.0175219  0.         0.         0.         0.         0.01627034]\n",
      " [0.00125156 0.         0.06508135 0.00250313 0.00125156 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0. -1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.8181044e-03 9.4464337e-03 6.6650800e-02 1.0388893e-02 1.3869821e-02\n",
      " 3.5535567e-04 1.9414397e-01 9.5015205e-03 2.0920476e-03 1.2847119e-03\n",
      " 6.6300094e-02 7.3627792e-02 1.7358569e-02 5.8301059e-05 3.3633376e-05\n",
      " 7.4995805e-05 4.3428323e-04 2.2656506e-02 1.1788875e-02 6.3518627e-04\n",
      " 6.3407805e-04 2.2290384e-05 2.2526493e-04 4.9007852e-03 4.2190902e-02\n",
      " 1.8912995e-02 2.2397120e-03 8.4633403e-04 2.2185577e-02 2.6993838e-01\n",
      " 7.7314582e-04 2.0360125e-02 4.1177738e-02 6.3983612e-02 5.8281356e-03\n",
      " 3.2611524e-03] \n",
      " -0.8251415\n",
      "p [[0.0175219  0.06007509 0.04505632 0.14893617 0.05131414 0.04255319]\n",
      " [0.         0.10012516 0.         0.         0.09887359 0.06007509]\n",
      " [0.02628285 0.         0.         0.         0.         0.        ]\n",
      " [0.01877347 0.         0.         0.         0.         0.        ]\n",
      " [0.06883605 0.         0.         0.         0.         0.03128911]\n",
      " [0.02628285 0.         0.02002503 0.10513141 0.03254068 0.04630788]]\n",
      "move 3\n",
      "board\n",
      " [[ 0.  0.  0.  1.  0.  0.]\n",
      " [-1.  0. -1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00567394 0.03656549 0.06943429 0.07150608 0.03282572 0.00302769\n",
      " 0.03778154 0.01063021 0.05435677 0.0199313  0.04226312 0.12471479\n",
      " 0.00063856 0.00418329 0.0002166  0.00014708 0.00057824 0.02151627\n",
      " 0.00900122 0.00082844 0.00079363 0.00026091 0.00511044 0.00030593\n",
      " 0.13745257 0.10064523 0.04302985 0.03422546 0.00426068 0.03669857\n",
      " 0.01115655 0.02670381 0.00956186 0.0258783  0.0070931  0.01100272] \n",
      " -0.2188344\n",
      "p [[1.25156446e-13 1.25156446e-03 6.25782228e-03 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [0.00000000e+00 7.07133917e-01 0.00000000e+00 0.00000000e+00\n",
      "  8.76095119e-03 1.00125156e-02]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.17772215e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.75469337e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.12891114e-02]\n",
      " [1.25156446e-13 0.00000000e+00 3.75469337e-03 7.50938673e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  1.  0.  0.]\n",
      " [-1. -1. -1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]]\n",
      "-1 won\n",
      "game 49 completed in 44.61010217666626 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.399742 entropy 1.7454116\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3832002 entropy 1.7458245\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3573 entropy 1.750284\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3280163 entropy 1.7568746\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2963605 entropy 1.763853\n",
      "kl 0.023539012\n",
      "completed in 0.16643524169921875 s\n",
      "game 50 completed in 8.66377305984497 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4166074 entropy 1.8143567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3946693 entropy 1.8190472\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3594224 entropy 1.8232316\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3220503 entropy 1.8259252\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.286511 entropy 1.8264422\n",
      "kl 0.019824691\n",
      "completed in 0.18207597732543945 s\n",
      "game 51 completed in 9.768764972686768 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.508151 entropy 1.8329744\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4833665 entropy 1.8305612\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.446157 entropy 1.8284518\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.406059 entropy 1.8270324\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.37033 entropy 1.8260958\n",
      "kl 0.018258067\n",
      "completed in 0.18790602684020996 s\n",
      "game 52 completed in 7.914247274398804 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5102894 entropy 1.822316\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4852312 entropy 1.8241932\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4500072 entropy 1.8261417\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4181967 entropy 1.8269726\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3847823 entropy 1.8251\n",
      "kl 0.023884967\n",
      "completed in 0.16904902458190918 s\n",
      "game 53 completed in 14.761713981628418 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5760155 entropy 1.831332\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5547054 entropy 1.8320003\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5209932 entropy 1.8357649\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4810717 entropy 1.8419366\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4426312 entropy 1.8496737\n",
      "kl 0.01788469\n",
      "completed in 0.18577003479003906 s\n",
      "game 54 completed in 13.034491062164307 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.592682 entropy 1.8685199\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5751803 entropy 1.8742363\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5461035 entropy 1.8773389\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.515155 entropy 1.8776158\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4847202 entropy 1.8758167\n",
      "kl 0.017755384\n",
      "completed in 0.16990208625793457 s\n",
      "game 55 completed in 5.887778043746948 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.544013 entropy 1.8912395\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5240428 entropy 1.88862\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4921596 entropy 1.8854383\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4573448 entropy 1.8816864\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4257329 entropy 1.877352\n",
      "kl 0.023984175\n",
      "completed in 0.16522598266601562 s\n",
      "game 56 completed in 8.976190090179443 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5798295 entropy 1.8720192\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.552543 entropy 1.8700213\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5147552 entropy 1.8694654\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.477513 entropy 1.8701457\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4440722 entropy 1.8717475\n",
      "kl 0.026371142\n",
      "completed in 0.19258499145507812 s\n",
      "game 57 completed in 8.893197059631348 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5468345 entropy 1.8617933\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5264466 entropy 1.8649879\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4891975 entropy 1.8678976\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4452207 entropy 1.8686768\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.396812 entropy 1.8666377\n",
      "kl 0.021938981\n",
      "completed in 0.17736387252807617 s\n",
      "game 58 completed in 9.965194940567017 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.564878 entropy 1.8642082\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5339181 entropy 1.8639388\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5020883 entropy 1.8651712\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.47091 entropy 1.8668803\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4408135 entropy 1.8687291\n",
      "kl 0.023339327\n",
      "completed in 0.21584796905517578 s\n",
      "game 59 completed in 5.896538734436035 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5409915 entropy 1.8541024\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5226042 entropy 1.8529639\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4926689 entropy 1.8498921\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4577763 entropy 1.8461335\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4224315 entropy 1.8419776\n",
      "kl 0.024578324\n",
      "completed in 0.16506481170654297 s\n",
      "game 60 completed in 7.444288969039917 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4871912 entropy 1.8856238\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4688368 entropy 1.8830125\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4367933 entropy 1.87959\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4052844 entropy 1.87577\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3735132 entropy 1.8719639\n",
      "kl 0.025701629\n",
      "completed in 0.1830289363861084 s\n",
      "game 61 completed in 10.812278985977173 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4892468 entropy 1.8100002\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4569902 entropy 1.8126963\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4172254 entropy 1.8176839\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3812664 entropy 1.8223298\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3452737 entropy 1.8232299\n",
      "kl 0.038389415\n",
      "completed in 0.1918790340423584 s\n",
      "game 62 completed in 9.009919881820679 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4219363 entropy 1.8227084\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3789394 entropy 1.8198867\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3518245 entropy 1.8152137\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3353639 entropy 1.8110106\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3106768 entropy 1.8078835\n",
      "kl 0.022911869\n",
      "completed in 0.18678879737854004 s\n",
      "game 63 completed in 10.862172842025757 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.451626 entropy 1.8120427\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4211347 entropy 1.8109579\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.38403 entropy 1.8086948\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3378558 entropy 1.8031454\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2966912 entropy 1.7954924\n",
      "kl 0.03147963\n",
      "completed in 0.1418139934539795 s\n",
      "game 64 completed in 7.801348686218262 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4290915 entropy 1.8094656\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4144876 entropy 1.8093534\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.389162 entropy 1.8114318\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3590825 entropy 1.8154078\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3278937 entropy 1.8206167\n",
      "kl 0.02648658\n",
      "completed in 0.17159676551818848 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 65 completed in 9.534907102584839 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3985996 entropy 1.7617567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3835948 entropy 1.7680035\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.36275 entropy 1.7767086\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3372004 entropy 1.7851017\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.305499 entropy 1.7905453\n",
      "kl 0.022475343\n",
      "completed in 0.23773407936096191 s\n",
      "game 66 completed in 9.580771207809448 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5284512 entropy 1.8598404\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5049407 entropy 1.8591499\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4681063 entropy 1.856395\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4267797 entropy 1.8509717\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3864684 entropy 1.8429809\n",
      "kl 0.028441949\n",
      "completed in 0.18805694580078125 s\n",
      "game 67 completed in 6.165086984634399 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4643655 entropy 1.8136852\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.443773 entropy 1.8055204\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4061828 entropy 1.7983961\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3634226 entropy 1.7926353\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3278024 entropy 1.7893536\n",
      "kl 0.0220392\n",
      "completed in 0.1667771339416504 s\n",
      "game 68 completed in 10.9351327419281 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.397282 entropy 1.7636647\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3825524 entropy 1.7634251\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3569007 entropy 1.7637007\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3269362 entropy 1.7644391\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.299704 entropy 1.7652617\n",
      "kl 0.028509062\n",
      "completed in 0.2219099998474121 s\n",
      "game 69 completed in 14.074617862701416 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4561446 entropy 1.8641922\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4185455 entropy 1.8705606\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3793116 entropy 1.878049\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3542287 entropy 1.8835331\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3278165 entropy 1.8847733\n",
      "kl 0.029949198\n",
      "completed in 0.16707611083984375 s\n",
      "game 70 completed in 10.096018075942993 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5445619 entropy 1.8507178\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4975784 entropy 1.8485214\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4448042 entropy 1.8471463\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.406078 entropy 1.8475142\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3734264 entropy 1.8488688\n",
      "kl 0.031978652\n",
      "completed in 0.1805710792541504 s\n",
      "game 71 completed in 6.001378774642944 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5099537 entropy 1.8404019\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4872026 entropy 1.8389072\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.452834 entropy 1.8356063\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4208846 entropy 1.8312106\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3899555 entropy 1.8270481\n",
      "kl 0.029013658\n",
      "completed in 0.19887089729309082 s\n",
      "game 72 completed in 6.048220872879028 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.510646 entropy 1.8265023\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4927726 entropy 1.8274579\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4630978 entropy 1.8304663\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4306474 entropy 1.8343513\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3981035 entropy 1.8373373\n",
      "kl 0.023892054\n",
      "completed in 0.16385316848754883 s\n",
      "game 73 completed in 7.727189064025879 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4665964 entropy 1.805471\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4394882 entropy 1.8051308\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.40176 entropy 1.8034207\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3607857 entropy 1.8005877\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3186464 entropy 1.7963178\n",
      "kl 0.029883945\n",
      "completed in 0.20183110237121582 s\n",
      "game 74 completed in 8.289868831634521 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.377443 entropy 1.7781718\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3604147 entropy 1.77445\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.333947 entropy 1.7718414\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3023262 entropy 1.7689364\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.268942 entropy 1.766262\n",
      "kl 0.026034739\n",
      "completed in 0.22029900550842285 s\n",
      "game 75 completed in 5.893452167510986 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5129354 entropy 1.8646711\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4913063 entropy 1.8669871\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4592633 entropy 1.8705766\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4298017 entropy 1.8744475\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4047043 entropy 1.8774736\n",
      "kl 0.02040727\n",
      "completed in 0.1893007755279541 s\n",
      "game 76 completed in 7.474789142608643 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5136874 entropy 1.8274007\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.480059 entropy 1.827565\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.43493 entropy 1.8277694\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3904648 entropy 1.8282969\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3558795 entropy 1.8285043\n",
      "kl 0.027980141\n",
      "completed in 0.17453289031982422 s\n",
      "game 77 completed in 8.28959608078003 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5434265 entropy 1.8364258\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5248597 entropy 1.8400548\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4885528 entropy 1.8450801\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4495032 entropy 1.8510735\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4129708 entropy 1.856484\n",
      "kl 0.016228586\n",
      "completed in 0.16342520713806152 s\n",
      "game 78 completed in 7.508404970169067 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4053094 entropy 1.8025072\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3853652 entropy 1.8040692\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3514924 entropy 1.8030517\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.316539 entropy 1.799235\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2885103 entropy 1.7937526\n",
      "kl 0.020856693\n",
      "completed in 0.18187522888183594 s\n",
      "game 79 completed in 8.386008024215698 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5181534 entropy 1.8536077\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.49428 entropy 1.8529527\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4603443 entropy 1.855617\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.423973 entropy 1.8613029\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3867326 entropy 1.8682814\n",
      "kl 0.017765116\n",
      "completed in 0.1657102108001709 s\n",
      "game 80 completed in 9.350405931472778 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.45582 entropy 1.8491795\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4334302 entropy 1.8568672\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4038234 entropy 1.8642163\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3701818 entropy 1.8693604\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3353271 entropy 1.871336\n",
      "kl 0.021514602\n",
      "completed in 0.19116902351379395 s\n",
      "game 81 completed in 7.55757212638855 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.37058 entropy 1.7864546\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3466425 entropy 1.7784858\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3216014 entropy 1.7672133\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2975538 entropy 1.7554486\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2662673 entropy 1.7455883\n",
      "kl 0.02831818\n",
      "completed in 0.17428302764892578 s\n",
      "game 82 completed in 6.038857936859131 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.427922 entropy 1.816389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4035714 entropy 1.8154447\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3632069 entropy 1.8192701\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3194678 entropy 1.825628\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2824333 entropy 1.8315816\n",
      "kl 0.019250322\n",
      "completed in 0.19332623481750488 s\n",
      "game 83 completed in 7.483111143112183 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.434703 entropy 1.8275397\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.409095 entropy 1.8317286\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3760657 entropy 1.8369855\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.340423 entropy 1.842546\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.306321 entropy 1.8468962\n",
      "kl 0.030387703\n",
      "completed in 0.16643404960632324 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 84 completed in 7.30630087852478 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4676802 entropy 1.9064329\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4531932 entropy 1.9031861\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4271877 entropy 1.8958235\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3995059 entropy 1.8853943\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3711522 entropy 1.8737619\n",
      "kl 0.026838103\n",
      "completed in 0.1871809959411621 s\n",
      "game 85 completed in 9.745054960250854 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.373619 entropy 1.7838144\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3519125 entropy 1.7783403\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3211856 entropy 1.7750605\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2930133 entropy 1.7733496\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2668526 entropy 1.7727379\n",
      "kl 0.027321592\n",
      "completed in 0.21690082550048828 s\n",
      "game 86 completed in 8.410775899887085 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4537556 entropy 1.8132327\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4340756 entropy 1.8179259\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.404157 entropy 1.822444\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3779428 entropy 1.826328\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3500898 entropy 1.8281341\n",
      "kl 0.015742835\n",
      "completed in 0.16873908042907715 s\n",
      "game 87 completed in 8.994899988174438 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3866065 entropy 1.7934899\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3504598 entropy 1.7957237\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3058486 entropy 1.7998424\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.278571 entropy 1.8029974\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2536209 entropy 1.8034036\n",
      "kl 0.03126379\n",
      "completed in 0.17072105407714844 s\n",
      "game 88 completed in 6.16355562210083 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5460436 entropy 1.8674237\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.517257 entropy 1.8673757\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4764123 entropy 1.8682451\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4404361 entropy 1.8703527\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.410027 entropy 1.8734772\n",
      "kl 0.038035814\n",
      "completed in 0.17104196548461914 s\n",
      "game 89 completed in 7.585116147994995 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4400735 entropy 1.8602575\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4206822 entropy 1.8643777\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3897035 entropy 1.8657441\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3552566 entropy 1.8643911\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3236992 entropy 1.8607717\n",
      "kl 0.015755022\n",
      "completed in 0.17101812362670898 s\n",
      "game 90 completed in 7.663818120956421 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4232626 entropy 1.8541543\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4006844 entropy 1.8436654\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3721862 entropy 1.8301749\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3464193 entropy 1.8166981\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3179083 entropy 1.8043318\n",
      "kl 0.02459541\n",
      "completed in 0.17471885681152344 s\n",
      "game 91 completed in 9.37374210357666 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.493148 entropy 1.7766831\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4736137 entropy 1.7731464\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.436677 entropy 1.7743654\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3914764 entropy 1.7795491\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3549871 entropy 1.786724\n",
      "kl 0.024586976\n",
      "completed in 0.1899268627166748 s\n",
      "game 92 completed in 6.771124839782715 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.446594 entropy 1.8113122\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4218478 entropy 1.8167276\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3884146 entropy 1.8184271\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3532197 entropy 1.8157105\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3162887 entropy 1.8090682\n",
      "kl 0.026969735\n",
      "completed in 0.16935181617736816 s\n",
      "game 93 completed in 9.12501072883606 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4100623 entropy 1.8151113\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3938832 entropy 1.8090339\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3683693 entropy 1.8076351\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3396454 entropy 1.8119075\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3066375 entropy 1.8205488\n",
      "kl 0.014145538\n",
      "completed in 0.1648709774017334 s\n",
      "game 94 completed in 8.447514057159424 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5193305 entropy 1.8741438\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.49757 entropy 1.883974\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4647424 entropy 1.8913596\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4307597 entropy 1.8946234\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3967144 entropy 1.8931005\n",
      "kl 0.023450166\n",
      "completed in 0.19998788833618164 s\n",
      "game 95 completed in 8.533637285232544 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5113883 entropy 1.896256\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4818969 entropy 1.8887876\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4498522 entropy 1.8793559\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4203966 entropy 1.8695872\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.384938 entropy 1.8607674\n",
      "kl 0.020819101\n",
      "completed in 0.19234299659729004 s\n",
      "game 96 completed in 8.584281921386719 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4138145 entropy 1.8136071\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3801095 entropy 1.8137463\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3395693 entropy 1.8177059\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3054585 entropy 1.8224752\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2662086 entropy 1.824933\n",
      "kl 0.020062912\n",
      "completed in 0.16644787788391113 s\n",
      "game 97 completed in 6.371917724609375 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4646692 entropy 1.8593161\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4490454 entropy 1.8610644\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.415542 entropy 1.8626693\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3787174 entropy 1.8629681\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3469985 entropy 1.8610415\n",
      "kl 0.021475116\n",
      "completed in 0.16909408569335938 s\n",
      "game 98 completed in 11.218260288238525 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.446298 entropy 1.8619579\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4251041 entropy 1.8582742\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3898375 entropy 1.8547353\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3528683 entropy 1.8540642\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.320782 entropy 1.855833\n",
      "kl 0.020152066\n",
      "completed in 0.19348382949829102 s\n",
      "prediction:\n",
      " [0.00382293 0.00705307 0.00177464 0.00248655 0.00261282 0.00160438\n",
      " 0.00262774 0.07887314 0.04199683 0.02015943 0.01216289 0.00199947\n",
      " 0.00164411 0.03709851 0.19859412 0.02902703 0.02879607 0.00265374\n",
      " 0.00287169 0.01597436 0.05102264 0.25507486 0.03596222 0.00143585\n",
      " 0.00218448 0.01096751 0.02282282 0.03747726 0.06981298 0.00367074\n",
      " 0.00231781 0.00175387 0.00263407 0.00333208 0.00218726 0.00351022] \n",
      " -0.23598446\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.64330413e-01 9.76220275e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.06508135e-01 2.31539424e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [6.05393609e-04 2.35522195e-04 6.53351657e-04 1.17214819e-04\n",
      " 3.04529211e-04 1.30597080e-04 7.19630261e-05 3.96097824e-03\n",
      " 3.42250522e-03 1.08712189e-01 2.82484893e-04 1.83698663e-04\n",
      " 2.95125210e-04 1.67926750e-03 2.99295271e-03 1.24922656e-01\n",
      " 1.98954836e-01 1.15066243e-04 1.45292099e-04 1.76150993e-01\n",
      " 2.82395035e-01 2.40531797e-03 2.23834114e-03 5.03500225e-04\n",
      " 1.29554450e-04 2.40278794e-04 8.12503174e-02 1.97882857e-03\n",
      " 2.81436322e-03 1.09897963e-04 1.16562704e-04 2.08614336e-04\n",
      " 3.16952413e-04 7.57972768e-04 8.38410269e-05 5.14179119e-04] \n",
      " 0.26068953\n",
      "p [[0.00125156 0.00625782 0.00125156 0.00250313 0.00250313 0.00125156]\n",
      " [0.00125156 0.07133917 0.06758448 0.01001252 0.01501877 0.00125156]\n",
      " [0.00125156 0.03128911 0.         0.01501877 0.01126408 0.00125156]\n",
      " [0.00250313 0.00876095 0.0350438  0.4931164  0.02878598 0.00125156]\n",
      " [0.00250313 0.01376721 0.01251564 0.07634543 0.06758448 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00876095 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.3091594e-03 7.8615698e-04 1.5150675e-03 9.6329086e-04 1.0868274e-03\n",
      " 4.6394303e-04 3.2258418e-04 4.0630000e-03 4.2920238e-03 3.4347016e-01\n",
      " 7.4879604e-04 2.3987377e-03 1.9792267e-03 6.5521519e-03 1.2303265e-03\n",
      " 7.3035315e-02 1.1124640e-02 3.3404041e-04 3.2821146e-04 7.4090036e-03\n",
      " 1.3524200e-01 1.3062069e-03 6.2596514e-03 2.6214733e-03 1.5021322e-03\n",
      " 7.2717585e-04 3.7290838e-01 4.2217122e-03 5.0388691e-03 3.6844681e-04\n",
      " 4.2886400e-04 1.4528394e-03 1.2857537e-03 1.5728794e-03 2.9089794e-04\n",
      " 1.3601204e-03] \n",
      " -0.73469347\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.40175219e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 7.13391740e-02\n",
      "  9.26157697e-02 1.25156446e-13]\n",
      " [1.25156446e-13 5.06883605e-01 1.56445557e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.25406758e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.10194994e-04 3.13562603e-04 2.24984204e-03 1.95466215e-04\n",
      " 6.49091613e-04 4.85170312e-05 2.07206962e-04 2.70139053e-03\n",
      " 5.07603399e-03 1.26882214e-02 4.35342081e-04 1.37053698e-03\n",
      " 2.63619440e-04 6.70663314e-03 1.10590183e-04 6.40869439e-01\n",
      " 2.84836930e-03 1.66182639e-04 4.51996493e-05 2.22452800e-03\n",
      " 2.99136937e-01 1.03005623e-04 4.99051949e-03 5.67535986e-04\n",
      " 1.34931842e-03 4.19486081e-04 7.85840675e-03 1.29649683e-03\n",
      " 2.28466303e-03 5.10413724e-04 1.09293745e-04 4.77220921e-04\n",
      " 7.72685453e-05 8.13291932e-04 1.40689313e-04 4.85547353e-04] \n",
      " 0.9483044\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.34292866 0.00125156 0.00125156]\n",
      " [0.00125156 0.00250313 0.         0.07133917 0.04505632 0.00125156]\n",
      " [0.00125156 0.         0.18147685 0.         0.00375469 0.00125156]\n",
      " [0.00125156 0.00125156 0.31789737 0.00250313 0.00250313 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00825399 0.00548627 0.00934252 0.00235853 0.0080232  0.00375029\n",
      " 0.00901992 0.02294281 0.05746176 0.02369148 0.02075073 0.01034892\n",
      " 0.02064778 0.04180484 0.00076227 0.03535504 0.36363158 0.00920613\n",
      " 0.00509358 0.10205659 0.02468505 0.00095865 0.02025203 0.02451948\n",
      " 0.01287488 0.02656926 0.01893468 0.05931123 0.0161612  0.00211802\n",
      " 0.00288048 0.00972386 0.00227378 0.01110325 0.00421458 0.00343145] \n",
      " -0.9802973\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 9.63704631e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 3.37922403e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.1647697e-03 1.3629432e-03 4.6816049e-03 2.2804835e-03 5.3544366e-03\n",
      " 3.5875107e-04 9.7180897e-04 4.2021503e-03 2.3723869e-02 5.6538444e-02\n",
      " 1.1659373e-02 2.4022188e-02 3.6250219e-02 4.1745585e-01 4.8299178e-05\n",
      " 2.1041939e-02 2.8859286e-04 1.3333173e-03 3.9361962e-04 3.5949014e-04\n",
      " 7.4064708e-03 3.9635739e-05 2.6145542e-01 1.9847177e-02 1.7549792e-02\n",
      " 1.3455341e-02 4.6309464e-02 2.8499479e-03 1.7180289e-03 1.8973742e-03\n",
      " 6.5521145e-04 4.9702101e-03 1.3248554e-03 3.8132935e-03 7.4193795e-04\n",
      " 1.4738842e-03] \n",
      " 0.97140664\n",
      "p [[0.00500626 0.00250313 0.00500626 0.00125156 0.00375469 0.00250313]\n",
      " [0.00500626 0.01501877 0.06508135 0.         0.02753442 0.00625782]\n",
      " [0.01376721 0.03629537 0.         0.         0.6020025  0.00500626]\n",
      " [0.00250313 0.         0.03128911 0.         0.01251564 0.01501877]\n",
      " [0.01376721 0.01627034 0.01376721 0.06633292 0.01001252 0.00125156]\n",
      " [0.00125156 0.00500626 0.00125156 0.00876095 0.00250313 0.00250313]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.10869447e-03 3.87496990e-03 1.07573811e-02 7.75568406e-05\n",
      " 1.86077375e-02 8.28547636e-05 1.15972979e-03 5.77255385e-03\n",
      " 2.35138531e-03 1.18760858e-03 2.12188624e-03 1.04327770e-02\n",
      " 2.86838412e-01 4.04779101e-04 1.06281595e-05 2.94604135e-04\n",
      " 3.56738165e-04 4.47218452e-04 4.92570340e-04 1.13607959e-04\n",
      " 6.63836079e-04 2.32471339e-05 2.88512238e-04 5.82119584e-01\n",
      " 1.48671530e-02 2.80177291e-03 3.43708694e-03 1.69307739e-03\n",
      " 1.51958806e-03 2.90802796e-04 1.01257720e-04 2.09504366e-02\n",
      " 1.96726862e-04 2.21814774e-02 2.18579685e-03 1.86088218e-04] \n",
      " -0.93374634\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.37672090e-02 0.00000000e+00\n",
      "  7.50938673e-03 1.37672090e-02]\n",
      " [1.57697121e-01 6.78347935e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-03 0.00000000e+00\n",
      "  4.63078849e-02 6.25782228e-03]\n",
      " [1.62703379e-02 4.25531915e-02 1.62703379e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  1.  1.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.5326649e-03 6.9156983e-03 2.9027665e-03 1.4667407e-03 4.9882784e-02\n",
      " 1.0792668e-03 2.2025704e-03 2.3869839e-01 4.9824640e-03 6.9495323e-03\n",
      " 3.5193941e-01 7.7558248e-03 9.2365658e-03 1.4433911e-03 1.9282699e-05\n",
      " 5.6043793e-03 2.4878320e-03 3.1221432e-03 1.3159219e-03 5.5564637e-04\n",
      " 2.1536562e-03 2.3559509e-05 1.2047385e-03 4.0707183e-03 1.1462814e-02\n",
      " 8.2212463e-02 7.2364076e-03 8.5180870e-04 1.5796806e-01 1.8308059e-03\n",
      " 6.8291265e-04 1.0537676e-02 2.2522132e-03 7.5916499e-03 7.2245612e-03\n",
      " 1.6027380e-03] \n",
      " 0.98906904\n",
      "p [[0.00125156 0.00125156 0.00500626 0.00125156 0.01001252 0.00125156]\n",
      " [0.00125156 0.00500626 0.00125156 0.         0.00125156 0.00500626]\n",
      " [0.56821026 0.         0.         0.         0.         0.00125156]\n",
      " [0.00125156 0.         0.00125156 0.         0.00125156 0.34918648]\n",
      " [0.00876095 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.01126408 0.00125156 0.01251564 0.00125156 0.00125156]]\n",
      "move 12\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.7859836e-03 7.4930540e-03 4.0627059e-02 1.8199987e-04 2.8310302e-01\n",
      " 2.0399345e-03 2.9678736e-03 3.9305527e-02 6.7159329e-03 5.6057773e-03\n",
      " 2.9056675e-03 4.7230098e-02 6.2961608e-02 1.6203491e-03 2.5295316e-05\n",
      " 8.6830225e-04 5.6555629e-04 6.3077715e-04 1.0256032e-03 2.0737934e-04\n",
      " 1.9998844e-03 8.4694810e-05 5.6478579e-04 6.4221844e-02 8.4745273e-02\n",
      " 3.6682123e-03 1.3164993e-02 3.1184978e-03 1.7847782e-02 1.0162393e-03\n",
      " 1.6259775e-03 1.8148242e-01 4.2960802e-04 1.1202157e-01 5.7218880e-03\n",
      " 4.1956772e-04] \n",
      " -0.89463115\n",
      "p [[1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  2.00250313e-02 1.25156446e-13]\n",
      " [1.25156446e-13 2.10262829e-01 1.25156446e-13 0.00000000e+00\n",
      "  1.26408010e-01 1.25156446e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [4.75594493e-02 4.39299124e-01 6.25782228e-03 1.25156446e-13\n",
      "  5.13141427e-02 1.25156446e-13]\n",
      " [1.25156446e-13 6.88360451e-02 1.25156446e-13 1.50187735e-02\n",
      "  1.25156446e-02 1.25156446e-13]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.8420259e-03 2.1730785e-04 2.7174066e-05 2.7581602e-05 1.6489418e-01\n",
      " 1.5202961e-04 8.5403779e-05 5.9660798e-01 2.9380617e-04 8.0392300e-04\n",
      " 2.2209010e-03 4.4880316e-04 1.0093314e-03 2.9421441e-04 1.2479749e-06\n",
      " 2.0750505e-05 5.0854072e-04 2.5412950e-05 3.4210236e-05 1.4510060e-04\n",
      " 1.6472130e-05 5.2806486e-06 1.5651844e-04 1.6841180e-04 1.2085809e-03\n",
      " 9.5639535e-04 5.4045772e-04 2.5373525e-05 1.8943137e-01 1.8330464e-05\n",
      " 1.7708719e-04 3.6266055e-02 1.4396208e-04 7.7830024e-05 1.0172653e-03\n",
      " 1.3081472e-04] \n",
      " 0.9996163\n",
      "p [[0.00125156 0.00750939 0.09762203 0.00125156 0.21276596 0.00125156]\n",
      " [0.00125156 0.03003755 0.00375469 0.         0.00125156 0.07259074]\n",
      " [0.         0.         0.         0.         0.         0.00125156]\n",
      " [0.00125156 0.         0.00125156 0.         0.00125156 0.12015019]\n",
      " [0.07133917 0.         0.04881101 0.00125156 0.01251564 0.00125156]\n",
      " [0.00125156 0.21026283 0.00125156 0.09136421 0.00375469 0.00125156]]\n",
      "move 4\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.6843518e-02 2.3172304e-01 2.5685700e-02 1.1574735e-03 9.7278498e-02\n",
      " 7.2456370e-03 1.3517262e-02 6.1888248e-03 9.5442915e-03 1.6525991e-03\n",
      " 7.5131506e-02 1.2773988e-02 3.3105899e-02 1.5482247e-02 1.9332359e-05\n",
      " 5.8592074e-03 1.5009013e-04 1.0487792e-03 1.4728775e-03 1.3000892e-04\n",
      " 1.8167274e-02 9.6396121e-05 5.5060796e-03 5.1582690e-02 2.3619870e-02\n",
      " 1.5032680e-01 5.9604454e-03 7.6653059e-03 1.1107000e-03 5.6384266e-03\n",
      " 8.1861373e-03 5.4236144e-02 2.8510734e-03 5.4446187e-02 5.2407343e-02\n",
      " 2.1886097e-03] \n",
      " -0.965639\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 7.40926158e-01 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  2.14017522e-01 1.25156446e-13]\n",
      " [1.25156446e-13 4.50563204e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 99 completed in 28.090816974639893 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3964627 entropy 1.7913488\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3722715 entropy 1.7907616\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3419821 entropy 1.7875848\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3114607 entropy 1.7819448\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2814817 entropy 1.773848\n",
      "kl 0.022806473\n",
      "completed in 0.19510173797607422 s\n",
      "game 100 completed in 13.657554864883423 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4143581 entropy 1.7940749\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3987937 entropy 1.7838033\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3715792 entropy 1.7745643\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.344253 entropy 1.7680959\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3186796 entropy 1.764682\n",
      "kl 0.02239598\n",
      "completed in 0.16817092895507812 s\n",
      "game 101 completed in 7.802895784378052 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.44308 entropy 1.7103035\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4211318 entropy 1.713331\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3811128 entropy 1.7198248\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3402514 entropy 1.7289063\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3056917 entropy 1.7396795\n",
      "kl 0.02147093\n",
      "completed in 0.19045233726501465 s\n",
      "game 102 completed in 8.03034782409668 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4033623 entropy 1.8089573\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3858483 entropy 1.8199048\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3587077 entropy 1.8285829\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3264432 entropy 1.8340765\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2969894 entropy 1.8371994\n",
      "kl 0.021071289\n",
      "completed in 0.20557689666748047 s\n",
      "game 103 completed in 9.685508012771606 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4314744 entropy 1.8472335\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.405022 entropy 1.8469396\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3635895 entropy 1.8448212\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3216686 entropy 1.8409582\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2872105 entropy 1.835069\n",
      "kl 0.028763806\n",
      "completed in 0.17633724212646484 s\n",
      "game 104 completed in 6.206174373626709 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.410023 entropy 1.8284075\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3904607 entropy 1.8235157\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3582609 entropy 1.8207968\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3245366 entropy 1.8195603\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2938519 entropy 1.8191731\n",
      "kl 0.018447246\n",
      "completed in 0.17023491859436035 s\n",
      "game 105 completed in 8.10326886177063 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4529774 entropy 1.8199759\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4370327 entropy 1.8220644\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4061048 entropy 1.8256111\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.371359 entropy 1.8286626\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3366253 entropy 1.8300545\n",
      "kl 0.019735154\n",
      "completed in 0.19078516960144043 s\n",
      "game 106 completed in 7.905202865600586 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3900113 entropy 1.8121679\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3726556 entropy 1.8069161\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.354987 entropy 1.8010013\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.332998 entropy 1.7956784\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3074322 entropy 1.7919397\n",
      "kl 0.02447745\n",
      "completed in 0.183729887008667 s\n",
      "game 107 completed in 7.998337030410767 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3600705 entropy 1.7590084\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3361735 entropy 1.756799\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2991378 entropy 1.754473\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.258786 entropy 1.7525814\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2196465 entropy 1.7509377\n",
      "kl 0.017901853\n",
      "completed in 0.19801783561706543 s\n",
      "game 108 completed in 7.860976219177246 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3584986 entropy 1.7802643\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3394327 entropy 1.7814065\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3107884 entropy 1.7838233\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.282233 entropy 1.7869114\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2535906 entropy 1.7890465\n",
      "kl 0.023800157\n",
      "completed in 0.1888580322265625 s\n",
      "game 109 completed in 9.983690977096558 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3625476 entropy 1.8033481\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3460844 entropy 1.8054981\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.317064 entropy 1.8078945\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2853448 entropy 1.8106229\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2582788 entropy 1.813732\n",
      "kl 0.019333826\n",
      "completed in 0.20129179954528809 s\n",
      "game 110 completed in 9.780755281448364 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3546429 entropy 1.8190515\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.332428 entropy 1.818869\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2900107 entropy 1.8143739\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2414267 entropy 1.8050157\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2027028 entropy 1.7924814\n",
      "kl 0.033276588\n",
      "completed in 0.17467403411865234 s\n",
      "game 111 completed in 12.561527252197266 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3975983 entropy 1.7902021\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3768208 entropy 1.7811146\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3526132 entropy 1.7760158\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3218365 entropy 1.7744763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.284 entropy 1.7753973\n",
      "kl 0.016286261\n",
      "completed in 0.20968389511108398 s\n",
      "game 112 completed in 6.773532152175903 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4369764 entropy 1.7617445\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.409089 entropy 1.7663069\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.369086 entropy 1.7709837\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3303256 entropy 1.7753245\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.29306 entropy 1.7785691\n",
      "kl 0.029848754\n",
      "completed in 0.21083402633666992 s\n",
      "game 113 completed in 10.196642875671387 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3843184 entropy 1.7842618\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3666627 entropy 1.786469\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3375368 entropy 1.7892895\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.303318 entropy 1.791602\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2703135 entropy 1.7923663\n",
      "kl 0.019663496\n",
      "completed in 0.190079927444458 s\n",
      "game 114 completed in 12.625764846801758 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.594857 entropy 1.8776351\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5709486 entropy 1.8793511\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5392835 entropy 1.8828804\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5026069 entropy 1.8876624\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.462998 entropy 1.8925734\n",
      "kl 0.025179703\n",
      "completed in 0.19968295097351074 s\n",
      "game 115 completed in 11.242147207260132 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.402453 entropy 1.8165826\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3791637 entropy 1.822129\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3521576 entropy 1.8263631\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3243482 entropy 1.8284397\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2972543 entropy 1.8270137\n",
      "kl 0.016768895\n",
      "completed in 0.1901867389678955 s\n",
      "game 116 completed in 11.328585147857666 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.423857 entropy 1.8539269\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4017873 entropy 1.8473741\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3726823 entropy 1.8394587\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3395934 entropy 1.830623\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3078322 entropy 1.8218205\n",
      "kl 0.02538621\n",
      "completed in 0.17535996437072754 s\n",
      "game 117 completed in 6.356627941131592 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3832579 entropy 1.7975354\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3537693 entropy 1.7907305\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3187597 entropy 1.7842383\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2868247 entropy 1.778572\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2540941 entropy 1.7733495\n",
      "kl 0.017468749\n",
      "completed in 0.1731719970703125 s\n",
      "game 118 completed in 12.477892875671387 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3954432 entropy 1.8342216\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.358276 entropy 1.8339589\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3294501 entropy 1.8365158\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.304606 entropy 1.842241\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2654061 entropy 1.8504059\n",
      "kl 0.021787964\n",
      "completed in 0.20230507850646973 s\n",
      "game 119 completed in 6.9577977657318115 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4223182 entropy 1.7961185\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3822775 entropy 1.8050773\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.338942 entropy 1.8098835\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2847915 entropy 1.8078086\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.237429 entropy 1.7991686\n",
      "kl 0.024925262\n",
      "completed in 0.17017269134521484 s\n",
      "game 120 completed in 6.928930997848511 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.398993 entropy 1.7486521\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3633883 entropy 1.7381244\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3149872 entropy 1.7318838\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2675207 entropy 1.730918\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.224297 entropy 1.734375\n",
      "kl 0.027302783\n",
      "completed in 0.19364619255065918 s\n",
      "game 121 completed in 7.119266033172607 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3872933 entropy 1.7126395\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3739138 entropy 1.7209971\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3507667 entropy 1.7304624\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3194346 entropy 1.7397037\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.28835 entropy 1.7482624\n",
      "kl 0.026592135\n",
      "completed in 0.17487883567810059 s\n",
      "game 122 completed in 7.743879795074463 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5108573 entropy 1.8416126\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4944224 entropy 1.8516376\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4649258 entropy 1.8612103\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4349816 entropy 1.8688685\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.407165 entropy 1.8733511\n",
      "kl 0.022265548\n",
      "completed in 0.2005009651184082 s\n",
      "game 123 completed in 11.500898122787476 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.482973 entropy 1.8589367\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.461647 entropy 1.8569943\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.439122 entropy 1.8541408\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4153807 entropy 1.8512186\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3884726 entropy 1.8488007\n",
      "kl 0.024035765\n",
      "completed in 0.1765141487121582 s\n",
      "game 124 completed in 7.879962921142578 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4436 entropy 1.7979372\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4234388 entropy 1.7999605\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.391488 entropy 1.8046026\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3569155 entropy 1.809937\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3233712 entropy 1.8146629\n",
      "kl 0.0294788\n",
      "completed in 0.17197608947753906 s\n",
      "game 125 completed in 14.318176984786987 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3976853 entropy 1.8956172\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3746185 entropy 1.8968432\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3419046 entropy 1.8939581\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3090348 entropy 1.8873265\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2814214 entropy 1.877856\n",
      "kl 0.019504525\n",
      "completed in 0.16126060485839844 s\n",
      "game 126 completed in 12.28737211227417 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.420674 entropy 1.8042791\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3976183 entropy 1.7974734\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3623538 entropy 1.7934947\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3270884 entropy 1.7925007\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2949731 entropy 1.7940592\n",
      "kl 0.023797292\n",
      "completed in 0.17283129692077637 s\n",
      "game 127 completed in 6.051748037338257 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4551466 entropy 1.8347135\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4304113 entropy 1.8414502\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.392265 entropy 1.8491452\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3579009 entropy 1.8561566\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3290915 entropy 1.8591118\n",
      "kl 0.017395448\n",
      "completed in 0.19006919860839844 s\n",
      "game 128 completed in 8.873881101608276 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3613272 entropy 1.8221169\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3424234 entropy 1.8158123\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3159285 entropy 1.8049811\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2878225 entropy 1.7913738\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.260806 entropy 1.7765173\n",
      "kl 0.034196503\n",
      "completed in 0.17121624946594238 s\n",
      "game 129 completed in 14.859516143798828 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.500897 entropy 1.808794\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4783502 entropy 1.7993822\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4437885 entropy 1.7958918\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.406208 entropy 1.7983952\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.37063 entropy 1.8054125\n",
      "kl 0.021634504\n",
      "completed in 0.18203520774841309 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 130 completed in 11.96317982673645 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.494557 entropy 1.8220065\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.477638 entropy 1.8308575\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4403977 entropy 1.8371619\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4048073 entropy 1.8408475\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.373209 entropy 1.8422446\n",
      "kl 0.01853424\n",
      "completed in 0.17399191856384277 s\n",
      "game 131 completed in 8.052414894104004 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3480682 entropy 1.7876436\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.33195 entropy 1.7850621\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3023355 entropy 1.7794824\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2700772 entropy 1.7719158\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.23807 entropy 1.7638476\n",
      "kl 0.03086476\n",
      "completed in 0.16809916496276855 s\n",
      "game 132 completed in 7.1469480991363525 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3972435 entropy 1.7739911\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.384791 entropy 1.7730069\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3593664 entropy 1.7761462\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3281732 entropy 1.7824502\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2964437 entropy 1.7903676\n",
      "kl 0.020907352\n",
      "completed in 0.18471193313598633 s\n",
      "game 133 completed in 11.272855043411255 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4889338 entropy 1.8146896\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.470048 entropy 1.8256316\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4373643 entropy 1.8354053\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4021533 entropy 1.8421955\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3719814 entropy 1.8451501\n",
      "kl 0.027891472\n",
      "completed in 0.18119382858276367 s\n",
      "game 134 completed in 5.981120824813843 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3715696 entropy 1.880044\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3550365 entropy 1.8739446\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3295667 entropy 1.8646162\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3002894 entropy 1.854521\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2715816 entropy 1.8453411\n",
      "kl 0.021455005\n",
      "completed in 0.1899890899658203 s\n",
      "game 135 completed in 10.906798839569092 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4179573 entropy 1.8381894\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4042819 entropy 1.8354633\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.380922 entropy 1.8366491\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.352247 entropy 1.8406675\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3224792 entropy 1.8459191\n",
      "kl 0.016599368\n",
      "completed in 0.1712510585784912 s\n",
      "game 136 completed in 6.4114508628845215 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3760445 entropy 1.830683\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3507342 entropy 1.8332999\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3180902 entropy 1.8351207\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2888489 entropy 1.8347833\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2642012 entropy 1.831429\n",
      "kl 0.026425824\n",
      "completed in 0.22182917594909668 s\n",
      "game 137 completed in 7.82849907875061 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3682652 entropy 1.775453\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3547158 entropy 1.768503\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3325841 entropy 1.7632517\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3048098 entropy 1.7600832\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2741632 entropy 1.758368\n",
      "kl 0.013478015\n",
      "completed in 0.19407415390014648 s\n",
      "game 138 completed in 6.335157155990601 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4105353 entropy 1.798942\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.394733 entropy 1.7973197\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3670123 entropy 1.7977171\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3327568 entropy 1.7999306\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.303175 entropy 1.802885\n",
      "kl 0.018595085\n",
      "completed in 0.1814260482788086 s\n",
      "game 139 completed in 14.807646989822388 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5427132 entropy 1.8109143\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5199058 entropy 1.8160057\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4882522 entropy 1.8226402\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4553077 entropy 1.8298956\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4239254 entropy 1.8364633\n",
      "kl 0.019036174\n",
      "completed in 0.18795013427734375 s\n",
      "game 140 completed in 8.451300859451294 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4900265 entropy 1.848769\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.461345 entropy 1.8501524\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.419954 entropy 1.8495746\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3913696 entropy 1.8487167\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3659463 entropy 1.8483689\n",
      "kl 0.016989157\n",
      "completed in 0.18761706352233887 s\n",
      "game 141 completed in 9.598697900772095 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4638 entropy 1.7964907\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4473932 entropy 1.7978554\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4172523 entropy 1.8001962\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3826673 entropy 1.8028333\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3502855 entropy 1.8050542\n",
      "kl 0.020902533\n",
      "completed in 0.20496106147766113 s\n",
      "game 142 completed in 15.651941061019897 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5081177 entropy 1.852481\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4893627 entropy 1.8551872\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4575741 entropy 1.858088\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4181564 entropy 1.860138\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3763978 entropy 1.8600528\n",
      "kl 0.021912951\n",
      "completed in 0.18386197090148926 s\n",
      "game 143 completed in 8.307775974273682 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4845657 entropy 1.8476996\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4559436 entropy 1.8407463\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.418217 entropy 1.8318272\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3812609 entropy 1.8221802\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3485386 entropy 1.8138514\n",
      "kl 0.018151626\n",
      "completed in 0.17427682876586914 s\n",
      "game 144 completed in 7.006198883056641 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3756242 entropy 1.8112344\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3568392 entropy 1.8094404\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.326106 entropy 1.8098284\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2922938 entropy 1.8119084\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2565594 entropy 1.8142979\n",
      "kl 0.025014628\n",
      "completed in 0.17580580711364746 s\n",
      "game 145 completed in 9.944762945175171 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3490756 entropy 1.8041235\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.329352 entropy 1.8078902\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3022556 entropy 1.810458\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2749567 entropy 1.8110354\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.24781 entropy 1.8092377\n",
      "kl 0.02503\n",
      "completed in 0.1648859977722168 s\n",
      "game 146 completed in 8.76974892616272 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4805007 entropy 1.8709812\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.462228 entropy 1.8680973\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.431637 entropy 1.8647888\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3980415 entropy 1.8618889\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3618693 entropy 1.8593739\n",
      "kl 0.016286256\n",
      "completed in 0.15909504890441895 s\n",
      "game 147 completed in 7.751060962677002 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4769292 entropy 1.8231794\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4541078 entropy 1.8201805\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4154549 entropy 1.8158128\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3708673 entropy 1.8096827\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.333584 entropy 1.802745\n",
      "kl 0.032639734\n",
      "completed in 0.19260406494140625 s\n",
      "game 148 completed in 7.546372175216675 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4320388 entropy 1.8394367\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4177825 entropy 1.8350143\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3906875 entropy 1.8337084\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3555448 entropy 1.8354108\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3191583 entropy 1.8388784\n",
      "kl 0.018322298\n",
      "completed in 0.19430780410766602 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00225201 0.00219815 0.00397009 0.00092688 0.00394964 0.00114556\n",
      " 0.00330884 0.01176278 0.01651121 0.05319103 0.06221755 0.00293976\n",
      " 0.00225347 0.00975964 0.04862063 0.17747629 0.04175314 0.00099253\n",
      " 0.00114049 0.0673921  0.23755817 0.03584236 0.01346747 0.00273358\n",
      " 0.00332655 0.08027796 0.05374271 0.02031523 0.02149028 0.00176992\n",
      " 0.00114889 0.00606646 0.00099216 0.00294233 0.00294561 0.00161873] \n",
      " -0.48473027\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.07759700e-01 1.21401752e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.81727159e-01 2.89111389e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [4.85102755e-05 5.15847787e-05 5.66597664e-05 8.20047513e-04\n",
      " 7.11843459e-05 7.25116697e-05 1.06217209e-04 2.53434526e-04\n",
      " 1.18673453e-02 4.78790933e-03 6.62325067e-04 6.06369795e-05\n",
      " 1.08768436e-04 1.23732416e-02 3.00535887e-01 1.51953802e-01\n",
      " 2.67398404e-03 7.09004671e-05 1.01463615e-04 3.12902732e-03\n",
      " 2.14088365e-01 2.48351634e-01 1.18495561e-02 9.82303609e-05\n",
      " 5.24096140e-05 1.28613692e-03 5.33592468e-03 2.73880996e-02\n",
      " 4.98455716e-04 6.46380940e-05 6.52521921e-05 9.19831436e-05\n",
      " 8.95098201e-04 3.02448061e-05 8.78192368e-05 1.08695585e-05] \n",
      " 0.64174855\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00500626 0.00125156]\n",
      " [0.00125156 0.01376721 0.00750939 0.03379224 0.06758448 0.00125156]\n",
      " [0.00125156 0.01001252 0.02878598 0.21777222 0.03754693 0.00125156]\n",
      " [0.00125156 0.06758448 0.         0.02252816 0.00750939 0.00125156]\n",
      " [0.00125156 0.38297872 0.05256571 0.01001252 0.01126408 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00210203 0.00211463 0.0060176  0.01109424 0.00382385 0.003641\n",
      " 0.00137193 0.01175167 0.1302287  0.18569385 0.00219632 0.00194356\n",
      " 0.00136835 0.01475072 0.00598541 0.0039799  0.01951756 0.00251827\n",
      " 0.00200065 0.0273456  0.00324714 0.00676262 0.01185996 0.00192746\n",
      " 0.00192792 0.00424422 0.32638174 0.16152732 0.01269662 0.00124453\n",
      " 0.00480326 0.00484946 0.01111298 0.0043751  0.00243024 0.0011637 ] \n",
      " -0.65407676\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 2.75344180e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.62953692e-02 4.69336671e-01 1.90237797e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 2.19023780e-01\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 2.50312891e-02 2.37797247e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [8.6859625e-05 2.9680643e-05 5.0769416e-03 7.3593110e-05 5.2768708e-05\n",
      " 7.7639277e-05 4.3960084e-05 1.0271169e-03 3.9789519e-01 7.2125037e-04\n",
      " 7.5968317e-05 1.6410298e-04 2.1604798e-04 2.6741766e-03 1.1059493e-03\n",
      " 9.5757266e-04 6.4369952e-03 6.0461494e-05 7.4147531e-05 7.6316255e-03\n",
      " 1.2906210e-03 3.1916380e-03 4.3325238e-03 2.5404408e-04 1.2557363e-04\n",
      " 3.4710847e-05 3.5541074e-04 5.6144732e-01 1.2528009e-03 5.4783402e-05\n",
      " 2.8286862e-05 5.5000073e-05 1.5512278e-04 2.8847882e-03 3.1800711e-05\n",
      " 2.3577826e-05] \n",
      " -0.09609665\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00250313 0.00125156 0.00125156]\n",
      " [0.00125156 0.00375469 0.31789737 0.05757196 0.00125156 0.00125156]\n",
      " [0.00125156 0.04630788 0.         0.00125156 0.00500626 0.00125156]\n",
      " [0.00125156 0.08385482 0.         0.00250313 0.00375469 0.00125156]\n",
      " [0.00125156 0.         0.38548185 0.05506884 0.00500626 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.00250313 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0019154  0.01153149 0.04412099 0.01443311 0.00721161 0.00730165\n",
      " 0.00692602 0.02660848 0.02216229 0.01047895 0.00310262 0.0538509\n",
      " 0.00261002 0.12768927 0.05107987 0.00231854 0.081482   0.00317888\n",
      " 0.00290335 0.20772457 0.00362635 0.07362118 0.04236932 0.00408076\n",
      " 0.02743078 0.00251686 0.00707692 0.04587809 0.02355506 0.00530583\n",
      " 0.00900022 0.00800635 0.01086727 0.03675351 0.00999677 0.00128497] \n",
      " 0.19245805\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.28911139e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 8.66082603e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.3358738e-04 1.3519583e-03 3.6728699e-03 9.2216558e-04 5.0891086e-04\n",
      " 1.4870102e-04 1.6007117e-04 4.6498682e-03 8.5867211e-02 5.6948727e-03\n",
      " 4.9660361e-04 3.9446325e-04 5.5027858e-04 8.8959225e-03 2.2241471e-03\n",
      " 3.0288741e-03 2.3768070e-01 2.6823871e-03 2.3871756e-03 5.2119875e-01\n",
      " 3.1080511e-03 1.5453548e-02 7.6657226e-03 9.0096949e-04 5.2540202e-04\n",
      " 2.4785404e-04 1.8386912e-03 7.6924719e-02 3.0368192e-03 2.2934692e-04\n",
      " 9.1312853e-05 5.0084369e-04 1.4416061e-03 3.8376749e-03 1.2666659e-03\n",
      " 8.1375198e-05] \n",
      " 0.9302073\n",
      "p [[0.00125156 0.00750939 0.02002503 0.00500626 0.00125156 0.00125156]\n",
      " [0.00125156 0.01376721 0.01501877 0.00375469 0.00125156 0.02628285]\n",
      " [0.00125156 0.36921151 0.         0.00125156 0.06758448 0.00125156]\n",
      " [0.00125156 0.19148936 0.         0.08385482 0.01501877 0.00125156]\n",
      " [0.01627034 0.         0.         0.         0.00876095 0.00125156]\n",
      " [0.00375469 0.00250313 0.00500626 0.12390488 0.00625782 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00098613 0.02084069 0.01443943 0.00982791 0.02174643 0.00963284\n",
      " 0.00915322 0.06341044 0.0198718  0.060526   0.00442181 0.08521991\n",
      " 0.00434112 0.01908454 0.05171816 0.0160365  0.02100484 0.01149532\n",
      " 0.01476806 0.0476794  0.0094869  0.13071375 0.00868434 0.00846926\n",
      " 0.08146481 0.00439451 0.04810026 0.0486102  0.06856709 0.00611071\n",
      " 0.00951849 0.03216575 0.0078887  0.00925165 0.01929378 0.00107562] \n",
      " -0.9060695\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.13016270e-02 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  3.87984981e-02 1.25156446e-13]\n",
      " [1.25156446e-13 9.13642053e-01 0.00000000e+00 2.50312891e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.6636937e-05 2.0561456e-03 1.1466498e-04 5.7534993e-02 1.0640823e-02\n",
      " 3.5723811e-04 2.1017675e-04 3.0738737e-03 1.7951816e-05 2.2495838e-02\n",
      " 1.5412256e-04 7.3395640e-02 1.3572613e-03 3.1161699e-03 3.0381224e-01\n",
      " 8.9475297e-04 6.6141580e-04 9.0792635e-03 1.1059615e-02 1.1561232e-03\n",
      " 5.9399626e-04 3.2079390e-01 1.1005199e-03 7.4152381e-04 8.8157728e-02\n",
      " 2.3066170e-04 1.3734430e-02 6.3550950e-05 3.7957199e-03 2.4990545e-04\n",
      " 2.0899708e-04 5.2831378e-02 1.5460086e-02 2.0654190e-04 5.9760036e-04\n",
      " 1.8715116e-05] \n",
      " 0.7877816\n",
      "p [[0.00125156 0.01126408 0.01877347 0.00375469 0.05131414 0.05006258]\n",
      " [0.00250313 0.04630788 0.1864831  0.02878598 0.00125156 0.12390488]\n",
      " [0.01251564 0.         0.         0.00500626 0.06508135 0.02628285]\n",
      " [0.0212766  0.         0.         0.13516896 0.00375469 0.00750939]\n",
      " [0.10387985 0.         0.         0.         0.05006258 0.00125156]\n",
      " [0.00500626 0.0175219  0.00250313 0.00500626 0.01126408 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [5.6114653e-04 1.7468465e-02 3.1897651e-03 1.9611773e-01 6.3007465e-03\n",
      " 2.3748716e-03 2.1942429e-02 6.1531674e-02 1.0568834e-04 1.1714761e-02\n",
      " 3.8032822e-04 7.3451690e-02 1.0159510e-03 7.5545027e-03 8.9371468e-05\n",
      " 1.8714038e-03 3.7102913e-03 7.7175833e-02 1.8380928e-01 6.9992137e-03\n",
      " 1.2380885e-03 9.4247654e-05 4.1267313e-03 9.2039391e-04 9.4361410e-02\n",
      " 4.2786988e-04 4.5815962e-03 1.0752780e-03 2.6859440e-02 7.7689430e-03\n",
      " 1.5956265e-03 3.2567445e-02 1.2384035e-01 5.6639807e-03 1.6949451e-02\n",
      " 5.6407932e-04] \n",
      " 0.9036896\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 2.75344180e-02\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.62703379e-02\n",
      "  1.25156446e-13 1.00125156e-02]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [8.26032541e-02 0.00000000e+00 0.00000000e+00 7.53441802e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [9.88735920e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 7.50938673e-03 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.04163475e-04 2.58101791e-04 4.26533958e-03 3.10420573e-01\n",
      " 1.86986336e-03 1.14860956e-03 1.42584802e-04 3.77949793e-03\n",
      " 9.41063263e-06 1.19113028e-01 1.46857556e-05 3.47788855e-02\n",
      " 1.40470928e-02 1.00070618e-01 1.55301950e-05 6.85992301e-04\n",
      " 3.03749839e-04 5.17083798e-04 5.87441726e-04 1.89113989e-03\n",
      " 9.38907382e-04 2.17513749e-04 4.27584574e-02 3.97069426e-03\n",
      " 3.58501337e-02 1.56566584e-05 4.57209609e-02 3.80176971e-05\n",
      " 2.11646780e-03 1.18015239e-04 2.31782105e-04 6.84434781e-03\n",
      " 2.49690190e-01 1.72516927e-02 1.17140175e-04 9.66413354e-05] \n",
      " 0.67371404\n",
      "p [[0.01877347 0.01627034 0.00125156 0.17146433 0.01001252 0.01376721]\n",
      " [0.02002503 0.05506884 0.         0.0212766  0.00125156 0.08635795]\n",
      " [0.00125156 0.         0.         0.00125156 0.00125156 0.04005006]\n",
      " [0.23028786 0.         0.         0.         0.02503129 0.00125156]\n",
      " [0.09261577 0.         0.         0.         0.02252816 0.00625782]\n",
      " [0.01501877 0.03003755 0.09011264 0.00750939 0.01877347 0.00125156]]\n",
      "move 18\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [-1.  1.  1.  1.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.4842746e-05 5.8312289e-04 8.7438832e-04 4.9192625e-01 1.5831700e-03\n",
      " 1.9320499e-04 2.2619837e-03 3.2359839e-03 8.4074185e-05 7.6714047e-04\n",
      " 4.0611849e-06 5.4180607e-02 1.2492575e-03 7.0626411e-05 8.2873612e-06\n",
      " 2.6300333e-05 6.7620669e-05 2.0088340e-04 5.9104268e-04 3.4109148e-04\n",
      " 2.7809436e-05 3.8161365e-05 2.0207979e-05 8.4827177e-04 1.9187875e-02\n",
      " 3.7523230e-06 7.8239373e-04 1.3090327e-03 1.1409803e-03 7.5359736e-04\n",
      " 9.2918774e-05 5.2757915e-03 4.1032517e-01 7.5396756e-04 1.1246739e-03\n",
      " 3.1504227e-05] \n",
      " 0.8231732\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 2.22778473e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.37672090e-02\n",
      "  1.25156446e-13 3.75469337e-03]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.27158949e-01 1.25156446e-13]\n",
      " [3.75469337e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.37797247e-02 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [-1.  1.  1.  1.  1.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 149 completed in 28.608281135559082 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3757932 entropy 1.7531765\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3496861 entropy 1.7558817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3260827 entropy 1.7597862\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.302518 entropy 1.7645442\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2779663 entropy 1.7690947\n",
      "kl 0.028517263\n",
      "completed in 0.19544005393981934 s\n",
      "game 150 completed in 6.3172829151153564 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4276 entropy 1.7861485\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.406213 entropy 1.7873409\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3729005 entropy 1.7874042\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3325796 entropy 1.7863097\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2926233 entropy 1.7840896\n",
      "kl 0.018877767\n",
      "completed in 0.18453025817871094 s\n",
      "game 151 completed in 13.777968168258667 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5308602 entropy 1.8568003\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5089223 entropy 1.8519385\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4792345 entropy 1.8458669\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.446726 entropy 1.8395156\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4126716 entropy 1.834099\n",
      "kl 0.021937829\n",
      "completed in 0.1860179901123047 s\n",
      "game 152 completed in 11.7269287109375 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3036692 entropy 1.7372277\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2821476 entropy 1.7396907\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2525542 entropy 1.7441807\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2212636 entropy 1.7495095\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1890216 entropy 1.7544463\n",
      "kl 0.021338789\n",
      "completed in 0.1715400218963623 s\n",
      "game 153 completed in 12.480951070785522 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5214782 entropy 1.8609363\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4995449 entropy 1.8643217\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4660976 entropy 1.8666897\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4311752 entropy 1.8672674\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.39896 entropy 1.8652953\n",
      "kl 0.023276007\n",
      "completed in 0.20112180709838867 s\n",
      "game 154 completed in 8.985509157180786 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4115076 entropy 1.7996079\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3902788 entropy 1.795366\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3570628 entropy 1.7910043\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.321882 entropy 1.7878324\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2843592 entropy 1.785347\n",
      "kl 0.021796275\n",
      "completed in 0.20622801780700684 s\n",
      "game 155 completed in 11.316837072372437 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4791641 entropy 1.830376\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4610655 entropy 1.8357589\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.427467 entropy 1.8435384\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.392053 entropy 1.8519361\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3597796 entropy 1.8589718\n",
      "kl 0.026149524\n",
      "completed in 0.1872110366821289 s\n",
      "game 156 completed in 7.8134331703186035 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.345343 entropy 1.8114238\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3293355 entropy 1.8155196\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3049965 entropy 1.8187573\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2752209 entropy 1.8195913\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.241774 entropy 1.8171575\n",
      "kl 0.020293424\n",
      "completed in 0.19072890281677246 s\n",
      "game 157 completed in 10.34353494644165 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3975022 entropy 1.8651348\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3700182 entropy 1.8588054\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3306868 entropy 1.8518798\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.293052 entropy 1.8444071\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2583778 entropy 1.8360956\n",
      "kl 0.019566204\n",
      "completed in 0.19001483917236328 s\n",
      "game 158 completed in 15.379744052886963 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5367467 entropy 1.8745408\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.513064 entropy 1.8714993\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.471338 entropy 1.8709481\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4295657 entropy 1.8719634\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3948903 entropy 1.8734303\n",
      "kl 0.026222747\n",
      "completed in 0.1839590072631836 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 159 completed in 6.028649806976318 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4238465 entropy 1.8410615\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.394649 entropy 1.8458631\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3603857 entropy 1.853152\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3330314 entropy 1.8591052\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3040316 entropy 1.8606198\n",
      "kl 0.022747375\n",
      "completed in 0.16821789741516113 s\n",
      "game 160 completed in 10.583611965179443 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4579694 entropy 1.8379025\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.435862 entropy 1.8322494\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.40575 entropy 1.8244584\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.376171 entropy 1.8166323\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3449903 entropy 1.810481\n",
      "kl 0.02781308\n",
      "completed in 0.17084884643554688 s\n",
      "game 161 completed in 7.460801839828491 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3910947 entropy 1.8396697\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3644683 entropy 1.8386345\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3274925 entropy 1.8390336\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2893286 entropy 1.8409669\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.252073 entropy 1.8433174\n",
      "kl 0.022366475\n",
      "completed in 0.2325608730316162 s\n",
      "game 162 completed in 8.223996877670288 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.503113 entropy 1.8245714\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4857233 entropy 1.8308706\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4477181 entropy 1.8373886\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4008608 entropy 1.843905\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.359206 entropy 1.8479475\n",
      "kl 0.018739987\n",
      "completed in 0.16682100296020508 s\n",
      "game 163 completed in 6.0176756381988525 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4183002 entropy 1.8975987\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4008825 entropy 1.8930078\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3714848 entropy 1.883897\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3384223 entropy 1.8730524\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3061604 entropy 1.8625555\n",
      "kl 0.03146845\n",
      "completed in 0.18462204933166504 s\n",
      "game 164 completed in 5.848336219787598 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.418554 entropy 1.8388938\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3985634 entropy 1.8338534\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3687756 entropy 1.8313965\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3341012 entropy 1.8316395\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3030066 entropy 1.8332231\n",
      "kl 0.015077901\n",
      "completed in 0.1754469871520996 s\n",
      "game 165 completed in 9.382866144180298 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4190555 entropy 1.8099039\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4018247 entropy 1.811044\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.380363 entropy 1.8104444\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3498878 entropy 1.8086941\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3181775 entropy 1.8053577\n",
      "kl 0.015435617\n",
      "completed in 0.16979217529296875 s\n",
      "game 166 completed in 6.011995077133179 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4189465 entropy 1.8296952\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4032362 entropy 1.8279649\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3774452 entropy 1.8274876\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3471615 entropy 1.8271371\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3178055 entropy 1.8255485\n",
      "kl 0.017778296\n",
      "completed in 0.17764019966125488 s\n",
      "game 167 completed in 6.1634202003479 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.379392 entropy 1.8059429\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3604794 entropy 1.8043382\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3305907 entropy 1.8020189\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2995994 entropy 1.7992237\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2737598 entropy 1.7962662\n",
      "kl 0.020119373\n",
      "completed in 0.16679906845092773 s\n",
      "game 168 completed in 6.75871205329895 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4170702 entropy 1.7759244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3954983 entropy 1.7809787\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.362771 entropy 1.7905991\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.334651 entropy 1.8025842\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.307286 entropy 1.8138235\n",
      "kl 0.02125651\n",
      "completed in 0.2023630142211914 s\n",
      "game 169 completed in 7.490945100784302 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4995801 entropy 1.8387514\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4744275 entropy 1.8447111\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.44026 entropy 1.848181\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4069138 entropy 1.8494399\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3763912 entropy 1.8488104\n",
      "kl 0.030572891\n",
      "completed in 0.1415410041809082 s\n",
      "game 170 completed in 9.496198177337646 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4853432 entropy 1.8855473\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4713974 entropy 1.8832724\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4444232 entropy 1.8814785\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4120197 entropy 1.879592\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3801322 entropy 1.8767797\n",
      "kl 0.020713238\n",
      "completed in 0.22159385681152344 s\n",
      "game 171 completed in 5.99078106880188 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.393453 entropy 1.8422434\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.376019 entropy 1.838114\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3519323 entropy 1.832416\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3313355 entropy 1.8269873\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3104534 entropy 1.8233039\n",
      "kl 0.022434818\n",
      "completed in 0.1822359561920166 s\n",
      "game 172 completed in 8.817846059799194 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4508162 entropy 1.8338544\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4263892 entropy 1.8376119\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3918004 entropy 1.8434037\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3542697 entropy 1.8485395\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3166595 entropy 1.8522096\n",
      "kl 0.026361529\n",
      "completed in 0.1965951919555664 s\n",
      "game 173 completed in 9.840046167373657 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.474379 entropy 1.8932707\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4592426 entropy 1.8914669\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4364462 entropy 1.883882\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4052944 entropy 1.872405\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3710492 entropy 1.8595372\n",
      "kl 0.023233153\n",
      "completed in 0.17364501953125 s\n",
      "game 174 completed in 7.827783823013306 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4629674 entropy 1.8232762\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4479086 entropy 1.8185434\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4223323 entropy 1.8173351\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3900216 entropy 1.819548\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.361373 entropy 1.8242594\n",
      "kl 0.017238181\n",
      "completed in 0.16828298568725586 s\n",
      "game 175 completed in 8.139425992965698 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4403572 entropy 1.8825662\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4207377 entropy 1.8919046\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3897727 entropy 1.9003675\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3561494 entropy 1.9064817\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3278813 entropy 1.9087274\n",
      "kl 0.017118182\n",
      "completed in 0.19417023658752441 s\n",
      "game 176 completed in 6.169593811035156 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3648357 entropy 1.8341174\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3494356 entropy 1.8299867\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3258963 entropy 1.8244853\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3030498 entropy 1.8191395\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.282309 entropy 1.8146312\n",
      "kl 0.019742157\n",
      "completed in 0.17272496223449707 s\n",
      "game 177 completed in 11.96500825881958 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3781662 entropy 1.7890763\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.357314 entropy 1.7883174\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3249302 entropy 1.7912105\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.292048 entropy 1.7962625\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.262675 entropy 1.8014693\n",
      "kl 0.020763436\n",
      "completed in 0.1594550609588623 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 178 completed in 11.157883882522583 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3249667 entropy 1.7491217\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3113067 entropy 1.7506353\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2881184 entropy 1.7505176\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.260755 entropy 1.7489828\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2311304 entropy 1.7460926\n",
      "kl 0.01999052\n",
      "completed in 0.174422025680542 s\n",
      "game 179 completed in 7.950459241867065 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4944396 entropy 1.8733046\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4755404 entropy 1.8747826\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4472992 entropy 1.8802053\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.415631 entropy 1.8878292\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3821576 entropy 1.8953266\n",
      "kl 0.026662517\n",
      "completed in 0.17126202583312988 s\n",
      "game 180 completed in 13.141814947128296 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3224132 entropy 1.8232217\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3037293 entropy 1.8266728\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2737608 entropy 1.8272932\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2423701 entropy 1.8241022\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2112117 entropy 1.8167467\n",
      "kl 0.022538563\n",
      "completed in 0.17803597450256348 s\n",
      "game 181 completed in 7.898996114730835 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.470368 entropy 1.8011755\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4542844 entropy 1.7916585\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4268668 entropy 1.783686\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3943646 entropy 1.7776608\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3615618 entropy 1.7738297\n",
      "kl 0.02633726\n",
      "completed in 0.17213010787963867 s\n",
      "game 182 completed in 8.729659795761108 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4553094 entropy 1.842216\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4368298 entropy 1.843473\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4096684 entropy 1.8478528\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3800554 entropy 1.853688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3495445 entropy 1.8593357\n",
      "kl 0.020535849\n",
      "completed in 0.18402385711669922 s\n",
      "game 183 completed in 5.993702173233032 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4230943 entropy 1.8294044\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4062128 entropy 1.8324172\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3807478 entropy 1.8340902\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3494048 entropy 1.834826\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3137255 entropy 1.8351319\n",
      "kl 0.018566936\n",
      "completed in 0.17726683616638184 s\n",
      "game 184 completed in 7.055126905441284 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4231036 entropy 1.8125422\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4062073 entropy 1.8145186\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.384019 entropy 1.8175048\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3609052 entropy 1.821953\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3365965 entropy 1.8267258\n",
      "kl 0.01607371\n",
      "completed in 0.19839000701904297 s\n",
      "game 185 completed in 13.190940141677856 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4500391 entropy 1.8530211\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4273791 entropy 1.8568549\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3918848 entropy 1.8602247\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3590324 entropy 1.8621302\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3323534 entropy 1.8618298\n",
      "kl 0.020542152\n",
      "completed in 0.2478489875793457 s\n",
      "game 186 completed in 9.501699686050415 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3942413 entropy 1.9093539\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3820925 entropy 1.9058867\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3599336 entropy 1.9006467\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.332318 entropy 1.8944011\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.303183 entropy 1.8876505\n",
      "kl 0.01635167\n",
      "completed in 0.18267607688903809 s\n",
      "game 187 completed in 13.041279792785645 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3563929 entropy 1.7898617\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3404655 entropy 1.7870947\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.310375 entropy 1.7870629\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2758107 entropy 1.7893875\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2441237 entropy 1.7924923\n",
      "kl 0.016604602\n",
      "completed in 0.19115209579467773 s\n",
      "game 188 completed in 11.980501174926758 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4494648 entropy 1.873173\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4313655 entropy 1.8715048\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4018526 entropy 1.8684387\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.370234 entropy 1.8643727\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3412821 entropy 1.8596579\n",
      "kl 0.019333236\n",
      "completed in 0.19615697860717773 s\n",
      "game 189 completed in 8.06824803352356 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3462868 entropy 1.7983366\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3293345 entropy 1.7933269\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3008022 entropy 1.7897187\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2677171 entropy 1.7884493\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.233673 entropy 1.7896616\n",
      "kl 0.019041676\n",
      "completed in 0.18107390403747559 s\n",
      "game 190 completed in 7.743067979812622 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.409397 entropy 1.7520823\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3834605 entropy 1.7580637\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3511722 entropy 1.7684131\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3199875 entropy 1.7812711\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2889807 entropy 1.7943227\n",
      "kl 0.025077887\n",
      "completed in 0.1707289218902588 s\n",
      "game 191 completed in 10.793596982955933 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4595528 entropy 1.8616666\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.443128 entropy 1.8665558\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4207504 entropy 1.8671513\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3943946 entropy 1.8649635\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3646684 entropy 1.861104\n",
      "kl 0.027000517\n",
      "completed in 0.1777479648590088 s\n",
      "game 192 completed in 11.114575147628784 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.44494 entropy 1.8441511\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.426231 entropy 1.841898\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3954124 entropy 1.8418882\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.360787 entropy 1.8438404\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3298244 entropy 1.8466909\n",
      "kl 0.020666346\n",
      "completed in 0.17218565940856934 s\n",
      "game 193 completed in 6.165933132171631 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.512636 entropy 1.8660278\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4980795 entropy 1.8704634\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4677727 entropy 1.8754424\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4291608 entropy 1.8806553\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3967264 entropy 1.8846943\n",
      "kl 0.016571939\n",
      "completed in 0.18195486068725586 s\n",
      "game 194 completed in 7.303930282592773 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4027734 entropy 1.8681567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3783112 entropy 1.8701112\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.347977 entropy 1.8711982\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3215628 entropy 1.8719193\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2945433 entropy 1.8716757\n",
      "kl 0.019109175\n",
      "completed in 0.19708681106567383 s\n",
      "game 195 completed in 7.243328809738159 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5007977 entropy 1.9321878\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4825695 entropy 1.9282951\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4545798 entropy 1.9239235\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4284062 entropy 1.9194891\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4037015 entropy 1.9145904\n",
      "kl 0.015509088\n",
      "completed in 0.18663620948791504 s\n",
      "game 196 completed in 9.207606077194214 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3550975 entropy 1.8242728\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.339805 entropy 1.8204116\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3145177 entropy 1.8177371\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2872455 entropy 1.8163686\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2605877 entropy 1.815221\n",
      "kl 0.01370056\n",
      "completed in 0.19620513916015625 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 197 completed in 6.397680997848511 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4297738 entropy 1.8603494\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4137821 entropy 1.8583832\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3858309 entropy 1.8555524\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3545365 entropy 1.8518113\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3276331 entropy 1.8468103\n",
      "kl 0.021870334\n",
      "completed in 0.17877888679504395 s\n",
      "game 198 completed in 9.597002029418945 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.351526 entropy 1.8086237\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3359911 entropy 1.8030168\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.307506 entropy 1.7966859\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2739398 entropy 1.7898688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2437935 entropy 1.78334\n",
      "kl 0.018565785\n",
      "completed in 0.17824912071228027 s\n",
      "prediction:\n",
      " [0.00229538 0.00293549 0.0044562  0.00117466 0.0038619  0.0020784\n",
      " 0.00297123 0.00901171 0.01366605 0.05986475 0.11871115 0.00372968\n",
      " 0.00187706 0.01564919 0.04085959 0.121072   0.05525085 0.00170075\n",
      " 0.00145761 0.06879058 0.1860086  0.02165472 0.01595998 0.00346002\n",
      " 0.0025932  0.12914282 0.05646302 0.01830313 0.01400949 0.00296548\n",
      " 0.00225133 0.00451433 0.00109989 0.00332923 0.00355625 0.0032744 ] \n",
      " -0.5618753\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.14017522e-01 1.20150188e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.18147685e-01 1.47684606e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [4.94415399e-05 1.19019365e-04 1.04216735e-04 1.17550662e-03\n",
      " 1.42909892e-04 1.00693411e-04 1.62963726e-04 1.74579793e-04\n",
      " 7.36043453e-02 1.00646084e-02 2.46254983e-03 5.50961959e-05\n",
      " 9.44804633e-05 7.45939761e-02 2.95934796e-01 1.05427325e-01\n",
      " 5.00030257e-03 2.54318235e-04 1.80084287e-04 4.56573861e-03\n",
      " 1.30830571e-01 1.64214939e-01 4.52507213e-02 2.57076928e-04\n",
      " 4.63350698e-05 2.86437571e-03 4.83459095e-03 7.52712116e-02\n",
      " 5.43843780e-04 2.99063162e-04 1.66997503e-04 1.02984603e-04\n",
      " 7.77552428e-04 5.46999254e-05 1.77916998e-04 4.02902151e-05] \n",
      " 0.45882863\n",
      "p [[0.00250313 0.00250313 0.00750939 0.00250313 0.00375469 0.00500626]\n",
      " [0.00250313 0.00876095 0.01877347 0.0563204  0.13266583 0.00250313]\n",
      " [0.0175219  0.00876095 0.01877347 0.11138924 0.02753442 0.00250313]\n",
      " [0.00250313 0.04130163 0.         0.01126408 0.00876095 0.01376721]\n",
      " [0.00125156 0.3979975  0.04005006 0.00876095 0.00876095 0.00375469]\n",
      " [0.00750939 0.00125156 0.00125156 0.01251564 0.00375469 0.00375469]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00484486 0.00223458 0.00831052 0.01141858 0.00430352 0.00574546\n",
      " 0.00148964 0.024497   0.19085166 0.14719932 0.00362801 0.00400935\n",
      " 0.00234695 0.0294723  0.00610169 0.0023997  0.02773363 0.00402604\n",
      " 0.00299601 0.03875164 0.00441521 0.00590103 0.02144206 0.00643991\n",
      " 0.002958   0.00446055 0.21398418 0.15024634 0.03119706 0.00311544\n",
      " 0.00640498 0.00544057 0.0087771  0.00627058 0.00271821 0.0038685 ] \n",
      " -0.5634304\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.87859825e-02 2.00250313e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.25406758e-02 4.26783479e-01 3.52941176e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 7.13391740e-02\n",
      "  1.62703379e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 5.13141427e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.21929872e-05 2.53218168e-05 4.82816109e-03 9.21670144e-05\n",
      " 7.16547875e-05 8.06202879e-05 4.32392735e-05 7.06488790e-04\n",
      " 4.06468570e-01 6.56633929e-04 2.15360895e-04 2.05189775e-04\n",
      " 2.05553093e-04 1.90373603e-03 9.74782975e-04 4.93754109e-04\n",
      " 4.52558976e-03 1.42975870e-04 1.46609105e-04 4.47597587e-03\n",
      " 1.42233795e-03 1.51741586e-03 1.99636305e-03 5.21679351e-04\n",
      " 7.04477425e-05 4.19173339e-05 2.47558055e-04 5.62543631e-01\n",
      " 1.04939507e-03 1.02399834e-04 4.00659483e-05 7.37717273e-05\n",
      " 1.72457381e-04 3.81418830e-03 4.61552663e-05 3.57897079e-05] \n",
      " 0.68613976\n",
      "p [[0.00125156 0.00125156 0.00375469 0.00375469 0.00125156 0.00125156]\n",
      " [0.00125156 0.01126408 0.20275344 0.05506884 0.00125156 0.00125156]\n",
      " [0.00125156 0.02252816 0.         0.00125156 0.01001252 0.00250313]\n",
      " [0.00125156 0.04505632 0.         0.00125156 0.00750939 0.00250313]\n",
      " [0.00125156 0.         0.51814768 0.07509387 0.01376721 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.00125156 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0019258  0.00616771 0.03070941 0.00776965 0.00421015 0.00425523\n",
      " 0.00350096 0.01744038 0.03068631 0.00729635 0.00322939 0.03426757\n",
      " 0.00150078 0.24864829 0.04746454 0.00150374 0.09399678 0.00297444\n",
      " 0.00205452 0.17683929 0.00326293 0.0581115  0.09613543 0.00278276\n",
      " 0.01108345 0.00134379 0.00349211 0.02910616 0.01703621 0.00718452\n",
      " 0.00533953 0.00387472 0.00653237 0.02030193 0.0060908  0.00188063] \n",
      " 0.36699134\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 7.25907384e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 9.27409262e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.6471078e-05 1.4230876e-03 1.0075831e-02 6.3769327e-04 7.9042402e-05\n",
      " 5.3340140e-05 1.2424026e-03 1.1866819e-03 6.5712570e-03 5.2119972e-04\n",
      " 3.1206978e-04 3.3866166e-04 1.7587985e-03 2.4706212e-01 1.8607075e-03\n",
      " 5.6115859e-03 1.4808301e-04 2.1163316e-04 9.3008493e-05 5.6950055e-04\n",
      " 5.4308241e-03 3.8519804e-03 6.7970490e-01 7.5013982e-03 8.9494970e-05\n",
      " 1.8124262e-04 1.2288858e-04 4.8301439e-03 1.8737477e-03 2.1509489e-03\n",
      " 5.4533146e-05 2.4095412e-04 1.1065301e-03 9.8566459e-03 3.1975743e-03\n",
      " 3.3102278e-05] \n",
      " 0.94031566\n",
      "p [[0.00125156 0.00125156 0.01376721 0.00500626 0.00125156 0.00125156]\n",
      " [0.00125156 0.01126408 0.03754693 0.00250313 0.00125156 0.0212766 ]\n",
      " [0.00125156 0.16645807 0.         0.00125156 0.11889862 0.00125156]\n",
      " [0.00125156 0.25907384 0.         0.12390488 0.07133917 0.00125156]\n",
      " [0.00876095 0.         0.         0.         0.00750939 0.00625782]\n",
      " [0.00125156 0.00500626 0.00625782 0.11389237 0.00500626 0.00125156]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00175453 0.04127067 0.06389867 0.009774   0.02538001 0.00278909\n",
      " 0.03394001 0.00616957 0.00500877 0.00134807 0.00202257 0.12132042\n",
      " 0.08712459 0.00743416 0.00262832 0.00037872 0.00146097 0.00206286\n",
      " 0.00166537 0.00892418 0.00109328 0.0033113  0.00271362 0.30114594\n",
      " 0.03530666 0.0011839  0.00064308 0.01121338 0.00347339 0.03429515\n",
      " 0.00301706 0.05143296 0.0163813  0.08243445 0.02272093 0.00327813] \n",
      " -0.44356254\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 9.18648310e-01 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  7.75969962e-02 1.25156446e-03]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [3.77215911e-05 3.41028750e-01 1.65341259e-03 3.20624036e-04\n",
      " 4.33870504e-04 3.48628892e-05 8.68204981e-02 2.11561332e-03\n",
      " 2.10297760e-03 4.28439467e-04 1.09471136e-03 1.21333078e-03\n",
      " 1.89460404e-02 1.10937352e-03 8.96022771e-04 7.20098838e-02\n",
      " 1.44914945e-03 5.60109562e-04 2.58921296e-04 2.98288697e-03\n",
      " 3.67531031e-02 2.52904440e-03 8.82010092e-04 1.11604691e-01\n",
      " 1.44937963e-04 3.65232263e-04 1.14711904e-04 9.50677786e-03\n",
      " 1.37054874e-03 2.68539339e-02 5.61236957e-05 1.20354537e-03\n",
      " 7.28237326e-04 7.49018183e-03 2.64797121e-01 1.02703700e-04] \n",
      " 0.99775845\n",
      "p [[0.00125156 0.02753442 0.07133917 0.01627034 0.03629537 0.00125156]\n",
      " [0.03254068 0.01627034 0.01126408 0.00125156 0.00125156 0.08886108]\n",
      " [0.1126408  0.         0.         0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.00125156 0.00125156 0.24155194]\n",
      " [0.03003755 0.         0.         0.         0.00125156 0.03379224]\n",
      " [0.00125156 0.04505632 0.02753442 0.1689612  0.02377972 0.00125156]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00160627 0.01017708 0.04233208 0.01394156 0.04741656 0.00532508\n",
      " 0.08299311 0.01275931 0.00306734 0.00105255 0.00139865 0.25721994\n",
      " 0.06145376 0.00301995 0.00100568 0.00044062 0.00139613 0.00533081\n",
      " 0.01033483 0.00643239 0.00118421 0.00311277 0.00153514 0.07851147\n",
      " 0.13626109 0.00095464 0.00087155 0.01369925 0.00478467 0.04168191\n",
      " 0.00894085 0.06461434 0.01254113 0.053344   0.00685024 0.00240916] \n",
      " -0.8422886\n",
      "p [[1.25156446e-13 3.52941176e-01 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.38923655e-01 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.37797247e-02 0.00000000e+00 0.00000000e+00 5.38172716e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 7.50938673e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  4.23028786e-01 1.25156446e-13]]\n",
      "move 34\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]]\n",
      "1 won\n",
      "game 199 completed in 27.814173936843872 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.348473 entropy 1.8403486\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.321592 entropy 1.8323119\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2908127 entropy 1.8256139\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2603242 entropy 1.8208287\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2327063 entropy 1.8177092\n",
      "kl 0.018399522\n",
      "completed in 0.16323089599609375 s\n",
      "game 200 completed in 6.259411811828613 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4301753 entropy 1.7803103\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4164305 entropy 1.7873979\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3905568 entropy 1.7990674\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3617709 entropy 1.8121688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.332242 entropy 1.8238844\n",
      "kl 0.025560914\n",
      "completed in 0.16906285285949707 s\n",
      "game 201 completed in 9.680174112319946 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4569266 entropy 1.8651694\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4420722 entropy 1.8680438\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4155495 entropy 1.8658315\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.384815 entropy 1.8603115\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3540149 entropy 1.8529519\n",
      "kl 0.028941032\n",
      "completed in 0.1741480827331543 s\n",
      "game 202 completed in 8.442514896392822 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.415345 entropy 1.8556389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3994944 entropy 1.8532791\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3732674 entropy 1.8565485\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3412826 entropy 1.8640544\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3102868 entropy 1.8730595\n",
      "kl 0.024007615\n",
      "completed in 0.16549277305603027 s\n",
      "game 203 completed in 11.333904027938843 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4291165 entropy 1.8564913\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4114785 entropy 1.8677526\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.37956 entropy 1.8771448\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3466876 entropy 1.8838286\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3185096 entropy 1.8860177\n",
      "kl 0.018079875\n",
      "completed in 0.1832289695739746 s\n",
      "game 204 completed in 7.621224880218506 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4757867 entropy 1.9147606\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4627223 entropy 1.9097537\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4404287 entropy 1.9028226\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.413211 entropy 1.895932\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3850513 entropy 1.890696\n",
      "kl 0.016075028\n",
      "completed in 0.17342495918273926 s\n",
      "game 205 completed in 7.301928997039795 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.347527 entropy 1.8532054\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3328214 entropy 1.8483527\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.312309 entropy 1.843859\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.288317 entropy 1.8400457\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2633982 entropy 1.8365182\n",
      "kl 0.020530906\n",
      "completed in 0.18863987922668457 s\n",
      "game 206 completed in 19.67750072479248 s 24 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.483822 entropy 1.8864915\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4594104 entropy 1.8873985\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4285197 entropy 1.89203\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3979137 entropy 1.8983614\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3666081 entropy 1.9044948\n",
      "kl 0.02404322\n",
      "completed in 0.17261695861816406 s\n",
      "game 207 completed in 5.872493028640747 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4109704 entropy 1.8700593\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3994179 entropy 1.8728025\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3752701 entropy 1.8725202\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3450437 entropy 1.8682925\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3156867 entropy 1.8609456\n",
      "kl 0.023959914\n",
      "completed in 0.2012500762939453 s\n",
      "game 208 completed in 10.336978197097778 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.495057 entropy 1.8535867\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.465132 entropy 1.8424711\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4267526 entropy 1.83181\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.396887 entropy 1.8266506\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3642833 entropy 1.8276858\n",
      "kl 0.022399085\n",
      "completed in 0.1757049560546875 s\n",
      "game 209 completed in 7.7706687450408936 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3838582 entropy 1.8920145\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.364595 entropy 1.9016452\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3364534 entropy 1.9128487\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3051195 entropy 1.9230515\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2750387 entropy 1.9302015\n",
      "kl 0.031314783\n",
      "completed in 0.18994903564453125 s\n",
      "game 210 completed in 6.290250062942505 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4002614 entropy 1.8826227\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3797982 entropy 1.8863459\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3538058 entropy 1.8871671\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.324943 entropy 1.8854249\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2962053 entropy 1.8816339\n",
      "kl 0.031026537\n",
      "completed in 0.20151901245117188 s\n",
      "game 211 completed in 13.410165071487427 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4968307 entropy 1.9057211\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4804254 entropy 1.90216\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4540582 entropy 1.899063\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4270575 entropy 1.8977556\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4000297 entropy 1.8984115\n",
      "kl 0.020723276\n",
      "completed in 0.16564297676086426 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 212 completed in 6.200987100601196 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4607923 entropy 1.8575943\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4375608 entropy 1.8621905\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4058216 entropy 1.86884\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3702912 entropy 1.8751879\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3347836 entropy 1.8789743\n",
      "kl 0.023979373\n",
      "completed in 0.19205403327941895 s\n",
      "game 213 completed in 8.987607955932617 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.383669 entropy 1.8969008\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3640785 entropy 1.8938211\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.339353 entropy 1.8863282\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3103933 entropy 1.8751678\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2779953 entropy 1.8622054\n",
      "kl 0.01788759\n",
      "completed in 0.21143031120300293 s\n",
      "game 214 completed in 6.364026069641113 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4593115 entropy 1.8732455\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4393098 entropy 1.8666028\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4041522 entropy 1.8630472\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3727493 entropy 1.8618662\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3412538 entropy 1.8616719\n",
      "kl 0.024044385\n",
      "completed in 0.17576885223388672 s\n",
      "game 215 completed in 9.793798208236694 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4333227 entropy 1.8708215\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4129004 entropy 1.869376\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3804157 entropy 1.8658576\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3508983 entropy 1.8611848\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3248613 entropy 1.8563015\n",
      "kl 0.024245325\n",
      "completed in 0.18310308456420898 s\n",
      "game 216 completed in 8.313523054122925 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4384582 entropy 1.8165483\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.419424 entropy 1.8161993\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3903608 entropy 1.8182833\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3602242 entropy 1.8224404\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.331217 entropy 1.8278131\n",
      "kl 0.024271883\n",
      "completed in 0.17516589164733887 s\n",
      "game 217 completed in 8.017436981201172 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4901302 entropy 1.8850307\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4702504 entropy 1.8877083\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4371374 entropy 1.8893812\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4031692 entropy 1.8890557\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3717055 entropy 1.8862834\n",
      "kl 0.035582837\n",
      "completed in 0.19377803802490234 s\n",
      "game 218 completed in 7.42729926109314 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4389036 entropy 1.8882815\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.421961 entropy 1.882681\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3998113 entropy 1.8766651\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3760324 entropy 1.8719317\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3554122 entropy 1.8696487\n",
      "kl 0.019886367\n",
      "completed in 0.17434096336364746 s\n",
      "game 219 completed in 13.020972967147827 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3866346 entropy 1.8424103\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3738801 entropy 1.8472097\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3524463 entropy 1.8541219\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3273237 entropy 1.8612013\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3008919 entropy 1.866846\n",
      "kl 0.027538102\n",
      "completed in 0.17748212814331055 s\n",
      "game 220 completed in 6.8767969608306885 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.2786515 entropy 1.8179896\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2593176 entropy 1.8250477\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2367415 entropy 1.8316197\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.208986 entropy 1.8343601\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1785405 entropy 1.8320348\n",
      "kl 0.019992936\n",
      "completed in 0.18774819374084473 s\n",
      "game 221 completed in 9.513612031936646 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4540036 entropy 1.9494356\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4362812 entropy 1.9441075\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4164734 entropy 1.9383235\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3940637 entropy 1.9327009\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3696601 entropy 1.9273686\n",
      "kl 0.017534453\n",
      "completed in 0.20266103744506836 s\n",
      "game 222 completed in 7.069284915924072 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.495744 entropy 1.9189152\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4814632 entropy 1.9151704\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4545944 entropy 1.9120548\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4200504 entropy 1.9083111\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3861275 entropy 1.9040586\n",
      "kl 0.017426997\n",
      "completed in 0.19634795188903809 s\n",
      "game 223 completed in 9.48753309249878 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3977199 entropy 1.85903\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3834894 entropy 1.8571684\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.360696 entropy 1.856818\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3388073 entropy 1.8576081\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3144772 entropy 1.8588336\n",
      "kl 0.01862757\n",
      "completed in 0.19706130027770996 s\n",
      "game 224 completed in 8.28991985321045 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.467499 entropy 1.8148389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4395943 entropy 1.8164139\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.404698 entropy 1.8168358\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3750389 entropy 1.8160329\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3510556 entropy 1.8139509\n",
      "kl 0.022208441\n",
      "completed in 0.21863389015197754 s\n",
      "game 225 completed in 6.533285856246948 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4221215 entropy 1.8196576\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4070742 entropy 1.8171755\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3823533 entropy 1.8145077\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3552063 entropy 1.8120279\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3295581 entropy 1.8104162\n",
      "kl 0.020063806\n",
      "completed in 0.19854092597961426 s\n",
      "game 226 completed in 9.762344121932983 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.521481 entropy 1.8264627\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4976125 entropy 1.8279431\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4635186 entropy 1.8309691\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4281878 entropy 1.8348632\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3959692 entropy 1.8392045\n",
      "kl 0.024041262\n",
      "completed in 0.1691441535949707 s\n",
      "game 227 completed in 6.195344924926758 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4776185 entropy 1.8458717\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4547338 entropy 1.853778\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4198587 entropy 1.8631971\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3873906 entropy 1.8713694\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.357067 entropy 1.8756696\n",
      "kl 0.024596758\n",
      "completed in 0.1918480396270752 s\n",
      "game 228 completed in 14.733213186264038 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4894078 entropy 1.8910658\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4724836 entropy 1.8905903\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4425797 entropy 1.8862922\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4086397 entropy 1.8799363\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3784027 entropy 1.8731824\n",
      "kl 0.023137104\n",
      "completed in 0.19353175163269043 s\n",
      "game 229 completed in 6.575339078903198 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4151049 entropy 1.8582212\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3980029 entropy 1.8554593\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3673594 entropy 1.8558103\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3331718 entropy 1.8581086\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2981918 entropy 1.8608828\n",
      "kl 0.024130454\n",
      "completed in 0.2016739845275879 s\n",
      "game 230 completed in 18.184244871139526 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3477218 entropy 1.8270065\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3232596 entropy 1.8315285\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2957218 entropy 1.8359454\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2648194 entropy 1.8379172\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2303293 entropy 1.8359555\n",
      "kl 0.024522569\n",
      "completed in 0.17110967636108398 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 231 completed in 10.91520380973816 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4580162 entropy 1.9077857\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4267385 entropy 1.8995526\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3922513 entropy 1.8914069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.359457 entropy 1.8846619\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.332311 entropy 1.8801723\n",
      "kl 0.020819949\n",
      "completed in 0.1743319034576416 s\n",
      "game 232 completed in 8.133962154388428 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3909676 entropy 1.8040376\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3693135 entropy 1.8048053\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3455849 entropy 1.8086098\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3217676 entropy 1.8139241\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2978334 entropy 1.8188343\n",
      "kl 0.02701877\n",
      "completed in 0.1632068157196045 s\n",
      "game 233 completed in 8.411654949188232 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5555556 entropy 1.8779162\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.532928 entropy 1.8803058\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.494983 entropy 1.8824676\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4532137 entropy 1.8850183\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4191618 entropy 1.887743\n",
      "kl 0.02490809\n",
      "completed in 0.18939614295959473 s\n",
      "game 234 completed in 9.854072093963623 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.514496 entropy 1.8539536\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4970734 entropy 1.8589351\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4689705 entropy 1.8645692\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4365675 entropy 1.8691345\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.404019 entropy 1.8710828\n",
      "kl 0.03607969\n",
      "completed in 0.19607996940612793 s\n",
      "game 235 completed in 13.138211727142334 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5145652 entropy 1.9228112\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4936018 entropy 1.9223297\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4589353 entropy 1.9203136\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4173863 entropy 1.916497\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.376111 entropy 1.9108133\n",
      "kl 0.026049279\n",
      "completed in 0.17672395706176758 s\n",
      "game 236 completed in 6.699145078659058 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.456284 entropy 1.8036573\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.438417 entropy 1.7966866\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.406565 entropy 1.78922\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.365337 entropy 1.7811966\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3269472 entropy 1.772979\n",
      "kl 0.031610653\n",
      "completed in 0.1884620189666748 s\n",
      "game 237 completed in 9.938085794448853 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5258822 entropy 1.8383608\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5125544 entropy 1.8353243\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.490571 entropy 1.8365247\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4634137 entropy 1.8412051\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4356 entropy 1.8477232\n",
      "kl 0.024507923\n",
      "completed in 0.2095928192138672 s\n",
      "game 238 completed in 7.524717807769775 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.591137 entropy 1.8259032\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.576749 entropy 1.8377719\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5534947 entropy 1.84942\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5243745 entropy 1.8585814\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4955032 entropy 1.8640876\n",
      "kl 0.023119777\n",
      "completed in 0.16390013694763184 s\n",
      "game 239 completed in 7.366060018539429 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4130635 entropy 1.9052244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.393376 entropy 1.9063516\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3635318 entropy 1.9057345\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3291788 entropy 1.9037192\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2948377 entropy 1.900024\n",
      "kl 0.027139634\n",
      "completed in 0.18867921829223633 s\n",
      "game 240 completed in 7.503831148147583 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5140233 entropy 1.9038186\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4954731 entropy 1.9022293\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4706943 entropy 1.904379\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.443267 entropy 1.9101696\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4159203 entropy 1.9181855\n",
      "kl 0.019817164\n",
      "completed in 0.19941306114196777 s\n",
      "game 241 completed in 6.0873918533325195 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.461317 entropy 1.8890319\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4415672 entropy 1.8973458\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.410042 entropy 1.9042253\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.373658 entropy 1.9081471\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3406065 entropy 1.9084885\n",
      "kl 0.018400759\n",
      "completed in 0.16317200660705566 s\n",
      "game 242 completed in 7.67469596862793 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3545105 entropy 1.9182596\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3399155 entropy 1.9126893\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3202946 entropy 1.9052813\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2991881 entropy 1.8966742\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2751067 entropy 1.887293\n",
      "kl 0.014749179\n",
      "completed in 0.1723780632019043 s\n",
      "game 243 completed in 9.421105861663818 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4174452 entropy 1.8171192\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3952608 entropy 1.8056145\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3628423 entropy 1.7928979\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3291852 entropy 1.7809918\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2944758 entropy 1.7710967\n",
      "kl 0.026968278\n",
      "completed in 0.18320107460021973 s\n",
      "game 244 completed in 12.852172136306763 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4599192 entropy 1.854487\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4442904 entropy 1.8513615\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4194455 entropy 1.8519057\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.39283 entropy 1.8544799\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3639393 entropy 1.8579636\n",
      "kl 0.016911916\n",
      "completed in 0.1797490119934082 s\n",
      "game 245 completed in 8.069568157196045 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4006495 entropy 1.8419983\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3815298 entropy 1.8459153\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3525488 entropy 1.8478665\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3221362 entropy 1.8469739\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2920046 entropy 1.8424997\n",
      "kl 0.027929248\n",
      "completed in 0.21108293533325195 s\n",
      "game 246 completed in 8.283354043960571 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4350893 entropy 1.836168\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4248414 entropy 1.8296087\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4053648 entropy 1.8248262\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3805435 entropy 1.8236264\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3557053 entropy 1.8263956\n",
      "kl 0.015905641\n",
      "completed in 0.16940736770629883 s\n",
      "game 247 completed in 6.070343017578125 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3988576 entropy 1.8031917\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.375634 entropy 1.8110329\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3447459 entropy 1.8211486\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.311119 entropy 1.8304554\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2770784 entropy 1.8366867\n",
      "kl 0.03635008\n",
      "completed in 0.16860103607177734 s\n",
      "game 248 completed in 7.570662260055542 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3965065 entropy 1.7918589\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.371677 entropy 1.7960162\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3407123 entropy 1.8002198\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.309258 entropy 1.8055664\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2788494 entropy 1.8114871\n",
      "kl 0.028647944\n",
      "completed in 0.21741890907287598 s\n",
      "prediction:\n",
      " [0.00355814 0.003214   0.00345055 0.00286555 0.00234045 0.0031162\n",
      " 0.00400882 0.22929041 0.06489427 0.01306913 0.01143185 0.00304726\n",
      " 0.00564391 0.05947603 0.07370156 0.0276359  0.01217198 0.00421201\n",
      " 0.00485421 0.01853359 0.01412206 0.07665094 0.05994449 0.00272455\n",
      " 0.00255326 0.01327534 0.01896325 0.05158938 0.18466292 0.00279642\n",
      " 0.00183737 0.00299597 0.0069681  0.00351888 0.00300286 0.00387859] \n",
      " -0.68421704\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.56570713e-01 2.90362954e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.53942428e-01 2.99123905e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [2.73845188e-04 3.52678180e-05 6.21128478e-04 1.49618805e-04\n",
      " 1.05718485e-04 4.01471480e-05 1.07156506e-04 3.40158050e-03\n",
      " 3.02966125e-03 9.49619487e-02 1.86844351e-04 1.03425344e-04\n",
      " 3.88900255e-04 1.42976211e-03 4.88851815e-02 4.81156707e-01\n",
      " 3.98362838e-02 3.07945273e-04 2.78056308e-04 2.76915245e-02\n",
      " 1.29781991e-01 5.51271066e-02 2.68566213e-03 1.62780590e-04\n",
      " 1.57584989e-04 1.99596310e-04 1.01360328e-01 3.13902786e-03\n",
      " 2.67032580e-03 4.08936394e-05 5.17285771e-05 7.51589105e-05\n",
      " 3.73597839e-04 7.94207735e-04 5.50078876e-05 3.34359764e-04] \n",
      " 0.5853337\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]\n",
      " [0.00250313 0.2077597  0.12765957 0.01251564 0.00750939 0.00250313]\n",
      " [0.00500626 0.10513141 0.12015019 0.01001252 0.00500626 0.00250313]\n",
      " [0.00250313 0.0212766  0.00750939 0.         0.08760951 0.00125156]\n",
      " [0.00125156 0.00750939 0.00750939 0.02628285 0.19649562 0.00125156]\n",
      " [0.00125156 0.00625782 0.00876095 0.00375469 0.00125156 0.00125156]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00121156 0.00264594 0.00991678 0.00801174 0.00084234 0.00147701\n",
      " 0.0010848  0.00200826 0.15139526 0.17422614 0.00674149 0.00094359\n",
      " 0.0074571  0.0367067  0.0011822  0.00267717 0.03357983 0.00341879\n",
      " 0.0038174  0.0429385  0.00070192 0.00138284 0.05135746 0.00387042\n",
      " 0.00090306 0.00810608 0.29275784 0.11286838 0.00301593 0.00079519\n",
      " 0.00199525 0.00077352 0.01059888 0.01436491 0.00224588 0.0019798 ] \n",
      " -0.57399476\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 7.75969962e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.75344180e-02 5.78222778e-01\n",
      "  2.12765957e-02 1.25156446e-13]\n",
      " [1.25156446e-13 6.88360451e-02 5.38172716e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.72715895e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.30661836e-04 5.87679620e-04 1.05257786e-03 1.33847259e-02\n",
      " 3.09483003e-04 8.98686412e-04 9.45851323e-04 2.14719120e-03\n",
      " 4.75961948e-03 5.93465865e-01 2.96215597e-03 1.78114948e-04\n",
      " 9.06156085e-04 8.68874229e-03 1.11223420e-03 3.80360149e-02\n",
      " 1.22827319e-02 1.02247368e-03 1.02136889e-03 2.64557488e-02\n",
      " 2.48487536e-02 8.87335860e-04 1.33827664e-02 7.59617251e-04\n",
      " 4.09209082e-04 4.08251956e-03 2.27298811e-01 2.28425884e-03\n",
      " 1.18373462e-03 2.89135845e-04 1.18932396e-03 1.49904023e-04\n",
      " 1.14997085e-02 3.32978729e-04 2.28143399e-04 5.25771698e-04] \n",
      " 0.6807553\n",
      "p [[0.00125156 0.00125156 0.00750939 0.01501877 0.00125156 0.00125156]\n",
      " [0.00250313 0.         0.10387985 0.20275344 0.00250313 0.00125156]\n",
      " [0.00250313 0.1339174  0.00500626 0.         0.01376721 0.00125156]\n",
      " [0.00125156 0.05506884 0.00250313 0.         0.02503129 0.00125156]\n",
      " [0.00125156 0.00250313 0.17647059 0.21777222 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.00876095 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.3202404e-04 2.4890043e-03 5.3133788e-03 3.1877294e-01 2.6795990e-04\n",
      " 8.7745441e-04 1.6808208e-03 3.6878148e-03 3.7022758e-02 2.3025861e-03\n",
      " 2.6679153e-03 1.1456345e-03 2.2593543e-03 2.2517484e-02 1.9822500e-03\n",
      " 2.0065939e-03 8.6119147e-03 2.0637847e-03 1.4125686e-03 1.2677995e-02\n",
      " 1.7765674e-03 1.8036995e-03 3.2050017e-02 2.5272821e-03 2.5178613e-03\n",
      " 5.7282131e-03 6.0280254e-03 2.7905211e-02 3.6777698e-03 1.0922961e-03\n",
      " 1.5553007e-03 7.4132864e-04 4.7578371e-01 4.4662794e-03 1.5916507e-03\n",
      " 5.6275778e-04] \n",
      " -0.945291\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 6.25782228e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 7.50938673e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.13141427e-02 3.00375469e-02 0.00000000e+00\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.46433041e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00286757 0.0031056  0.05288993 0.01359708 0.00509452 0.00142882\n",
      " 0.00369601 0.0184913  0.05212627 0.02361348 0.01714293 0.00530055\n",
      " 0.00959499 0.05829282 0.01259236 0.10943628 0.03106688 0.03518879\n",
      " 0.01640681 0.05870397 0.13551791 0.00324911 0.08679455 0.02290733\n",
      " 0.00814911 0.0471756  0.07932879 0.0278376  0.00671459 0.00225062\n",
      " 0.00274567 0.00434799 0.03148668 0.00698814 0.00165253 0.00221698] \n",
      " 0.8460098\n",
      "p [[0.00125156 0.00125156 0.00125156 0.78973717 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.02002503 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00876095 0.00125156 0.         0.00250313 0.00125156]\n",
      " [0.00125156 0.00250313 0.00125156 0.         0.00876095 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.13767209 0.00125156 0.00125156 0.00125156]]\n",
      "move 3\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00643669 0.02430684 0.08661177 0.05499211 0.00479377 0.00835295\n",
      " 0.00862277 0.02354651 0.06146836 0.00407175 0.00296033 0.00953366\n",
      " 0.0074668  0.11545956 0.00314438 0.00523937 0.02640183 0.01297219\n",
      " 0.01633623 0.06258482 0.00622466 0.00275831 0.14247534 0.01458903\n",
      " 0.01345175 0.00989535 0.0242376  0.06440966 0.02884807 0.01304747\n",
      " 0.01210327 0.0046919  0.04220895 0.05010289 0.01150469 0.01414863] \n",
      " -0.7192242\n",
      "p [[1.25156446e-13 1.25156446e-13 8.76095119e-03 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.50187735e-02 0.00000000e+00\n",
      "  6.53316646e-01 2.50312891e-03]\n",
      " [2.50312891e-03 1.12640801e-02 3.75469337e-03 0.00000000e+00\n",
      "  6.25782228e-03 6.25782228e-03]\n",
      " [3.75469337e-03 1.72715895e-01 2.87859825e-02 0.00000000e+00\n",
      "  1.50187735e-02 5.00625782e-03]\n",
      " [3.75469337e-03 2.25281602e-02 2.50312891e-02 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.25782228e-03 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00091335 0.00344108 0.01354993 0.0035726  0.0046182  0.01707761\n",
      " 0.0012372  0.00458804 0.13680221 0.00263372 0.00246676 0.00376404\n",
      " 0.0037428  0.02955333 0.00605232 0.22176021 0.00194795 0.00261331\n",
      " 0.00234046 0.00419858 0.2424866  0.00032905 0.0932764  0.01885802\n",
      " 0.0087419  0.02947128 0.01717585 0.07733762 0.0032798  0.00163468\n",
      " 0.03387167 0.00149173 0.00197306 0.00156228 0.00047653 0.0011599 ] \n",
      " 0.8627236\n",
      "p [[0.00250313 0.0951189  0.05757196 0.         0.00125156 0.00375469]\n",
      " [0.00375469 0.         0.12640801 0.         0.         0.00375469]\n",
      " [0.00375469 0.10638298 0.00125156 0.         0.00876095 0.00500626]\n",
      " [0.01001252 0.34292866 0.00250313 0.         0.06382979 0.00500626]\n",
      " [0.00500626 0.00750939 0.06508135 0.         0.02503129 0.00375469]\n",
      " [0.00500626 0.00250313 0.01501877 0.01877347 0.00375469 0.00500626]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.9898918e-03 1.3846396e-02 1.0409397e-02 6.6739945e-03 3.2222953e-03\n",
      " 6.0912869e-03 1.4908917e-03 2.4409674e-03 3.2570623e-03 1.2121511e-03\n",
      " 7.9017989e-03 4.6775374e-03 2.6413219e-03 3.9916572e-01 1.9095956e-04\n",
      " 1.2501990e-04 1.7247818e-03 2.0789232e-03 1.8247355e-03 4.4196965e-03\n",
      " 2.8781340e-04 1.7321989e-04 3.9662600e-01 5.8357022e-03 3.1221730e-03\n",
      " 6.7925103e-02 3.4654287e-03 2.7290937e-03 5.3882399e-03 5.0364309e-03\n",
      " 7.9164244e-03 3.4055552e-03 3.0602782e-03 4.6994239e-03 5.0251517e-03\n",
      " 9.9191982e-03] \n",
      " 0.79147214\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 0.00000000e+00 2.29036295e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 3.75469337e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 6.73341677e-01 0.00000000e+00\n",
      "  8.76095119e-03 1.25156446e-03]\n",
      " [1.25156446e-03 6.75844806e-02 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [5.00625782e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.9520207e-04 7.0850918e-05 1.0280042e-03 1.0163479e-03 5.7858310e-04\n",
      " 3.4946252e-02 1.3218491e-04 4.9804233e-04 6.3057328e-03 8.2030252e-04\n",
      " 5.4472539e-04 1.0054881e-03 7.0671755e-04 2.5059384e-01 3.6114245e-04\n",
      " 1.7286920e-04 1.8853979e-04 2.4861467e-04 2.1300639e-04 8.6010760e-04\n",
      " 1.6312356e-04 1.0016931e-04 6.3106406e-01 4.9682646e-03 1.5235844e-03\n",
      " 1.1170993e-02 8.4696067e-03 3.7806677e-03 3.4417887e-04 4.6011401e-04\n",
      " 3.4874354e-02 8.4264507e-04 1.3159295e-03 1.4141841e-04 2.5636606e-05\n",
      " 2.6884297e-04] \n",
      " -0.7634116\n",
      "p [[0.00125156 0.12265332 0.0387985  0.         0.00125156 0.01251564]\n",
      " [0.00125156 0.         0.03254068 0.         0.         0.00375469]\n",
      " [0.00125156 0.21401752 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.23404255 0.00250313]\n",
      " [0.00125156 0.27534418 0.00125156 0.         0.00250313 0.00250313]\n",
      " [0.03379224 0.00125156 0.00125156 0.00250313 0.00250313 0.00500626]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [8.3737148e-05 1.1777508e-04 6.7249530e-05 3.4911798e-05 1.0842987e-03\n",
      " 6.9569756e-04 1.6669621e-05 4.6984269e-04 1.3151232e-04 7.8111247e-05\n",
      " 2.8784989e-06 2.3330611e-04 1.3156339e-04 6.8491179e-01 3.2307755e-05\n",
      " 4.6591541e-07 1.1960792e-05 1.9007244e-05 6.8331001e-06 4.3633794e-05\n",
      " 1.3487985e-06 4.4970908e-05 3.0785546e-01 3.1728813e-04 2.2457360e-04\n",
      " 8.3561725e-05 3.1356647e-04 4.1560521e-05 5.8874203e-04 1.3022558e-04\n",
      " 8.5918896e-04 1.1596087e-03 3.4468161e-05 1.7020915e-05 9.1086025e-05\n",
      " 6.3878339e-05] \n",
      " 0.97798204\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 8.94868586e-01]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 4.63078849e-02 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.50688360e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.50312891e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 5\n",
      "board\n",
      " [[ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0. -1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 249 completed in 28.722278833389282 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4877965 entropy 1.8881717\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4600596 entropy 1.8930371\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4257188 entropy 1.8987811\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.392743 entropy 1.9064457\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3584092 entropy 1.9150741\n",
      "kl 0.019853398\n",
      "completed in 0.19959282875061035 s\n",
      "game 250 completed in 10.936984777450562 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3979745 entropy 1.9175091\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3771741 entropy 1.9207852\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.352601 entropy 1.9176905\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3295755 entropy 1.9090819\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3056781 entropy 1.8968759\n",
      "kl 0.035359472\n",
      "completed in 0.20267987251281738 s\n",
      "game 251 completed in 10.125806093215942 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4749596 entropy 1.9280145\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4594913 entropy 1.9181027\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.431509 entropy 1.9142776\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4025655 entropy 1.9154706\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3683019 entropy 1.9191127\n",
      "kl 0.023325006\n",
      "completed in 0.16115784645080566 s\n",
      "game 252 completed in 9.706912994384766 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4221022 entropy 1.910242\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4017692 entropy 1.9074035\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.374435 entropy 1.9007242\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.345823 entropy 1.8912761\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3198037 entropy 1.8793705\n",
      "kl 0.023159083\n",
      "completed in 0.19313931465148926 s\n",
      "game 253 completed in 5.860380172729492 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4343715 entropy 1.8369191\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4232297 entropy 1.8285353\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4015262 entropy 1.8225055\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3710659 entropy 1.8181777\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3412313 entropy 1.8143063\n",
      "kl 0.018899268\n",
      "completed in 0.17319703102111816 s\n",
      "game 254 completed in 5.94291090965271 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4250014 entropy 1.8652351\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4143667 entropy 1.8626666\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3895648 entropy 1.8615874\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.366533 entropy 1.8611332\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.342562 entropy 1.8601137\n",
      "kl 0.0135742985\n",
      "completed in 0.16999506950378418 s\n",
      "game 255 completed in 8.312996864318848 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.470645 entropy 1.8714212\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.452013 entropy 1.8684118\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4192939 entropy 1.8637445\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3799832 entropy 1.857832\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3404877 entropy 1.8511992\n",
      "kl 0.027960438\n",
      "completed in 0.16657185554504395 s\n",
      "game 256 completed in 10.811368942260742 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4669912 entropy 1.8500133\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4417365 entropy 1.8481984\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4092736 entropy 1.8512156\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3722613 entropy 1.8576\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3382423 entropy 1.8656069\n",
      "kl 0.02743823\n",
      "completed in 0.20818614959716797 s\n",
      "game 257 completed in 12.050493955612183 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4534898 entropy 1.847022\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4267228 entropy 1.8579551\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3875904 entropy 1.8691578\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3495162 entropy 1.8771353\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3140771 entropy 1.880609\n",
      "kl 0.022673715\n",
      "completed in 0.18720507621765137 s\n",
      "game 258 completed in 5.926873683929443 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4850333 entropy 1.9351004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4656699 entropy 1.9293989\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.43966 entropy 1.9229348\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4102108 entropy 1.9191816\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3777149 entropy 1.9187112\n",
      "kl 0.027037596\n",
      "completed in 0.1911611557006836 s\n",
      "game 259 completed in 8.450498104095459 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4658113 entropy 1.8821752\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4467196 entropy 1.8869662\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4199023 entropy 1.8928236\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3916805 entropy 1.8987291\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3652291 entropy 1.9032283\n",
      "kl 0.026173107\n",
      "completed in 0.1882929801940918 s\n",
      "game 260 completed in 8.603630065917969 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3923886 entropy 1.8438885\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3781102 entropy 1.8464148\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3529146 entropy 1.8504548\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3245642 entropy 1.854444\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3000288 entropy 1.8565136\n",
      "kl 0.022550343\n",
      "completed in 0.17140889167785645 s\n",
      "game 261 completed in 10.802201986312866 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.479194 entropy 1.8832781\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.45122 entropy 1.8805662\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.417388 entropy 1.8741848\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3894017 entropy 1.8654172\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.361348 entropy 1.8562671\n",
      "kl 0.0290809\n",
      "completed in 0.18752527236938477 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 262 completed in 8.410836935043335 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3854876 entropy 1.8571277\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3659015 entropy 1.8549764\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3360636 entropy 1.8568182\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3042052 entropy 1.8614719\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2721586 entropy 1.8669744\n",
      "kl 0.022869423\n",
      "completed in 0.17188501358032227 s\n",
      "game 263 completed in 7.528733968734741 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.530523 entropy 1.9345531\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5139642 entropy 1.9402881\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4869416 entropy 1.9427052\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4587796 entropy 1.9413307\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.432857 entropy 1.9368913\n",
      "kl 0.016020138\n",
      "completed in 0.1665809154510498 s\n",
      "game 264 completed in 13.734796047210693 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4838512 entropy 1.9197816\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4638605 entropy 1.917789\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4373162 entropy 1.9172052\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4097102 entropy 1.9168577\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3811877 entropy 1.9161034\n",
      "kl 0.014523585\n",
      "completed in 0.16597819328308105 s\n",
      "game 265 completed in 5.87310004234314 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4436972 entropy 1.88815\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4277306 entropy 1.8867297\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4001758 entropy 1.8840132\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3691173 entropy 1.8800601\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3384242 entropy 1.8748312\n",
      "kl 0.01949663\n",
      "completed in 0.1716480255126953 s\n",
      "game 266 completed in 7.895562171936035 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3797 entropy 1.8594335\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.361237 entropy 1.8573618\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3355923 entropy 1.8574914\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3074074 entropy 1.8587747\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2805932 entropy 1.8598406\n",
      "kl 0.015673013\n",
      "completed in 0.1858978271484375 s\n",
      "game 267 completed in 6.273723840713501 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4163723 entropy 1.8783622\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4009435 entropy 1.8774834\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3764524 entropy 1.8771663\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3510106 entropy 1.87724\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3265994 entropy 1.8774095\n",
      "kl 0.018969975\n",
      "completed in 0.20162510871887207 s\n",
      "game 268 completed in 9.616412878036499 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3778808 entropy 1.8180399\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3591907 entropy 1.8190167\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3328114 entropy 1.820801\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3055966 entropy 1.8231368\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2742121 entropy 1.8257103\n",
      "kl 0.011409055\n",
      "completed in 0.20839715003967285 s\n",
      "game 269 completed in 8.038535118103027 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3869658 entropy 1.8729705\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.369756 entropy 1.8725196\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3421252 entropy 1.8719124\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3100116 entropy 1.8713703\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2785463 entropy 1.8706383\n",
      "kl 0.018636908\n",
      "completed in 0.16901278495788574 s\n",
      "game 270 completed in 14.57760214805603 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5095012 entropy 1.9200478\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4901552 entropy 1.9220693\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.461163 entropy 1.9264663\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4251769 entropy 1.932112\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3904343 entropy 1.9373987\n",
      "kl 0.0142260855\n",
      "completed in 0.16782307624816895 s\n",
      "game 271 completed in 7.584318161010742 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3994043 entropy 1.8936652\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3789346 entropy 1.8931627\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3499618 entropy 1.8884201\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3182538 entropy 1.8810017\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2873864 entropy 1.8724186\n",
      "kl 0.023618067\n",
      "completed in 0.16882586479187012 s\n",
      "game 272 completed in 8.481498956680298 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4289382 entropy 1.8468642\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4121425 entropy 1.839222\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3844893 entropy 1.8326707\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3521435 entropy 1.8275633\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3193188 entropy 1.8232795\n",
      "kl 0.020129912\n",
      "completed in 0.17661499977111816 s\n",
      "game 273 completed in 9.250205039978027 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.419686 entropy 1.8637161\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4031441 entropy 1.8630531\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3776586 entropy 1.8649938\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3503249 entropy 1.867724\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3248982 entropy 1.870076\n",
      "kl 0.028741399\n",
      "completed in 0.17967605590820312 s\n",
      "game 274 completed in 10.698782920837402 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3038752 entropy 1.8396763\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.289206 entropy 1.8381041\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.265091 entropy 1.8344221\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2406297 entropy 1.829648\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2183108 entropy 1.8250877\n",
      "kl 0.017575424\n",
      "completed in 0.18003582954406738 s\n",
      "game 275 completed in 9.57519793510437 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5552464 entropy 1.8895943\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5395868 entropy 1.891695\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5129108 entropy 1.8949729\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4816403 entropy 1.8987772\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.449508 entropy 1.9020636\n",
      "kl 0.01999659\n",
      "completed in 0.17806482315063477 s\n",
      "game 276 completed in 10.066627025604248 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3654213 entropy 1.8733244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3567932 entropy 1.8750432\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.341394 entropy 1.8770227\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3214502 entropy 1.8788929\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2997413 entropy 1.8799158\n",
      "kl 0.017303862\n",
      "completed in 0.21068501472473145 s\n",
      "game 277 completed in 6.369051933288574 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4417567 entropy 1.8640177\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4227388 entropy 1.8670709\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3960736 entropy 1.8719724\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3689444 entropy 1.8774383\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3444345 entropy 1.8822019\n",
      "kl 0.022232663\n",
      "completed in 0.17629218101501465 s\n",
      "game 278 completed in 7.523630142211914 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4379876 entropy 1.9380038\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4226213 entropy 1.9418606\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3968685 entropy 1.9454927\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3653116 entropy 1.9483602\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.333653 entropy 1.9500341\n",
      "kl 0.015019042\n",
      "completed in 0.17507004737854004 s\n",
      "game 279 completed in 6.12236475944519 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4720747 entropy 1.9060671\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4511607 entropy 1.9043756\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4227772 entropy 1.9010524\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.393537 entropy 1.8957238\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.364342 entropy 1.889148\n",
      "kl 0.019067876\n",
      "completed in 0.1843268871307373 s\n",
      "game 280 completed in 10.987245082855225 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.301482 entropy 1.8398218\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2849078 entropy 1.8326507\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2630165 entropy 1.8260386\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.238936 entropy 1.8204994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.2127917 entropy 1.81527\n",
      "kl 0.020596767\n",
      "completed in 0.20254015922546387 s\n",
      "game 281 completed in 7.027614116668701 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4780254 entropy 1.8401852\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.462246 entropy 1.8387185\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4268107 entropy 1.8403566\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.383751 entropy 1.8436197\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3425179 entropy 1.8472314\n",
      "kl 0.019939864\n",
      "completed in 0.19789576530456543 s\n",
      "game 282 completed in 7.992854833602905 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3594804 entropy 1.8567017\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.346269 entropy 1.8604043\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3261113 entropy 1.8644636\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3035297 entropy 1.8686318\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2824416 entropy 1.8727435\n",
      "kl 0.021741647\n",
      "completed in 0.1703810691833496 s\n",
      "game 283 completed in 9.571871042251587 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.34843 entropy 1.8461703\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3284116 entropy 1.8494946\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3029318 entropy 1.8507736\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2782047 entropy 1.8509778\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2536662 entropy 1.8514466\n",
      "kl 0.017304745\n",
      "completed in 0.1883549690246582 s\n",
      "game 284 completed in 6.271625995635986 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3767064 entropy 1.9392958\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.355788 entropy 1.9420164\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3281732 entropy 1.9448353\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3006938 entropy 1.9463966\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.274402 entropy 1.9460919\n",
      "kl 0.016866928\n",
      "completed in 0.1759657859802246 s\n",
      "game 285 completed in 6.0544562339782715 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3588598 entropy 1.8677485\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3460622 entropy 1.8679945\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.326193 entropy 1.867532\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3028865 entropy 1.8662219\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2752478 entropy 1.8641093\n",
      "kl 0.014094639\n",
      "completed in 0.20191502571105957 s\n",
      "game 286 completed in 15.568310976028442 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3959265 entropy 1.8655652\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.36744 entropy 1.8593676\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3385296 entropy 1.8526455\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3114502 entropy 1.8465731\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2856424 entropy 1.8412119\n",
      "kl 0.019232234\n",
      "completed in 0.16763806343078613 s\n",
      "game 287 completed in 9.27488398551941 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3400364 entropy 1.8756933\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3226628 entropy 1.8719764\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2993834 entropy 1.8693111\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.275374 entropy 1.867584\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2520485 entropy 1.8659867\n",
      "kl 0.015266784\n",
      "completed in 0.21896600723266602 s\n",
      "game 288 completed in 9.171514987945557 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4551275 entropy 1.8790705\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4355886 entropy 1.8812602\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4071398 entropy 1.8856876\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3805752 entropy 1.8898947\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3501449 entropy 1.8919848\n",
      "kl 0.023533752\n",
      "completed in 0.17635393142700195 s\n",
      "game 289 completed in 9.369493007659912 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.336386 entropy 1.8880742\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3195686 entropy 1.8907526\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2966878 entropy 1.8951197\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2741039 entropy 1.9003024\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2522876 entropy 1.9055943\n",
      "kl 0.01615486\n",
      "completed in 0.22787714004516602 s\n",
      "game 290 completed in 9.897053956985474 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4421315 entropy 1.9044559\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4240375 entropy 1.9073634\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3940132 entropy 1.9086058\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3638635 entropy 1.9080557\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3415174 entropy 1.9060487\n",
      "kl 0.022848597\n",
      "completed in 0.17278695106506348 s\n",
      "game 291 completed in 6.927932977676392 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3942163 entropy 1.8938226\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3800523 entropy 1.8944829\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3565037 entropy 1.8967459\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.332654 entropy 1.8996859\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3071766 entropy 1.9025714\n",
      "kl 0.019500315\n",
      "completed in 0.1658942699432373 s\n",
      "game 292 completed in 9.511148929595947 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.427373 entropy 1.9351873\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4104912 entropy 1.9372361\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.387953 entropy 1.9393876\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.370848 entropy 1.9404713\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3497565 entropy 1.9394367\n",
      "kl 0.017938666\n",
      "completed in 0.17737221717834473 s\n",
      "game 293 completed in 5.91874098777771 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3631017 entropy 1.9220258\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3436036 entropy 1.9174488\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3183358 entropy 1.9124231\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.293191 entropy 1.906974\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2725587 entropy 1.90107\n",
      "kl 0.02195246\n",
      "completed in 0.18201708793640137 s\n",
      "game 294 completed in 15.628336906433105 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3543751 entropy 1.8858759\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3339767 entropy 1.8829594\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3061135 entropy 1.8814389\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2770123 entropy 1.8797755\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2457702 entropy 1.8772547\n",
      "kl 0.019010866\n",
      "completed in 0.1781601905822754 s\n",
      "game 295 completed in 12.502259254455566 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3576803 entropy 1.8571388\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3436587 entropy 1.8513116\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3208814 entropy 1.8448408\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2971807 entropy 1.8393362\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.272808 entropy 1.8357034\n",
      "kl 0.016871244\n",
      "completed in 0.17360591888427734 s\n",
      "game 296 completed in 7.699743986129761 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5092342 entropy 1.8961079\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4844556 entropy 1.8967812\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.448675 entropy 1.897693\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.414709 entropy 1.8984196\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.386162 entropy 1.8985488\n",
      "kl 0.024082704\n",
      "completed in 0.1686859130859375 s\n",
      "game 297 completed in 6.767132759094238 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.348533 entropy 1.8336837\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3329287 entropy 1.8348237\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3103085 entropy 1.8371966\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2866886 entropy 1.8399566\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.264585 entropy 1.8424411\n",
      "kl 0.023686878\n",
      "completed in 0.18908095359802246 s\n",
      "game 298 completed in 6.077480792999268 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4128482 entropy 1.9115967\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3934593 entropy 1.908741\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3649645 entropy 1.9039757\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.338958 entropy 1.8978436\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.31468 entropy 1.8910073\n",
      "kl 0.021865997\n",
      "completed in 0.1980140209197998 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00542614 0.0038856  0.00286673 0.00663045 0.00214378 0.00365142\n",
      " 0.00480343 0.21545747 0.0473316  0.01526191 0.011341   0.00217772\n",
      " 0.00353036 0.0464882  0.07296404 0.01512908 0.02093402 0.01135905\n",
      " 0.00639017 0.01438961 0.01911207 0.09223121 0.04731594 0.00459612\n",
      " 0.00220747 0.00897793 0.01424284 0.05037989 0.21865736 0.00324645\n",
      " 0.00199145 0.00289575 0.00818062 0.00275387 0.00458274 0.00646664] \n",
      " -0.71591157\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.65331665e-01 2.36545682e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.39048811e-01 2.59073842e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [2.2877131e-04 9.3134979e-05 3.0956876e-03 1.0467299e-03 7.8517210e-04\n",
      " 1.7593596e-04 1.1828183e-04 3.2111749e-03 3.2704882e-02 8.8263825e-02\n",
      " 1.5224733e-03 5.4415659e-04 3.5113996e-04 2.2144279e-02 3.3741891e-02\n",
      " 1.2296981e-01 7.5098611e-02 4.0945169e-04 2.0970004e-04 1.5231740e-01\n",
      " 1.7682230e-01 3.4804273e-02 2.9199876e-02 2.3666092e-03 1.9032249e-04\n",
      " 4.8734871e-04 1.8800472e-01 2.2607135e-02 3.2876297e-03 1.1383267e-04\n",
      " 1.0954199e-04 3.7402866e-04 9.7699382e-04 1.4021468e-03 6.0378865e-05\n",
      " 1.6053699e-04] \n",
      " 0.5678201\n",
      "p [[0.01627034 0.00250313 0.00250313 0.00750939 0.00125156 0.00500626]\n",
      " [0.00250313 0.26032541 0.01877347 0.00876095 0.0212766  0.00250313]\n",
      " [0.00375469 0.02377972 0.         0.00876095 0.01126408 0.01001252]\n",
      " [0.00500626 0.01126408 0.00876095 0.19899875 0.03629537 0.00500626]\n",
      " [0.00750939 0.00625782 0.01001252 0.02252816 0.25156446 0.00250313]\n",
      " [0.00250313 0.00125156 0.00500626 0.00375469 0.00375469 0.01126408]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0030227  0.00326802 0.01170757 0.01146055 0.00238367 0.0015539\n",
      " 0.00284676 0.004793   0.17365676 0.00894115 0.01706121 0.0024607\n",
      " 0.00245332 0.05968702 0.01104058 0.12284132 0.08790756 0.00598035\n",
      " 0.00686417 0.07756963 0.07798803 0.00724083 0.07024581 0.00373478\n",
      " 0.00134989 0.01455811 0.01477853 0.13533974 0.00746488 0.00321061\n",
      " 0.00183846 0.00118667 0.02148493 0.01568262 0.00185054 0.00454584] \n",
      " -0.69470614\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 4.88110138e-02 3.25406758e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-02 0.00000000e+00 2.09011264e-01\n",
      "  3.50438048e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.45181477e-01 1.38923655e-01 6.38297872e-02\n",
      "  4.63078849e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.14017522e-01 1.62703379e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.2507091e-05 4.8803216e-05 4.2519576e-04 2.4675077e-03 3.3568585e-04\n",
      " 1.1937943e-05 7.7643424e-05 1.5777221e-04 5.9780017e-03 3.3602954e-04\n",
      " 3.0735557e-03 4.7140929e-05 5.0810704e-05 5.5428063e-03 1.0214279e-03\n",
      " 3.8527891e-01 6.9029082e-04 1.6643340e-04 1.7128281e-04 8.0917380e-04\n",
      " 5.7584018e-01 5.0170062e-04 7.2268802e-03 2.7495841e-04 5.8116202e-05\n",
      " 2.4404926e-03 6.1227020e-04 5.1301681e-03 3.6218148e-04 5.9321814e-05\n",
      " 1.9448564e-05 6.4481588e-05 5.2908895e-04 1.2082276e-04 1.8114886e-05\n",
      " 2.8936465e-05] \n",
      " 0.688478\n",
      "p [[0.00125156 0.00125156 0.01251564 0.00750939 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.14893617 0.00625782 0.01627034 0.00125156]\n",
      " [0.00125156 0.14768461 0.         0.08135169 0.05506884 0.00375469]\n",
      " [0.00375469 0.16395494 0.11639549 0.06633292 0.0350438  0.00375469]\n",
      " [0.00125156 0.00750939 0.         0.08010013 0.00250313 0.00125156]\n",
      " [0.00125156 0.00125156 0.01627034 0.00750939 0.00125156 0.00250313]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.0065789e-03 2.0106204e-03 2.3900857e-03 7.5600125e-02 7.6345989e-04\n",
      " 7.6374901e-04 1.1355067e-03 2.8713210e-04 8.8299334e-02 4.6451259e-03\n",
      " 3.4950092e-02 1.5555128e-03 1.0536319e-03 3.2326171e-01 9.4970723e-04\n",
      " 8.4436900e-04 4.1521243e-03 2.3861455e-03 2.2316813e-03 4.8337379e-03\n",
      " 7.5552659e-04 7.6648308e-04 2.0410630e-01 3.2126559e-03 4.4509547e-04\n",
      " 3.1884741e-02 7.3986980e-03 5.8747720e-02 9.5562451e-04 2.0772901e-03\n",
      " 7.9982023e-04 3.6839989e-04 1.2910014e-01 2.5187524e-03 1.7006638e-03\n",
      " 2.0419266e-03] \n",
      " -0.78603536\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 4.25531915e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 9.56195244e-01 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.1827573e-06 3.0838021e-06 3.8625083e-05 2.2624084e-01 2.6035183e-05\n",
      " 9.2595354e-07 2.8678783e-06 2.6532530e-07 1.7997062e-01 7.1986564e-05\n",
      " 7.1214797e-04 1.8360592e-05 1.1332369e-06 3.3713179e-05 4.3476118e-07\n",
      " 6.9977782e-06 7.8470493e-06 7.5261728e-06 2.7947981e-05 1.4151722e-05\n",
      " 4.8148950e-06 7.3489273e-06 2.6572592e-05 4.1433900e-06 1.2641092e-05\n",
      " 5.8301812e-04 2.2557836e-04 5.1687747e-01 1.4153240e-06 1.1010090e-05\n",
      " 1.3394128e-06 1.0667183e-05 7.4927151e-02 1.0584146e-04 1.0440181e-05\n",
      " 3.0069871e-06] \n",
      " 0.9998572\n",
      "p [[0.00125156 0.00125156 0.00125156 0.04255319 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.06007509 0.00750939 0.02753442 0.00125156]\n",
      " [0.00125156 0.45181477 0.         0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.         0.         0.00125156 0.1301627  0.00125156]\n",
      " [0.00125156 0.08510638 0.         0.03379224 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.1339174  0.00125156 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.8592911e-04 3.7216479e-01 2.6526968e-03 2.0657401e-03 1.2405952e-03\n",
      " 9.2126505e-04 9.9399604e-04 4.2126107e-04 1.1036493e-04 3.6372108e-05\n",
      " 2.1913530e-01 1.6151521e-04 5.0301715e-05 1.2003959e-03 1.2368964e-04\n",
      " 9.3057999e-05 2.6264242e-03 6.0748691e-05 1.2923829e-04 4.9177944e-03\n",
      " 2.2318664e-04 1.1886532e-04 1.3721096e-03 1.5001858e-04 1.4033019e-04\n",
      " 2.1219011e-01 1.4713015e-04 1.0566698e-04 4.1032556e-04 9.8342891e-04\n",
      " 9.5480646e-05 7.4079930e-04 2.4683033e-03 3.0045551e-03 1.6844290e-01\n",
      " 1.1544546e-04] \n",
      " -0.70178777\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 2.12765957e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 6.58322904e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 4.75594493e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.72841051e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 299 completed in 17.624600172042847 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4035823 entropy 1.9043181\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.382651 entropy 1.9016532\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3497252 entropy 1.9025732\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3177776 entropy 1.90595\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2934365 entropy 1.9100621\n",
      "kl 0.0314795\n",
      "completed in 0.17311716079711914 s\n",
      "training pipeline completed in 2872.745341062546 s\n"
     ]
    }
   ],
   "source": [
    "k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4bee95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.save('n2-1200.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "067542a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 7.50545597076416 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4060495 entropy 1.8667347\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.392938 entropy 1.8682678\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3661366 entropy 1.870348\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.335247 entropy 1.8715175\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3052037 entropy 1.871023\n",
      "kl 0.019948922\n",
      "completed in 0.17284083366394043 s\n",
      "game 1 completed in 7.47498083114624 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.327504 entropy 1.8818567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.310401 entropy 1.8786076\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2829447 entropy 1.8741794\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.257152 entropy 1.8705096\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2343912 entropy 1.8687543\n",
      "kl 0.026166867\n",
      "completed in 0.17522263526916504 s\n",
      "game 2 completed in 7.580127954483032 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.322889 entropy 1.8224406\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2997475 entropy 1.8290197\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2644591 entropy 1.8374152\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2385833 entropy 1.8451627\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2162302 entropy 1.8503716\n",
      "kl 0.03176092\n",
      "completed in 0.1840219497680664 s\n",
      "game 3 completed in 8.39769983291626 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.302492 entropy 1.870607\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.290002 entropy 1.8747268\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.269671 entropy 1.8766303\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2478714 entropy 1.876148\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2271655 entropy 1.8730175\n",
      "kl 0.012402426\n",
      "completed in 0.19614887237548828 s\n",
      "game 4 completed in 9.496550798416138 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.323411 entropy 1.848469\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2981062 entropy 1.8402109\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.263349 entropy 1.8311875\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2300901 entropy 1.8221078\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2024324 entropy 1.813827\n",
      "kl 0.033536408\n",
      "completed in 0.22883200645446777 s\n",
      "game 5 completed in 11.523222208023071 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.391202 entropy 1.8516542\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.382177 entropy 1.8483404\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3630893 entropy 1.8481562\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.339353 entropy 1.8509737\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.312851 entropy 1.8553956\n",
      "kl 0.011417752\n",
      "completed in 0.18848204612731934 s\n",
      "game 6 completed in 8.998018980026245 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.1811728 entropy 1.7721087\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.1653085 entropy 1.7793047\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.1441472 entropy 1.7866884\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.1209745 entropy 1.7917048\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1000283 entropy 1.7930648\n",
      "kl 0.016604587\n",
      "completed in 0.16740107536315918 s\n",
      "game 7 completed in 6.9140260219573975 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.2800813 entropy 1.7990181\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2580593 entropy 1.794278\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2251067 entropy 1.7888994\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.1895444 entropy 1.7838621\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1558025 entropy 1.7800579\n",
      "kl 0.01926255\n",
      "completed in 0.16857314109802246 s\n",
      "game 8 completed in 14.745011806488037 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4058688 entropy 1.8855016\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.389559 entropy 1.8858328\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3651123 entropy 1.8863399\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3381445 entropy 1.8860185\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3121986 entropy 1.8846816\n",
      "kl 0.026082983\n",
      "completed in 0.16578197479248047 s\n",
      "game 9 completed in 11.703563928604126 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5339825 entropy 1.9056697\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5131307 entropy 1.9024034\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4841065 entropy 1.896564\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4528632 entropy 1.8893745\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4210038 entropy 1.8815455\n",
      "kl 0.02128812\n",
      "completed in 0.16931390762329102 s\n",
      "game 10 completed in 9.123708009719849 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.391497 entropy 1.7930394\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3706567 entropy 1.7933782\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.33954 entropy 1.7991942\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.309337 entropy 1.809767\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2820086 entropy 1.8217031\n",
      "kl 0.025395654\n",
      "completed in 0.2043137550354004 s\n",
      "game 11 completed in 8.171197175979614 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.453313 entropy 1.8431833\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4346824 entropy 1.84978\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4029973 entropy 1.8528277\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3662694 entropy 1.852459\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3330986 entropy 1.8502727\n",
      "kl 0.021222267\n",
      "completed in 0.169266939163208 s\n",
      "game 12 completed in 5.952246904373169 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.426522 entropy 1.8693243\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.407462 entropy 1.8621275\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3771358 entropy 1.8559712\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.345603 entropy 1.8518767\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3201423 entropy 1.8508177\n",
      "kl 0.024846671\n",
      "completed in 0.21129584312438965 s\n",
      "game 13 completed in 8.328316926956177 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4282916 entropy 1.8158331\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4073522 entropy 1.8233278\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3691971 entropy 1.8316456\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3317618 entropy 1.8400348\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3021855 entropy 1.8481815\n",
      "kl 0.02577065\n",
      "completed in 0.17019915580749512 s\n",
      "game 14 completed in 6.720055103302002 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.435189 entropy 1.9400749\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.41089 entropy 1.9459401\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3812642 entropy 1.9483601\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3554702 entropy 1.9452915\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.329217 entropy 1.93694\n",
      "kl 0.01932298\n",
      "completed in 0.1878058910369873 s\n",
      "game 15 completed in 12.33079195022583 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3372111 entropy 1.8960183\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.321123 entropy 1.886765\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2956948 entropy 1.8788064\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2696092 entropy 1.872489\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2418885 entropy 1.8670642\n",
      "kl 0.020029724\n",
      "completed in 0.1692049503326416 s\n",
      "game 16 completed in 5.892297983169556 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.403849 entropy 1.8940597\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3895357 entropy 1.8927532\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3679287 entropy 1.8923473\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3457198 entropy 1.8926611\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3192527 entropy 1.8925982\n",
      "kl 0.022635892\n",
      "completed in 0.203139066696167 s\n",
      "game 17 completed in 7.391382694244385 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3659403 entropy 1.8411071\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3459573 entropy 1.8410287\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3147311 entropy 1.8400793\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2806396 entropy 1.8379116\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2489166 entropy 1.8344986\n",
      "kl 0.017241836\n",
      "completed in 0.15644288063049316 s\n",
      "game 18 completed in 7.5631489753723145 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4529262 entropy 1.8898425\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4203804 entropy 1.882942\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3879018 entropy 1.8752054\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3623185 entropy 1.8688688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3364859 entropy 1.8647206\n",
      "kl 0.023160018\n",
      "completed in 0.18826007843017578 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 19 completed in 10.580837965011597 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.317258 entropy 1.8165792\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3017101 entropy 1.8154633\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2766387 entropy 1.8139884\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.250312 entropy 1.8121455\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.226294 entropy 1.8100573\n",
      "kl 0.016232762\n",
      "completed in 0.17157721519470215 s\n",
      "game 20 completed in 5.884858131408691 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3298535 entropy 1.8155799\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3087778 entropy 1.8146746\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.282509 entropy 1.8151174\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.255789 entropy 1.8173623\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2293239 entropy 1.8205516\n",
      "kl 0.021800946\n",
      "completed in 0.20227718353271484 s\n",
      "game 21 completed in 12.19047212600708 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3379216 entropy 1.8068283\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3185225 entropy 1.8088615\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2868013 entropy 1.8099527\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2586045 entropy 1.8105838\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.230398 entropy 1.8106896\n",
      "kl 0.02477894\n",
      "completed in 0.19319391250610352 s\n",
      "game 22 completed in 7.475484848022461 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.363835 entropy 1.8603389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3400443 entropy 1.8611\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.304319 entropy 1.8617237\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2732658 entropy 1.8629953\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2460823 entropy 1.8649709\n",
      "kl 0.015020083\n",
      "completed in 0.17183208465576172 s\n",
      "game 23 completed in 16.766175031661987 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4324553 entropy 1.8706241\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.41282 entropy 1.8782701\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3803031 entropy 1.887338\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3450572 entropy 1.89609\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3131464 entropy 1.9023314\n",
      "kl 0.022585547\n",
      "completed in 0.17226791381835938 s\n",
      "game 24 completed in 5.93610692024231 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.389819 entropy 1.9099903\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3736029 entropy 1.9077332\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.346654 entropy 1.9020629\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3172011 entropy 1.8944921\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.29272 entropy 1.8860106\n",
      "kl 0.015483176\n",
      "completed in 0.1928410530090332 s\n",
      "game 25 completed in 5.86696195602417 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.414676 entropy 1.8467432\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3966985 entropy 1.8408064\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3670175 entropy 1.837812\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3399215 entropy 1.8360562\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3145034 entropy 1.8349755\n",
      "kl 0.016810555\n",
      "completed in 0.16090011596679688 s\n",
      "game 26 completed in 6.6207239627838135 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.374349 entropy 1.8319767\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3539028 entropy 1.8341873\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3221896 entropy 1.8368057\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2899935 entropy 1.8385282\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.261649 entropy 1.838205\n",
      "kl 0.020580335\n",
      "completed in 0.17341208457946777 s\n",
      "game 27 completed in 6.624037742614746 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3839147 entropy 1.8398767\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.364518 entropy 1.8365654\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.337912 entropy 1.8312769\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3139865 entropy 1.8247033\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2906017 entropy 1.8178322\n",
      "kl 0.018838452\n",
      "completed in 0.17312312126159668 s\n",
      "game 28 completed in 14.778540134429932 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4748933 entropy 1.8702123\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.447197 entropy 1.8704114\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4155574 entropy 1.8725657\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3871949 entropy 1.8749883\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3577223 entropy 1.8762287\n",
      "kl 0.02722156\n",
      "completed in 0.16344499588012695 s\n",
      "game 29 completed in 12.44205379486084 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4371672 entropy 1.8302861\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4123821 entropy 1.8330294\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.378553 entropy 1.8370881\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3466039 entropy 1.8414674\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3192146 entropy 1.8442253\n",
      "kl 0.016415313\n",
      "completed in 0.24503707885742188 s\n",
      "game 30 completed in 8.243433952331543 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3954866 entropy 1.8259504\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3784854 entropy 1.8265016\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3463132 entropy 1.826128\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.305896 entropy 1.8256986\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.269039 entropy 1.8243124\n",
      "kl 0.022670379\n",
      "completed in 0.17645692825317383 s\n",
      "game 31 completed in 9.077414274215698 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4598734 entropy 1.8226843\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4236085 entropy 1.8199718\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3859835 entropy 1.8158069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3554993 entropy 1.8107517\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3303902 entropy 1.8058119\n",
      "kl 0.018578887\n",
      "completed in 0.2083289623260498 s\n",
      "game 32 completed in 6.020182847976685 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4716792 entropy 1.8337839\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4367695 entropy 1.8315074\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4095247 entropy 1.8300574\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3813531 entropy 1.8302541\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.349672 entropy 1.8316314\n",
      "kl 0.021846918\n",
      "completed in 0.17293787002563477 s\n",
      "game 33 completed in 5.8564910888671875 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3587542 entropy 1.855618\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.340951 entropy 1.8581711\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3227386 entropy 1.8611927\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3034103 entropy 1.8648548\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2814844 entropy 1.8687367\n",
      "kl 0.015771091\n",
      "completed in 0.17192673683166504 s\n",
      "game 34 completed in 10.686335802078247 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3285522 entropy 1.7733831\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3063562 entropy 1.7780526\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2767177 entropy 1.7824762\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2500913 entropy 1.7848842\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2266185 entropy 1.784508\n",
      "kl 0.019522797\n",
      "completed in 0.19866394996643066 s\n",
      "game 35 completed in 8.360580205917358 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4496958 entropy 1.8232504\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4370856 entropy 1.8226378\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4128172 entropy 1.8235433\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3831298 entropy 1.8250723\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3527284 entropy 1.8264399\n",
      "kl 0.017808305\n",
      "completed in 0.19915390014648438 s\n",
      "game 36 completed in 7.722959756851196 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.395788 entropy 1.9006791\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3780146 entropy 1.9006479\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3520243 entropy 1.9011483\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.32421 entropy 1.9023662\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.292897 entropy 1.9031525\n",
      "kl 0.01612264\n",
      "completed in 0.19130992889404297 s\n",
      "game 37 completed in 8.451066970825195 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3055155 entropy 1.7983843\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2868268 entropy 1.7997475\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.254827 entropy 1.8005731\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2198431 entropy 1.8004858\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1865559 entropy 1.7996175\n",
      "kl 0.01339882\n",
      "completed in 0.17093300819396973 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 38 completed in 9.268835067749023 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4234233 entropy 1.8598492\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.390618 entropy 1.8513565\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.351682 entropy 1.841669\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3218615 entropy 1.8352723\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2917285 entropy 1.8320441\n",
      "kl 0.018633341\n",
      "completed in 0.1748948097229004 s\n",
      "game 39 completed in 7.572691202163696 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.431999 entropy 1.8271692\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4134781 entropy 1.8306473\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.386154 entropy 1.8365798\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3532603 entropy 1.843919\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3192194 entropy 1.8526696\n",
      "kl 0.024366919\n",
      "completed in 0.18933987617492676 s\n",
      "game 40 completed in 15.522583961486816 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4036455 entropy 1.8744274\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.388367 entropy 1.8830752\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.360408 entropy 1.8888652\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3307676 entropy 1.8910189\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3023314 entropy 1.8895736\n",
      "kl 0.020116132\n",
      "completed in 0.16652512550354004 s\n",
      "game 41 completed in 9.253363847732544 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4937272 entropy 1.9161206\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4756951 entropy 1.9107757\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.446369 entropy 1.9053388\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4099758 entropy 1.9000759\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3696492 entropy 1.8947861\n",
      "kl 0.022306398\n",
      "completed in 0.17934060096740723 s\n",
      "game 42 completed in 7.289301872253418 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3767316 entropy 1.8298647\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3633792 entropy 1.8272057\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3404028 entropy 1.8248767\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3080983 entropy 1.8227766\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2742002 entropy 1.820075\n",
      "kl 0.022427432\n",
      "completed in 0.19396376609802246 s\n",
      "game 43 completed in 13.726608991622925 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.413646 entropy 1.8142793\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3841295 entropy 1.8118956\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.347568 entropy 1.8100674\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.313546 entropy 1.8083628\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2837865 entropy 1.8068358\n",
      "kl 0.02045204\n",
      "completed in 0.2035079002380371 s\n",
      "game 44 completed in 12.332274913787842 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3660357 entropy 1.8065228\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3513148 entropy 1.8086302\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3253565 entropy 1.8123045\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.298227 entropy 1.8165256\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2729053 entropy 1.8198564\n",
      "kl 0.020549338\n",
      "completed in 0.16342902183532715 s\n",
      "game 45 completed in 15.306810855865479 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4403157 entropy 1.898839\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4204278 entropy 1.9038323\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3883755 entropy 1.909676\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.355743 entropy 1.9141265\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3231342 entropy 1.9159019\n",
      "kl 0.021521881\n",
      "completed in 0.19976496696472168 s\n",
      "game 46 completed in 9.3357412815094 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4628258 entropy 1.9053091\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4412553 entropy 1.8997372\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4091697 entropy 1.8910738\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3800068 entropy 1.881808\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3547273 entropy 1.8735992\n",
      "kl 0.021207245\n",
      "completed in 0.1994931697845459 s\n",
      "game 47 completed in 10.926328897476196 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4717793 entropy 1.8449807\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4500985 entropy 1.8443334\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4180965 entropy 1.846689\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3866894 entropy 1.8506444\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.358719 entropy 1.8543713\n",
      "kl 0.024335016\n",
      "completed in 0.16546320915222168 s\n",
      "game 48 completed in 11.87419080734253 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4651954 entropy 1.8905139\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4369364 entropy 1.8949814\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.408944 entropy 1.8998604\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3838127 entropy 1.9027702\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3566053 entropy 1.9019978\n",
      "kl 0.021074958\n",
      "completed in 0.17575907707214355 s\n",
      "prediction:\n",
      " [0.00751735 0.00385579 0.00380681 0.00739144 0.00374884 0.00447187\n",
      " 0.00735146 0.25193483 0.04567729 0.01496815 0.01680879 0.00422098\n",
      " 0.00515966 0.03773494 0.07111294 0.01523821 0.01571907 0.01219031\n",
      " 0.00668142 0.00874598 0.01924966 0.07002977 0.03525814 0.00459916\n",
      " 0.00293611 0.01299575 0.00990465 0.03153957 0.23335612 0.00437215\n",
      " 0.00221032 0.00302781 0.00884886 0.00327774 0.00491788 0.0091403 ] \n",
      " -0.5623276\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.55569462e-01 1.83979975e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.36545682e-01 1.23904881e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [2.1983964e-04 3.7133228e-05 1.5538196e-03 5.4988352e-04 2.3909952e-04\n",
      " 1.5555134e-04 7.7732700e-05 3.2836127e-03 3.4656569e-02 5.1546499e-02\n",
      " 1.3173684e-03 2.7919837e-04 2.8618868e-04 3.7508618e-02 2.8815582e-02\n",
      " 2.6136193e-01 4.9017165e-02 2.3370807e-04 1.0581552e-04 1.3218574e-01\n",
      " 2.1225117e-01 2.9749162e-02 3.6540702e-02 8.6720282e-04 3.3570184e-05\n",
      " 2.3758956e-04 8.9852750e-02 2.3585003e-02 1.9118524e-03 7.4553609e-05\n",
      " 6.3628875e-05 5.9090315e-05 5.8653264e-04 5.3760060e-04 4.5866276e-05\n",
      " 1.7275401e-04] \n",
      " 0.35094693\n",
      "p [[0.0175219  0.00250313 0.00625782 0.01501877 0.00250313 0.00625782]\n",
      " [0.00500626 0.23404255 0.04130163 0.01126408 0.11138924 0.00375469]\n",
      " [0.00375469 0.05882353 0.         0.00876095 0.01251564 0.01501877]\n",
      " [0.00625782 0.00876095 0.01126408 0.17396746 0.02377972 0.00375469]\n",
      " [0.00250313 0.01376721 0.00876095 0.01627034 0.13767209 0.00375469]\n",
      " [0.00250313 0.00125156 0.00625782 0.00625782 0.00375469 0.01376721]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00271561 0.00174466 0.00329814 0.00068773 0.00116879 0.00358039\n",
      " 0.00222275 0.00124383 0.02305717 0.008453   0.00908384 0.00126379\n",
      " 0.01278494 0.23936711 0.0005843  0.00135116 0.16124865 0.00465309\n",
      " 0.00550977 0.20213659 0.00093116 0.00043368 0.2576009  0.01502033\n",
      " 0.00041501 0.00573431 0.01227949 0.01082735 0.00058878 0.00168935\n",
      " 0.00162142 0.00028273 0.00147793 0.00246547 0.00077033 0.00170654] \n",
      " -0.7379049\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 3.00375469e-02 1.62703379e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.25406758e-02 0.00000000e+00 3.94242804e-01\n",
      "  1.62703379e-02 1.25156446e-13]\n",
      " [1.25156446e-13 5.25657071e-02 3.55444305e-01 2.00250313e-02\n",
      "  1.50187735e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.38297872e-02 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.89280792e-04 2.64807368e-05 1.15628034e-04 1.72795029e-04\n",
      " 2.56835901e-05 1.44770456e-05 1.30431972e-05 1.30727800e-04\n",
      " 2.71289470e-03 1.32313941e-03 2.29169382e-03 9.00231680e-06\n",
      " 2.72542875e-05 1.37977477e-04 1.18895594e-04 4.04277962e-04\n",
      " 3.52460444e-01 5.68393152e-04 7.92375416e-04 6.33973956e-01\n",
      " 3.87270498e-04 5.19718633e-05 3.46783723e-04 1.51824370e-05\n",
      " 5.31088563e-06 4.69901599e-04 9.74706723e-04 1.87986100e-03\n",
      " 7.67413439e-05 3.48931712e-06 8.50204924e-06 5.59543059e-06\n",
      " 1.62066819e-04 5.14766143e-05 8.11944574e-06 4.48189130e-05] \n",
      " 0.84446234\n",
      "p [[0.00250313 0.00125156 0.00125156 0.00125156 0.00125156 0.00250313]\n",
      " [0.00125156 0.         0.04005006 0.00500626 0.00625782 0.00250313]\n",
      " [0.01126408 0.41301627 0.         0.         0.10638298 0.00250313]\n",
      " [0.00500626 0.15018773 0.00125156 0.00125156 0.19899875 0.01251564]\n",
      " [0.00125156 0.00250313 0.01126408 0.00625782 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00607504 0.04755528 0.01255693 0.00792306 0.01494695 0.00559147\n",
      " 0.02484033 0.00644149 0.08628371 0.1006389  0.01038203 0.00723711\n",
      " 0.00976311 0.04872163 0.00376589 0.07667346 0.01450852 0.04763274\n",
      " 0.07348581 0.0190827  0.04434573 0.00287124 0.02474486 0.01313056\n",
      " 0.00929249 0.01001371 0.09059829 0.13783115 0.00261532 0.00439878\n",
      " 0.00246466 0.00463367 0.00449904 0.00642767 0.0140759  0.00395099] \n",
      " -0.92478174\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.04005006e-01 1.25156446e-13]\n",
      " [1.25156446e-13 7.95994994e-01 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.4103326e-05 9.7916476e-05 1.9236057e-04 1.3058089e-03 1.8652132e-03\n",
      " 1.1173970e-04 1.5196235e-04 5.4316735e-04 5.8042648e-04 5.5473351e-01\n",
      " 1.6824285e-03 2.1476417e-03 3.4487445e-04 7.0623955e-04 2.1799283e-04\n",
      " 1.5054298e-04 3.0631223e-03 1.9331402e-03 1.5237130e-03 4.2070765e-03\n",
      " 1.6282468e-04 6.6005625e-05 3.3113599e-04 2.6311536e-04 4.2359908e-03\n",
      " 6.6887832e-04 4.1664356e-01 7.5700582e-04 4.7450527e-04 9.1291040e-06\n",
      " 5.0435348e-05 2.4040531e-04 3.6998375e-04 7.3002506e-05 2.4077208e-05\n",
      " 3.7041624e-05] \n",
      " -0.52327967\n",
      "p [[0.00500626 0.02628285 0.00750939 0.04630788 0.00750939 0.00250313]\n",
      " [0.0175219  0.         0.28035044 0.21276596 0.00876095 0.00625782]\n",
      " [0.00876095 0.         0.         0.         0.00876095 0.0387985 ]\n",
      " [0.04881101 0.         0.06132666 0.00125156 0.01501877 0.01001252]\n",
      " [0.00625782 0.00625782 0.0563204  0.09011264 0.00250313 0.00250313]\n",
      " [0.00250313 0.00250313 0.00250313 0.00500626 0.00750939 0.00250313]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00292258 0.03906579 0.00788437 0.12646647 0.05248994 0.0057625\n",
      " 0.12569024 0.00830971 0.00231399 0.0173521  0.00685949 0.033486\n",
      " 0.01058413 0.05479634 0.00554954 0.01210709 0.02338554 0.08838413\n",
      " 0.08218127 0.0140971  0.00481411 0.00767449 0.00853976 0.00734073\n",
      " 0.03839551 0.00485119 0.01566351 0.01124188 0.00705066 0.02106047\n",
      " 0.00075564 0.0326631  0.08242482 0.00606314 0.02818197 0.00359066] \n",
      " -0.9996681\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 9.54943680e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.50563204e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.5909776e-04 8.8708289e-04 2.7400821e-03 6.1286040e-02 1.3122648e-01\n",
      " 6.3091854e-04 1.3124603e-03 1.4815618e-03 1.5488338e-03 2.8301962e-03\n",
      " 6.7609421e-04 4.5947480e-01 2.3759091e-03 8.1603992e-04 1.1918367e-03\n",
      " 1.8140655e-04 2.3895307e-03 1.0242845e-03 1.3360080e-04 1.4070650e-03\n",
      " 7.6453893e-05 1.0144591e-03 2.9719717e-04 7.6373405e-04 2.4705024e-01\n",
      " 9.8210503e-04 1.8193775e-03 3.4973682e-03 7.9228287e-04 7.5956290e-05\n",
      " 1.1174343e-04 4.0789772e-02 2.7993245e-02 5.4497947e-04 2.4634047e-04\n",
      " 1.7156417e-04] \n",
      " 0.987421\n",
      "p [[0.00125156 0.04505632 0.00750939 0.14392991 0.0350438  0.00250313]\n",
      " [0.1339174  0.         0.         0.         0.00375469 0.0212766 ]\n",
      " [0.0212766  0.         0.         0.         0.02753442 0.11013767]\n",
      " [0.18147685 0.         0.00250313 0.00375469 0.01376721 0.00750939]\n",
      " [0.03128911 0.00250313 0.01251564 0.01251564 0.00375469 0.02002503]\n",
      " [0.00125156 0.04755945 0.0738423  0.00876095 0.02252816 0.00125156]]\n",
      "move 18\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [-1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.9822043e-03 1.8297717e-02 3.2171153e-03 2.8898814e-01 5.0500347e-03\n",
      " 1.4826552e-03 1.3300420e-01 2.3020229e-03 9.6018119e-03 1.5781293e-02\n",
      " 4.5222309e-03 4.5560696e-03 4.6840324e-03 2.7338466e-02 1.1947824e-03\n",
      " 1.0932471e-03 1.1605021e-02 7.0911935e-03 1.2922062e-02 9.3766050e-03\n",
      " 4.0322929e-04 2.4435958e-03 4.1183550e-03 3.4608578e-03 2.5294593e-03\n",
      " 2.4521458e-03 1.1368844e-02 4.9725074e-02 1.9018932e-03 2.2598339e-02\n",
      " 1.6731281e-04 6.8482687e-03 2.7945477e-01 2.4867977e-03 3.8487896e-02\n",
      " 6.4623095e-03] \n",
      " -0.9980533\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.50187735e-02\n",
      "  3.19148936e-01 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 5.38172716e-02]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [6.00750939e-01 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 5.00625782e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 24\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [-1.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 49 completed in 22.928574800491333 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.471415 entropy 1.8567244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4487314 entropy 1.8463112\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4215991 entropy 1.8342371\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.392506 entropy 1.8234627\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.360696 entropy 1.8166306\n",
      "kl 0.028504368\n",
      "completed in 0.16802716255187988 s\n",
      "game 50 completed in 5.910678863525391 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4541461 entropy 1.8630993\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4323301 entropy 1.8681958\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3999448 entropy 1.8804011\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3686814 entropy 1.8963994\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.337605 entropy 1.9129106\n",
      "kl 0.02547069\n",
      "completed in 0.1718301773071289 s\n",
      "game 51 completed in 7.488893032073975 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3764586 entropy 1.9053123\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3626103 entropy 1.9162767\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.337796 entropy 1.9230082\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.307886 entropy 1.9251957\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2807977 entropy 1.923027\n",
      "kl 0.022270026\n",
      "completed in 0.17081189155578613 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 52 completed in 9.291576147079468 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.362565 entropy 1.857205\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3443906 entropy 1.8506943\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3173208 entropy 1.8419788\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2894666 entropy 1.8329871\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2631218 entropy 1.8249424\n",
      "kl 0.027903572\n",
      "completed in 0.17203474044799805 s\n",
      "game 53 completed in 9.10146713256836 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3557122 entropy 1.8456764\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.332558 entropy 1.845968\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3032708 entropy 1.8510399\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2739837 entropy 1.8592855\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.243502 entropy 1.8685122\n",
      "kl 0.024318121\n",
      "completed in 0.16961216926574707 s\n",
      "game 54 completed in 11.787399053573608 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3042326 entropy 1.836637\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2860012 entropy 1.8422761\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2593577 entropy 1.8441969\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2340622 entropy 1.8425257\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.209945 entropy 1.8387873\n",
      "kl 0.022383528\n",
      "completed in 0.14927411079406738 s\n",
      "game 55 completed in 11.960553884506226 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3666053 entropy 1.8913267\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.348548 entropy 1.8854988\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3176315 entropy 1.8777274\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.282807 entropy 1.8700951\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2528222 entropy 1.8639997\n",
      "kl 0.021468662\n",
      "completed in 0.16364574432373047 s\n",
      "game 56 completed in 12.429849863052368 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4233534 entropy 1.8836389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4008899 entropy 1.8857946\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3675458 entropy 1.8891523\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.335085 entropy 1.8914746\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.300493 entropy 1.8913606\n",
      "kl 0.01918936\n",
      "completed in 0.18598675727844238 s\n",
      "game 57 completed in 16.24475598335266 s 20 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4163234 entropy 1.8564912\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3993645 entropy 1.854874\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3717253 entropy 1.8525178\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3417351 entropy 1.8505034\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.317304 entropy 1.848005\n",
      "kl 0.019577175\n",
      "completed in 0.17098331451416016 s\n",
      "game 58 completed in 7.537974834442139 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.39764 entropy 1.814387\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3861067 entropy 1.8130951\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.365203 entropy 1.813098\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3397973 entropy 1.8135765\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.313502 entropy 1.8136668\n",
      "kl 0.019044735\n",
      "completed in 0.1989450454711914 s\n",
      "game 59 completed in 11.773300170898438 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5059705 entropy 1.9226825\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4839804 entropy 1.9248964\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4500542 entropy 1.9270128\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4154823 entropy 1.9272629\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.382557 entropy 1.9240947\n",
      "kl 0.019450355\n",
      "completed in 0.17309999465942383 s\n",
      "game 60 completed in 9.3215491771698 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5083506 entropy 1.9043745\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4647908 entropy 1.8921146\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4313245 entropy 1.8814344\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3996527 entropy 1.8750261\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3586347 entropy 1.8726482\n",
      "kl 0.02396526\n",
      "completed in 0.16492390632629395 s\n",
      "game 61 completed in 10.69720196723938 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4726002 entropy 1.897803\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4473171 entropy 1.8970422\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4204817 entropy 1.8957138\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3963962 entropy 1.892092\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3717363 entropy 1.8866475\n",
      "kl 0.02638353\n",
      "completed in 0.20431208610534668 s\n",
      "game 62 completed in 6.001206159591675 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4349298 entropy 1.8670639\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4209676 entropy 1.8694655\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3938422 entropy 1.8767545\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3645248 entropy 1.8857416\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3345423 entropy 1.8933997\n",
      "kl 0.025091402\n",
      "completed in 0.1721959114074707 s\n",
      "game 63 completed in 7.5226287841796875 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4625506 entropy 1.8390367\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4343522 entropy 1.8430684\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3952346 entropy 1.8449442\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3671014 entropy 1.8458875\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3412876 entropy 1.846452\n",
      "kl 0.025016252\n",
      "completed in 0.22693204879760742 s\n",
      "game 64 completed in 10.710608005523682 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4615645 entropy 1.8525741\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4344418 entropy 1.8482598\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4026299 entropy 1.8444889\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3755698 entropy 1.8438258\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3472075 entropy 1.8479135\n",
      "kl 0.01873361\n",
      "completed in 0.17390990257263184 s\n",
      "game 65 completed in 5.938150882720947 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3558831 entropy 1.8346756\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3289628 entropy 1.8454769\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2995913 entropy 1.856852\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2727375 entropy 1.8660386\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.248478 entropy 1.8708117\n",
      "kl 0.02326973\n",
      "completed in 0.2161710262298584 s\n",
      "game 66 completed in 12.158099889755249 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3800125 entropy 1.9211537\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3667917 entropy 1.9213632\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.343156 entropy 1.9198487\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.317181 entropy 1.9163597\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2925932 entropy 1.910666\n",
      "kl 0.018664619\n",
      "completed in 0.19172096252441406 s\n",
      "game 67 completed in 8.350984811782837 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3667483 entropy 1.8674603\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3458097 entropy 1.8604624\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3200123 entropy 1.8539758\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2913873 entropy 1.8495948\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2612858 entropy 1.8469863\n",
      "kl 0.021148758\n",
      "completed in 0.18819403648376465 s\n",
      "game 68 completed in 11.291470766067505 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3101604 entropy 1.8628905\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2994087 entropy 1.8626759\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.279039 entropy 1.8639786\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2540066 entropy 1.865864\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2284756 entropy 1.8674675\n",
      "kl 0.019229509\n",
      "completed in 0.20557594299316406 s\n",
      "game 69 completed in 9.817609071731567 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4659553 entropy 1.8704262\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4319386 entropy 1.8702979\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3921702 entropy 1.8688793\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3551202 entropy 1.8635039\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3208046 entropy 1.854661\n",
      "kl 0.029155714\n",
      "completed in 0.16248798370361328 s\n",
      "game 70 completed in 7.5659849643707275 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3711646 entropy 1.8109806\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3492136 entropy 1.8039751\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3198996 entropy 1.7994766\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2909758 entropy 1.798684\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2637908 entropy 1.8013699\n",
      "kl 0.014895685\n",
      "completed in 0.18808794021606445 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 71 completed in 7.547907829284668 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4118168 entropy 1.8711455\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.395919 entropy 1.8812113\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3697946 entropy 1.8935498\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.340878 entropy 1.905209\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3124058 entropy 1.9138877\n",
      "kl 0.02628551\n",
      "completed in 0.16987085342407227 s\n",
      "game 72 completed in 8.8195059299469 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5109959 entropy 1.9095949\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4839396 entropy 1.9094102\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.442263 entropy 1.9056025\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3958821 entropy 1.8996819\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3542814 entropy 1.8924589\n",
      "kl 0.024313647\n",
      "completed in 0.17635798454284668 s\n",
      "game 73 completed in 8.846415758132935 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4734473 entropy 1.8875746\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4581418 entropy 1.8776067\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4331994 entropy 1.8703486\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4021072 entropy 1.8656745\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3658254 entropy 1.8625846\n",
      "kl 0.023864485\n",
      "completed in 0.17116713523864746 s\n",
      "game 74 completed in 6.656867980957031 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.405065 entropy 1.8370967\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3841648 entropy 1.8413937\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.346941 entropy 1.8469634\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.306469 entropy 1.8521932\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2672207 entropy 1.8554478\n",
      "kl 0.028615627\n",
      "completed in 0.1868281364440918 s\n",
      "game 75 completed in 8.33263111114502 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5364692 entropy 1.8947551\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5148098 entropy 1.8985605\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.488453 entropy 1.9018016\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4632082 entropy 1.9029042\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4359438 entropy 1.901341\n",
      "kl 0.019516965\n",
      "completed in 0.16610097885131836 s\n",
      "game 76 completed in 8.499303102493286 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4867156 entropy 1.9181907\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4554763 entropy 1.9163677\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.41483 entropy 1.9141531\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.374439 entropy 1.9109328\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3429022 entropy 1.9061193\n",
      "kl 0.04626316\n",
      "completed in 0.20628881454467773 s\n",
      "game 77 completed in 7.569537878036499 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3889828 entropy 1.830991\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3759496 entropy 1.8272873\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.352355 entropy 1.8239028\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3254783 entropy 1.8207655\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.298241 entropy 1.8173152\n",
      "kl 0.014976382\n",
      "completed in 0.1684732437133789 s\n",
      "game 78 completed in 17.506058931350708 s 21 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5848982 entropy 1.9373965\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5577364 entropy 1.9327549\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.520244 entropy 1.9265244\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4826863 entropy 1.9208407\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4466047 entropy 1.9164429\n",
      "kl 0.019792013\n",
      "completed in 0.19001126289367676 s\n",
      "game 79 completed in 8.38804578781128 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3213348 entropy 1.8133717\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3011684 entropy 1.8151857\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.2726495 entropy 1.8187965\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2463567 entropy 1.8238094\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.224235 entropy 1.8292313\n",
      "kl 0.01780688\n",
      "completed in 0.1650848388671875 s\n",
      "game 80 completed in 5.927944898605347 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.433241 entropy 1.889457\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4156349 entropy 1.8952725\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3881664 entropy 1.9014691\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3619692 entropy 1.9071505\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3361163 entropy 1.9116211\n",
      "kl 0.0114423055\n",
      "completed in 0.17496991157531738 s\n",
      "game 81 completed in 6.889753818511963 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.424416 entropy 1.8149861\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.4042366 entropy 1.8136332\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3716133 entropy 1.8110907\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3374882 entropy 1.8080282\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.307188 entropy 1.8048214\n",
      "kl 0.011952985\n",
      "completed in 0.17512106895446777 s\n",
      "game 82 completed in 8.314842700958252 s 10 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4565964 entropy 1.8687148\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.43781 entropy 1.8670505\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4108205 entropy 1.8671187\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3841815 entropy 1.8688327\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3599164 entropy 1.8708351\n",
      "kl 0.016585635\n",
      "completed in 0.16645073890686035 s\n",
      "game 83 completed in 6.844291925430298 s 8 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3956184 entropy 1.80751\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.3794396 entropy 1.8082538\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3549554 entropy 1.8059967\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3322744 entropy 1.8017739\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3125842 entropy 1.7965082\n",
      "kl 0.013842877\n",
      "completed in 0.18871402740478516 s\n",
      "game 84 completed in 11.294393062591553 s 14 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3755083 entropy 1.8504977\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.363536 entropy 1.8459496\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.3413987 entropy 1.841701\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3156397 entropy 1.8377619\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2906477 entropy 1.83431\n",
      "kl 0.011493973\n",
      "completed in 0.16455793380737305 s\n",
      "game 85 completed in 10.709699869155884 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5229163 entropy 1.8763398\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5042155 entropy 1.8790069\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4751859 entropy 1.8841631\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4432733 entropy 1.8903966\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4101458 entropy 1.8962067\n",
      "kl 0.014810337\n",
      "completed in 0.1716160774230957 s\n",
      "game 86 completed in 10.372278928756714 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.469508 entropy 1.8662546\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.456476 entropy 1.8691045\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4351826 entropy 1.8707755\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.4103272 entropy 1.8716888\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3832421 entropy 1.8717989\n",
      "kl 0.013268471\n",
      "completed in 0.1730790138244629 s\n",
      "game 87 completed in 9.371883630752563 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.4416194 entropy 1.8114572\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.427235 entropy 1.810729\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.4026437 entropy 1.8094633\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.3740294 entropy 1.8079824\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.3485096 entropy 1.806447\n",
      "kl 0.013553822\n",
      "completed in 0.22743487358093262 s\n",
      "game 88 completed in 9.181699991226196 s 11 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.3052096 entropy 1.8321668\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.287631 entropy 1.8304404\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.2631798 entropy 1.8276579\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.2405405 entropy 1.8250127\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.2182465 entropy 1.8224429\n",
      "kl 0.009006297\n",
      "completed in 0.21175503730773926 s\n",
      "game 89 completed in 10.615990161895752 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.391204 entropy 1.8318462\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3703265 entropy 1.830218\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3398483 entropy 1.8291026\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3076427 entropy 1.8274649\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.277476 entropy 1.8250678\n",
      "kl 0.026079223\n",
      "completed in 0.17876982688903809 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 90 completed in 5.8250579833984375 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5004854 entropy 1.8389347\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.486095 entropy 1.8376791\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.457781 entropy 1.8383844\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4283216 entropy 1.8411115\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3988926 entropy 1.8450136\n",
      "kl 0.027025297\n",
      "completed in 0.20171904563903809 s\n",
      "game 91 completed in 6.8718860149383545 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.34265 entropy 1.8235624\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3272216 entropy 1.8243375\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3066251 entropy 1.822216\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2834935 entropy 1.8189228\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2568264 entropy 1.8153827\n",
      "kl 0.016904786\n",
      "completed in 0.17990493774414062 s\n",
      "game 92 completed in 15.01402997970581 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4878237 entropy 1.8133819\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4566414 entropy 1.8149841\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4150827 entropy 1.817363\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3772013 entropy 1.819894\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3457527 entropy 1.8227503\n",
      "kl 0.02624913\n",
      "completed in 0.17342305183410645 s\n",
      "game 93 completed in 6.025133848190308 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4157472 entropy 1.8192091\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3961306 entropy 1.8271399\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3636522 entropy 1.836806\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3307962 entropy 1.846867\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.301494 entropy 1.8545845\n",
      "kl 0.026388202\n",
      "completed in 0.17829108238220215 s\n",
      "game 94 completed in 7.610170125961304 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5189888 entropy 1.8666394\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4928286 entropy 1.8664995\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4528227 entropy 1.8626912\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.412837 entropy 1.8554631\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3736238 entropy 1.8460108\n",
      "kl 0.026920315\n",
      "completed in 0.1640300750732422 s\n",
      "game 95 completed in 6.0851640701293945 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3698802 entropy 1.7935283\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3481197 entropy 1.7872715\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3161223 entropy 1.784946\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.282243 entropy 1.7868172\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2555418 entropy 1.7920024\n",
      "kl 0.017297726\n",
      "completed in 0.19675016403198242 s\n",
      "game 96 completed in 10.868079900741577 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.46142 entropy 1.8561326\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.436025 entropy 1.866878\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.397871 entropy 1.8765712\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.359294 entropy 1.8834057\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.322397 entropy 1.8864685\n",
      "kl 0.032427344\n",
      "completed in 0.16680908203125 s\n",
      "game 97 completed in 7.623484134674072 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4281416 entropy 1.8769937\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4067583 entropy 1.8725156\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.378356 entropy 1.8636044\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3484366 entropy 1.850917\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3154674 entropy 1.8358786\n",
      "kl 0.027972672\n",
      "completed in 0.1752009391784668 s\n",
      "game 98 completed in 12.975618124008179 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5053077 entropy 1.838063\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4759405 entropy 1.8309569\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4358728 entropy 1.8271371\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.397533 entropy 1.8254285\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.362561 entropy 1.8250179\n",
      "kl 0.03048937\n",
      "completed in 0.18950176239013672 s\n",
      "prediction:\n",
      " [0.00344478 0.00339238 0.00540485 0.00283417 0.00346683 0.00625515\n",
      " 0.00464272 0.02416311 0.02178936 0.03760143 0.21480538 0.00270305\n",
      " 0.00849565 0.01302645 0.01289166 0.12301189 0.02362965 0.00241692\n",
      " 0.00417665 0.02342208 0.09652419 0.016552   0.00895421 0.00710657\n",
      " 0.0037847  0.22094366 0.02298459 0.01133528 0.0295565  0.00637098\n",
      " 0.00805166 0.00385816 0.00475111 0.01019912 0.00378982 0.00366336] \n",
      " -0.3696624\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.76470588e-01 3.36670839e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.34042553e-01 2.52816020e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.3498611e-05 3.7076752e-05 1.8897021e-04 2.3070085e-04 1.4791568e-05\n",
      " 2.2827876e-04 8.4915846e-05 9.0730353e-04 4.6590157e-02 3.0135098e-03\n",
      " 1.4211686e-03 2.3366092e-05 2.1550636e-04 3.8933132e-02 1.9013026e-01\n",
      " 9.0240605e-02 2.4523751e-03 1.1510005e-04 1.4013654e-04 3.2079807e-03\n",
      " 8.3644189e-02 4.1296446e-01 6.6976070e-02 1.5269947e-04 4.4021966e-05\n",
      " 2.0199283e-03 2.0291533e-03 5.2146304e-02 6.5323547e-04 1.0103152e-04\n",
      " 3.3768042e-04 1.3229759e-05 3.3145351e-04 3.3259628e-04 1.7968259e-05\n",
      " 2.7391896e-05] \n",
      " 0.6005586\n",
      "p [[0.00375469 0.00375469 0.00625782 0.00250313 0.00375469 0.06257822]\n",
      " [0.00750939 0.01877347 0.01251564 0.02252816 0.21151439 0.00625782]\n",
      " [0.00876095 0.01126408 0.00876095 0.         0.01501877 0.00625782]\n",
      " [0.00500626 0.01877347 0.15519399 0.00876095 0.00625782 0.01376721]\n",
      " [0.00375469 0.21652065 0.0175219  0.01001252 0.05757196 0.00750939]\n",
      " [0.03254068 0.00250313 0.00625782 0.01376721 0.00625782 0.00625782]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00185948 0.00083916 0.00339266 0.00887042 0.00133019 0.00977405\n",
      " 0.00150724 0.01116382 0.03080085 0.07470053 0.00348834 0.00215607\n",
      " 0.0090102  0.25410622 0.00195685 0.00154714 0.0965258  0.01283119\n",
      " 0.01885515 0.08094295 0.00106789 0.00222543 0.19461092 0.01030813\n",
      " 0.00128514 0.00253774 0.09706455 0.02685477 0.01033865 0.00175533\n",
      " 0.00474701 0.00114826 0.01345583 0.00388941 0.0007217  0.00233107] \n",
      " -0.9231309\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.50688360e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-02 3.31664581e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.88360451e-02 2.97872340e-01\n",
      "  1.63954944e-01 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 5.75719650e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.5305380e-05 4.5033198e-06 1.6360676e-05 2.1043898e-05 6.4187243e-06\n",
      " 1.1578665e-05 5.1947504e-06 2.4193227e-03 2.6404569e-03 4.6339669e-04\n",
      " 5.4209897e-05 3.0529570e-06 2.0906913e-05 1.3563666e-04 2.9379441e-03\n",
      " 9.7928802e-05 5.5180299e-01 5.3232863e-05 1.0133384e-04 4.2806756e-01\n",
      " 1.3597080e-04 5.8268211e-03 2.1279321e-04 1.6707801e-05 3.9098109e-06\n",
      " 2.4588900e-05 1.7267164e-04 2.6226372e-03 1.9785766e-03 6.4051064e-06\n",
      " 6.1344931e-06 2.8124057e-06 2.7759937e-05 3.4370081e-05 1.2084822e-06\n",
      " 1.8347149e-05] \n",
      " 0.6455301\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00500626 0.00125156 0.00500626]\n",
      " [0.00125156 0.00750939 0.03003755 0.05006258 0.00250313 0.00125156]\n",
      " [0.00500626 0.37421777 0.         0.         0.10262829 0.00625782]\n",
      " [0.01126408 0.07509387 0.00500626 0.00125156 0.12015019 0.00500626]\n",
      " [0.00125156 0.         0.14392991 0.01877347 0.00500626 0.00125156]\n",
      " [0.00250313 0.00125156 0.00750939 0.00125156 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00234033 0.00232562 0.00464861 0.00806925 0.00355489 0.00313719\n",
      " 0.00426897 0.03334735 0.15179372 0.152657   0.00203892 0.01538797\n",
      " 0.00385348 0.00966678 0.00406068 0.03339266 0.04632369 0.03902065\n",
      " 0.04686571 0.03279524 0.04042937 0.00352086 0.00910631 0.00561556\n",
      " 0.0164599  0.00221803 0.11610379 0.15612696 0.01831784 0.00174765\n",
      " 0.00144221 0.00530489 0.01130788 0.00736889 0.00162686 0.00375439] \n",
      " -0.92650956\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.24155194e-01 1.25156446e-13]\n",
      " [1.25156446e-13 6.75844806e-01 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.40923643e-04 1.07723026e-04 6.07034075e-04 6.29268761e-04\n",
      " 1.25622377e-04 4.79813425e-05 2.22152274e-04 9.95355379e-03\n",
      " 2.29028898e-04 6.90945685e-01 3.26669135e-04 1.13064027e-03\n",
      " 3.38058715e-04 7.34702509e-04 8.13113619e-03 3.01867141e-03\n",
      " 2.20627571e-03 2.11935519e-04 3.29357805e-04 6.10681437e-03\n",
      " 1.73841638e-03 4.16660076e-03 4.15541435e-04 1.14720548e-03\n",
      " 2.59736320e-03 1.31398745e-04 2.54938632e-01 3.28331342e-04\n",
      " 7.85527099e-03 1.15564646e-04 5.00951901e-05 1.38715273e-04\n",
      " 3.18473147e-04 3.44502827e-04 4.55607587e-05 1.25174993e-04] \n",
      " 0.86868083\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00750939 0.00125156 0.00125156]\n",
      " [0.00250313 0.01877347 0.16020025 0.13266583 0.00125156 0.00750939]\n",
      " [0.00250313 0.         0.         0.         0.02628285 0.03379224]\n",
      " [0.03128911 0.         0.04005006 0.00125156 0.00500626 0.00250313]\n",
      " [0.01251564 0.         0.13642053 0.33917397 0.01001252 0.00125156]\n",
      " [0.00125156 0.00500626 0.00625782 0.00375469 0.00250313 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00182867 0.0088614  0.00640311 0.01787147 0.00937661 0.00325794\n",
      " 0.03455326 0.13990864 0.00521968 0.2753752  0.00078674 0.10099834\n",
      " 0.00532396 0.00166663 0.00090313 0.00204199 0.00624737 0.00258158\n",
      " 0.00275948 0.00478205 0.00225327 0.00124031 0.00073325 0.0106466\n",
      " 0.11134097 0.00129966 0.09232471 0.00474837 0.04832431 0.01281337\n",
      " 0.00236998 0.04254943 0.02782658 0.00288426 0.00462882 0.00326903] \n",
      " -0.9879325\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 9.36170213e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 4.00500626e-02 0.00000000e+00\n",
      "  2.25281602e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.3373197e-04 4.5836807e-04 2.1872325e-03 8.6078333e-04 3.2868303e-02\n",
      " 5.9684395e-04 3.1030090e-03 8.3697192e-02 8.4706197e-05 3.3614251e-03\n",
      " 2.2131109e-04 2.6222354e-01 1.2359407e-03 6.2796572e-04 1.2022628e-03\n",
      " 4.3091757e-04 5.9863733e-04 1.4571019e-04 1.1640596e-04 8.7644916e-04\n",
      " 2.6278282e-04 3.1365172e-03 4.5466766e-04 8.7190809e-04 4.8456004e-01\n",
      " 1.0225472e-04 1.6671179e-03 2.4702106e-04 5.9510551e-02 2.9737325e-04\n",
      " 3.2715863e-04 5.1334031e-02 2.1350059e-04 1.6250915e-03 1.7783388e-04\n",
      " 1.8136174e-04] \n",
      " 0.004094693\n",
      "p [[0.00250313 0.00625782 0.05882353 0.08635795 0.00625782 0.00250313]\n",
      " [0.04630788 0.14518148 0.00375469 0.         0.00125156 0.09887359]\n",
      " [0.00375469 0.         0.         0.         0.00375469 0.00125156]\n",
      " [0.00125156 0.         0.00250313 0.00125156 0.00125156 0.01251564]\n",
      " [0.1514393  0.         0.17146433 0.         0.077597   0.00876095]\n",
      " [0.00375469 0.06382979 0.02753442 0.00125156 0.00375469 0.00500626]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.4543295e-04 2.4496342e-04 1.2967441e-03 1.1524427e-03 1.0284975e-03\n",
      " 2.4648383e-04 2.9720087e-03 7.0022279e-01 1.7392124e-03 1.0604828e-04\n",
      " 2.1320638e-04 1.5442617e-03 3.3421311e-04 2.0924146e-05 2.6232938e-04\n",
      " 2.7592941e-05 1.4310751e-04 9.5596719e-05 2.8241487e-04 1.8902986e-04\n",
      " 1.4865244e-05 4.5797459e-04 1.7528138e-05 8.0102292e-04 3.2326342e-03\n",
      " 3.1905196e-04 7.4845193e-05 1.3425418e-03 2.7355078e-01 1.3108185e-03\n",
      " 1.6415684e-04 3.1347470e-03 2.2731898e-03 7.2595046e-04 1.5744919e-04\n",
      " 1.5516480e-04] \n",
      " -0.8752407\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  6.00750939e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.00125156e-02 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 2.50312891e-02]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [8.92365457e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 24\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 1. -1. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 99 completed in 21.05586886405945 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4555216 entropy 1.8758996\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4291375 entropy 1.8783193\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3966067 entropy 1.880295\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.36648 entropy 1.881558\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3337262 entropy 1.8812951\n",
      "kl 0.025929399\n",
      "completed in 0.16229486465454102 s\n",
      "game 100 completed in 6.638900995254517 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4666004 entropy 1.8170116\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4441092 entropy 1.8142831\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4089313 entropy 1.8094306\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.374431 entropy 1.803645\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3403444 entropy 1.7979\n",
      "kl 0.021251544\n",
      "completed in 0.17788124084472656 s\n",
      "game 101 completed in 5.832773208618164 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4207642 entropy 1.7890162\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3855731 entropy 1.788465\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3446827 entropy 1.7897481\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3081837 entropy 1.7918245\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2727344 entropy 1.7940496\n",
      "kl 0.027855814\n",
      "completed in 0.1640310287475586 s\n",
      "game 102 completed in 7.5898778438568115 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3424947 entropy 1.7915518\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3172581 entropy 1.7973064\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2846313 entropy 1.8041487\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.25677 entropy 1.8101193\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2308474 entropy 1.8140599\n",
      "kl 0.016490778\n",
      "completed in 0.17325091361999512 s\n",
      "game 103 completed in 8.996683120727539 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4674842 entropy 1.8485097\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4395947 entropy 1.8520666\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.401685 entropy 1.8558547\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3640392 entropy 1.8589478\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.336427 entropy 1.8591233\n",
      "kl 0.0250959\n",
      "completed in 0.18640422821044922 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 104 completed in 11.641247987747192 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3755262 entropy 1.8634944\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.349959 entropy 1.8604274\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3217783 entropy 1.8575082\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2939525 entropy 1.8564081\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2614276 entropy 1.8579286\n",
      "kl 0.020473044\n",
      "completed in 0.19711995124816895 s\n",
      "game 105 completed in 6.669168710708618 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3279526 entropy 1.8176568\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3002536 entropy 1.8189695\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2629106 entropy 1.8188967\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2273445 entropy 1.8176446\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.1983814 entropy 1.8141339\n",
      "kl 0.027779087\n",
      "completed in 0.19162273406982422 s\n",
      "game 106 completed in 16.996073007583618 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4595752 entropy 1.8889759\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4370756 entropy 1.8867049\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.402866 entropy 1.8842251\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.36902 entropy 1.8804388\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3404925 entropy 1.8765103\n",
      "kl 0.021245258\n",
      "completed in 0.16896605491638184 s\n",
      "game 107 completed in 7.642608165740967 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4634113 entropy 1.8444357\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.436979 entropy 1.8378396\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4004965 entropy 1.8300457\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3645086 entropy 1.8221602\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3306437 entropy 1.814266\n",
      "kl 0.02190749\n",
      "completed in 0.17129802703857422 s\n",
      "game 108 completed in 5.976971864700317 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4699826 entropy 1.754213\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4430459 entropy 1.7510909\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3983848 entropy 1.7514386\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3515577 entropy 1.7551532\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3127227 entropy 1.762383\n",
      "kl 0.022023764\n",
      "completed in 0.1722261905670166 s\n",
      "game 109 completed in 9.270348072052002 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4995701 entropy 1.8346535\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.477937 entropy 1.849134\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4383316 entropy 1.866585\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.394265 entropy 1.8838612\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3622954 entropy 1.8975188\n",
      "kl 0.021880973\n",
      "completed in 0.17771291732788086 s\n",
      "game 110 completed in 13.306852102279663 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.457994 entropy 1.8447657\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4305408 entropy 1.8485062\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3891623 entropy 1.8472228\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3512728 entropy 1.8417919\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3175552 entropy 1.8330071\n",
      "kl 0.02172456\n",
      "completed in 0.16907286643981934 s\n",
      "game 111 completed in 11.34612774848938 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4765759 entropy 1.8599285\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.461506 entropy 1.8554101\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.437806 entropy 1.854001\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4114661 entropy 1.8525846\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.380073 entropy 1.8486264\n",
      "kl 0.02092738\n",
      "completed in 0.1724259853363037 s\n",
      "game 112 completed in 17.431591987609863 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3852582 entropy 1.8332208\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3652623 entropy 1.8274764\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3378446 entropy 1.8213696\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3085387 entropy 1.8150935\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2807884 entropy 1.8081523\n",
      "kl 0.022241715\n",
      "completed in 0.1996479034423828 s\n",
      "game 113 completed in 8.405616283416748 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4272935 entropy 1.7484918\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4007344 entropy 1.7383871\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.362487 entropy 1.7267313\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3237774 entropy 1.7166958\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.284265 entropy 1.7088168\n",
      "kl 0.023911353\n",
      "completed in 0.19101381301879883 s\n",
      "game 114 completed in 10.731861114501953 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5280485 entropy 1.7654268\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4913137 entropy 1.7688046\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.454936 entropy 1.7777379\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.425853 entropy 1.7887367\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3903904 entropy 1.7995758\n",
      "kl 0.025430363\n",
      "completed in 0.18085813522338867 s\n",
      "game 115 completed in 8.985415935516357 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4898694 entropy 1.7944958\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.462195 entropy 1.8051186\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4237285 entropy 1.8160231\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3832848 entropy 1.824781\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3445854 entropy 1.8295329\n",
      "kl 0.020671263\n",
      "completed in 0.16933202743530273 s\n",
      "game 116 completed in 8.536364078521729 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4786732 entropy 1.8272494\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4492414 entropy 1.8257804\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4070005 entropy 1.8195977\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3724945 entropy 1.812907\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3386464 entropy 1.8091835\n",
      "kl 0.021259882\n",
      "completed in 0.17080211639404297 s\n",
      "game 117 completed in 9.682443857192993 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5330791 entropy 1.8407886\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4892519 entropy 1.8444817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.449687 entropy 1.8501575\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4115665 entropy 1.8549412\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3786285 entropy 1.8570318\n",
      "kl 0.018653482\n",
      "completed in 0.1692190170288086 s\n",
      "game 118 completed in 10.788429021835327 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4983249 entropy 1.8386316\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4421682 entropy 1.8319416\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.390407 entropy 1.823381\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3597312 entropy 1.8161767\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3300164 entropy 1.8115821\n",
      "kl 0.03283198\n",
      "completed in 0.20685195922851562 s\n",
      "game 119 completed in 7.601673126220703 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4388347 entropy 1.7490785\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.411361 entropy 1.7516737\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3703203 entropy 1.7552638\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3250806 entropy 1.7576029\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2861254 entropy 1.7575316\n",
      "kl 0.019066857\n",
      "completed in 0.19558405876159668 s\n",
      "game 120 completed in 6.0537049770355225 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4142978 entropy 1.790519\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3901312 entropy 1.7869529\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3562138 entropy 1.7834281\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3215847 entropy 1.7800467\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.287285 entropy 1.7772224\n",
      "kl 0.02082594\n",
      "completed in 0.20592093467712402 s\n",
      "game 121 completed in 11.544066905975342 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.424968 entropy 1.8447329\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4038844 entropy 1.844578\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3720686 entropy 1.845255\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3372095 entropy 1.8464915\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3052495 entropy 1.847476\n",
      "kl 0.017182346\n",
      "completed in 0.16086983680725098 s\n",
      "game 122 completed in 7.563557863235474 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.512139 entropy 1.8263278\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4881334 entropy 1.8277204\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.449197 entropy 1.8282392\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4121552 entropy 1.8283534\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3777597 entropy 1.8277917\n",
      "kl 0.020990275\n",
      "completed in 0.16465497016906738 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 123 completed in 11.043834924697876 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5454626 entropy 1.8872962\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5276566 entropy 1.8860037\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.494253 entropy 1.8821839\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4527144 entropy 1.8766274\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4095278 entropy 1.8695173\n",
      "kl 0.02014678\n",
      "completed in 0.17749691009521484 s\n",
      "game 124 completed in 7.789741039276123 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.461311 entropy 1.8228323\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4327955 entropy 1.8220862\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.391479 entropy 1.8243926\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3526556 entropy 1.8279378\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3208327 entropy 1.8320642\n",
      "kl 0.017825121\n",
      "completed in 0.17281103134155273 s\n",
      "game 125 completed in 9.121973037719727 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4876776 entropy 1.8525219\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4667814 entropy 1.8545246\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4320307 entropy 1.853829\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3933444 entropy 1.8515404\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3575885 entropy 1.8484145\n",
      "kl 0.02500937\n",
      "completed in 0.18995308876037598 s\n",
      "game 126 completed in 10.728670120239258 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4900858 entropy 1.8530668\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.474143 entropy 1.8547461\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4424913 entropy 1.8597425\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4066951 entropy 1.8666021\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.366831 entropy 1.873312\n",
      "kl 0.01831155\n",
      "completed in 0.16805386543273926 s\n",
      "game 127 completed in 11.995198011398315 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.465208 entropy 1.8381057\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4370506 entropy 1.8404884\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.402848 entropy 1.8410257\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3680038 entropy 1.8402491\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3314962 entropy 1.8386446\n",
      "kl 0.016389865\n",
      "completed in 0.16757607460021973 s\n",
      "game 128 completed in 9.105298042297363 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4915645 entropy 1.9074972\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.465433 entropy 1.9051368\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4257789 entropy 1.9017377\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3887002 entropy 1.8977194\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.353852 entropy 1.8932457\n",
      "kl 0.023207743\n",
      "completed in 0.16856718063354492 s\n",
      "game 129 completed in 9.09875202178955 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4925506 entropy 1.8596464\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4648616 entropy 1.8549746\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4165652 entropy 1.8512232\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3647192 entropy 1.8480254\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.321745 entropy 1.8445604\n",
      "kl 0.022856291\n",
      "completed in 0.19368600845336914 s\n",
      "game 130 completed in 9.195106029510498 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4333608 entropy 1.8296255\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4115078 entropy 1.8272672\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3800232 entropy 1.82664\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.346902 entropy 1.8276983\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3117542 entropy 1.8300192\n",
      "kl 0.023549736\n",
      "completed in 0.1815500259399414 s\n",
      "game 131 completed in 9.393428087234497 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.463931 entropy 1.851352\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4316723 entropy 1.8562251\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3946338 entropy 1.8587303\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.366547 entropy 1.8570397\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3341675 entropy 1.8500521\n",
      "kl 0.033413947\n",
      "completed in 0.17205595970153809 s\n",
      "game 132 completed in 11.051900148391724 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5539389 entropy 1.8682821\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5226307 entropy 1.8607235\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.478559 entropy 1.8560028\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4380126 entropy 1.8543341\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4003022 entropy 1.8544278\n",
      "kl 0.020447357\n",
      "completed in 0.16644668579101562 s\n",
      "game 133 completed in 16.796921730041504 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.443794 entropy 1.8644336\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4119544 entropy 1.8668444\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3739731 entropy 1.8689654\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3398867 entropy 1.8699491\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3090816 entropy 1.8694925\n",
      "kl 0.02468355\n",
      "completed in 0.17231512069702148 s\n",
      "game 134 completed in 8.12163496017456 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4864986 entropy 1.847894\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4637547 entropy 1.8488092\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4303036 entropy 1.8502526\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3916638 entropy 1.8514518\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3536253 entropy 1.8520954\n",
      "kl 0.021627352\n",
      "completed in 0.17306804656982422 s\n",
      "game 135 completed in 11.641570091247559 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4898734 entropy 1.8502166\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.458744 entropy 1.8542758\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4160287 entropy 1.8608098\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3720756 entropy 1.8688183\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.331057 entropy 1.8750843\n",
      "kl 0.026887394\n",
      "completed in 0.2257540225982666 s\n",
      "game 136 completed in 9.785088062286377 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4755757 entropy 1.8741989\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4553182 entropy 1.879617\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4251337 entropy 1.8862147\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3903368 entropy 1.8922766\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3563454 entropy 1.8967702\n",
      "kl 0.021220293\n",
      "completed in 0.18878793716430664 s\n",
      "game 137 completed in 7.569211006164551 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5698013 entropy 1.9352854\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5349715 entropy 1.9344493\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4835157 entropy 1.9290397\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4357235 entropy 1.9210455\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3933077 entropy 1.9114292\n",
      "kl 0.027597172\n",
      "completed in 0.16480469703674316 s\n",
      "game 138 completed in 6.66026496887207 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4883559 entropy 1.8751415\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4641232 entropy 1.8690846\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4268782 entropy 1.8651069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.387088 entropy 1.8632486\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3473725 entropy 1.8628063\n",
      "kl 0.021766024\n",
      "completed in 0.1728959083557129 s\n",
      "game 139 completed in 8.91066598892212 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.463258 entropy 1.844521\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.437822 entropy 1.8468466\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4047282 entropy 1.8475131\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.373407 entropy 1.8458502\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.343731 entropy 1.8419144\n",
      "kl 0.020670457\n",
      "completed in 0.20247387886047363 s\n",
      "game 140 completed in 11.552560091018677 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4986439 entropy 1.8653004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4719563 entropy 1.8600297\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4280076 entropy 1.8552357\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3792892 entropy 1.8511934\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3360677 entropy 1.8483479\n",
      "kl 0.020529114\n",
      "completed in 0.17299985885620117 s\n",
      "game 141 completed in 8.365288972854614 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6416903 entropy 1.8977786\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6098104 entropy 1.9051044\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.563562 entropy 1.9161041\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5195832 entropy 1.9283085\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.484975 entropy 1.9389353\n",
      "kl 0.027646802\n",
      "completed in 0.16153216361999512 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 142 completed in 8.447226762771606 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4498212 entropy 1.8590287\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.419609 entropy 1.8597065\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3839715 entropy 1.8549864\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3546095 entropy 1.8474954\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3259404 entropy 1.8393326\n",
      "kl 0.019757682\n",
      "completed in 0.17385077476501465 s\n",
      "game 143 completed in 14.085175037384033 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4710066 entropy 1.869825\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.446285 entropy 1.8602747\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.402492 entropy 1.8498287\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3501651 entropy 1.8399651\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2983184 entropy 1.8315463\n",
      "kl 0.028006852\n",
      "completed in 0.17441391944885254 s\n",
      "game 144 completed in 9.484856843948364 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.471606 entropy 1.864854\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4378397 entropy 1.86676\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.402429 entropy 1.8738862\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3671904 entropy 1.8820654\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3353477 entropy 1.8897504\n",
      "kl 0.02009746\n",
      "completed in 0.17353510856628418 s\n",
      "game 145 completed in 7.682056903839111 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3380635 entropy 1.7802407\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.317289 entropy 1.7866035\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2890737 entropy 1.7936877\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2587628 entropy 1.8007374\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2307165 entropy 1.8059545\n",
      "kl 0.019497262\n",
      "completed in 0.1705777645111084 s\n",
      "game 146 completed in 6.768049001693726 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4675157 entropy 1.8342099\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4359171 entropy 1.8344829\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3956692 entropy 1.8328503\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3539128 entropy 1.8294854\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3129184 entropy 1.8244128\n",
      "kl 0.027861003\n",
      "completed in 0.1788029670715332 s\n",
      "game 147 completed in 7.795975923538208 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.505127 entropy 1.8405502\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4847841 entropy 1.8359121\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.450665 entropy 1.8347659\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.415176 entropy 1.8364997\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.381634 entropy 1.840694\n",
      "kl 0.021328315\n",
      "completed in 0.1755387783050537 s\n",
      "game 148 completed in 6.909607887268066 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5626433 entropy 1.9073167\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5423012 entropy 1.9157363\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5071313 entropy 1.922823\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4657457 entropy 1.9266868\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4277534 entropy 1.9267943\n",
      "kl 0.024875969\n",
      "completed in 0.17218399047851562 s\n",
      "prediction:\n",
      " [0.00710528 0.0074828  0.01282724 0.01645549 0.00498794 0.00485679\n",
      " 0.00475919 0.15297782 0.04344676 0.0196455  0.02466089 0.00414591\n",
      " 0.01329756 0.02981242 0.11429783 0.01096173 0.02415962 0.01913428\n",
      " 0.01112625 0.01354978 0.01577533 0.10040639 0.02916235 0.01139965\n",
      " 0.00738553 0.03605305 0.01283222 0.02330873 0.17158753 0.00460215\n",
      " 0.00308491 0.00350133 0.0114994  0.01680584 0.0054051  0.00749958] \n",
      " -0.5080614\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.30413016e-01 2.34042553e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.82728411e-01 2.52816020e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [1.2707585e-03 1.1493650e-04 2.1297472e-04 3.7188924e-04 1.8561482e-04\n",
      " 1.3904665e-04 8.0480168e-05 1.7723368e-03 1.0814042e-02 8.0949612e-02\n",
      " 1.1277639e-03 9.4596136e-05 9.7081828e-04 6.1203786e-03 3.4115333e-02\n",
      " 2.4890879e-01 9.1241181e-02 2.9686774e-04 1.9204126e-04 1.2365728e-01\n",
      " 2.6342958e-01 4.2731367e-02 1.4861574e-02 1.0732777e-03 7.1773378e-05\n",
      " 9.3397591e-04 6.3887790e-02 6.4048748e-03 1.9839124e-03 9.4934498e-05\n",
      " 6.6166845e-05 8.5317086e-05 2.0639462e-04 5.3177431e-04 1.0070580e-04\n",
      " 9.0007205e-04] \n",
      " -0.41346857\n",
      "p [[0.00625782 0.00500626 0.09261577 0.00876095 0.00375469 0.00250313]\n",
      " [0.0175219  0.07634543 0.01877347 0.00876095 0.01627034 0.00250313]\n",
      " [0.01001252 0.01501877 0.         0.00500626 0.0175219  0.01126408]\n",
      " [0.00625782 0.00625782 0.0175219  0.08760951 0.0175219  0.00625782]\n",
      " [0.00750939 0.02878598 0.0212766  0.01126408 0.43429287 0.00500626]\n",
      " [0.00125156 0.00375469 0.00750939 0.01126408 0.00500626 0.00375469]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00309803 0.0016476  0.00692693 0.0024521  0.00069513 0.00175915\n",
      " 0.00258225 0.00186115 0.12835513 0.04383551 0.01090276 0.00062619\n",
      " 0.00765442 0.19620891 0.00364041 0.00096487 0.13743049 0.00860845\n",
      " 0.00431389 0.09438645 0.00112187 0.00306615 0.19047432 0.00810136\n",
      " 0.00055479 0.00948468 0.03111411 0.07817382 0.0015456  0.00148146\n",
      " 0.00158397 0.00043232 0.00184903 0.00929603 0.00126443 0.00250644] \n",
      " -0.4880036\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 3.00375469e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 4.99374218e-01\n",
      "  1.95244055e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.27659574e-01 7.25907384e-02 2.12765957e-02\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.88110138e-02 1.25156446e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [7.16041686e-05 2.32023940e-05 2.90646003e-05 6.53335155e-05\n",
      " 2.65142953e-05 2.07347202e-05 1.45929835e-05 1.41896971e-05\n",
      " 1.13181071e-03 6.87553431e-04 2.39380612e-03 2.04298904e-05\n",
      " 3.36965953e-04 4.34217006e-01 2.18784353e-05 8.93679753e-05\n",
      " 8.05747841e-05 3.44646760e-05 5.75685772e-06 8.10615820e-05\n",
      " 1.01131292e-04 4.05558276e-05 5.57021081e-01 1.61448683e-04\n",
      " 6.97030373e-06 2.25787144e-03 4.43067722e-04 4.52250475e-04\n",
      " 1.00340403e-05 1.37954776e-05 2.11992010e-05 3.18741741e-06\n",
      " 3.04852456e-05 3.28997230e-05 8.67074596e-06 2.93642715e-05] \n",
      " -0.5966267\n",
      "p [[0.00500626 0.00250313 0.02002503 0.00250313 0.00125156 0.00250313]\n",
      " [0.00250313 0.00125156 0.09637046 0.03254068 0.00750939 0.00125156]\n",
      " [0.00375469 0.17396746 0.         0.         0.24780976 0.00625782]\n",
      " [0.00375469 0.06382979 0.00125156 0.01001252 0.14768461 0.0175219 ]\n",
      " [0.00125156 0.00500626 0.05381727 0.06883605 0.         0.00125156]\n",
      " [0.00125156 0.00250313 0.00125156 0.00750939 0.00375469 0.00250313]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00127014 0.00255422 0.0081685  0.00192984 0.00318677 0.00094246\n",
      " 0.00207967 0.00221659 0.3208329  0.09777682 0.00827743 0.0012089\n",
      " 0.0481023  0.04867702 0.00979831 0.00270892 0.00781322 0.00620489\n",
      " 0.00237862 0.00306111 0.00196258 0.02442379 0.05156361 0.04036622\n",
      " 0.0008117  0.00651332 0.08967516 0.18389693 0.00240405 0.00266053\n",
      " 0.00090311 0.00140107 0.00115298 0.00969891 0.00214558 0.00123205] \n",
      " -0.7551905\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.91489362e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  8.08510638e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [5.4470589e-04 1.7105959e-03 1.1550763e-03 1.2556106e-02 5.4627802e-04\n",
      " 5.7394640e-04 5.5497726e-03 1.4696559e-03 9.2631362e-02 1.2385408e-01\n",
      " 4.3630451e-02 1.3443803e-03 7.6899994e-03 1.5499292e-01 6.4424672e-03\n",
      " 1.8156102e-03 5.5216607e-03 5.3553558e-03 1.3880043e-03 5.8556269e-03\n",
      " 1.2827347e-03 9.1410093e-03 3.5336396e-01 2.6603376e-03 2.5162278e-04\n",
      " 3.4726363e-02 8.1190176e-02 1.9629050e-02 1.2269765e-03 1.1729948e-02\n",
      " 4.7117446e-04 8.6564156e-05 7.0812288e-03 9.8438410e-04 6.2812027e-04\n",
      " 9.1845653e-04] \n",
      " 0.45189238\n",
      "p [[0.00125156 0.00125156 0.01126408 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.43929912 0.07634543 0.00625782 0.00125156]\n",
      " [0.02503129 0.02753442 0.         0.         0.         0.00375469]\n",
      " [0.00125156 0.00375469 0.00125156 0.01877347 0.         0.0212766 ]\n",
      " [0.00125156 0.00500626 0.07634543 0.25156446 0.         0.00750939]\n",
      " [0.00125156 0.00125156 0.00125156 0.00625782 0.00125156 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.1759265e-03 3.2329455e-03 3.1879116e-03 2.0923490e-02 1.5086572e-03\n",
      " 2.9201824e-03 6.4285998e-03 1.3464725e-02 2.9570481e-02 2.6430899e-01\n",
      " 2.7303558e-02 1.5513973e-03 1.3996545e-02 2.5020082e-02 2.7282102e-04\n",
      " 7.9296430e-04 3.4567858e-03 5.0011226e-03 2.2494206e-03 1.2829206e-03\n",
      " 5.8856944e-04 1.6292457e-04 2.3499362e-02 9.3467226e-03 1.3403209e-03\n",
      " 1.8749261e-02 4.6449178e-01 1.0136729e-02 1.4942418e-02 6.9582830e-03\n",
      " 1.7332640e-03 1.6550991e-03 9.7987521e-03 4.2549409e-03 3.1859907e-03\n",
      " 1.5063002e-03] \n",
      " -0.77989256\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.87734668e-01\n",
      "  4.00500626e-02 1.25156446e-13]\n",
      " [2.50312891e-03 3.09136421e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 3.76720901e-01\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.12640801e-02 2.37797247e-02 4.00500626e-02\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [1.25156446e-13 1.25156446e-13 5.00625782e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.95453433e-04 3.15377302e-03 4.60525826e-02 6.50513498e-03\n",
      " 4.11271671e-04 6.44842366e-05 7.83393066e-03 5.17079905e-02\n",
      " 2.72181612e-02 1.42007560e-01 1.31809479e-02 1.21838227e-03\n",
      " 2.61239678e-01 4.11918759e-03 4.98523696e-05 3.92688103e-02\n",
      " 1.25322929e-02 1.81877818e-02 3.00763408e-03 1.55957835e-02\n",
      " 1.60491616e-02 1.70465748e-04 1.98794566e-02 8.56617987e-02\n",
      " 1.11585134e-03 1.24197211e-02 9.77478251e-02 5.00030490e-03\n",
      " 6.31688759e-02 1.40198907e-02 1.54956433e-04 7.00715813e-04\n",
      " 5.41504798e-03 1.93120465e-02 3.69697553e-03 1.43638032e-03] \n",
      " 0.93538517\n",
      "p [[0.00125156 0.00125156 0.00125156 0.02002503 0.00125156 0.00250313]\n",
      " [0.00375469 0.00876095 0.         0.38673342 0.0212766  0.00125156]\n",
      " [0.01001252 0.19649562 0.         0.         0.         0.00250313]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.         0.00625782]\n",
      " [0.00125156 0.01376721 0.28785982 0.00876095 0.         0.00375469]\n",
      " [0.00125156 0.00125156 0.00625782 0.00250313 0.00375469 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.0737764e-04 1.6970816e-03 1.7361764e-02 4.1199615e-03 2.2679139e-03\n",
      " 1.7914475e-03 7.6584816e-03 9.5395394e-02 4.7981185e-03 3.0799420e-03\n",
      " 4.8012704e-01 5.0168890e-03 3.7376836e-03 2.9753267e-03 3.6839301e-05\n",
      " 1.4750744e-03 1.1021930e-03 6.3520232e-03 2.2524204e-03 2.9381373e-04\n",
      " 7.9762534e-04 5.2481839e-05 5.0410656e-03 1.9774430e-03 3.8823863e-03\n",
      " 2.1570568e-01 3.2491914e-03 1.6858929e-03 6.5904349e-02 1.9543016e-02\n",
      " 9.6454244e-04 2.4283505e-03 5.0401934e-03 3.0136170e-02 1.4532903e-03\n",
      " 1.9163713e-04] \n",
      " -0.026132964\n",
      "p [[1.25156446e-13 1.25156446e-13 8.76095119e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.12640801e-02 6.63329161e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.62703379e-02 1.25156446e-13]\n",
      " [2.57822278e-01 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-13 2.00250313e-02 1.50187735e-02 0.00000000e+00\n",
      "  0.00000000e+00 5.41927409e-01]\n",
      " [1.25156446e-13 1.25156446e-03 3.62953692e-02 1.25156446e-13\n",
      "  0.00000000e+00 1.12640801e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-02\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.9056544e-04 3.6996508e-03 1.0876829e-02 5.4471660e-03 2.6884850e-03\n",
      " 2.9696967e-04 2.0860536e-02 4.1784842e-02 2.6399407e-03 2.0921675e-02\n",
      " 2.8099061e-03 4.7022710e-03 1.5082926e-02 4.9845455e-04 3.8595183e-05\n",
      " 3.6829957e-01 2.9570797e-02 4.0649276e-02 1.2387864e-02 1.2663573e-02\n",
      " 1.2276877e-01 2.5780461e-04 2.7960034e-03 2.2128071e-03 2.6969414e-02\n",
      " 7.6773409e-03 1.0131645e-02 8.3172112e-04 1.9098972e-01 1.8744426e-02\n",
      " 7.1265956e-04 1.6819641e-03 8.1281587e-03 6.0299346e-03 3.1359326e-03\n",
      " 4.2191401e-04] \n",
      " 0.9701708\n",
      "p [[0.00125156 0.00125156 0.01376721 0.00375469 0.00125156 0.00125156]\n",
      " [0.00750939 0.17146433 0.         0.         0.5494368  0.00375469]\n",
      " [0.00250313 0.00250313 0.         0.         0.         0.00500626]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.         0.        ]\n",
      " [0.00250313 0.17772215 0.00250313 0.00125156 0.         0.01501877]\n",
      " [0.00125156 0.00125156 0.00375469 0.02377972 0.00125156 0.00125156]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.81618074e-04 1.80130664e-04 5.95857529e-03 1.01722160e-03\n",
      " 1.80273820e-02 5.87149384e-03 2.87991995e-03 8.95410329e-02\n",
      " 1.62282661e-02 1.20016700e-03 3.73675535e-03 3.25534403e-01\n",
      " 1.13546872e-03 7.99586473e-04 6.50494549e-05 4.56410999e-06\n",
      " 1.48926314e-03 2.06947661e-04 3.48582020e-04 1.64899466e-04\n",
      " 5.82758457e-06 3.24847861e-05 2.74541555e-03 2.57060863e-03\n",
      " 3.51660043e-01 3.02612968e-03 1.37999188e-03 2.11649016e-02\n",
      " 1.07197866e-01 8.71709827e-03 2.66901986e-03 9.52510536e-03\n",
      " 1.08020997e-03 1.31791821e-02 4.57513379e-04 1.74194538e-05] \n",
      " -0.9206739\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [3.75469337e-03 6.25782228e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [2.50312891e-03 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.00625782e-03]\n",
      " [2.50312891e-03 3.75469337e-03 9.62453066e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.50312891e-03 2.50312891e-03 2.50312891e-03 1.25156446e-13\n",
      "  0.00000000e+00 3.75469337e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 149 completed in 29.298848867416382 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6144717 entropy 1.9516742\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5918975 entropy 1.9528446\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5611613 entropy 1.9530647\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5271134 entropy 1.9513831\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.492817 entropy 1.9478593\n",
      "kl 0.03721393\n",
      "completed in 0.173414945602417 s\n",
      "game 150 completed in 5.930098056793213 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.519319 entropy 1.8379514\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5031748 entropy 1.839844\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.478716 entropy 1.8464605\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.444999 entropy 1.8566914\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4069557 entropy 1.8684669\n",
      "kl 0.016693983\n",
      "completed in 0.16718316078186035 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 151 completed in 6.779544115066528 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5399942 entropy 1.9064772\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.518411 entropy 1.9183863\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4857116 entropy 1.925814\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4501867 entropy 1.9277021\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4147396 entropy 1.9249648\n",
      "kl 0.021011055\n",
      "completed in 0.18841004371643066 s\n",
      "game 152 completed in 7.47509503364563 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4763772 entropy 1.9050204\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4555478 entropy 1.8976736\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4154563 entropy 1.8881469\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3720298 entropy 1.8773003\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3371723 entropy 1.8657086\n",
      "kl 0.022535581\n",
      "completed in 0.16987395286560059 s\n",
      "game 153 completed in 12.887494087219238 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.489833 entropy 1.90628\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.461288 entropy 1.8982711\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.420444 entropy 1.8937715\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3769393 entropy 1.8922799\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3345537 entropy 1.892214\n",
      "kl 0.02164593\n",
      "completed in 0.19261384010314941 s\n",
      "game 154 completed in 10.734745979309082 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4503438 entropy 1.8747038\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4302568 entropy 1.8760982\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4006212 entropy 1.8749216\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3685145 entropy 1.8710018\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3330681 entropy 1.8641928\n",
      "kl 0.0223112\n",
      "completed in 0.1751999855041504 s\n",
      "game 155 completed in 8.354368925094604 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.494767 entropy 1.8386453\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4682531 entropy 1.8304396\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.429929 entropy 1.8232768\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.393426 entropy 1.8190366\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.35893 entropy 1.816978\n",
      "kl 0.023244413\n",
      "completed in 0.17287874221801758 s\n",
      "game 156 completed in 10.761983156204224 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5750582 entropy 1.8671651\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.544642 entropy 1.8672526\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4972858 entropy 1.8689724\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.449743 entropy 1.8706431\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.402651 entropy 1.8717535\n",
      "kl 0.022552602\n",
      "completed in 0.16446805000305176 s\n",
      "game 157 completed in 5.927774906158447 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5452964 entropy 1.856972\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5269482 entropy 1.8599403\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4930868 entropy 1.8665653\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.454753 entropy 1.8757083\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.420533 entropy 1.8848778\n",
      "kl 0.018643782\n",
      "completed in 0.16587114334106445 s\n",
      "game 158 completed in 6.923529863357544 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5093 entropy 1.9158762\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4776878 entropy 1.9202235\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4270933 entropy 1.9195974\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3805268 entropy 1.9150233\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3418655 entropy 1.909022\n",
      "kl 0.024460223\n",
      "completed in 0.18056321144104004 s\n",
      "game 159 completed in 7.7799341678619385 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3715818 entropy 1.827187\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3470361 entropy 1.8230641\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3145058 entropy 1.8188152\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.279694 entropy 1.8134918\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2472918 entropy 1.8066933\n",
      "kl 0.031650025\n",
      "completed in 0.165496826171875 s\n",
      "game 160 completed in 13.304675102233887 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5311372 entropy 1.8376706\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4987366 entropy 1.8367515\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4478397 entropy 1.8427652\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4018106 entropy 1.8528612\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3572762 entropy 1.863549\n",
      "kl 0.033220485\n",
      "completed in 0.17777204513549805 s\n",
      "game 161 completed in 9.654211282730103 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4850564 entropy 1.8740962\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4613404 entropy 1.8787911\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.424001 entropy 1.8784902\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3839931 entropy 1.8724828\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3483741 entropy 1.8615892\n",
      "kl 0.036752805\n",
      "completed in 0.2084059715270996 s\n",
      "game 162 completed in 12.770117044448853 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.483778 entropy 1.8760676\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4515927 entropy 1.8649467\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.409512 entropy 1.8567791\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3656058 entropy 1.8518245\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3243313 entropy 1.8499949\n",
      "kl 0.03152027\n",
      "completed in 0.1611039638519287 s\n",
      "game 163 completed in 12.64577317237854 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5603297 entropy 1.851325\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5364716 entropy 1.8542252\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5029445 entropy 1.857301\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4620464 entropy 1.8595222\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4176886 entropy 1.8603014\n",
      "kl 0.022262158\n",
      "completed in 0.1645190715789795 s\n",
      "game 164 completed in 9.210588216781616 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4726038 entropy 1.8291619\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4486716 entropy 1.8308089\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4077296 entropy 1.8338199\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3655753 entropy 1.8373532\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3297687 entropy 1.8405247\n",
      "kl 0.028189292\n",
      "completed in 0.1984691619873047 s\n",
      "game 165 completed in 9.163239002227783 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5350645 entropy 1.884541\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5099175 entropy 1.8865002\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.471296 entropy 1.8868773\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4307828 entropy 1.8884919\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3860016 entropy 1.8915904\n",
      "kl 0.015816629\n",
      "completed in 0.1807248592376709 s\n",
      "game 166 completed in 9.096113920211792 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6038575 entropy 1.9005297\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5778904 entropy 1.9024764\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.533352 entropy 1.9018035\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4825058 entropy 1.8992784\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.444157 entropy 1.8954041\n",
      "kl 0.02560529\n",
      "completed in 0.1656050682067871 s\n",
      "game 167 completed in 9.61568307876587 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6038878 entropy 1.8918139\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5653431 entropy 1.8864179\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5109138 entropy 1.8825285\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4699068 entropy 1.8828571\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4351535 entropy 1.8877797\n",
      "kl 0.017660908\n",
      "completed in 0.2049417495727539 s\n",
      "game 168 completed in 6.909451007843018 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5998812 entropy 1.9153736\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.572738 entropy 1.9264022\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5264719 entropy 1.9391315\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.47541 entropy 1.950726\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4270191 entropy 1.9583002\n",
      "kl 0.025116816\n",
      "completed in 0.17215991020202637 s\n",
      "game 169 completed in 9.957351207733154 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4986641 entropy 1.9226483\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4776804 entropy 1.9203465\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4454448 entropy 1.9149598\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4114685 entropy 1.9077656\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3757524 entropy 1.8990786\n",
      "kl 0.019939676\n",
      "completed in 0.1709117889404297 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 170 completed in 6.088212966918945 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4847417 entropy 1.9148836\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4508302 entropy 1.9101322\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4081423 entropy 1.906954\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3669167 entropy 1.9033958\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3302364 entropy 1.8985691\n",
      "kl 0.0214682\n",
      "completed in 0.18107199668884277 s\n",
      "game 171 completed in 14.350351095199585 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.432116 entropy 1.8689524\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3958755 entropy 1.8615144\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3474014 entropy 1.8534178\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3040738 entropy 1.8468986\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2691517 entropy 1.8428298\n",
      "kl 0.02505302\n",
      "completed in 0.16100502014160156 s\n",
      "game 172 completed in 6.858235120773315 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.563878 entropy 1.8415159\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.537499 entropy 1.8442822\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5025291 entropy 1.8488333\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4628966 entropy 1.8540314\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4270058 entropy 1.8573925\n",
      "kl 0.029097676\n",
      "completed in 0.1788620948791504 s\n",
      "game 173 completed in 9.125415086746216 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5885038 entropy 1.8945311\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5592585 entropy 1.8998042\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5193264 entropy 1.9091768\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4755116 entropy 1.921705\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4348645 entropy 1.9345891\n",
      "kl 0.028472042\n",
      "completed in 0.1901090145111084 s\n",
      "game 174 completed in 7.738285779953003 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.523198 entropy 1.9072514\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4964159 entropy 1.9099863\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4533846 entropy 1.9068081\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4125385 entropy 1.9000553\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3754318 entropy 1.8913739\n",
      "kl 0.03672614\n",
      "completed in 0.17064309120178223 s\n",
      "game 175 completed in 12.389584064483643 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5296633 entropy 1.8574864\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4999382 entropy 1.8507171\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.457443 entropy 1.8463565\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4158933 entropy 1.845202\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3786275 entropy 1.8467023\n",
      "kl 0.021962395\n",
      "completed in 0.16461420059204102 s\n",
      "game 176 completed in 7.87451171875 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5471606 entropy 1.9018313\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5206707 entropy 1.904825\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4824839 entropy 1.9086418\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4461544 entropy 1.910423\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4065995 entropy 1.9088657\n",
      "kl 0.024631087\n",
      "completed in 0.16799521446228027 s\n",
      "game 177 completed in 9.626928806304932 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4886217 entropy 1.9028547\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4617193 entropy 1.900289\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4299173 entropy 1.897533\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.395539 entropy 1.8957341\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3636668 entropy 1.894976\n",
      "kl 0.019270658\n",
      "completed in 0.17308807373046875 s\n",
      "game 178 completed in 7.487591981887817 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5120401 entropy 1.8640108\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4823256 entropy 1.8635767\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4426975 entropy 1.8616763\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4053655 entropy 1.8581681\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.370426 entropy 1.8536757\n",
      "kl 0.030210746\n",
      "completed in 0.172529935836792 s\n",
      "game 179 completed in 10.099205017089844 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5258317 entropy 1.882801\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.498259 entropy 1.8845029\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4625294 entropy 1.887784\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4206777 entropy 1.8915626\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3805735 entropy 1.8950566\n",
      "kl 0.027976599\n",
      "completed in 0.16249585151672363 s\n",
      "game 180 completed in 9.046097993850708 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5470684 entropy 1.8965828\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5133436 entropy 1.899735\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4704034 entropy 1.9014684\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4327734 entropy 1.9017637\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3972821 entropy 1.9004936\n",
      "kl 0.02053057\n",
      "completed in 0.17060017585754395 s\n",
      "game 181 completed in 9.260848045349121 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4147327 entropy 1.8625472\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3847063 entropy 1.8615861\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3477075 entropy 1.8589175\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3071098 entropy 1.8542279\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2670212 entropy 1.8482375\n",
      "kl 0.02370215\n",
      "completed in 0.1693110466003418 s\n",
      "game 182 completed in 6.79117488861084 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5172544 entropy 1.879433\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4777937 entropy 1.8695912\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4441128 entropy 1.8594605\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4174595 entropy 1.8513769\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3822546 entropy 1.846022\n",
      "kl 0.017587585\n",
      "completed in 0.2347850799560547 s\n",
      "game 183 completed in 7.564213037490845 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.594574 entropy 1.8877057\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5724454 entropy 1.8858037\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5383258 entropy 1.8869157\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.497998 entropy 1.8886033\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4551363 entropy 1.8903127\n",
      "kl 0.016182188\n",
      "completed in 0.18616509437561035 s\n",
      "game 184 completed in 10.656059980392456 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4790096 entropy 1.8650463\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4508915 entropy 1.8681364\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.413816 entropy 1.8721322\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3726578 entropy 1.8766716\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3348353 entropy 1.8809485\n",
      "kl 0.022097792\n",
      "completed in 0.17769193649291992 s\n",
      "game 185 completed in 10.903145790100098 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3818274 entropy 1.8495235\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3578713 entropy 1.8468618\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3187506 entropy 1.8406792\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2844882 entropy 1.8334575\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2512465 entropy 1.8268862\n",
      "kl 0.019686384\n",
      "completed in 0.1702721118927002 s\n",
      "game 186 completed in 12.55936312675476 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4671004 entropy 1.883811\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4390402 entropy 1.8859336\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.404608 entropy 1.891952\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.371012 entropy 1.8986722\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.339145 entropy 1.9042257\n",
      "kl 0.029185437\n",
      "completed in 0.16707706451416016 s\n",
      "game 187 completed in 7.4396891593933105 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4824438 entropy 1.8874531\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4453485 entropy 1.8872917\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.396723 entropy 1.8844066\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3575685 entropy 1.879491\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3238287 entropy 1.8728821\n",
      "kl 0.025360484\n",
      "completed in 0.2037358283996582 s\n",
      "game 188 completed in 5.872366189956665 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4995894 entropy 1.900989\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4724371 entropy 1.9001606\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4310088 entropy 1.9051481\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3859854 entropy 1.9150317\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3430867 entropy 1.9267075\n",
      "kl 0.03066577\n",
      "completed in 0.16593480110168457 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 189 completed in 5.912349224090576 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4615874 entropy 1.867023\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.42986 entropy 1.8746629\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3810465 entropy 1.8794613\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3371506 entropy 1.8805683\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2956991 entropy 1.8781482\n",
      "kl 0.028220683\n",
      "completed in 0.17319083213806152 s\n",
      "game 190 completed in 8.323572874069214 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5308146 entropy 1.918392\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4970691 entropy 1.9105321\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4513268 entropy 1.9014904\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4083245 entropy 1.8944414\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.375965 entropy 1.8896129\n",
      "kl 0.027493773\n",
      "completed in 0.17076396942138672 s\n",
      "game 191 completed in 10.735198020935059 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5338876 entropy 1.9075146\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5066617 entropy 1.9055935\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4621136 entropy 1.9041934\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.413954 entropy 1.903409\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3762832 entropy 1.9036547\n",
      "kl 0.028040398\n",
      "completed in 0.16482996940612793 s\n",
      "game 192 completed in 5.943028211593628 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.553057 entropy 1.9182798\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5240946 entropy 1.9267719\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4859662 entropy 1.9352256\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.448533 entropy 1.9411857\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4117582 entropy 1.9432383\n",
      "kl 0.026987711\n",
      "completed in 0.16829991340637207 s\n",
      "game 193 completed in 9.897104740142822 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4964511 entropy 1.9181172\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4675922 entropy 1.9108827\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.434196 entropy 1.8994352\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3972397 entropy 1.8874092\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.362362 entropy 1.8763374\n",
      "kl 0.029034287\n",
      "completed in 0.17499375343322754 s\n",
      "game 194 completed in 6.016945838928223 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4847584 entropy 1.8470565\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4633434 entropy 1.8432825\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4334722 entropy 1.8425457\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3992765 entropy 1.8439311\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3642273 entropy 1.8468249\n",
      "kl 0.024979452\n",
      "completed in 0.16885805130004883 s\n",
      "game 195 completed in 8.291096210479736 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5689828 entropy 1.9212534\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5442765 entropy 1.9232389\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.505024 entropy 1.9252694\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4614298 entropy 1.9279609\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.412107 entropy 1.9317055\n",
      "kl 0.02506841\n",
      "completed in 0.20134711265563965 s\n",
      "game 196 completed in 9.372482776641846 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5551229 entropy 1.9039509\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5243747 entropy 1.9117457\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.488611 entropy 1.9223886\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.455363 entropy 1.9314853\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4196196 entropy 1.936403\n",
      "kl 0.022832368\n",
      "completed in 0.171065092086792 s\n",
      "game 197 completed in 9.299314737319946 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.495402 entropy 1.9400417\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4691534 entropy 1.937583\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4359138 entropy 1.933562\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.400034 entropy 1.9295678\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3646443 entropy 1.9250221\n",
      "kl 0.027073573\n",
      "completed in 0.17055583000183105 s\n",
      "game 198 completed in 9.593139886856079 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.543057 entropy 1.9492652\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.509248 entropy 1.9447849\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.459208 entropy 1.9414101\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4167428 entropy 1.9392195\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3809137 entropy 1.9369247\n",
      "kl 0.02311548\n",
      "completed in 0.1721956729888916 s\n",
      "prediction:\n",
      " [0.00587316 0.00669664 0.01281486 0.01331875 0.0074768  0.00587433\n",
      " 0.01048252 0.02493429 0.01714884 0.02022239 0.21944681 0.00408328\n",
      " 0.01860976 0.01897633 0.00475185 0.05333569 0.0245408  0.01356608\n",
      " 0.01117225 0.01663029 0.05127136 0.00985809 0.0136955  0.01046589\n",
      " 0.00923578 0.26761857 0.0159871  0.00758063 0.04180115 0.00998649\n",
      " 0.00830751 0.00646322 0.01620408 0.00921094 0.00824433 0.00411389] \n",
      " -0.5459518\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.30162703e-01 3.35419274e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.22903630e-01 2.11514393e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [5.15978645e-05 1.07788481e-04 1.10868335e-04 4.36182367e-04\n",
      " 3.96783980e-05 8.11470149e-04 6.88561937e-04 7.94291438e-04\n",
      " 5.20313047e-02 5.56173641e-03 6.79816701e-04 6.79612494e-05\n",
      " 1.81565265e-04 3.21160220e-02 2.83525407e-01 1.39713094e-01\n",
      " 3.83959664e-03 4.10564331e-04 2.82210764e-04 4.74109268e-03\n",
      " 1.07782580e-01 2.25655332e-01 6.57556057e-02 2.32734776e-04\n",
      " 7.94463413e-05 1.43896136e-03 3.79441539e-03 6.59626871e-02\n",
      " 7.90588034e-04 2.00841256e-04 1.00364001e-03 3.79534322e-05\n",
      " 8.22389207e-04 9.76291922e-05 8.18000335e-05 7.26158178e-05] \n",
      " 0.5534513\n",
      "p [[0.00250313 0.00375469 0.00500626 0.00500626 0.00250313 0.00500626]\n",
      " [0.00500626 0.00876095 0.00625782 0.00876095 0.10888611 0.00250313]\n",
      " [0.00625782 0.04881101 0.00250313 0.         0.01001252 0.00625782]\n",
      " [0.00375469 0.04380476 0.05256571 0.00250313 0.00500626 0.00375469]\n",
      " [0.00375469 0.58698373 0.00625782 0.00375469 0.02753442 0.00500626]\n",
      " [0.00375469 0.00125156 0.00500626 0.00250313 0.00375469 0.00125156]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00382109 0.00474787 0.00858399 0.00590467 0.01017705 0.09554157\n",
      " 0.00529553 0.01962278 0.08257153 0.03691702 0.09181523 0.01902372\n",
      " 0.01032921 0.05454293 0.00998707 0.00116566 0.04755786 0.02583091\n",
      " 0.01415251 0.02762834 0.00197644 0.00761157 0.0413191  0.0083171\n",
      " 0.01800372 0.10058568 0.03132553 0.04061764 0.03519411 0.00871171\n",
      " 0.08101904 0.01238433 0.01761506 0.00674883 0.00708058 0.00627307] \n",
      " -0.7732224\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.48936170e-01 6.25782228e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.00125156e-02 1.61451815e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.53191489e-01 8.51063830e-02\n",
      "  1.37672090e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 2.12765957e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.3450288e-04 1.3104023e-03 6.6138047e-04 3.5708040e-04 4.0664405e-04\n",
      " 4.4022076e-02 7.0685945e-03 1.7435377e-03 1.1490429e-02 4.4632433e-03\n",
      " 2.6968458e-01 3.2896164e-04 1.5849306e-04 1.7948762e-01 2.0433068e-02\n",
      " 1.4277782e-03 1.8563340e-04 4.3744709e-05 2.8250010e-05 1.3535767e-04\n",
      " 2.0604287e-03 1.2916714e-02 1.6080897e-01 5.2227726e-04 3.2082468e-04\n",
      " 1.9657083e-01 3.8630795e-03 5.9495131e-03 1.6346298e-03 3.3829093e-03\n",
      " 6.5011181e-02 2.7279943e-04 1.3647974e-03 2.5889807e-04 8.3080668e-04\n",
      " 5.6005083e-04] \n",
      " 0.41692472\n",
      "p [[0.00250313 0.00375469 0.00375469 0.00250313 0.00500626 0.08635795]\n",
      " [0.00250313 0.00876095 0.04130163 0.01627034 0.05882353 0.0212766 ]\n",
      " [0.00375469 0.12891114 0.01001252 0.         0.02252816 0.01501877]\n",
      " [0.00625782 0.32165207 0.         0.00250313 0.01877347 0.00375469]\n",
      " [0.01001252 0.         0.02503129 0.03254068 0.06382979 0.00500626]\n",
      " [0.04881101 0.01001252 0.00750939 0.00500626 0.00375469 0.00250313]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.69444465e-04 7.85543933e-04 9.71724628e-04 4.21306671e-04\n",
      " 2.13290639e-02 9.60202068e-02 1.02158228e-03 3.82676558e-03\n",
      " 1.23021088e-03 2.98804883e-03 5.58070664e-04 3.81764723e-03\n",
      " 1.71459571e-03 1.09345362e-01 2.88988900e-04 1.10480287e-05\n",
      " 1.05678671e-04 1.91365732e-04 4.53483954e-04 2.36728520e-04\n",
      " 1.07205415e-05 2.08329235e-04 1.01372875e-01 2.66064215e-03\n",
      " 9.04310320e-04 1.27462053e-03 3.03371460e-03 5.99821156e-04\n",
      " 4.49416507e-03 1.28924195e-03 6.06234252e-01 2.89241355e-02\n",
      " 9.26512352e-04 3.07800539e-04 1.71684311e-03 5.55212784e-04] \n",
      " -0.72356325\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.12640801e-02]\n",
      " [1.25156446e-03 1.25156446e-13 5.00625782e-03 1.25156446e-13\n",
      "  7.62202753e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.86483104e-01 3.75469337e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-03\n",
      "  2.12765957e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [6.25782228e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.17072095e-05 8.89042640e-05 3.22610176e-05 5.83554311e-06\n",
      " 3.27613052e-05 2.92729944e-01 5.47401898e-04 1.84552933e-04\n",
      " 1.11927034e-03 7.44772187e-05 5.01486757e-05 4.37061135e-06\n",
      " 1.50152118e-06 5.03676012e-03 3.27480305e-03 2.41226462e-05\n",
      " 7.96455060e-06 6.94354242e-07 8.03119462e-07 7.50571598e-06\n",
      " 2.73687347e-05 2.25996104e-04 1.18879899e-02 6.00097201e-06\n",
      " 5.39090433e-06 5.03426963e-05 2.13700027e-04 4.29603911e-04\n",
      " 1.19296979e-04 2.30253121e-04 6.83403909e-01 1.28759666e-05\n",
      " 5.07211407e-05 1.16112524e-05 8.09453195e-05 8.37227344e-06] \n",
      " 0.7601292\n",
      "p [[0.01001252 0.01501877 0.00125156 0.00125156 0.02878598 0.11389237]\n",
      " [0.00125156 0.06633292 0.00125156 0.00250313 0.         0.07509387]\n",
      " [0.00125156 0.20150188 0.00750939 0.         0.00125156 0.00250313]\n",
      " [0.00125156 0.         0.         0.00125156 0.05381727 0.00125156]\n",
      " [0.00125156 0.         0.00375469 0.00125156 0.0212766  0.01376721]\n",
      " [0.26658323 0.09637046 0.00125156 0.00125156 0.00250313 0.00250313]]\n",
      "move 30\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.3533020e-04 1.3749180e-03 1.1804108e-02 8.5048232e-04 6.5507874e-02\n",
      " 2.3767171e-02 1.7065313e-03 1.3333212e-02 4.1204193e-03 5.3781546e-03\n",
      " 1.2355153e-03 6.6612195e-03 1.2879910e-02 3.1058899e-01 4.4109211e-03\n",
      " 1.1846200e-04 4.4743560e-04 6.0117355e-04 2.0387608e-03 6.6215231e-04\n",
      " 8.6878346e-05 4.2383061e-03 3.0743957e-01 1.3969928e-02 4.0840558e-03\n",
      " 2.1087222e-03 5.1140408e-03 3.1601633e-03 1.9453017e-02 1.9249197e-03\n",
      " 9.4495319e-02 6.3930802e-02 1.9411830e-03 6.1937789e-03 3.0790549e-03\n",
      " 9.5761014e-04] \n",
      " -0.97511214\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 9.69962453e-01]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  3.00375469e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 5\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 199 completed in 19.217411994934082 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5301025 entropy 1.9158788\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5083516 entropy 1.9146241\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.47688 entropy 1.9155395\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.439791 entropy 1.917039\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4027195 entropy 1.9174829\n",
      "kl 0.018728876\n",
      "completed in 0.17435193061828613 s\n",
      "game 200 completed in 6.663514137268066 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5456984 entropy 1.9092537\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5147028 entropy 1.9105443\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4784703 entropy 1.9099425\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4401073 entropy 1.9071144\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4075954 entropy 1.9025743\n",
      "kl 0.022988528\n",
      "completed in 0.1717970371246338 s\n",
      "game 201 completed in 6.984047889709473 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.521463 entropy 1.866303\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.493961 entropy 1.8614819\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4550815 entropy 1.8578074\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4181135 entropy 1.8570508\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3838537 entropy 1.8589196\n",
      "kl 0.019786082\n",
      "completed in 0.2044072151184082 s\n",
      "game 202 completed in 16.52822709083557 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5415413 entropy 1.8953736\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5170097 entropy 1.9034517\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.474519 entropy 1.9129033\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4375994 entropy 1.9210658\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4046407 entropy 1.9275203\n",
      "kl 0.01834144\n",
      "completed in 0.15719318389892578 s\n",
      "game 203 completed in 10.052836894989014 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5660994 entropy 1.8985574\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.537997 entropy 1.8945385\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5019794 entropy 1.8857505\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.463628 entropy 1.8750906\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4274633 entropy 1.8641679\n",
      "kl 0.021317452\n",
      "completed in 0.1633741855621338 s\n",
      "game 204 completed in 8.452853202819824 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5001533 entropy 1.9177439\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4844403 entropy 1.9143311\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4573896 entropy 1.9175751\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4250383 entropy 1.9248956\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.388489 entropy 1.9333167\n",
      "kl 0.019184725\n",
      "completed in 0.17411088943481445 s\n",
      "game 205 completed in 8.528664827346802 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5489686 entropy 1.930761\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5208635 entropy 1.9350308\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4809136 entropy 1.9367607\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4409025 entropy 1.9357407\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.403767 entropy 1.9322653\n",
      "kl 0.018759344\n",
      "completed in 0.16767287254333496 s\n",
      "game 206 completed in 9.36819314956665 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4441977 entropy 1.8871343\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4286926 entropy 1.8790069\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4017038 entropy 1.8685042\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3715076 entropy 1.8571472\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3427005 entropy 1.846011\n",
      "kl 0.022518223\n",
      "completed in 0.17527413368225098 s\n",
      "game 207 completed in 6.927850246429443 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5738323 entropy 1.8700358\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5503132 entropy 1.866293\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5133638 entropy 1.865933\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.476211 entropy 1.8693761\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4407246 entropy 1.8763624\n",
      "kl 0.017249625\n",
      "completed in 0.19150900840759277 s\n",
      "game 208 completed in 7.5511698722839355 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.478559 entropy 1.878541\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.454148 entropy 1.8901484\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4219236 entropy 1.9023526\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3883038 entropy 1.9128444\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3608127 entropy 1.9190023\n",
      "kl 0.01853006\n",
      "completed in 0.1711728572845459 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 209 completed in 7.6391050815582275 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.46264 entropy 1.9514569\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4333727 entropy 1.9484819\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3944452 entropy 1.9421628\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3577473 entropy 1.9344132\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3242433 entropy 1.9270557\n",
      "kl 0.019325236\n",
      "completed in 0.1695702075958252 s\n",
      "game 210 completed in 7.64754581451416 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4520566 entropy 1.8486004\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4266663 entropy 1.8469402\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.391054 entropy 1.8466945\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3533862 entropy 1.8468475\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3152466 entropy 1.8463788\n",
      "kl 0.016783051\n",
      "completed in 0.17757606506347656 s\n",
      "game 211 completed in 7.920046091079712 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4957886 entropy 1.8426802\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.468455 entropy 1.8417836\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4311461 entropy 1.8417153\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3911338 entropy 1.8410394\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3559146 entropy 1.838907\n",
      "kl 0.023909658\n",
      "completed in 0.17608022689819336 s\n",
      "game 212 completed in 7.6065709590911865 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.543705 entropy 1.9013734\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5223734 entropy 1.9009092\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.481318 entropy 1.901567\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.439357 entropy 1.9026449\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.402402 entropy 1.9036193\n",
      "kl 0.017656326\n",
      "completed in 0.19906091690063477 s\n",
      "game 213 completed in 7.5011067390441895 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4631884 entropy 1.8719661\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4286911 entropy 1.8756087\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3911018 entropy 1.8791909\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3551013 entropy 1.8797284\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3182719 entropy 1.8769965\n",
      "kl 0.020500546\n",
      "completed in 0.17403602600097656 s\n",
      "game 214 completed in 10.140152931213379 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5811884 entropy 1.9103762\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5366056 entropy 1.901288\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.499938 entropy 1.8929654\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4670975 entropy 1.8880806\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4339526 entropy 1.887032\n",
      "kl 0.020191872\n",
      "completed in 0.19071316719055176 s\n",
      "game 215 completed in 9.21748399734497 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4456658 entropy 1.8653681\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.420436 entropy 1.8674089\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3928668 entropy 1.8702441\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3665843 entropy 1.8728884\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.340267 entropy 1.8745202\n",
      "kl 0.010678064\n",
      "completed in 0.1701798439025879 s\n",
      "game 216 completed in 7.495557069778442 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4446247 entropy 1.8790548\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4249086 entropy 1.8828914\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.391301 entropy 1.8897235\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3562608 entropy 1.8976779\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3259957 entropy 1.9047596\n",
      "kl 0.022856664\n",
      "completed in 0.16794419288635254 s\n",
      "game 217 completed in 9.267231941223145 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.393292 entropy 1.9014255\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3753726 entropy 1.9023199\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3445466 entropy 1.8987345\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3113983 entropy 1.891681\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2790751 entropy 1.8827102\n",
      "kl 0.015804008\n",
      "completed in 0.1679248809814453 s\n",
      "game 218 completed in 7.390237808227539 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5923336 entropy 1.9347141\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5669925 entropy 1.9260428\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5258965 entropy 1.9187763\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4831915 entropy 1.9134278\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4411347 entropy 1.909148\n",
      "kl 0.02443036\n",
      "completed in 0.17201995849609375 s\n",
      "game 219 completed in 7.562294960021973 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5192842 entropy 1.8834822\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4820151 entropy 1.8871801\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4455037 entropy 1.8927612\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4056997 entropy 1.8976424\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3668442 entropy 1.901183\n",
      "kl 0.01673236\n",
      "completed in 0.21321797370910645 s\n",
      "game 220 completed in 9.27529001235962 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4565356 entropy 1.9027606\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.434849 entropy 1.9022303\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4055238 entropy 1.8994992\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.375812 entropy 1.8961874\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3496776 entropy 1.8910939\n",
      "kl 0.025107276\n",
      "completed in 0.1859431266784668 s\n",
      "game 221 completed in 6.015866041183472 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4674115 entropy 1.9039896\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4396365 entropy 1.8993948\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4100156 entropy 1.8962617\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3804638 entropy 1.8959777\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3508499 entropy 1.8982052\n",
      "kl 0.020136135\n",
      "completed in 0.16777515411376953 s\n",
      "game 222 completed in 9.177571058273315 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5574331 entropy 1.8865798\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5233424 entropy 1.894434\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4817667 entropy 1.9041069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4478033 entropy 1.9112823\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4156172 entropy 1.9144207\n",
      "kl 0.019412972\n",
      "completed in 0.18498611450195312 s\n",
      "game 223 completed in 9.930853843688965 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5269773 entropy 1.8971272\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4953804 entropy 1.8975435\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4519515 entropy 1.8969913\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.418247 entropy 1.8960781\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3832276 entropy 1.8954844\n",
      "kl 0.016885526\n",
      "completed in 0.16785407066345215 s\n",
      "game 224 completed in 11.012152910232544 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.551882 entropy 1.9008691\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.529097 entropy 1.8970633\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4931839 entropy 1.8905573\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.451085 entropy 1.8823284\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4094965 entropy 1.8730923\n",
      "kl 0.027077092\n",
      "completed in 0.1761629581451416 s\n",
      "game 225 completed in 8.461395978927612 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4638972 entropy 1.8532356\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4540899 entropy 1.8440684\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4290724 entropy 1.8348465\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3953912 entropy 1.8263463\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3565552 entropy 1.8189175\n",
      "kl 0.015613003\n",
      "completed in 0.18546795845031738 s\n",
      "game 226 completed in 11.101374864578247 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4666235 entropy 1.8241583\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4349022 entropy 1.8215559\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.397977 entropy 1.8209561\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3614988 entropy 1.8211195\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.329508 entropy 1.8220898\n",
      "kl 0.019597847\n",
      "completed in 0.17590999603271484 s\n",
      "game 227 completed in 8.302097082138062 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.489188 entropy 1.8538893\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4556592 entropy 1.8558166\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.417882 entropy 1.8560257\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.384294 entropy 1.8564525\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3498025 entropy 1.8573365\n",
      "kl 0.024879072\n",
      "completed in 0.1854400634765625 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 228 completed in 7.565752029418945 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4414914 entropy 1.8241913\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.409247 entropy 1.8273761\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3563993 entropy 1.8319056\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3220768 entropy 1.8356417\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2923968 entropy 1.8376197\n",
      "kl 0.025810327\n",
      "completed in 0.1711118221282959 s\n",
      "game 229 completed in 8.994099855422974 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3811984 entropy 1.8667638\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.362919 entropy 1.8673269\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3335187 entropy 1.8676827\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3029764 entropy 1.8684459\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2726216 entropy 1.8698727\n",
      "kl 0.015940832\n",
      "completed in 0.16324496269226074 s\n",
      "game 230 completed in 7.313467264175415 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3839717 entropy 1.897222\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3618197 entropy 1.902528\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3271677 entropy 1.910633\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2917855 entropy 1.9188111\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2588089 entropy 1.9248818\n",
      "kl 0.020109765\n",
      "completed in 0.16958308219909668 s\n",
      "game 231 completed in 5.975341796875 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4920099 entropy 1.9133017\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4734876 entropy 1.9147081\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4444342 entropy 1.9139798\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4090116 entropy 1.9122018\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3716302 entropy 1.9106085\n",
      "kl 0.018585924\n",
      "completed in 0.17040157318115234 s\n",
      "game 232 completed in 7.489540100097656 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5438359 entropy 1.943537\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5164661 entropy 1.9393756\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4794776 entropy 1.9345067\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4432847 entropy 1.9299498\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.409426 entropy 1.9261974\n",
      "kl 0.025878824\n",
      "completed in 0.1599428653717041 s\n",
      "game 233 completed in 9.316597938537598 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5203817 entropy 1.9153774\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.504657 entropy 1.9149077\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4738405 entropy 1.915081\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.440589 entropy 1.9156702\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4093852 entropy 1.9168088\n",
      "kl 0.018919319\n",
      "completed in 0.22286200523376465 s\n",
      "game 234 completed in 9.447798013687134 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.537886 entropy 1.9360126\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5138993 entropy 1.9365748\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.477214 entropy 1.9374485\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4429085 entropy 1.9389244\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.416208 entropy 1.9391172\n",
      "kl 0.030315306\n",
      "completed in 0.197005033493042 s\n",
      "game 235 completed in 5.921647787094116 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4631565 entropy 1.913695\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4384727 entropy 1.9074185\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4058735 entropy 1.8976665\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3645809 entropy 1.8868666\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3257222 entropy 1.8755344\n",
      "kl 0.020373676\n",
      "completed in 0.17275309562683105 s\n",
      "game 236 completed in 8.575641870498657 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.467217 entropy 1.8480353\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4320478 entropy 1.8418133\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3840778 entropy 1.8383194\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3422966 entropy 1.8374863\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.312794 entropy 1.8377557\n",
      "kl 0.023855124\n",
      "completed in 0.1866462230682373 s\n",
      "game 237 completed in 8.498229026794434 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4017367 entropy 1.7841473\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.377368 entropy 1.7851932\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3481 entropy 1.787153\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3162766 entropy 1.7897936\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2826576 entropy 1.7922833\n",
      "kl 0.024736535\n",
      "completed in 0.20058608055114746 s\n",
      "game 238 completed in 11.428122282028198 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5370328 entropy 1.8379073\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5090764 entropy 1.8418627\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4691117 entropy 1.84648\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4365396 entropy 1.8500235\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4095602 entropy 1.8517172\n",
      "kl 0.018067162\n",
      "completed in 0.17874717712402344 s\n",
      "game 239 completed in 7.673408031463623 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5613406 entropy 1.8816209\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5387192 entropy 1.881568\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5023673 entropy 1.8816221\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4670224 entropy 1.8821399\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4347484 entropy 1.8842525\n",
      "kl 0.021083448\n",
      "completed in 0.21071386337280273 s\n",
      "game 240 completed in 9.473210096359253 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4712453 entropy 1.8931161\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.450636 entropy 1.899058\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4177372 entropy 1.9038695\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.38245 entropy 1.9072936\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3517988 entropy 1.9092517\n",
      "kl 0.017871369\n",
      "completed in 0.17033982276916504 s\n",
      "game 241 completed in 5.776421308517456 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4374063 entropy 1.8873692\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4089477 entropy 1.8910263\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3752036 entropy 1.8950682\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.345272 entropy 1.8981898\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3159955 entropy 1.8987355\n",
      "kl 0.027880358\n",
      "completed in 0.18013429641723633 s\n",
      "game 242 completed in 12.322397947311401 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4715629 entropy 1.910141\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4534242 entropy 1.9083428\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4250176 entropy 1.9039755\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3944032 entropy 1.8970367\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3656633 entropy 1.8886888\n",
      "kl 0.014008751\n",
      "completed in 0.16696619987487793 s\n",
      "game 243 completed in 10.276792049407959 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5510273 entropy 1.8886843\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5191689 entropy 1.8876791\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4843976 entropy 1.889939\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4515026 entropy 1.8931632\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4198132 entropy 1.8951414\n",
      "kl 0.028545685\n",
      "completed in 0.16986489295959473 s\n",
      "game 244 completed in 7.579385995864868 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5103261 entropy 1.9213209\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4942064 entropy 1.9187262\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.468976 entropy 1.9153965\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.442832 entropy 1.9120929\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4171276 entropy 1.90951\n",
      "kl 0.018373558\n",
      "completed in 0.19210600852966309 s\n",
      "game 245 completed in 9.363542079925537 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5150664 entropy 1.8483962\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4925883 entropy 1.8479896\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.46149 entropy 1.8504187\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4305577 entropy 1.8542665\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4009283 entropy 1.8584629\n",
      "kl 0.02407987\n",
      "completed in 0.17435598373413086 s\n",
      "game 246 completed in 9.329684972763062 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4492073 entropy 1.9130281\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4317346 entropy 1.9164926\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4094 entropy 1.9180686\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3833063 entropy 1.9178102\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3565006 entropy 1.9147854\n",
      "kl 0.023817154\n",
      "completed in 0.1730329990386963 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 247 completed in 7.590184211730957 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4529262 entropy 1.8978641\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4368894 entropy 1.8949484\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4113014 entropy 1.8905373\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.382133 entropy 1.884975\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3544006 entropy 1.878171\n",
      "kl 0.018509611\n",
      "completed in 0.17730998992919922 s\n",
      "game 248 completed in 7.643913984298706 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4275556 entropy 1.834612\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4132502 entropy 1.8317921\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3906968 entropy 1.8306699\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3625438 entropy 1.8301457\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3359134 entropy 1.8299714\n",
      "kl 0.023226118\n",
      "completed in 0.19951796531677246 s\n",
      "prediction:\n",
      " [0.01131022 0.00248397 0.00674954 0.00383095 0.00375794 0.00245601\n",
      " 0.00519055 0.2636243  0.02068883 0.01002417 0.02425316 0.00524578\n",
      " 0.00753186 0.01358142 0.08975308 0.01081459 0.01572249 0.00735765\n",
      " 0.00606019 0.02425046 0.00959374 0.07686032 0.01306495 0.00967899\n",
      " 0.00344358 0.0152769  0.0183584  0.01709286 0.25372228 0.00452812\n",
      " 0.00611717 0.0049671  0.00598968 0.01171094 0.00378314 0.01112486] \n",
      " -0.56478995\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.41426783e-01 2.05256571e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.59073842e-01 3.94242804e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [7.0507597e-04 1.5007253e-04 3.2727595e-04 1.0116197e-04 1.5126326e-04\n",
      " 8.7895067e-05 2.3938152e-04 9.6823304e-04 1.2147769e-02 6.9437988e-02\n",
      " 3.9837667e-04 1.2529180e-04 5.3537905e-04 1.5771475e-02 2.7382692e-02\n",
      " 2.0343608e-01 7.6883882e-02 1.7337507e-04 7.7127341e-05 4.3484863e-02\n",
      " 4.4632697e-01 2.0590847e-02 1.4161836e-02 4.0665083e-04 1.3937484e-04\n",
      " 5.0914363e-04 5.1918514e-02 9.5234886e-03 1.1723422e-03 2.2319899e-04\n",
      " 3.3156353e-04 2.5495450e-04 2.3064234e-04 8.0920046e-04 1.8620485e-04\n",
      " 6.3050922e-04] \n",
      " 0.6420534\n",
      "p [[0.01001252 0.00125156 0.00375469 0.00250313 0.00250313 0.00250313]\n",
      " [0.00500626 0.2853567  0.01001252 0.01501877 0.01126408 0.00250313]\n",
      " [0.00876095 0.00750939 0.16520651 0.01251564 0.01877347 0.00375469]\n",
      " [0.00250313 0.02377972 0.01251564 0.         0.00625782 0.00500626]\n",
      " [0.00250313 0.00750939 0.01501877 0.01001252 0.30913642 0.00125156]\n",
      " [0.00375469 0.00625782 0.00250313 0.00750939 0.00125156 0.01501877]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00465679 0.00231916 0.00297226 0.0033088  0.0008909  0.00267052\n",
      " 0.00608921 0.00202955 0.05020259 0.02112756 0.01551201 0.00271431\n",
      " 0.0102786  0.2430507  0.00438467 0.00560428 0.08476063 0.0075773\n",
      " 0.00709877 0.08015767 0.00669735 0.00326584 0.29723957 0.00404513\n",
      " 0.00229858 0.02463702 0.01838647 0.04465704 0.00242838 0.00693624\n",
      " 0.00722713 0.00212041 0.0041299  0.00639972 0.00577307 0.00635189] \n",
      " -0.69061077\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.12640801e-02 4.50563204e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-02 2.37797247e-02 1.91489362e-01\n",
      "  1.12640801e-01 1.25156446e-13]\n",
      " [1.25156446e-13 2.00250313e-02 3.85481852e-01 0.00000000e+00\n",
      "  1.75219024e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.65206508e-01 1.50187735e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.40439835e-04 3.16412130e-04 9.65988584e-05 6.84396247e-04\n",
      " 1.73332828e-05 1.33860594e-04 1.97030284e-04 1.61294942e-04\n",
      " 9.97104961e-03 3.01126763e-03 8.53011385e-04 1.20936544e-04\n",
      " 3.15279554e-04 4.71074507e-03 1.59984187e-03 9.14788980e-04\n",
      " 3.85949165e-01 1.18346093e-03 9.66234191e-04 5.63893080e-01\n",
      " 8.78959021e-04 1.75704318e-03 2.50824355e-03 3.75583884e-04\n",
      " 5.55059778e-05 7.70513609e-04 2.98501691e-03 1.25412662e-02\n",
      " 3.19191953e-04 3.43670981e-04 2.03755175e-04 6.33710806e-05\n",
      " 4.84367512e-04 2.46301468e-04 9.21984029e-04 3.09126655e-04] \n",
      " 0.35860413\n",
      "p [[0.00750939 0.00375469 0.00125156 0.00250313 0.00750939 0.00250313]\n",
      " [0.00250313 0.00125156 0.03254068 0.02252816 0.01376721 0.00250313]\n",
      " [0.01001252 0.11889862 0.00250313 0.00375469 0.11639549 0.00750939]\n",
      " [0.00500626 0.0387985  0.         0.         0.1902378  0.01501877]\n",
      " [0.00125156 0.01376721 0.16020025 0.12390488 0.         0.01126408]\n",
      " [0.01001252 0.00125156 0.00500626 0.00750939 0.04130163 0.01627034]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00570483 0.02960126 0.0034457  0.00886007 0.00330756 0.00151982\n",
      " 0.0170987  0.00550102 0.1412806  0.12996738 0.00941907 0.01486748\n",
      " 0.00567354 0.00651229 0.002865   0.0726858  0.02230906 0.02782534\n",
      " 0.03475305 0.03749353 0.03894839 0.00255908 0.01140931 0.00582041\n",
      " 0.00605512 0.00871542 0.09836382 0.10966356 0.00792448 0.01837719\n",
      " 0.00420382 0.00486733 0.01078463 0.00707038 0.07857377 0.00597235] \n",
      " -0.8468432\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  5.09386733e-01 1.25156446e-13]\n",
      " [1.25156446e-13 4.85607009e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 3.75469337e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.7275615e-04 1.1993266e-03 3.6493267e-04 3.8184426e-04 1.6307629e-04\n",
      " 3.8582634e-04 6.0563121e-04 5.6176685e-04 5.4763287e-01 1.0332149e-03\n",
      " 5.2139438e-03 1.1588508e-03 1.0815954e-03 1.0101943e-02 3.4957359e-04\n",
      " 4.2995312e-03 1.6030049e-02 1.0299237e-03 1.7942755e-03 3.8792212e-02\n",
      " 2.9572714e-03 1.3975750e-03 1.6199635e-02 7.8266836e-04 1.4217839e-03\n",
      " 1.4816686e-03 4.4587255e-03 3.2982782e-01 6.8419852e-04 6.8880297e-04\n",
      " 3.7723570e-04 3.9471162e-04 3.0315109e-04 1.5025390e-03 5.0251707e-03\n",
      " 1.4405162e-04] \n",
      " 0.83702487\n",
      "p [[0.00375469 0.02002503 0.00125156 0.00625782 0.00250313 0.00125156]\n",
      " [0.01001252 0.00375469 0.11889862 0.09386733 0.00625782 0.01376721]\n",
      " [0.00375469 0.00375469 0.00125156 0.06257822 0.         0.01877347]\n",
      " [0.02503129 0.02628285 0.         0.         0.         0.00375469]\n",
      " [0.00375469 0.00500626 0.37797247 0.09637046 0.         0.01376721]\n",
      " [0.00250313 0.00250313 0.00625782 0.00500626 0.05506884 0.00500626]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.95294153e-03 4.56738062e-02 5.22170402e-03 2.39073765e-03\n",
      " 1.93809473e-03 4.20488010e-04 1.50915012e-02 2.79087503e-03\n",
      " 2.95067672e-02 3.96693032e-03 1.53551353e-02 1.07646007e-02\n",
      " 1.86975102e-03 6.41315384e-03 8.81401298e-04 4.72696036e-01\n",
      " 1.17219975e-02 1.54300155e-02 1.75158083e-02 2.86944211e-02\n",
      " 1.14676371e-01 6.74334355e-04 1.36032412e-02 3.26382206e-03\n",
      " 9.22156870e-03 1.23133250e-02 2.70180684e-03 2.06311680e-02\n",
      " 3.44954245e-03 9.44103952e-03 9.26426670e-04 1.96368108e-03\n",
      " 2.17966340e-03 1.71888527e-02 9.59642977e-02 1.50480552e-03] \n",
      " -0.63231647\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.38172716e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.02628285e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 8.42302879e-01\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [2.25349795e-04 1.14554495e-01 8.98737833e-03 4.77027334e-03\n",
      " 5.48483280e-04 6.46926754e-04 1.69350132e-02 6.26718625e-04\n",
      " 2.25137789e-02 3.48851737e-03 2.55428348e-02 2.29250058e-03\n",
      " 2.04003672e-03 1.04642451e-01 2.01544477e-04 4.14068066e-03\n",
      " 3.19041945e-02 4.77991393e-03 5.82540967e-03 6.11926988e-02\n",
      " 3.69149004e-03 1.73244090e-03 2.84343690e-01 1.38626536e-02\n",
      " 6.10682298e-04 7.12536927e-03 3.08882957e-03 2.31762566e-02\n",
      " 1.30110141e-03 1.44507485e-02 2.07780628e-03 1.04111596e-03\n",
      " 1.37572666e-03 7.98357464e-03 2.18083948e-01 1.95516375e-04] \n",
      " 0.98297906\n",
      "p [[0.00125156 0.03379224 0.00625782 0.00125156 0.00125156 0.00125156]\n",
      " [0.01251564 0.00125156 0.0212766  0.00500626 0.01126408 0.00750939]\n",
      " [0.00125156 0.00500626 0.00125156 0.61076345 0.         0.01877347]\n",
      " [0.02252816 0.02252816 0.         0.         0.         0.00125156]\n",
      " [0.00876095 0.02002503 0.         0.         0.         0.00625782]\n",
      " [0.00125156 0.00125156 0.00125156 0.01376721 0.15894869 0.00125156]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [7.2688987e-03 1.7929167e-01 4.9896012e-03 5.4506632e-03 4.7827158e-03\n",
      " 6.0923764e-04 1.6951188e-01 2.4838517e-03 6.9248289e-02 3.0844864e-03\n",
      " 2.4739305e-02 6.0841981e-03 7.4582023e-04 5.9108943e-04 5.9713662e-04\n",
      " 7.1189371e-03 3.2512650e-03 1.2678346e-02 9.6528875e-03 1.0483083e-02\n",
      " 2.8539079e-03 1.8674957e-04 1.4060636e-03 1.3308686e-03 5.6949756e-03\n",
      " 1.1705771e-02 5.4775989e-03 8.1678279e-02 2.2369435e-03 1.9722454e-01\n",
      " 1.6140073e-03 1.8777942e-03 7.1048569e-03 5.6651393e-03 1.4926213e-01\n",
      " 2.0171013e-03] \n",
      " -0.9805379\n",
      "p [[1.25156446e-13 5.88235294e-02 6.25782228e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.75219024e-02 1.25156446e-13 4.75594493e-02 1.25156446e-13\n",
      "  1.25156446e-02 1.25156446e-13]\n",
      " [1.25156446e-13 3.62953692e-01 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.61451815e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-02]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.62703379e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 2.50312891e-03\n",
      "  3.01627034e-01 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.83800643e-04 2.11609721e-01 8.39205386e-05 1.14393514e-03\n",
      " 4.76917885e-05 4.91079918e-05 1.22271970e-01 8.57201376e-05\n",
      " 3.34389904e-03 9.35215736e-04 1.41324440e-03 1.82501142e-04\n",
      " 4.29179636e-05 2.90528787e-05 1.33453841e-06 1.28206142e-04\n",
      " 9.84764425e-04 9.29217902e-04 1.44163356e-03 2.02761730e-03\n",
      " 2.21132810e-04 1.99988335e-05 2.36949869e-04 3.66317981e-04\n",
      " 1.72037500e-04 5.22889721e-04 1.91589061e-04 5.33828884e-03\n",
      " 1.29842767e-04 3.71999592e-02 1.27261694e-04 4.30539862e-04\n",
      " 4.29500069e-04 1.79465540e-04 6.07377648e-01 1.21208686e-04] \n",
      " 0.99755126\n",
      "p [[0.00625782 0.19524406 0.00375469 0.00500626 0.00375469 0.00125156]\n",
      " [0.15894869 0.00125156 0.11889862 0.00250313 0.02252816 0.00500626]\n",
      " [0.00125156 0.         0.00125156 0.         0.         0.01126408]\n",
      " [0.00876095 0.00876095 0.         0.         0.         0.00125156]\n",
      " [0.00500626 0.01001252 0.         0.         0.         0.26533166]\n",
      " [0.00125156 0.00125156 0.00625782 0.00500626 0.14768461 0.00125156]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1. -1. -1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.9800670e-04 4.8687164e-04 4.2435233e-04 2.0205101e-03 1.0489112e-03\n",
      " 7.0564944e-05 3.3891432e-03 4.3942712e-04 6.6045529e-01 1.5623546e-03\n",
      " 7.3058335e-03 7.6674263e-04 4.7838149e-04 1.2726740e-04 1.7186778e-04\n",
      " 3.1823376e-03 6.6454645e-04 5.4003242e-03 2.0326027e-03 1.4574786e-03\n",
      " 1.0735403e-03 9.0343063e-05 2.0956909e-04 2.6190467e-04 1.8683099e-03\n",
      " 2.6385852e-03 2.0479332e-03 2.9178318e-01 1.7844037e-04 2.6236253e-03\n",
      " 3.8069836e-04 4.5623936e-04 2.1289492e-03 3.1220404e-04 1.7768190e-03\n",
      " 1.8704563e-04] \n",
      " -0.97965527\n",
      "p [[1.25156446e-13 1.87734668e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.63954944e-01 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  8.17271589e-01 1.25156446e-13]]\n",
      "move 34\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1. -1. -1.]\n",
      " [ 0.  0.  0.  0.  1.  0.]]\n",
      "1 won\n",
      "game 249 completed in 27.048909187316895 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4512634 entropy 1.8699778\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.432757 entropy 1.8706712\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4043434 entropy 1.8738402\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3728898 entropy 1.8784618\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3403323 entropy 1.882931\n",
      "kl 0.01409092\n",
      "completed in 0.1900632381439209 s\n",
      "game 250 completed in 7.6675238609313965 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4701722 entropy 1.8619132\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.457353 entropy 1.8664193\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4348946 entropy 1.8697689\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4095285 entropy 1.8720073\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.382751 entropy 1.8732687\n",
      "kl 0.014880698\n",
      "completed in 0.1747570037841797 s\n",
      "game 251 completed in 7.5757410526275635 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4128757 entropy 1.8507468\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3962376 entropy 1.8538254\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3693867 entropy 1.8560511\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3384085 entropy 1.8553704\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3104794 entropy 1.8524556\n",
      "kl 0.014022632\n",
      "completed in 0.16942310333251953 s\n",
      "game 252 completed in 7.5075929164886475 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4349883 entropy 1.9093988\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4222202 entropy 1.9059949\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.401124 entropy 1.9022448\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3797462 entropy 1.8986773\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3579612 entropy 1.8956963\n",
      "kl 0.011693591\n",
      "completed in 0.1823110580444336 s\n",
      "game 253 completed in 7.658379077911377 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.44207 entropy 1.9106805\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.428857 entropy 1.9093232\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4051173 entropy 1.9081289\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3760226 entropy 1.9064667\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3467891 entropy 1.9043541\n",
      "kl 0.011705766\n",
      "completed in 0.17750763893127441 s\n",
      "game 254 completed in 7.563745021820068 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5136604 entropy 1.9052908\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.493497 entropy 1.9053552\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4609373 entropy 1.9075859\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4269004 entropy 1.9116268\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3967645 entropy 1.9171352\n",
      "kl 0.019226128\n",
      "completed in 0.20919108390808105 s\n",
      "game 255 completed in 8.33396291732788 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4679532 entropy 1.9014863\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.446586 entropy 1.9041717\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4197962 entropy 1.9030106\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3942902 entropy 1.8993719\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3715959 entropy 1.8951452\n",
      "kl 0.015732251\n",
      "completed in 0.15813493728637695 s\n",
      "game 256 completed in 10.9515860080719 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4882016 entropy 1.9325144\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4664967 entropy 1.9314808\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4327848 entropy 1.9316666\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3991904 entropy 1.9328425\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.370319 entropy 1.9341295\n",
      "kl 0.016257819\n",
      "completed in 0.17195916175842285 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 257 completed in 9.210858821868896 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4639812 entropy 1.8930844\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4484403 entropy 1.8952324\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.426618 entropy 1.897779\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4010007 entropy 1.9003916\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3746955 entropy 1.9021585\n",
      "kl 0.012792254\n",
      "completed in 0.19163894653320312 s\n",
      "game 258 completed in 9.322349071502686 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4523716 entropy 1.9281912\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.424702 entropy 1.9258177\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4026182 entropy 1.9218292\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.379251 entropy 1.9180472\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3529227 entropy 1.9149079\n",
      "kl 0.02021838\n",
      "completed in 0.20804286003112793 s\n",
      "game 259 completed in 9.071393966674805 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4676116 entropy 1.8811233\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4434383 entropy 1.8764622\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4094281 entropy 1.8707147\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.378425 entropy 1.8646979\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3517103 entropy 1.8592297\n",
      "kl 0.013948946\n",
      "completed in 0.17604923248291016 s\n",
      "game 260 completed in 6.874054908752441 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.418104 entropy 1.8431146\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3967757 entropy 1.8387653\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3548105 entropy 1.8349813\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3181114 entropy 1.8321546\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2912269 entropy 1.8297937\n",
      "kl 0.024277087\n",
      "completed in 0.1686570644378662 s\n",
      "game 261 completed in 7.640671968460083 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3855896 entropy 1.8764707\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3750618 entropy 1.8770059\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.349826 entropy 1.8796874\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3216147 entropy 1.883307\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2943468 entropy 1.8863742\n",
      "kl 0.017399872\n",
      "completed in 0.1672220230102539 s\n",
      "game 262 completed in 7.421926021575928 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3692927 entropy 1.8285456\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3404675 entropy 1.829806\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.304228 entropy 1.8309331\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2728927 entropy 1.8331697\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2426338 entropy 1.8368757\n",
      "kl 0.0251052\n",
      "completed in 0.17095136642456055 s\n",
      "game 263 completed in 7.654520034790039 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5250704 entropy 1.8607751\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4930606 entropy 1.8622713\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4494355 entropy 1.8607268\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4130874 entropy 1.858619\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3851888 entropy 1.8578167\n",
      "kl 0.023768071\n",
      "completed in 0.1622147560119629 s\n",
      "game 264 completed in 10.075377941131592 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4069707 entropy 1.8869778\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3799744 entropy 1.8877482\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.345217 entropy 1.8897316\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3128102 entropy 1.8922939\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2819853 entropy 1.8948324\n",
      "kl 0.025398336\n",
      "completed in 0.17507600784301758 s\n",
      "game 265 completed in 8.886112928390503 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4474854 entropy 1.9100845\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4314268 entropy 1.909863\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.401404 entropy 1.9073048\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3689556 entropy 1.9029441\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3433752 entropy 1.8985128\n",
      "kl 0.011852486\n",
      "completed in 0.1805717945098877 s\n",
      "game 266 completed in 10.55486798286438 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5119965 entropy 1.854899\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4909422 entropy 1.8556206\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.454067 entropy 1.859031\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4095113 entropy 1.8644029\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3707912 entropy 1.8698511\n",
      "kl 0.020183733\n",
      "completed in 0.17455506324768066 s\n",
      "game 267 completed in 5.937786817550659 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5184102 entropy 1.8948716\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4990098 entropy 1.9002137\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4728584 entropy 1.9053748\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.439976 entropy 1.908801\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4031372 entropy 1.909367\n",
      "kl 0.013276065\n",
      "completed in 0.17650580406188965 s\n",
      "game 268 completed in 7.75475811958313 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3611546 entropy 1.8640162\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3445709 entropy 1.8617872\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3188217 entropy 1.8591866\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2926543 entropy 1.8567429\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.268049 entropy 1.8545\n",
      "kl 0.014483025\n",
      "completed in 0.186384916305542 s\n",
      "game 269 completed in 11.042009115219116 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3549123 entropy 1.8754491\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3358355 entropy 1.8753699\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3050432 entropy 1.876598\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2752652 entropy 1.8777462\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2502246 entropy 1.8781681\n",
      "kl 0.011230536\n",
      "completed in 0.17781400680541992 s\n",
      "game 270 completed in 6.870137929916382 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4794743 entropy 1.8991135\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4582305 entropy 1.8995303\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4284334 entropy 1.8991842\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3936384 entropy 1.8965532\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.359371 entropy 1.8917346\n",
      "kl 0.014151429\n",
      "completed in 0.16123414039611816 s\n",
      "game 271 completed in 7.477246284484863 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4545498 entropy 1.8872664\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4340813 entropy 1.8792541\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.409246 entropy 1.8712808\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3835657 entropy 1.865562\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3549302 entropy 1.8631129\n",
      "kl 0.018841876\n",
      "completed in 0.18954801559448242 s\n",
      "game 272 completed in 5.92858624458313 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3540332 entropy 1.8295149\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3343902 entropy 1.835588\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3084662 entropy 1.8463167\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.280443 entropy 1.8593774\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2509716 entropy 1.8710756\n",
      "kl 0.034317046\n",
      "completed in 0.1766197681427002 s\n",
      "game 273 completed in 10.592254877090454 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3135548 entropy 1.9099567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.2930613 entropy 1.9150589\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.2692256 entropy 1.9167073\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2455056 entropy 1.9137946\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2261 entropy 1.9064176\n",
      "kl 0.01541698\n",
      "completed in 0.19078397750854492 s\n",
      "game 274 completed in 8.49867296218872 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3844461 entropy 1.8844683\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3640985 entropy 1.870757\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3351004 entropy 1.8562002\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3072052 entropy 1.8425679\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2859492 entropy 1.8320158\n",
      "kl 0.023710478\n",
      "completed in 0.16371774673461914 s\n",
      "game 275 completed in 9.278203010559082 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5104723 entropy 1.8535361\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.479082 entropy 1.8555188\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4446578 entropy 1.8639791\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4190228 entropy 1.8732727\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3921669 entropy 1.8796942\n",
      "kl 0.025979608\n",
      "completed in 0.15709495544433594 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 276 completed in 10.803669929504395 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4715466 entropy 1.8970623\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4517183 entropy 1.8958185\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4201994 entropy 1.8911644\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3873613 entropy 1.8846538\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3546777 entropy 1.8772087\n",
      "kl 0.019499797\n",
      "completed in 0.20764422416687012 s\n",
      "game 277 completed in 7.621458292007446 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3998666 entropy 1.8471079\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3838642 entropy 1.8421665\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3578663 entropy 1.8381587\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3308885 entropy 1.8357493\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3054028 entropy 1.8363016\n",
      "kl 0.017950848\n",
      "completed in 0.1703200340270996 s\n",
      "game 278 completed in 6.00111985206604 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5600476 entropy 1.8782356\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5322711 entropy 1.8882803\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4986098 entropy 1.9017372\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4700687 entropy 1.914973\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4437435 entropy 1.9242097\n",
      "kl 0.036850523\n",
      "completed in 0.17137885093688965 s\n",
      "game 279 completed in 9.933855772018433 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5028274 entropy 1.9272798\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.484326 entropy 1.9315666\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.44765 entropy 1.9322999\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4085834 entropy 1.9293048\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.375896 entropy 1.9239385\n",
      "kl 0.018998705\n",
      "completed in 0.18915820121765137 s\n",
      "game 280 completed in 11.008848190307617 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3510141 entropy 1.8381326\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.333238 entropy 1.831209\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3103702 entropy 1.8245692\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.2879472 entropy 1.8209362\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2654946 entropy 1.8209817\n",
      "kl 0.023337126\n",
      "completed in 0.18348431587219238 s\n",
      "game 281 completed in 10.353669166564941 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.392207 entropy 1.8605183\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.369278 entropy 1.8669097\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3384879 entropy 1.8748965\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3123007 entropy 1.8820117\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2888875 entropy 1.886395\n",
      "kl 0.033403795\n",
      "completed in 0.17778611183166504 s\n",
      "game 282 completed in 8.262397050857544 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4956322 entropy 1.9085178\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.480722 entropy 1.9064108\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.454665 entropy 1.9027805\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4269657 entropy 1.897516\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3966522 entropy 1.8904546\n",
      "kl 0.015908936\n",
      "completed in 0.17154502868652344 s\n",
      "game 283 completed in 9.325947999954224 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.45966 entropy 1.8930709\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4393458 entropy 1.8826743\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4089134 entropy 1.8709084\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3789804 entropy 1.8606932\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.352329 entropy 1.8546054\n",
      "kl 0.023019746\n",
      "completed in 0.16520977020263672 s\n",
      "game 284 completed in 9.31283974647522 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4759536 entropy 1.8418825\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4538767 entropy 1.8453283\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4244568 entropy 1.850951\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3939953 entropy 1.8586296\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.364266 entropy 1.8673126\n",
      "kl 0.019444153\n",
      "completed in 0.17537426948547363 s\n",
      "game 285 completed in 5.972254276275635 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4168162 entropy 1.9145379\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4016721 entropy 1.9196591\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3762343 entropy 1.9223977\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3475537 entropy 1.9221303\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3191104 entropy 1.9185226\n",
      "kl 0.019811774\n",
      "completed in 0.21634292602539062 s\n",
      "game 286 completed in 7.616316080093384 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4707215 entropy 1.9360571\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4510634 entropy 1.927533\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4195695 entropy 1.9171646\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3943436 entropy 1.9071295\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.373131 entropy 1.8996751\n",
      "kl 0.01259323\n",
      "completed in 0.174393892288208 s\n",
      "game 287 completed in 8.403181076049805 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4396539 entropy 1.904093\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.419954 entropy 1.9046824\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3860557 entropy 1.905719\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.351461 entropy 1.9066057\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3235986 entropy 1.906044\n",
      "kl 0.010527783\n",
      "completed in 0.16574501991271973 s\n",
      "game 288 completed in 8.553395986557007 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4500294 entropy 1.8625903\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4368713 entropy 1.859108\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4132109 entropy 1.8537716\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3851001 entropy 1.8477087\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3560567 entropy 1.8424002\n",
      "kl 0.015717005\n",
      "completed in 0.17736101150512695 s\n",
      "game 289 completed in 18.76228404045105 s 23 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4625556 entropy 1.8515949\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4416144 entropy 1.8535314\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.415775 entropy 1.8586748\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3873146 entropy 1.8660393\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3567727 entropy 1.8738377\n",
      "kl 0.01705352\n",
      "completed in 0.17335295677185059 s\n",
      "game 290 completed in 7.722377777099609 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.465 entropy 1.9128373\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4500701 entropy 1.9199111\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4260292 entropy 1.9254715\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4013472 entropy 1.9287876\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3740284 entropy 1.9294608\n",
      "kl 0.010192638\n",
      "completed in 0.18354296684265137 s\n",
      "game 291 completed in 7.477288007736206 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4620843 entropy 1.8566132\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4384344 entropy 1.8542105\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4064841 entropy 1.8505359\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3805053 entropy 1.8464298\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3523831 entropy 1.8424922\n",
      "kl 0.021115506\n",
      "completed in 0.17565298080444336 s\n",
      "game 292 completed in 10.024413108825684 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4256399 entropy 1.8937746\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.408165 entropy 1.8933078\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.385892 entropy 1.8923264\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3618615 entropy 1.8901507\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3380136 entropy 1.8864994\n",
      "kl 0.013817102\n",
      "completed in 0.19456100463867188 s\n",
      "game 293 completed in 9.426057815551758 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4008625 entropy 1.8297223\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3635461 entropy 1.826256\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3317287 entropy 1.8246114\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3062334 entropy 1.8247073\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.284079 entropy 1.8255452\n",
      "kl 0.02149928\n",
      "completed in 0.21580791473388672 s\n",
      "game 294 completed in 10.893659114837646 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4281576 entropy 1.8284533\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4107108 entropy 1.8314459\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3810158 entropy 1.8358839\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3511527 entropy 1.8404727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 4 lr_mult 0.4444444444444444 loss 2.32333 entropy 1.8432133\n",
      "kl 0.024412341\n",
      "completed in 0.20113205909729004 s\n",
      "game 295 completed in 13.190146923065186 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4569876 entropy 1.8671787\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4419177 entropy 1.8630499\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4162273 entropy 1.8564111\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3880744 entropy 1.8485212\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3595655 entropy 1.8404735\n",
      "kl 0.0191673\n",
      "completed in 0.2012770175933838 s\n",
      "game 296 completed in 6.8316240310668945 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5575163 entropy 1.8310341\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5341997 entropy 1.8268018\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4972212 entropy 1.8234122\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.458449 entropy 1.821903\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.42237 entropy 1.8219745\n",
      "kl 0.014501032\n",
      "completed in 0.1873178482055664 s\n",
      "game 297 completed in 7.54482889175415 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4208019 entropy 1.8203456\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4058235 entropy 1.8273559\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.385285 entropy 1.8368301\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.363949 entropy 1.8470016\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.341072 entropy 1.8563304\n",
      "kl 0.014674801\n",
      "completed in 0.1739521026611328 s\n",
      "game 298 completed in 6.830008029937744 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.469122 entropy 1.8950825\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4459329 entropy 1.8969259\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4104352 entropy 1.8963573\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3721397 entropy 1.8945894\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3400738 entropy 1.891856\n",
      "kl 0.016246997\n",
      "completed in 0.16777420043945312 s\n",
      "prediction:\n",
      " [0.00382956 0.00687375 0.0035831  0.0073777  0.00400178 0.00975232\n",
      " 0.00589619 0.01650741 0.01978459 0.01510892 0.32655886 0.00435221\n",
      " 0.00467519 0.02033031 0.00726586 0.03774272 0.01308847 0.00512842\n",
      " 0.00665267 0.01330628 0.03658336 0.00808327 0.02166792 0.00673192\n",
      " 0.00505447 0.3042252  0.0105693  0.02178665 0.01033493 0.00667783\n",
      " 0.0102103  0.0038846  0.00536832 0.00427007 0.00736847 0.00536717] \n",
      " -0.3789117\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.70212766e-01 1.96495620e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.30538173e-01 2.02753442e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [1.95652428e-05 1.22284880e-04 2.92302993e-05 4.18678945e-04\n",
      " 7.89587721e-05 1.21126242e-03 1.12357979e-04 6.65963453e-04\n",
      " 1.10748246e-01 3.86954681e-03 1.63376483e-03 6.22593288e-05\n",
      " 8.83824978e-05 1.70697942e-01 5.04289307e-02 1.03978589e-01\n",
      " 3.40732886e-03 2.50617653e-04 2.94305617e-04 3.37459263e-03\n",
      " 1.23883612e-01 1.93526119e-01 1.28789768e-01 1.15372044e-04\n",
      " 2.44952316e-05 1.55875902e-03 3.81674804e-03 9.50955749e-02\n",
      " 3.73222661e-04 2.19628200e-04 4.09523956e-04 9.67345622e-05\n",
      " 3.49394249e-04 5.81812492e-05 1.46100632e-04 4.41152661e-05] \n",
      " 0.54317504\n",
      "p [[0.00625782 0.00625782 0.00250313 0.00625782 0.00500626 0.01126408]\n",
      " [0.00750939 0.0212766  0.01001252 0.01376721 0.41176471 0.00500626]\n",
      " [0.00500626 0.01126408 0.01126408 0.12015019 0.00750939 0.00625782]\n",
      " [0.00876095 0.00750939 0.         0.01126408 0.02878598 0.01001252]\n",
      " [0.00500626 0.18147685 0.00625782 0.01001252 0.00876095 0.00750939]\n",
      " [0.01627034 0.00500626 0.00876095 0.00250313 0.00750939 0.00625782]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00162841 0.0021425  0.00288896 0.00540086 0.00196943 0.00881602\n",
      " 0.0098538  0.00639194 0.34908575 0.01878075 0.00285764 0.00226456\n",
      " 0.00085174 0.00927499 0.00451138 0.00074751 0.02838778 0.00533983\n",
      " 0.00860604 0.03274878 0.0012174  0.0033094  0.01270815 0.00182096\n",
      " 0.00392034 0.00214579 0.01248535 0.42837012 0.00333787 0.00755227\n",
      " 0.00434543 0.00347073 0.00385334 0.00355941 0.0031028  0.00225207] \n",
      " -0.82878613\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.83979975e-01 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 3.70463079e-01 3.75469337e-02 1.25156446e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.32665832e-01\n",
      "  6.00750939e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 9.01126408e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.7249175e-04 3.0063537e-03 1.3211566e-03 2.8337289e-02 4.5978240e-04\n",
      " 1.0873588e-02 2.7481996e-02 8.6106537e-03 1.3103320e-01 4.3205313e-02\n",
      " 2.9159790e-02 2.0609871e-03 5.4497842e-04 1.7796325e-02 5.2545756e-02\n",
      " 8.4530320e-03 2.5803050e-02 5.7065287e-03 8.3803302e-03 6.7250408e-02\n",
      " 1.8726010e-02 1.9134293e-01 2.2839256e-02 2.9337290e-03 5.6221493e-04\n",
      " 1.8985705e-02 2.3569645e-02 1.4492235e-01 3.2685427e-03 5.6805108e-02\n",
      " 1.8675475e-03 3.2736182e-03 3.1990338e-02 9.5649390e-04 5.2087554e-03\n",
      " 5.4491143e-04] \n",
      " 0.6975359\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00250313]\n",
      " [0.00375469 0.00250313 0.17146433 0.01001252 0.         0.00125156]\n",
      " [0.00125156 0.         0.00125156 0.00125156 0.23654568 0.00125156]\n",
      " [0.00250313 0.01251564 0.         0.00125156 0.00625782 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.51814768 0.00125156 0.00250313]\n",
      " [0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00481676 0.00271307 0.00408005 0.02276831 0.00317456 0.00679111\n",
      " 0.02054476 0.07626422 0.00907545 0.11860722 0.00771699 0.0070333\n",
      " 0.00640034 0.17781837 0.00141343 0.00077418 0.03605313 0.00897372\n",
      " 0.01406076 0.05470237 0.00125684 0.00096823 0.20256287 0.00630721\n",
      " 0.01071754 0.00506136 0.07139831 0.00886611 0.0306017  0.01791082\n",
      " 0.00650461 0.01165316 0.02573644 0.0056076  0.00670556 0.00435972] \n",
      " -0.82819784\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 7.50938673e-02\n",
      "  1.25156446e-13 1.25156446e-02]\n",
      " [1.50187735e-02 2.00250313e-02 1.28911139e-01 7.38423029e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 6.88360451e-02 1.50187735e-02\n",
      "  1.25156446e-02 3.75469337e-03]\n",
      " [1.00125156e-02 1.50187735e-02 0.00000000e+00 4.58072591e-01\n",
      "  1.25156446e-02 1.25156446e-13]\n",
      " [1.25156446e-13 3.12891114e-02 1.37672090e-02 0.00000000e+00\n",
      "  1.25156446e-13 2.25281602e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.12640801e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.0185461e-04 1.9256174e-04 3.9887829e-05 1.8294908e-03 4.1914936e-05\n",
      " 4.4476113e-04 1.4502743e-03 2.1922924e-03 9.0741999e-03 2.1518979e-03\n",
      " 6.9189339e-04 1.0656126e-04 1.6234348e-05 1.0011096e-04 6.2915776e-04\n",
      " 7.1884962e-05 2.8515017e-01 7.9428504e-04 2.8113737e-03 6.7460269e-01\n",
      " 2.5927165e-04 2.3937400e-03 6.4994951e-05 1.2871149e-04 4.9809314e-05\n",
      " 2.0944142e-04 1.0300543e-03 7.2846762e-03 8.1321283e-04 2.2956827e-03\n",
      " 9.4742849e-05 1.3866858e-04 2.2491503e-03 3.7842368e-05 1.5840618e-04\n",
      " 2.9817718e-04] \n",
      " 0.9698375\n",
      "p [[0.00500626 0.00125156 0.00125156 0.01501877 0.00250313 0.00500626]\n",
      " [0.02377972 0.06132666 0.06257822 0.22653317 0.         0.01251564]\n",
      " [0.00250313 0.         0.00125156 0.00500626 0.03254068 0.00750939]\n",
      " [0.01001252 0.03754693 0.         0.         0.31289111 0.00876095]\n",
      " [0.00876095 0.00250313 0.06007509 0.         0.03379224 0.01001252]\n",
      " [0.00375469 0.00625782 0.02628285 0.00250313 0.00876095 0.00250313]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.0758243e-03 5.4735960e-03 1.0322088e-03 6.0967766e-02 1.0882416e-02\n",
      " 7.2510459e-04 8.4332200e-03 9.7219162e-02 8.9817873e-04 6.7589795e-03\n",
      " 4.9871486e-04 4.9077352e-03 8.9139811e-04 2.6691522e-04 7.4097770e-05\n",
      " 9.9231242e-05 1.2880175e-01 4.4455379e-02 4.5436901e-01 8.3343960e-02\n",
      " 1.6971957e-04 1.8535001e-04 1.5473951e-04 1.1863294e-03 8.6028110e-03\n",
      " 2.5718973e-04 2.2215461e-03 1.2317664e-03 3.3990335e-02 9.1852313e-03\n",
      " 8.2927733e-04 1.0225161e-02 1.3469656e-02 1.8843393e-03 3.9471560e-03\n",
      " 1.2849036e-03] \n",
      " -0.85609984\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.00625782e-03 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  7.63454318e-02 1.25156446e-13]\n",
      " [1.25156446e-13 9.18648310e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.0900279e-04 1.1049099e-03 2.1491956e-04 5.3578182e-03 2.1254092e-03\n",
      " 1.5859347e-03 8.8343106e-04 6.3578576e-01 2.7604341e-03 9.7480901e-03\n",
      " 8.1449486e-02 3.2542725e-04 7.3413446e-04 9.9227182e-04 1.4292175e-04\n",
      " 1.1300651e-04 2.6954725e-02 1.4557005e-03 3.0141724e-03 2.4383174e-02\n",
      " 3.5975216e-04 1.2555770e-03 3.8000083e-04 6.1924203e-04 1.2967769e-04\n",
      " 6.3243531e-02 3.8719738e-03 1.9048556e-03 1.0865163e-01 1.0164395e-03\n",
      " 5.1066570e-04 4.0648603e-03 5.3996239e-03 2.1898821e-04 5.3095492e-03\n",
      " 3.0230086e-03] \n",
      " 0.6518042\n",
      "p [[0.00250313 0.00250313 0.00125156 0.03629537 0.00625782 0.00250313]\n",
      " [0.00625782 0.05506884 0.00250313 0.00375469 0.         0.00500626]\n",
      " [0.00125156 0.         0.00125156 0.00125156 0.16645807 0.02753442]\n",
      " [0.60951189 0.         0.         0.         0.         0.00250313]\n",
      " [0.00500626 0.00125156 0.00250313 0.         0.02503129 0.00500626]\n",
      " [0.00125156 0.00625782 0.01376721 0.00125156 0.00375469 0.00125156]]\n",
      "move 18\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.7595951e-03 9.3188204e-02 3.1465283e-03 1.4681232e-01 1.8695487e-02\n",
      " 1.1058265e-03 1.6334852e-02 2.6843449e-02 1.9337902e-03 9.7113363e-03\n",
      " 4.5445571e-03 6.9336211e-03 1.4196669e-03 3.5549735e-04 2.1484355e-04\n",
      " 4.0143722e-04 2.4918829e-01 8.3370293e-03 3.5802942e-02 1.4510798e-01\n",
      " 4.0514753e-04 2.8616303e-04 2.0855427e-04 3.2483083e-03 2.2468789e-02\n",
      " 1.9592748e-03 5.0775590e-03 2.1847766e-03 1.1444005e-02 2.2753729e-02\n",
      " 1.7902775e-03 2.2812873e-02 4.0361904e-02 2.2989120e-03 8.0483206e-02\n",
      " 5.3793984e-03] \n",
      " -0.9906193\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 4.68085106e-01 1.25156446e-13 1.00125156e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  1.50187735e-02 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 4.39299124e-01 1.25156446e-13 0.00000000e+00\n",
      "  6.75844806e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.01758880e-04 7.76552111e-02 6.75254923e-05 1.84086763e-04\n",
      " 1.52878196e-03 1.66941129e-04 1.54046298e-04 6.84291183e-04\n",
      " 9.64407227e-05 5.02260227e-05 1.85348496e-01 1.92045190e-05\n",
      " 8.24298422e-06 6.08845257e-05 1.23386383e-06 7.72039857e-06\n",
      " 1.36216939e-03 1.31246707e-04 1.23886784e-04 1.02752785e-03\n",
      " 7.56228292e-06 3.95375992e-06 2.66922962e-05 6.76651180e-05\n",
      " 4.36835944e-05 2.32029930e-02 3.01600958e-05 5.58256143e-05\n",
      " 2.51212536e-04 5.27633238e-04 6.54903415e-05 9.73211322e-03\n",
      " 2.73831072e-04 1.15721632e-05 6.96807444e-01 1.12463895e-04] \n",
      " -0.07800171\n",
      "p [[0.00876095 0.04881101 0.00125156 0.08260325 0.08510638 0.00125156]\n",
      " [0.01001252 0.         0.00125156 0.00500626 0.         0.00375469]\n",
      " [0.00125156 0.         0.00125156 0.00125156 0.33541927 0.00375469]\n",
      " [0.         0.         0.         0.         0.         0.00125156]\n",
      " [0.01376721 0.00125156 0.00250313 0.         0.11764706 0.02753442]\n",
      " [0.00125156 0.01376721 0.18523154 0.00125156 0.04130163 0.00250313]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.7276571e-04 2.8216464e-03 9.2334434e-05 4.8993057e-05 9.5415838e-02\n",
      " 3.6759762e-04 1.6098021e-04 3.9658350e-01 9.3026101e-06 1.8943438e-05\n",
      " 2.2588643e-04 2.6287857e-04 1.5973843e-04 7.4209362e-05 3.4406958e-06\n",
      " 2.8128551e-07 8.7049688e-05 2.6507823e-05 1.0500738e-04 5.4377397e-05\n",
      " 3.9806693e-07 1.7620595e-06 2.2164892e-05 2.2055372e-05 2.1208758e-03\n",
      " 2.7496457e-05 1.0114455e-05 1.9789832e-05 3.0887708e-01 3.8774835e-04\n",
      " 2.3408883e-04 1.8864593e-01 3.9112056e-06 4.4596544e-04 2.3442004e-03\n",
      " 1.4527091e-04] \n",
      " -0.97319114\n",
      "p [[1.25156446e-13 7.13391740e-01 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 2.12765957e-01 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  7.25907384e-02 1.25156446e-13]]\n",
      "move 1\n",
      "board\n",
      " [[ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0.  0. -1.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 299 completed in 25.422067165374756 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4541016 entropy 1.847625\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.435154 entropy 1.8488921\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4091508 entropy 1.8523533\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.380107 entropy 1.8572791\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3535383 entropy 1.8627541\n",
      "kl 0.015673822\n",
      "completed in 0.1730489730834961 s\n",
      "training pipeline completed in 2870.0616869926453 s\n"
     ]
    }
   ],
   "source": [
    "k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5602037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.save('n2-1500.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664ab8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43e834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3a95f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:18: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:22: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:26: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:31: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:40: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:44: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:51: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
      "2022-01-20 15:18:48.384785: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-20 15:18:48.384809: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-20 15:18:48.390911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "k = Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f798851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:18:53.298288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 13.68191909790039 s 17 steps\n",
      "training pipeline completed in 13.682025909423828 s\n"
     ]
    }
   ],
   "source": [
    "k.run(n_games=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ee7e1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02874902, 0.02816677, 0.02737665, 0.02786939, 0.02817374,\n",
       "        0.02880505, 0.02842465, 0.02777849, 0.0273738 , 0.02997385,\n",
       "        0.02888173, 0.0272564 , 0.02807645, 0.02801098, 0.02532525,\n",
       "        0.02746927, 0.02689827, 0.02734488, 0.02804661, 0.02762723,\n",
       "        0.02768766, 0.02771193, 0.02898358, 0.02825021, 0.02702713,\n",
       "        0.02528107, 0.02628838, 0.02733569, 0.02815543, 0.02581511,\n",
       "        0.027064  , 0.02844283, 0.02840897, 0.02999027, 0.0269438 ,\n",
       "        0.02898561], dtype=float32),\n",
       " -0.029936753)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:28:35.683306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "k.pv_net.predict(b.get_state().reshape(-1, 4, 6, 6))\n",
    "k.save('test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7474cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:18: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:22: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:26: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:31: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:40: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:44: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:51: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
      "2022-01-20 15:28:44.437709: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-20 15:28:44.437729: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-20 15:28:44.444137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:28:44.524546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-20 15:28:44.548772: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.02874902, 0.02816677, 0.02737665, 0.02786939, 0.02817374,\n",
       "        0.02880505, 0.02842465, 0.02777849, 0.0273738 , 0.02997385,\n",
       "        0.02888173, 0.0272564 , 0.02807645, 0.02801098, 0.02532525,\n",
       "        0.02746927, 0.02689827, 0.02734488, 0.02804661, 0.02762723,\n",
       "        0.02768766, 0.02771193, 0.02898358, 0.02825021, 0.02702713,\n",
       "        0.02528107, 0.02628838, 0.02733569, 0.02815543, 0.02581511,\n",
       "        0.027064  , 0.02844283, 0.02840897, 0.02999027, 0.0269438 ,\n",
       "        0.02898561], dtype=float32),\n",
       " -0.029936753)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PVNet2(6, 6)\n",
    "p.restore('test.model')\n",
    "p.predict(b.get_state().reshape(-1, 4, 6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a052d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df3fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f715271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:17: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:21: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:25: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:30: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:39: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:43: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:50: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:53: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
      "2022-01-20 12:09:51.092888: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-20 12:09:51.092905: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-20 12:09:51.113028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-20 12:09:51.295629: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 10.20585298538208 s 12 steps\n",
      "game 1 completed in 12.43356990814209 s 15 steps\n",
      "game 2 completed in 12.412672996520996 s 15 steps\n",
      "game 3 completed in 16.40099811553955 s 20 steps\n",
      "game 4 completed in 8.33475923538208 s 10 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 12:10:51.105840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 0 lr_mult 1.0 loss 4.6394787 entropy 3.581136\n",
      "training 1 lr_mult 1.0 loss 4.628387 entropy 3.5826116\n",
      "training 2 lr_mult 1.0 loss 4.617593 entropy 3.5819411\n",
      "training 3 lr_mult 1.0 loss 4.5853596 entropy 3.5821579\n",
      "training 4 lr_mult 1.0 loss 4.5643735 entropy 3.5815341\n",
      "kl 0.0034765895\n",
      "completed in 0.5984289646148682 s\n",
      "game 5 completed in 10.418401956558228 s 12 steps\n",
      "training 0 lr_mult 1.5 loss 4.520674 entropy 3.5799809\n",
      "training 1 lr_mult 1.5 loss 4.445717 entropy 3.573915\n",
      "training 2 lr_mult 1.5 loss 4.3892646 entropy 3.5645156\n",
      "training 3 lr_mult 1.5 loss 4.3492365 entropy 3.5629597\n",
      "training 4 lr_mult 1.5 loss 4.2846427 entropy 3.5693307\n",
      "kl 0.004093402\n",
      "completed in 0.303513765335083 s\n",
      "game 6 completed in 13.651462078094482 s 16 steps\n",
      "training 0 lr_mult 2.25 loss 4.2197266 entropy 3.5744061\n",
      "training 1 lr_mult 2.25 loss 4.191503 entropy 3.5744042\n",
      "training 2 lr_mult 2.25 loss 4.2177305 entropy 3.5664349\n",
      "training 3 lr_mult 2.25 loss 4.011654 entropy 3.553117\n",
      "training 4 lr_mult 2.25 loss 4.0838737 entropy 3.5432405\n",
      "kl 0.015318338\n",
      "completed in 0.298403263092041 s\n",
      "game 7 completed in 12.635275840759277 s 15 steps\n",
      "training 0 lr_mult 2.25 loss 4.190814 entropy 3.5470104\n",
      "training 1 lr_mult 2.25 loss 4.0698476 entropy 3.559446\n",
      "training 2 lr_mult 2.25 loss 3.9681814 entropy 3.5597034\n",
      "training 3 lr_mult 2.25 loss 3.9199667 entropy 3.5488372\n",
      "training 4 lr_mult 2.25 loss 3.8422616 entropy 3.5312269\n",
      "kl 0.015435003\n",
      "completed in 0.31867098808288574 s\n",
      "game 8 completed in 14.508755922317505 s 17 steps\n",
      "training 0 lr_mult 2.25 loss 3.878013 entropy 3.5207105\n",
      "training 1 lr_mult 2.25 loss 3.8399143 entropy 3.5444837\n",
      "training 2 lr_mult 2.25 loss 3.822772 entropy 3.5573244\n",
      "training 3 lr_mult 2.25 loss 3.755512 entropy 3.5526533\n",
      "training 4 lr_mult 2.25 loss 3.718082 entropy 3.5356178\n",
      "kl 0.022008408\n",
      "completed in 0.27265095710754395 s\n",
      "game 9 completed in 10.281950950622559 s 12 steps\n",
      "training 0 lr_mult 2.25 loss 3.940127 entropy 3.517608\n",
      "training 1 lr_mult 2.25 loss 3.9456687 entropy 3.5115383\n",
      "training 2 lr_mult 2.25 loss 3.846556 entropy 3.5162551\n",
      "training 3 lr_mult 2.25 loss 3.8427742 entropy 3.515914\n",
      "training 4 lr_mult 2.25 loss 3.7877426 entropy 3.5116396\n",
      "kl 0.025192134\n",
      "completed in 0.37868690490722656 s\n",
      "game 10 completed in 13.662455081939697 s 16 steps\n",
      "training 0 lr_mult 2.25 loss 4.185064 entropy 3.512167\n",
      "training 1 lr_mult 2.25 loss 4.1307707 entropy 3.5015192\n",
      "training 2 lr_mult 2.25 loss 4.0813007 entropy 3.4825463\n",
      "training 3 lr_mult 2.25 loss 4.0262256 entropy 3.4585881\n",
      "training 4 lr_mult 2.25 loss 3.9985805 entropy 3.4569142\n",
      "kl 0.046513397\n",
      "completed in 0.29891490936279297 s\n",
      "game 11 completed in 18.063499689102173 s 21 steps\n",
      "training 0 lr_mult 1.5 loss 4.075766 entropy 3.462834\n",
      "training 1 lr_mult 1.5 loss 4.015968 entropy 3.4706502\n",
      "training 2 lr_mult 1.5 loss 3.9755545 entropy 3.4764407\n",
      "training 3 lr_mult 1.5 loss 3.9280467 entropy 3.4755597\n",
      "training 4 lr_mult 1.5 loss 3.9086096 entropy 3.4673064\n",
      "kl 0.03990493\n",
      "completed in 0.28755903244018555 s\n",
      "game 12 completed in 13.127608060836792 s 15 steps\n",
      "training 0 lr_mult 1.5 loss 3.8636498 entropy 3.4643295\n",
      "training 1 lr_mult 1.5 loss 3.8380558 entropy 3.4463208\n",
      "training 2 lr_mult 1.5 loss 3.8082716 entropy 3.4282894\n",
      "training 3 lr_mult 1.5 loss 3.780153 entropy 3.4144082\n",
      "training 4 lr_mult 1.5 loss 3.752573 entropy 3.393807\n",
      "kl 0.051127832\n",
      "completed in 0.2890629768371582 s\n",
      "game 13 completed in 11.995296716690063 s 14 steps\n",
      "training 0 lr_mult 1.0 loss 4.008721 entropy 3.372916\n",
      "training 1 lr_mult 1.0 loss 3.988435 entropy 3.365899\n",
      "training 2 lr_mult 1.0 loss 3.9553592 entropy 3.3663864\n",
      "training 3 lr_mult 1.0 loss 3.9118552 entropy 3.3657138\n",
      "training 4 lr_mult 1.0 loss 3.86851 entropy 3.360136\n",
      "kl 0.022874715\n",
      "completed in 0.3115570545196533 s\n",
      "game 14 completed in 19.91490411758423 s 24 steps\n",
      "training 0 lr_mult 1.0 loss 4.272371 entropy 3.367675\n",
      "training 1 lr_mult 1.0 loss 4.2321744 entropy 3.3706317\n",
      "training 2 lr_mult 1.0 loss 4.187338 entropy 3.384116\n",
      "training 3 lr_mult 1.0 loss 4.144335 entropy 3.3989186\n",
      "training 4 lr_mult 1.0 loss 4.102348 entropy 3.403203\n",
      "kl 0.02686046\n",
      "completed in 0.28765392303466797 s\n",
      "game 15 completed in 9.482294797897339 s 11 steps\n",
      "training 0 lr_mult 1.0 loss 4.1286473 entropy 3.4006665\n",
      "training 1 lr_mult 1.0 loss 4.0886254 entropy 3.3796952\n",
      "training 2 lr_mult 1.0 loss 4.031048 entropy 3.3672132\n",
      "training 3 lr_mult 1.0 loss 3.9788997 entropy 3.3724136\n",
      "training 4 lr_mult 1.0 loss 3.9369843 entropy 3.3788521\n",
      "kl 0.014752563\n",
      "completed in 0.28449320793151855 s\n",
      "game 16 completed in 19.313764095306396 s 23 steps\n",
      "training 0 lr_mult 1.0 loss 3.9782708 entropy 3.3662996\n",
      "training 1 lr_mult 1.0 loss 3.9440513 entropy 3.3555772\n",
      "training 2 lr_mult 1.0 loss 3.8996897 entropy 3.3413787\n",
      "training 3 lr_mult 1.0 loss 3.8500657 entropy 3.3224876\n",
      "training 4 lr_mult 1.0 loss 3.8014112 entropy 3.2993941\n",
      "kl 0.03457816\n",
      "completed in 0.29103899002075195 s\n",
      "game 17 completed in 20.27878499031067 s 24 steps\n",
      "training 0 lr_mult 1.0 loss 4.100208 entropy 3.2952948\n",
      "training 1 lr_mult 1.0 loss 4.056813 entropy 3.284607\n",
      "training 2 lr_mult 1.0 loss 4.0026317 entropy 3.2890491\n",
      "training 3 lr_mult 1.0 loss 3.9413989 entropy 3.2934418\n",
      "training 4 lr_mult 1.0 loss 3.8888915 entropy 3.292727\n",
      "kl 0.032422632\n",
      "completed in 0.29116392135620117 s\n",
      "game 18 completed in 16.646970748901367 s 20 steps\n",
      "training 0 lr_mult 1.0 loss 4.080464 entropy 3.2916918\n",
      "training 1 lr_mult 1.0 loss 4.0274787 entropy 3.296256\n",
      "training 2 lr_mult 1.0 loss 3.964617 entropy 3.3135884\n",
      "training 3 lr_mult 1.0 loss 3.9134634 entropy 3.3318157\n",
      "training 4 lr_mult 1.0 loss 3.8575208 entropy 3.340321\n",
      "kl 0.020537632\n",
      "completed in 0.2912440299987793 s\n",
      "game 19 completed in 12.60854983329773 s 15 steps\n",
      "training 0 lr_mult 1.0 loss 4.0473843 entropy 3.3528745\n",
      "training 1 lr_mult 1.0 loss 4.0076394 entropy 3.3470695\n",
      "training 2 lr_mult 1.0 loss 3.968787 entropy 3.3409357\n",
      "training 3 lr_mult 1.0 loss 3.923002 entropy 3.337585\n",
      "training 4 lr_mult 1.0 loss 3.8776593 entropy 3.3344626\n",
      "kl 0.016461732\n",
      "completed in 0.35628199577331543 s\n",
      "game 20 completed in 10.191401958465576 s 12 steps\n",
      "training 0 lr_mult 1.0 loss 4.026392 entropy 3.337765\n",
      "training 1 lr_mult 1.0 loss 3.9846704 entropy 3.3352818\n",
      "training 2 lr_mult 1.0 loss 3.9291828 entropy 3.3315089\n",
      "training 3 lr_mult 1.0 loss 3.8821874 entropy 3.325083\n",
      "training 4 lr_mult 1.0 loss 3.8507822 entropy 3.3134153\n",
      "kl 0.030572373\n",
      "completed in 0.2623159885406494 s\n",
      "game 21 completed in 14.715435981750488 s 18 steps\n",
      "training 0 lr_mult 1.0 loss 3.9391134 entropy 3.3114333\n",
      "training 1 lr_mult 1.0 loss 3.8801448 entropy 3.3040068\n",
      "training 2 lr_mult 1.0 loss 3.8276196 entropy 3.3002946\n",
      "training 3 lr_mult 1.0 loss 3.7742 entropy 3.29682\n",
      "training 4 lr_mult 1.0 loss 3.726234 entropy 3.2939296\n",
      "kl 0.02615497\n",
      "completed in 0.29331207275390625 s\n",
      "game 22 completed in 10.333263874053955 s 12 steps\n",
      "training 0 lr_mult 1.0 loss 3.8696742 entropy 3.2808223\n",
      "training 1 lr_mult 1.0 loss 3.8474054 entropy 3.2921948\n",
      "training 2 lr_mult 1.0 loss 3.8087292 entropy 3.3108344\n",
      "training 3 lr_mult 1.0 loss 3.7715979 entropy 3.3299413\n",
      "training 4 lr_mult 1.0 loss 3.7302318 entropy 3.340807\n",
      "kl 0.031058453\n",
      "completed in 0.3044312000274658 s\n",
      "game 23 completed in 8.36453914642334 s 9 steps\n",
      "training 0 lr_mult 1.0 loss 3.8817582 entropy 3.353867\n",
      "training 1 lr_mult 1.0 loss 3.8443863 entropy 3.3407698\n",
      "training 2 lr_mult 1.0 loss 3.8131948 entropy 3.3154273\n",
      "training 3 lr_mult 1.0 loss 3.7627776 entropy 3.2824674\n",
      "training 4 lr_mult 1.0 loss 3.736541 entropy 3.2593613\n",
      "kl 0.029920338\n",
      "completed in 0.29613208770751953 s\n",
      "game 24 completed in 10.078070163726807 s 11 steps\n",
      "training 0 lr_mult 1.0 loss 4.0931807 entropy 3.2664137\n",
      "training 1 lr_mult 1.0 loss 4.0562587 entropy 3.2951484\n",
      "training 2 lr_mult 1.0 loss 4.008056 entropy 3.319255\n",
      "training 3 lr_mult 1.0 loss 3.9632754 entropy 3.3314178\n",
      "training 4 lr_mult 1.0 loss 3.918499 entropy 3.331377\n",
      "kl 0.027307129\n",
      "completed in 0.337352991104126 s\n",
      "game 25 completed in 12.937255859375 s 14 steps\n",
      "training 0 lr_mult 1.0 loss 3.9064274 entropy 3.3287716\n",
      "training 1 lr_mult 1.0 loss 3.8872313 entropy 3.2932746\n",
      "training 2 lr_mult 1.0 loss 3.859326 entropy 3.2467308\n",
      "training 3 lr_mult 1.0 loss 3.8248894 entropy 3.2222846\n",
      "training 4 lr_mult 1.0 loss 3.784028 entropy 3.226912\n",
      "kl 0.03299198\n",
      "completed in 0.29709911346435547 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 26 completed in 12.000976800918579 s 13 steps\n",
      "training 0 lr_mult 1.0 loss 3.8849018 entropy 3.2332413\n",
      "training 1 lr_mult 1.0 loss 3.8604217 entropy 3.2617896\n",
      "training 2 lr_mult 1.0 loss 3.8180218 entropy 3.2823243\n",
      "training 3 lr_mult 1.0 loss 3.7674122 entropy 3.2843022\n",
      "training 4 lr_mult 1.0 loss 3.7299535 entropy 3.269187\n",
      "kl 0.043320514\n",
      "completed in 0.2742042541503906 s\n",
      "game 27 completed in 7.415899753570557 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.793778 entropy 3.25625\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.776403 entropy 3.2562332\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.745338 entropy 3.2656827\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.71293 entropy 3.274415\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6853256 entropy 3.277104\n",
      "kl 0.03681104\n",
      "completed in 0.2846081256866455 s\n",
      "game 28 completed in 18.898313999176025 s 21 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.9653125 entropy 3.2783716\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.9416149 entropy 3.2760034\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.9056458 entropy 3.2725754\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.864452 entropy 3.2677708\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.826552 entropy 3.2657957\n",
      "kl 0.036090024\n",
      "completed in 0.27474308013916016 s\n",
      "game 29 completed in 11.888936996459961 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.890723 entropy 3.2739718\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8728597 entropy 3.2807646\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.8466947 entropy 3.2881722\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.8164237 entropy 3.2923498\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.7837276 entropy 3.2912025\n",
      "kl 0.023382101\n",
      "completed in 0.3452610969543457 s\n",
      "game 30 completed in 18.002033948898315 s 20 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.874742 entropy 3.2825446\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8422942 entropy 3.2756605\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7973258 entropy 3.2672362\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.7515972 entropy 3.2569118\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.7096539 entropy 3.2473514\n",
      "kl 0.031839997\n",
      "completed in 0.27901792526245117 s\n",
      "game 31 completed in 7.406805992126465 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.797688 entropy 3.2219548\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.764898 entropy 3.2294984\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7233796 entropy 3.2394216\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6872466 entropy 3.2431295\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6589947 entropy 3.238265\n",
      "kl 0.022990737\n",
      "completed in 0.2678239345550537 s\n",
      "game 32 completed in 13.644236087799072 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8820994 entropy 3.2493074\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8517346 entropy 3.2311168\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.8032827 entropy 3.217488\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.756654 entropy 3.2204037\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.7223127 entropy 3.2308564\n",
      "kl 0.017638072\n",
      "completed in 0.28268885612487793 s\n",
      "game 33 completed in 16.552181005477905 s 18 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8481028 entropy 3.2349648\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8118114 entropy 3.2359648\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7712533 entropy 3.2309153\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.72271 entropy 3.22445\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6754782 entropy 3.2193756\n",
      "kl 0.026829055\n",
      "completed in 0.30450010299682617 s\n",
      "game 34 completed in 16.336260080337524 s 18 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8138025 entropy 3.2357578\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7835205 entropy 3.229214\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.74809 entropy 3.2194514\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.7091699 entropy 3.2108634\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6638575 entropy 3.205814\n",
      "kl 0.017499179\n",
      "completed in 0.2742636203765869 s\n",
      "game 35 completed in 7.523236989974976 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.784687 entropy 3.2085807\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7303648 entropy 3.2048736\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.693849 entropy 3.204\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6754372 entropy 3.2072053\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6419835 entropy 3.2158644\n",
      "kl 0.02017397\n",
      "completed in 0.28424906730651855 s\n",
      "game 36 completed in 17.222205877304077 s 19 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8113596 entropy 3.217035\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.787811 entropy 3.2347732\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7658536 entropy 3.250414\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.7349885 entropy 3.259345\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6892343 entropy 3.258024\n",
      "kl 0.015001883\n",
      "completed in 0.28571414947509766 s\n",
      "game 37 completed in 12.7695791721344 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7793708 entropy 3.2646327\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7522917 entropy 3.2449036\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.710177 entropy 3.2231693\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.664919 entropy 3.2022243\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6310792 entropy 3.1840882\n",
      "kl 0.021637062\n",
      "completed in 0.30437397956848145 s\n",
      "game 38 completed in 15.41278886795044 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8346922 entropy 3.1597834\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.807373 entropy 3.1555128\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.764983 entropy 3.16316\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.724168 entropy 3.1818347\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6876085 entropy 3.2061343\n",
      "kl 0.020111207\n",
      "completed in 0.2965688705444336 s\n",
      "game 39 completed in 13.043161869049072 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8533144 entropy 3.2532759\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8285987 entropy 3.2690501\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7927327 entropy 3.2760067\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.7493527 entropy 3.2739325\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.7033088 entropy 3.2640102\n",
      "kl 0.014505059\n",
      "completed in 0.2997438907623291 s\n",
      "game 40 completed in 6.516642093658447 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8226109 entropy 3.25031\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8022463 entropy 3.2276223\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7738512 entropy 3.2003388\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.7323399 entropy 3.1737213\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6829746 entropy 3.1595674\n",
      "kl 0.02296063\n",
      "completed in 0.3038361072540283 s\n",
      "game 41 completed in 13.673789978027344 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7481627 entropy 3.1736565\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7152555 entropy 3.1980963\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6830158 entropy 3.2275412\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6521387 entropy 3.248585\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6178737 entropy 3.2544556\n",
      "kl 0.025411073\n",
      "completed in 0.30952906608581543 s\n",
      "game 42 completed in 12.987796068191528 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7064877 entropy 3.2433953\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6878045 entropy 3.2260785\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6644678 entropy 3.2044945\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.634756 entropy 3.1850615\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.599409 entropy 3.1740394\n",
      "kl 0.015513273\n",
      "completed in 0.28856801986694336 s\n",
      "game 43 completed in 11.141128063201904 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7867424 entropy 3.169747\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7525554 entropy 3.1760187\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.716433 entropy 3.183042\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6785479 entropy 3.1886091\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6326077 entropy 3.1915119\n",
      "kl 0.019040491\n",
      "completed in 0.3182260990142822 s\n",
      "game 44 completed in 8.425767183303833 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6837401 entropy 3.170239\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6627724 entropy 3.1712987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.6666666666666666 loss 3.624922 entropy 3.1761272\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5818093 entropy 3.1868944\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5406396 entropy 3.2010913\n",
      "kl 0.01451853\n",
      "completed in 0.32370710372924805 s\n",
      "game 45 completed in 14.409925937652588 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7621932 entropy 3.2510507\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.718409 entropy 3.2544646\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6761334 entropy 3.2474241\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6449049 entropy 3.2288024\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6113362 entropy 3.2016606\n",
      "kl 0.027662762\n",
      "completed in 0.3142566680908203 s\n",
      "game 46 completed in 8.328476905822754 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7391424 entropy 3.1767154\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7002702 entropy 3.1722636\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.672407 entropy 3.1843367\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6508527 entropy 3.201739\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.611149 entropy 3.210544\n",
      "kl 0.02955646\n",
      "completed in 0.29497408866882324 s\n",
      "game 47 completed in 10.82175087928772 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8481665 entropy 3.2185082\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8015509 entropy 3.2047906\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.763624 entropy 3.179569\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.736162 entropy 3.159853\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.695474 entropy 3.1697593\n",
      "kl 0.033300772\n",
      "completed in 0.31508898735046387 s\n",
      "game 48 completed in 10.242159128189087 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.729134 entropy 3.176306\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6911232 entropy 3.2137413\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.661973 entropy 3.2350864\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6339784 entropy 3.2385542\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5979478 entropy 3.2260017\n",
      "kl 0.021271069\n",
      "completed in 0.33991098403930664 s\n",
      "prediction:\n",
      " [0.00818945 0.02226962 0.01100412 0.01247443 0.02285797 0.01339221\n",
      " 0.02144681 0.038043   0.02000092 0.01269343 0.04518007 0.01417556\n",
      " 0.01273222 0.01685474 0.10812828 0.07421206 0.01284394 0.01340162\n",
      " 0.01477262 0.01420538 0.05441413 0.11263948 0.0211187  0.0136319\n",
      " 0.0264741  0.06674732 0.01721116 0.01955283 0.03568713 0.02344729\n",
      " 0.01736869 0.02335572 0.01357819 0.0128195  0.02422953 0.00884619] \n",
      " 0.10800003\n",
      "p [[0.00125156 0.01376721 0.00125156 0.00125156 0.01627034 0.00125156]\n",
      " [0.01376721 0.01501877 0.00250313 0.03754693 0.01376721 0.01501877]\n",
      " [0.00125156 0.00876095 0.0951189  0.56821026 0.02628285 0.00125156]\n",
      " [0.00125156 0.00125156 0.02878598 0.02377972 0.01501877 0.00125156]\n",
      " [0.00750939 0.01501877 0.00750939 0.00125156 0.01627034 0.01251564]\n",
      " [0.00125156 0.01501877 0.00125156 0.00375469 0.01251564 0.00125156]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.00728053 0.0216129  0.00988939 0.00985239 0.01942885 0.01443827\n",
      " 0.02847622 0.04161308 0.01883362 0.01089981 0.08160079 0.02129945\n",
      " 0.01202275 0.01145896 0.12323337 0.03662445 0.01381978 0.01192336\n",
      " 0.01092033 0.01293165 0.03046431 0.11165502 0.01218105 0.01034415\n",
      " 0.02731056 0.07022645 0.01324844 0.01427043 0.07040366 0.03376025\n",
      " 0.0120992  0.02140922 0.01218495 0.01233912 0.02208402 0.00785938] \n",
      " 0.60036296\n",
      "p [[0.00500626 0.0175219  0.00750939 0.00375469 0.04881101 0.00625782]\n",
      " [0.00625782 0.01126408 0.00750939 0.02753442 0.03003755 0.01001252]\n",
      " [0.00375469 0.01126408 0.11889862 0.         0.00500626 0.00500626]\n",
      " [0.00375469 0.01126408 0.36295369 0.05506884 0.02628285 0.00500626]\n",
      " [0.00750939 0.04255319 0.01376721 0.02377972 0.01126408 0.02878598]\n",
      " [0.00750939 0.01001252 0.00375469 0.00375469 0.05381727 0.00375469]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01080379 0.01985705 0.02293967 0.01064296 0.01268577 0.01845206\n",
      " 0.02693618 0.03738479 0.03176882 0.00975747 0.06447156 0.02076933\n",
      " 0.01596553 0.02126928 0.11929312 0.01963676 0.01596593 0.01505415\n",
      " 0.02111493 0.02598277 0.01578038 0.12541327 0.01623005 0.0104674\n",
      " 0.02805912 0.04604007 0.00809701 0.02850378 0.01913239 0.04313547\n",
      " 0.01207127 0.01777902 0.01699673 0.03651113 0.02752293 0.00750847] \n",
      " -0.5180094\n",
      "p [[0.00125156 0.02252816 0.00125156 0.00125156 0.02377972 0.00125156]\n",
      " [0.01376721 0.01501877 0.02002503 0.23153942 0.0212766  0.00750939]\n",
      " [0.00876095 0.08010013 0.14768461 0.         0.1126408  0.00750939]\n",
      " [0.00125156 0.00625782 0.         0.04881101 0.00125156 0.00125156]\n",
      " [0.01001252 0.01126408 0.00125156 0.11639549 0.0175219  0.04130163]\n",
      " [0.00125156 0.01001252 0.00125156 0.00125156 0.01126408 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00779666 0.01576626 0.02530113 0.01005682 0.01845813 0.01692186\n",
      " 0.02020899 0.03569306 0.03296529 0.00904499 0.10088369 0.03384526\n",
      " 0.02085448 0.01193755 0.13290809 0.01660681 0.01487351 0.0151878\n",
      " 0.01720134 0.01507471 0.01254192 0.07482511 0.01565193 0.01986894\n",
      " 0.03418729 0.05029742 0.00801464 0.03097854 0.04326318 0.02749254\n",
      " 0.01488885 0.01828729 0.02456471 0.02126133 0.02130458 0.01098543] \n",
      " 0.57547104\n",
      "p [[0.00375469 0.01877347 0.02002503 0.00125156 0.21902378 0.00500626]\n",
      " [0.30788486 0.04505632 0.01251564 0.         0.0350438  0.01501877]\n",
      " [0.00375469 0.01627034 0.04130163 0.         0.01877347 0.00625782]\n",
      " [0.02503129 0.01251564 0.         0.04005006 0.01376721 0.00250313]\n",
      " [0.00876095 0.0175219  0.00250313 0.01251564 0.01001252 0.02377972]\n",
      " [0.00375469 0.00500626 0.01126408 0.0175219  0.02252816 0.00125156]]\n",
      "move 6\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01082765 0.03277932 0.01613737 0.01193402 0.01241742 0.02338184\n",
      " 0.02500346 0.05395871 0.01788485 0.01561585 0.07876378 0.02010312\n",
      " 0.02763197 0.02996787 0.05916489 0.0234643  0.02024993 0.02176061\n",
      " 0.02765823 0.02184139 0.02497693 0.11526747 0.02463978 0.01348138\n",
      " 0.02588882 0.03190312 0.01431053 0.01245677 0.0151468  0.02388551\n",
      " 0.01528567 0.01837727 0.02762475 0.02258394 0.04673222 0.01689261] \n",
      " -0.67967033\n",
      "p [[0.00125156 0.00876095 0.00625782 0.01001252 0.01627034 0.00125156]\n",
      " [0.         0.03128911 0.31789737 0.         0.02252816 0.01501877]\n",
      " [0.01251564 0.29411765 0.03379224 0.         0.01376721 0.00625782]\n",
      " [0.01126408 0.00125156 0.         0.02503129 0.00375469 0.01251564]\n",
      " [0.02377972 0.01501877 0.00125156 0.02753442 0.01877347 0.01501877]\n",
      " [0.00500626 0.01251564 0.00500626 0.00625782 0.02377972 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00516997 0.01608089 0.01884567 0.01145219 0.00601477 0.01827817\n",
      " 0.02353781 0.08557724 0.0164067  0.01121989 0.14182338 0.02294341\n",
      " 0.02313262 0.01904016 0.0793335  0.01800406 0.01518166 0.01576336\n",
      " 0.01605313 0.01525093 0.01474399 0.08131908 0.02422222 0.01191846\n",
      " 0.02323165 0.0142351  0.008278   0.00882113 0.0661443  0.02463118\n",
      " 0.01336052 0.02218104 0.034384   0.02510679 0.03443133 0.01388192] \n",
      " -0.29082292\n",
      "p [[0.00375469 0.02503129 0.00500626 0.00125156 0.00500626 0.00500626]\n",
      " [0.         0.02377972 0.         0.         0.7359199  0.00375469]\n",
      " [0.00625782 0.01501877 0.01877347 0.         0.00500626 0.00500626]\n",
      " [0.00876095 0.00625782 0.         0.02753442 0.01251564 0.00250313]\n",
      " [0.00500626 0.01001252 0.00375469 0.00375469 0.00375469 0.00625782]\n",
      " [0.00375469 0.00625782 0.00750939 0.00500626 0.02503129 0.00375469]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01116409 0.03855165 0.0118298  0.01064795 0.01236526 0.02431492\n",
      " 0.01705628 0.02158424 0.01887876 0.01492396 0.05576646 0.02377123\n",
      " 0.02829036 0.03142825 0.05265662 0.02115156 0.02711126 0.02147542\n",
      " 0.04077277 0.01968768 0.01879757 0.10380191 0.02543988 0.01190152\n",
      " 0.02246529 0.0199164  0.02045628 0.02025451 0.00515514 0.02698067\n",
      " 0.03189002 0.03824891 0.02780581 0.03480233 0.06521058 0.02344482] \n",
      " -0.9967017\n",
      "p [[0.00250313 0.01126408 0.01126408 0.01126408 0.01501877 0.00500626]\n",
      " [0.         0.06758448 0.         0.         0.         0.01376721]\n",
      " [0.01627034 0.02252816 0.10262829 0.         0.01251564 0.00625782]\n",
      " [0.01001252 0.00500626 0.         0.14643304 0.01126408 0.0175219 ]\n",
      " [0.02002503 0.00876095 0.00250313 0.16770964 0.21151439 0.0175219 ]\n",
      " [0.00750939 0.00876095 0.01251564 0.01251564 0.03379224 0.00876095]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00952141 0.02248048 0.01047801 0.00836831 0.0152576  0.0210897\n",
      " 0.01777155 0.0446679  0.0204751  0.01606418 0.09117896 0.0437575\n",
      " 0.02669016 0.0293459  0.06067771 0.02364763 0.01633823 0.01022742\n",
      " 0.01094544 0.04084085 0.01743337 0.0409581  0.03686671 0.0117873\n",
      " 0.03317706 0.01454955 0.01631156 0.00607787 0.01855342 0.05840092\n",
      " 0.02293267 0.04065935 0.06302622 0.0258683  0.0361056  0.01746818] \n",
      " -0.5317269\n",
      "p [[0.00625782 0.07259074 0.00375469 0.00125156 0.00750939 0.00750939]\n",
      " [0.         0.01126408 0.         0.         0.         0.00750939]\n",
      " [0.01126408 0.0387985  0.48310388 0.         0.01001252 0.00500626]\n",
      " [0.02878598 0.0175219  0.         0.06508135 0.07509387 0.00500626]\n",
      " [0.00876095 0.00750939 0.00876095 0.00625782 0.         0.01126408]\n",
      " [0.00750939 0.01627034 0.00750939 0.00750939 0.05256571 0.00876095]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01871355 0.06035158 0.01772874 0.01032835 0.01443154 0.04026783\n",
      " 0.00947013 0.04277708 0.00788384 0.0389695  0.0269875  0.04898188\n",
      " 0.0284656  0.0355314  0.00771198 0.03117399 0.00823581 0.01870646\n",
      " 0.02843331 0.01783987 0.02800014 0.01753776 0.05567893 0.02149844\n",
      " 0.02564489 0.02345461 0.04551208 0.01117868 0.00533032 0.02825539\n",
      " 0.04053331 0.0458892  0.0399839  0.03146241 0.03353674 0.03351381] \n",
      " -0.9544043\n",
      "p [[0.00500626 0.0175219  0.00750939 0.00750939 0.01627034 0.00625782]\n",
      " [0.         0.01251564 0.         0.         0.         0.01376721]\n",
      " [0.00876095 0.02628285 0.         0.         0.38047559 0.00250313]\n",
      " [0.01126408 0.00876095 0.         0.02252816 0.01627034 0.00500626]\n",
      " [0.0175219  0.00500626 0.01251564 0.30162703 0.         0.0175219 ]\n",
      " [0.00876095 0.02252816 0.01627034 0.01251564 0.01376721 0.00375469]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00540689 0.02325271 0.02417958 0.00263682 0.02687617 0.01840238\n",
      " 0.00857942 0.03534774 0.02104682 0.0155406  0.08871073 0.06250291\n",
      " 0.03626402 0.02075446 0.04559582 0.00707622 0.0042575  0.02576788\n",
      " 0.02028326 0.02528773 0.01172092 0.0308218  0.02743202 0.03276262\n",
      " 0.02226733 0.03345266 0.01840027 0.00514679 0.00762988 0.07991002\n",
      " 0.01822487 0.05548262 0.06258381 0.02488702 0.04113401 0.01037388] \n",
      " -0.6144778\n",
      "p [[0.01251564 0.08135169 0.00750939 0.00125156 0.02878598 0.03629537]\n",
      " [0.         0.04881101 0.         0.         0.         0.02503129]\n",
      " [0.00876095 0.01376721 0.         0.         0.         0.00625782]\n",
      " [0.02252816 0.00625782 0.         0.02503129 0.31038798 0.01627034]\n",
      " [0.12140175 0.01126408 0.02252816 0.00375469 0.         0.01627034]\n",
      " [0.01501877 0.04630788 0.04255319 0.0175219  0.03128911 0.0212766 ]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01168299 0.04320966 0.02927035 0.00986506 0.00828475 0.01976053\n",
      " 0.0104726  0.03980628 0.01137659 0.04889499 0.00564965 0.05581412\n",
      " 0.02354543 0.00645183 0.00401361 0.02648588 0.00981752 0.02774601\n",
      " 0.07034842 0.02390854 0.01569154 0.00868429 0.0077979  0.02220196\n",
      " 0.01133928 0.01508324 0.03826372 0.01610977 0.0014586  0.04844371\n",
      " 0.03997587 0.06251958 0.12937503 0.04523396 0.02391687 0.02749999] \n",
      " -0.8704811\n",
      "p [[0.00500626 0.03254068 0.07884856 0.00250313 0.01627034 0.01251564]\n",
      " [0.         0.02377972 0.         0.         0.         0.04755945]\n",
      " [0.01877347 0.05506884 0.         0.         0.         0.02753442]\n",
      " [0.01376721 0.01251564 0.         0.04255319 0.         0.35419274]\n",
      " [0.00876095 0.00876095 0.01251564 0.06007509 0.         0.05256571]\n",
      " [0.01251564 0.0563204  0.01627034 0.01376721 0.01126408 0.00375469]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0. -1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00439982 0.03215459 0.03741032 0.00377707 0.01708883 0.01626447\n",
      " 0.00963358 0.02677144 0.01344518 0.01953424 0.03539984 0.06685034\n",
      " 0.01603569 0.01347679 0.04623073 0.00562792 0.00414465 0.02139407\n",
      " 0.03759154 0.02823726 0.00700067 0.05315358 0.03250984 0.03119637\n",
      " 0.01497046 0.02030035 0.03006533 0.00612727 0.00385803 0.11480281\n",
      " 0.02796458 0.05051427 0.08654807 0.02377345 0.03112582 0.01062103] \n",
      " -0.38011023\n",
      "p [[0.02377972 0.01376721 0.66833542 0.00125156 0.02503129 0.00876095]\n",
      " [0.         0.01501877 0.         0.         0.         0.01501877]\n",
      " [0.01126408 0.00250313 0.         0.         0.         0.01376721]\n",
      " [0.01877347 0.00876095 0.         0.01501877 0.         0.        ]\n",
      " [0.00876095 0.01001252 0.01001252 0.00375469 0.         0.01251564]\n",
      " [0.01376721 0.01877347 0.03254068 0.02002503 0.01251564 0.01627034]]\n",
      "move 2\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0. -1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01741339 0.04800348 0.01441953 0.01506366 0.01058432 0.02699116\n",
      " 0.00420639 0.0640159  0.02899336 0.09356132 0.0022487  0.02618846\n",
      " 0.04355789 0.00588144 0.00420929 0.01916922 0.01060332 0.03108488\n",
      " 0.05230178 0.0218969  0.01500781 0.01642028 0.00695655 0.02320938\n",
      " 0.01012772 0.02644482 0.03647175 0.0299983  0.00113956 0.01313716\n",
      " 0.03633417 0.05619406 0.05943447 0.04089878 0.0598055  0.02802557] \n",
      " -0.5539402\n",
      "p [[0.00750939 0.05256571 0.         0.0212766  0.02002503 0.00750939]\n",
      " [0.         0.07259074 0.         0.         0.         0.06382979]\n",
      " [0.04005006 0.10888611 0.         0.         0.         0.05506884]\n",
      " [0.04130163 0.01126408 0.         0.09261577 0.         0.        ]\n",
      " [0.00876095 0.00750939 0.01251564 0.09136421 0.         0.12891114]\n",
      " [0.02252816 0.08635795 0.0212766  0.01376721 0.01001252 0.00250313]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0. -1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00798228 0.04912205 0.02501136 0.00454701 0.01975229 0.04353103\n",
      " 0.00522194 0.03890837 0.04187884 0.02159982 0.03759649 0.08628108\n",
      " 0.02166514 0.00831566 0.03282544 0.01175286 0.00768832 0.02195511\n",
      " 0.03176263 0.03571697 0.00474615 0.01897558 0.03152561 0.03449379\n",
      " 0.02217421 0.01450495 0.02215962 0.01084031 0.0036121  0.02523911\n",
      " 0.02713736 0.05608811 0.07533664 0.03193473 0.05460217 0.01351514] \n",
      " -0.7104047\n",
      "p [[0.00625782 0.077597   0.         0.00125156 0.01001252 0.03379224]\n",
      " [0.         0.0387985  0.         0.         0.         0.01126408]\n",
      " [0.0175219  0.00250313 0.         0.         0.         0.01501877]\n",
      " [0.03128911 0.00250313 0.         0.40550688 0.         0.        ]\n",
      " [0.02252816 0.01001252 0.01126408 0.00876095 0.         0.        ]\n",
      " [0.01877347 0.06758448 0.05381727 0.01501877 0.03629537 0.10262829]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  0.]\n",
      " [ 0.  0. -1. -1. -1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.04654421 0.04289144 0.00688954 0.02143567 0.01894051 0.02416898\n",
      " 0.00370253 0.11449865 0.02562355 0.06950543 0.00400035 0.04032415\n",
      " 0.07798718 0.00305884 0.00189768 0.01761038 0.01815488 0.02613819\n",
      " 0.02995339 0.01840688 0.01350858 0.00581101 0.00444033 0.01365967\n",
      " 0.01024044 0.03525454 0.02551172 0.01791856 0.00162333 0.00961251\n",
      " 0.02449089 0.04094662 0.05615158 0.02686017 0.03357786 0.06865991] \n",
      " 0.5414456\n",
      "p [[0.06508135 0.06633292 0.         0.06883605 0.10137672 0.03128911]\n",
      " [0.         0.08260325 0.         0.         0.         0.10888611]\n",
      " [0.0563204  0.04255319 0.         0.         0.         0.11013767]\n",
      " [0.04005006 0.03128911 0.         0.         0.         0.        ]\n",
      " [0.01251564 0.01001252 0.0175219  0.00750939 0.         0.        ]\n",
      " [0.01627034 0.04130163 0.02503129 0.02503129 0.03379224 0.00625782]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0. -1. -1. -1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00860105 0.02831146 0.02730975 0.00449513 0.01554314 0.03627081\n",
      " 0.00436575 0.02171261 0.03698902 0.02283742 0.01956648 0.18261665\n",
      " 0.04529178 0.01036949 0.01014917 0.02148351 0.00493473 0.01534349\n",
      " 0.02401716 0.01846223 0.00446149 0.01002699 0.05653665 0.0570105\n",
      " 0.02287001 0.00928493 0.03620833 0.01083125 0.00250698 0.0140941\n",
      " 0.02881713 0.02558188 0.07585257 0.03757367 0.04118646 0.00848633] \n",
      " 0.038891096\n",
      "p [[5.00625782e-03 5.00625782e-03 0.00000000e+00 2.50312891e-03\n",
      "  2.50312891e-03 3.75469337e-03]\n",
      " [0.00000000e+00 1.00125156e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.50312891e-02]\n",
      " [7.50938673e-03 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.75469337e-03 8.94868586e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.50312891e-03 3.75469337e-03 3.75469337e-03 2.50312891e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.50312891e-03 5.00625782e-03 6.25782228e-03 3.75469337e-03\n",
      "  3.75469337e-03 6.25782228e-03]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [-1.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0. -1. -1. -1. -1.  1.]\n",
      " [ 0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "-1 won\n",
      "game 49 completed in 39.79166889190674 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7072976 entropy 3.225647\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.680907 entropy 3.193036\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6418147 entropy 3.1649868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.6666666666666666 loss 3.5953367 entropy 3.150302\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5514398 entropy 3.1423402\n",
      "kl 0.029717606\n",
      "completed in 0.2748110294342041 s\n",
      "game 50 completed in 14.853839874267578 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.742231 entropy 3.1270144\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7106893 entropy 3.1124637\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6769364 entropy 3.10178\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6530714 entropy 3.1002104\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6244254 entropy 3.1088867\n",
      "kl 0.02204761\n",
      "completed in 0.30457186698913574 s\n",
      "game 51 completed in 6.57374906539917 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8224392 entropy 3.1292434\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.762957 entropy 3.148099\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7200885 entropy 3.1624322\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6992378 entropy 3.1711004\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6684284 entropy 3.1758637\n",
      "kl 0.020687025\n",
      "completed in 0.2929399013519287 s\n",
      "game 52 completed in 10.160019159317017 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7326849 entropy 3.1874704\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6880417 entropy 3.1914735\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6446319 entropy 3.1957016\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.60648 entropy 3.1983218\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5667956 entropy 3.1952085\n",
      "kl 0.015525859\n",
      "completed in 0.2720198631286621 s\n",
      "game 53 completed in 6.425204038619995 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7701974 entropy 3.1785555\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.74272 entropy 3.1648266\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7081563 entropy 3.1504939\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6708684 entropy 3.1380386\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6228576 entropy 3.1301517\n",
      "kl 0.014660431\n",
      "completed in 0.33197474479675293 s\n",
      "game 54 completed in 12.09446096420288 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7753608 entropy 3.15549\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7386231 entropy 3.1605024\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.684475 entropy 3.1673288\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6229918 entropy 3.1728535\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5738862 entropy 3.1745455\n",
      "kl 0.022682074\n",
      "completed in 0.26717710494995117 s\n",
      "game 55 completed in 11.07318902015686 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7528963 entropy 3.1727016\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7379076 entropy 3.170666\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7073374 entropy 3.171318\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6652853 entropy 3.174273\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.620931 entropy 3.178201\n",
      "kl 0.015166678\n",
      "completed in 0.29045605659484863 s\n",
      "game 56 completed in 12.835529804229736 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8443315 entropy 3.175321\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8147004 entropy 3.17824\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7639866 entropy 3.1795535\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.708171 entropy 3.1768086\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6593437 entropy 3.1688654\n",
      "kl 0.018943254\n",
      "completed in 0.28806519508361816 s\n",
      "game 57 completed in 11.297476768493652 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7031527 entropy 3.1614976\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.681799 entropy 3.151177\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6481755 entropy 3.1491747\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.607366 entropy 3.1561942\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5645738 entropy 3.1655674\n",
      "kl 0.020146199\n",
      "completed in 0.3387641906738281 s\n",
      "game 58 completed in 10.277949810028076 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7517517 entropy 3.175426\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7207584 entropy 3.172665\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6803699 entropy 3.162766\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6447413 entropy 3.1489375\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6094885 entropy 3.1375208\n",
      "kl 0.017379507\n",
      "completed in 0.32001614570617676 s\n",
      "game 59 completed in 15.629270792007446 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7198007 entropy 3.1434753\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6838918 entropy 3.1433177\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6416535 entropy 3.1436877\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.593972 entropy 3.1434023\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5499632 entropy 3.1396325\n",
      "kl 0.014452963\n",
      "completed in 0.31079602241516113 s\n",
      "game 60 completed in 9.087630033493042 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.779225 entropy 3.1144376\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7494488 entropy 3.1162362\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6989815 entropy 3.1239643\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6413956 entropy 3.132051\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5914946 entropy 3.1378098\n",
      "kl 0.017534725\n",
      "completed in 0.31681203842163086 s\n",
      "game 61 completed in 10.858240127563477 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7119453 entropy 3.1583815\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.687586 entropy 3.1546485\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6518345 entropy 3.1491377\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6107483 entropy 3.1485167\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5660727 entropy 3.1549096\n",
      "kl 0.014708005\n",
      "completed in 0.2965576648712158 s\n",
      "game 62 completed in 10.868554830551147 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7361858 entropy 3.1771126\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7061453 entropy 3.1822152\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6621342 entropy 3.1778119\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6135561 entropy 3.1646495\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5685804 entropy 3.149314\n",
      "kl 0.016791176\n",
      "completed in 0.2994968891143799 s\n",
      "game 63 completed in 13.646743059158325 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7777255 entropy 3.1496062\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7543278 entropy 3.1538846\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7043195 entropy 3.1618557\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6444612 entropy 3.1621222\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.587019 entropy 3.1502335\n",
      "kl 0.024233649\n",
      "completed in 0.3417668342590332 s\n",
      "game 64 completed in 7.297025680541992 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7826164 entropy 3.119754\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7547872 entropy 3.1030152\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7018769 entropy 3.0997944\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6461127 entropy 3.1082344\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.596579 entropy 3.1189032\n",
      "kl 0.025704015\n",
      "completed in 0.27614498138427734 s\n",
      "game 65 completed in 19.815217971801758 s 22 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7607036 entropy 3.137268\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7308476 entropy 3.1406624\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6899056 entropy 3.143272\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6434531 entropy 3.1527479\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5989683 entropy 3.1713133\n",
      "kl 0.025682975\n",
      "completed in 0.2771158218383789 s\n",
      "game 66 completed in 18.425815105438232 s 20 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8147924 entropy 3.1887407\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7841818 entropy 3.2032113\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7354262 entropy 3.205137\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6829123 entropy 3.1916394\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6288466 entropy 3.164732\n",
      "kl 0.030960225\n",
      "completed in 0.27666711807250977 s\n",
      "game 67 completed in 19.391603231430054 s 21 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7966125 entropy 3.1341422\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7507591 entropy 3.1025739\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.698026 entropy 3.0767305\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.65536 entropy 3.064263\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6174688 entropy 3.0743887\n",
      "kl 0.032369085\n",
      "completed in 0.28438305854797363 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 68 completed in 11.18932580947876 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8641424 entropy 3.1136734\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.808608 entropy 3.1454334\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7455359 entropy 3.167887\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6917062 entropy 3.1854315\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.640162 entropy 3.2013485\n",
      "kl 0.032897085\n",
      "completed in 0.37497496604919434 s\n",
      "game 69 completed in 17.71237087249756 s 19 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7544544 entropy 3.1961412\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7217863 entropy 3.185467\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6691184 entropy 3.1582847\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6111925 entropy 3.1220572\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5634875 entropy 3.0922904\n",
      "kl 0.031865958\n",
      "completed in 0.35276103019714355 s\n",
      "game 70 completed in 13.278326034545898 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.816028 entropy 3.1137433\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7799065 entropy 3.1301033\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7249758 entropy 3.1569414\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.670712 entropy 3.181078\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6253893 entropy 3.1951594\n",
      "kl 0.028882118\n",
      "completed in 0.27373480796813965 s\n",
      "game 71 completed in 16.571563005447388 s 18 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7350323 entropy 3.192465\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6940415 entropy 3.1943192\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6452315 entropy 3.1938322\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6059034 entropy 3.1924074\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5719717 entropy 3.1915061\n",
      "kl 0.033176437\n",
      "completed in 0.3328077793121338 s\n",
      "game 72 completed in 12.030622959136963 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7647676 entropy 3.188799\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7366428 entropy 3.191103\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6938179 entropy 3.1926394\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.64215 entropy 3.1933877\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5885086 entropy 3.1943514\n",
      "kl 0.028315306\n",
      "completed in 0.2693471908569336 s\n",
      "game 73 completed in 14.534040927886963 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8454778 entropy 3.2020793\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8130357 entropy 3.2011452\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.759255 entropy 3.195616\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6984036 entropy 3.1872044\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.64518 entropy 3.1799386\n",
      "kl 0.02024312\n",
      "completed in 0.2913219928741455 s\n",
      "game 74 completed in 11.033060073852539 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7720456 entropy 3.180972\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7406077 entropy 3.1791947\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7011487 entropy 3.1775322\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6661875 entropy 3.1760902\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6297226 entropy 3.1754973\n",
      "kl 0.01893441\n",
      "completed in 0.279386043548584 s\n",
      "game 75 completed in 14.642226934432983 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7115128 entropy 3.152463\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6642563 entropy 3.139472\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5959504 entropy 3.1212096\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5386477 entropy 3.1062326\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4961038 entropy 3.1049526\n",
      "kl 0.026859675\n",
      "completed in 0.2863428592681885 s\n",
      "game 76 completed in 9.617793083190918 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8633428 entropy 3.132469\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8172433 entropy 3.149216\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7451131 entropy 3.1623096\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6805992 entropy 3.1698303\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6283927 entropy 3.1712704\n",
      "kl 0.016908951\n",
      "completed in 0.2941899299621582 s\n",
      "game 77 completed in 13.167787075042725 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.774487 entropy 3.1931982\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.744301 entropy 3.1872637\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6988485 entropy 3.181142\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6457639 entropy 3.1759427\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.592687 entropy 3.175269\n",
      "kl 0.018219616\n",
      "completed in 0.30186009407043457 s\n",
      "game 78 completed in 10.171858787536621 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7652745 entropy 3.1636057\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7423851 entropy 3.181248\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7031353 entropy 3.1997013\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6559231 entropy 3.2080595\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.607091 entropy 3.202652\n",
      "kl 0.022467524\n",
      "completed in 0.27103114128112793 s\n",
      "game 79 completed in 13.611002922058105 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7420642 entropy 3.1782558\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7061296 entropy 3.1379824\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6665964 entropy 3.089449\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6201396 entropy 3.0678864\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.570616 entropy 3.0873408\n",
      "kl 0.02350175\n",
      "completed in 0.27074170112609863 s\n",
      "game 80 completed in 10.065526962280273 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.885064 entropy 3.1198797\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8329873 entropy 3.1446013\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7596226 entropy 3.1582596\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.693171 entropy 3.1622038\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6349223 entropy 3.1619582\n",
      "kl 0.025607344\n",
      "completed in 0.3003571033477783 s\n",
      "game 81 completed in 9.25118899345398 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.732167 entropy 3.1710446\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7161796 entropy 3.1802914\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.679551 entropy 3.1937633\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6370049 entropy 3.20693\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5946562 entropy 3.2154655\n",
      "kl 0.01684415\n",
      "completed in 0.32596516609191895 s\n",
      "game 82 completed in 12.017477989196777 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.805297 entropy 3.2149742\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7808566 entropy 3.2096405\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7353501 entropy 3.196909\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6848168 entropy 3.1784015\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6379218 entropy 3.1573515\n",
      "kl 0.019390553\n",
      "completed in 0.2763667106628418 s\n",
      "game 83 completed in 14.438745021820068 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7488174 entropy 3.140808\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7075367 entropy 3.126523\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.655176 entropy 3.1163635\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6020288 entropy 3.1130047\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5579686 entropy 3.117425\n",
      "kl 0.025400482\n",
      "completed in 0.3536069393157959 s\n",
      "game 84 completed in 9.800455093383789 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.84392 entropy 3.1330588\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.8201935 entropy 3.1449413\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7799482 entropy 3.1565628\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.736084 entropy 3.1658695\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6919336 entropy 3.1736448\n",
      "kl 0.014563549\n",
      "completed in 0.3472728729248047 s\n",
      "game 85 completed in 7.297451019287109 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7564247 entropy 3.1851797\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7289333 entropy 3.1973116\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.687826 entropy 3.2114534\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6381526 entropy 3.2232132\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5850549 entropy 3.2293046\n",
      "kl 0.014708738\n",
      "completed in 0.30064988136291504 s\n",
      "game 86 completed in 12.865176916122437 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.66924 entropy 3.220934\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.640504 entropy 3.2047446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.6666666666666666 loss 3.6044075 entropy 3.175625\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.563346 entropy 3.1375484\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5178769 entropy 3.101214\n",
      "kl 0.03120521\n",
      "completed in 0.30889081954956055 s\n",
      "game 87 completed in 11.205818891525269 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.8077426 entropy 3.0916138\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7662432 entropy 3.0891323\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7360947 entropy 3.1008444\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6942756 entropy 3.1185136\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6430073 entropy 3.1325026\n",
      "kl 0.026216256\n",
      "completed in 0.29215168952941895 s\n",
      "game 88 completed in 6.538998126983643 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7240078 entropy 3.1149797\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7008374 entropy 3.1136975\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6690462 entropy 3.1093488\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6186378 entropy 3.107371\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5678065 entropy 3.1129816\n",
      "kl 0.022243412\n",
      "completed in 0.2731778621673584 s\n",
      "game 89 completed in 12.131222009658813 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7171679 entropy 3.1291964\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6782174 entropy 3.143423\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.653729 entropy 3.1527\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6194952 entropy 3.1522415\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5620105 entropy 3.1406236\n",
      "kl 0.016885212\n",
      "completed in 0.31295228004455566 s\n",
      "game 90 completed in 13.685410022735596 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7865803 entropy 3.1233597\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7666013 entropy 3.1099455\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.7299347 entropy 3.1062603\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.675019 entropy 3.1122432\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.630256 entropy 3.1273766\n",
      "kl 0.017639942\n",
      "completed in 0.2752869129180908 s\n",
      "game 91 completed in 9.300223112106323 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6963851 entropy 3.1772633\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6627393 entropy 3.1889625\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6095414 entropy 3.1911674\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5599036 entropy 3.1847668\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.517167 entropy 3.1728797\n",
      "kl 0.024142085\n",
      "completed in 0.2910580635070801 s\n",
      "game 92 completed in 14.20086407661438 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7617877 entropy 3.144475\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7333198 entropy 3.131762\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6856968 entropy 3.119691\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6393855 entropy 3.11155\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.596552 entropy 3.109294\n",
      "kl 0.015600863\n",
      "completed in 0.2913968563079834 s\n",
      "game 93 completed in 11.332549095153809 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7020595 entropy 3.1270113\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6692655 entropy 3.1275852\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6215646 entropy 3.1229486\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5795405 entropy 3.1137404\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5427794 entropy 3.1023736\n",
      "kl 0.026256468\n",
      "completed in 0.3174772262573242 s\n",
      "game 94 completed in 13.008496761322021 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6867 entropy 3.0879598\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6675751 entropy 3.076465\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6305568 entropy 3.0655391\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5910685 entropy 3.0602536\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5522878 entropy 3.0640748\n",
      "kl 0.013198714\n",
      "completed in 0.29944896697998047 s\n",
      "game 95 completed in 15.81043815612793 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.783202 entropy 3.0768461\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7282255 entropy 3.0928226\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6743634 entropy 3.1031332\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6247318 entropy 3.1009598\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5680003 entropy 3.08825\n",
      "kl 0.021176063\n",
      "completed in 0.28853297233581543 s\n",
      "game 96 completed in 16.64640212059021 s 18 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.736573 entropy 3.0871933\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.714914 entropy 3.0867865\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6719322 entropy 3.0980053\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6178503 entropy 3.1152132\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5681655 entropy 3.1313176\n",
      "kl 0.02690791\n",
      "completed in 0.28734898567199707 s\n",
      "game 97 completed in 15.699735164642334 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7674432 entropy 3.137251\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.738989 entropy 3.1433077\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6974673 entropy 3.1406083\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6487942 entropy 3.1312084\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.6006641 entropy 3.121948\n",
      "kl 0.022727689\n",
      "completed in 0.3008768558502197 s\n",
      "game 98 completed in 13.146507978439331 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6561756 entropy 3.1042547\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6149673 entropy 3.0938911\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5661967 entropy 3.0785809\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5212877 entropy 3.0622687\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4783583 entropy 3.0519052\n",
      "kl 0.01975731\n",
      "completed in 0.3079230785369873 s\n",
      "prediction:\n",
      " [0.00389631 0.01399734 0.00549443 0.00461492 0.02049305 0.00375966\n",
      " 0.01439234 0.04759808 0.01579738 0.02422787 0.02706348 0.02428766\n",
      " 0.00475981 0.02500794 0.06493987 0.19205302 0.03411122 0.00583991\n",
      " 0.00525778 0.0203955  0.1515809  0.05667271 0.0249635  0.00401957\n",
      " 0.02155029 0.03142516 0.02076249 0.01519901 0.04871724 0.01785782\n",
      " 0.00243575 0.01668786 0.00383697 0.00514863 0.01791787 0.00323687] \n",
      " -0.45137715\n",
      "p [[0.00125156 0.01126408 0.00250313 0.00250313 0.01126408 0.00125156]\n",
      " [0.00625782 0.01251564 0.04630788 0.03754693 0.01001252 0.02878598]\n",
      " [0.00500626 0.02002503 0.06382979 0.18773467 0.00876095 0.00500626]\n",
      " [0.00125156 0.02002503 0.12265332 0.21026283 0.08760951 0.00250313]\n",
      " [0.01251564 0.01501877 0.01251564 0.00500626 0.01376721 0.00876095]\n",
      " [0.00125156 0.00876095 0.00125156 0.00375469 0.01001252 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.00409393 0.01883943 0.00524762 0.00498838 0.03609803 0.00413324\n",
      " 0.02185576 0.03813256 0.0243192  0.02120272 0.05689261 0.02412662\n",
      " 0.00521088 0.01951797 0.14412884 0.05374454 0.03556885 0.00700239\n",
      " 0.0066318  0.02615449 0.05694592 0.11140948 0.01340537 0.00539324\n",
      " 0.02424515 0.04169403 0.01984295 0.03284512 0.04405192 0.02455392\n",
      " 0.00397527 0.01786038 0.00617674 0.00771318 0.025297   0.00670067] \n",
      " -0.7151568\n",
      "p [[0.00125156 0.00375469 0.00375469 0.00125156 0.00625782 0.00125156]\n",
      " [0.00500626 0.03003755 0.05381727 0.16395494 0.00500626 0.00625782]\n",
      " [0.01001252 0.03128911 0.02628285 0.36295369 0.02753442 0.00375469]\n",
      " [0.02878598 0.01376721 0.0951189  0.         0.04005006 0.00375469]\n",
      " [0.00750939 0.00876095 0.01376721 0.01501877 0.01001252 0.00500626]\n",
      " [0.00125156 0.00250313 0.00250313 0.00250313 0.00500626 0.00125156]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00286018 0.01407962 0.0175029  0.00651404 0.02241252 0.00674486\n",
      " 0.02444409 0.04350414 0.02870817 0.01251307 0.05225264 0.02624193\n",
      " 0.01027535 0.03934708 0.07937595 0.1235101  0.03786594 0.00833859\n",
      " 0.00624977 0.04266528 0.0360682  0.03677996 0.03438227 0.00699187\n",
      " 0.02265438 0.03890055 0.00649518 0.06459714 0.04844838 0.04801382\n",
      " 0.00380042 0.01240274 0.00736514 0.0104208  0.0121556  0.00511758] \n",
      " -0.80482805\n",
      "p [[0.00125156 0.00625782 0.00250313 0.00250313 0.01627034 0.00250313]\n",
      " [0.00375469 0.01251564 0.03254068 0.60325407 0.01877347 0.01251564]\n",
      " [0.00250313 0.00625782 0.06132666 0.         0.05381727 0.00250313]\n",
      " [0.00125156 0.05131414 0.01376721 0.         0.00375469 0.00250313]\n",
      " [0.01001252 0.00750939 0.00500626 0.02377972 0.00750939 0.01001252]\n",
      " [0.00125156 0.00750939 0.00125156 0.00625782 0.00500626 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00373481 0.01205246 0.00765716 0.0043279  0.04177877 0.00340827\n",
      " 0.02758447 0.01020945 0.01890532 0.00772408 0.20010123 0.02288011\n",
      " 0.00700898 0.02284018 0.11594695 0.0202225  0.0340977  0.00438782\n",
      " 0.00404735 0.05964929 0.02740472 0.10752228 0.01101586 0.00204782\n",
      " 0.04262272 0.03597768 0.00535409 0.04420409 0.01607999 0.01652865\n",
      " 0.00252272 0.02157525 0.00556487 0.00949653 0.0176298  0.00588831] \n",
      " -0.5862848\n",
      "p [[0.00250313 0.00625782 0.01627034 0.00876095 0.01627034 0.00250313]\n",
      " [0.01251564 0.35669587 0.01001252 0.         0.05882353 0.02377972]\n",
      " [0.03379224 0.04130163 0.0175219  0.         0.15018773 0.00500626]\n",
      " [0.01001252 0.01376721 0.00750939 0.         0.00876095 0.00625782]\n",
      " [0.00625782 0.01001252 0.00750939 0.02503129 0.02377972 0.09136421]\n",
      " [0.00250313 0.00375469 0.00375469 0.00625782 0.00750939 0.00375469]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00362962 0.01961177 0.01088136 0.00982984 0.0385069  0.00809562\n",
      " 0.01826028 0.01805697 0.00755932 0.02298937 0.06738272 0.02410249\n",
      " 0.0123063  0.0819194  0.04656441 0.17655005 0.04148028 0.00983064\n",
      " 0.00386249 0.03097631 0.04193695 0.03526596 0.04479206 0.0045415\n",
      " 0.02433592 0.04142825 0.01512455 0.00924401 0.01370441 0.02632656\n",
      " 0.00417641 0.02384002 0.00580254 0.01414939 0.03170727 0.01122816] \n",
      " -0.9231909\n",
      "p [[0.00125156 0.00500626 0.00250313 0.00375469 0.09887359 0.00250313]\n",
      " [0.0175219  0.         0.53316646 0.         0.06382979 0.01126408]\n",
      " [0.00750939 0.00876095 0.04380476 0.         0.0563204  0.00125156]\n",
      " [0.00125156 0.04881101 0.00750939 0.         0.00125156 0.00250313]\n",
      " [0.01627034 0.01001252 0.00250313 0.00876095 0.00250313 0.00625782]\n",
      " [0.00125156 0.01627034 0.00125156 0.00750939 0.00750939 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00216293 0.01942779 0.00672544 0.00654323 0.03207438 0.00252272\n",
      " 0.01725279 0.01469513 0.00866627 0.01010692 0.19716853 0.03945266\n",
      " 0.00892067 0.02459752 0.16128825 0.02583701 0.01784905 0.00823599\n",
      " 0.00288318 0.01568719 0.0319243  0.09096862 0.01504023 0.00315363\n",
      " 0.0654681  0.04713738 0.01399491 0.00687418 0.00951189 0.01583282\n",
      " 0.00172962 0.01616635 0.00827158 0.01285776 0.03304236 0.0059288 ] \n",
      " -0.63161796\n",
      "p [[0.00250313 0.00750939 0.00250313 0.00500626 0.02503129 0.00375469]\n",
      " [0.02878598 0.         0.         0.         0.04881101 0.02878598]\n",
      " [0.01501877 0.07509387 0.02252816 0.         0.57822278 0.00500626]\n",
      " [0.01376721 0.00750939 0.01001252 0.         0.01001252 0.00500626]\n",
      " [0.00750939 0.01126408 0.00500626 0.00375469 0.01126408 0.02628285]\n",
      " [0.00250313 0.00625782 0.00625782 0.00750939 0.01126408 0.00625782]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0043895  0.02401224 0.01507424 0.00875385 0.0392606  0.00858867\n",
      " 0.01371138 0.01476301 0.00678545 0.02101424 0.08894616 0.00962281\n",
      " 0.01238768 0.11268815 0.03990741 0.1036596  0.02348935 0.02081355\n",
      " 0.00761355 0.01981793 0.04361355 0.03315708 0.0524903  0.00732008\n",
      " 0.01122152 0.07006621 0.01883618 0.01220344 0.01412873 0.01662309\n",
      " 0.00643722 0.04144473 0.00478562 0.01843665 0.03661408 0.01732244] \n",
      " -0.30406976\n",
      "p [[1.25156446e-13 7.50938673e-03 3.75469337e-03 2.50312891e-03\n",
      "  1.75219024e-02 1.25156446e-03]\n",
      " [7.50938673e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.63579474e-02 5.36921151e-01]\n",
      " [2.50312891e-03 2.00250313e-02 1.73967459e-01 0.00000000e+00\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [2.50312891e-03 2.87859825e-02 1.00125156e-02 0.00000000e+00\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [2.87859825e-02 2.00250313e-02 3.75469337e-03 2.50312891e-03\n",
      "  2.50312891e-03 5.00625782e-03]\n",
      " [1.25156446e-13 1.12640801e-02 1.25156446e-03 5.00625782e-03\n",
      "  7.50938673e-03 1.25156446e-03]]\n",
      "move 11\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  1.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00341338 0.03132597 0.00843858 0.00837481 0.03679377 0.00454982\n",
      " 0.02172216 0.02984792 0.01007011 0.00779244 0.06292913 0.01592157\n",
      " 0.01282859 0.02681185 0.14910243 0.04188975 0.01872103 0.01520641\n",
      " 0.00228398 0.01536839 0.04566854 0.12670851 0.01288906 0.00567906\n",
      " 0.02851005 0.01501798 0.0178748  0.01163558 0.02283244 0.02898718\n",
      " 0.00427754 0.05119076 0.01017886 0.01216021 0.07270636 0.0102912 ] \n",
      " -0.67133474\n",
      "p [[0.00375469 0.00625782 0.00500626 0.00500626 0.01126408 0.00375469]\n",
      " [0.00500626 0.         0.         0.         0.79974969 0.        ]\n",
      " [0.00500626 0.02377972 0.00876095 0.         0.         0.00625782]\n",
      " [0.00500626 0.00500626 0.00876095 0.         0.01126408 0.00500626]\n",
      " [0.00500626 0.01627034 0.00625782 0.00500626 0.00500626 0.00625782]\n",
      " [0.00375469 0.00876095 0.00375469 0.00625782 0.00876095 0.00625782]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00944857 0.04413594 0.01747348 0.00723014 0.05628751 0.00783616\n",
      " 0.01250687 0.02693846 0.0134352  0.01338392 0.00633209 0.00957754\n",
      " 0.02070345 0.10224693 0.00703179 0.06579839 0.03061822 0.01371124\n",
      " 0.00378189 0.03859568 0.02938131 0.00921599 0.05632711 0.00655876\n",
      " 0.00746086 0.0085177  0.01855777 0.03248519 0.03074275 0.03706659\n",
      " 0.00944222 0.07530266 0.00660598 0.01413858 0.12591366 0.02520934] \n",
      " -0.21984561\n",
      "p [[0.00125156 0.00876095 0.00500626 0.00876095 0.21652065 0.00250313]\n",
      " [0.07133917 0.         0.         0.         0.         0.        ]\n",
      " [0.00250313 0.03379224 0.31414268 0.         0.         0.00250313]\n",
      " [0.00125156 0.11013767 0.01251564 0.         0.00125156 0.00250313]\n",
      " [0.02753442 0.00500626 0.00375469 0.00250313 0.00375469 0.00876095]\n",
      " [0.00125156 0.1126408  0.00125156 0.00500626 0.03254068 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0.  0.  1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01162763 0.02872128 0.01713032 0.01659747 0.02326851 0.00382016\n",
      " 0.01745668 0.16532284 0.00708558 0.00833963 0.04076649 0.0218646\n",
      " 0.02510575 0.02419    0.03490195 0.03076832 0.01855075 0.01486051\n",
      " 0.00181082 0.02068757 0.05907009 0.02099281 0.01742285 0.0089862\n",
      " 0.03752841 0.01286651 0.03597026 0.00614722 0.06966553 0.02171453\n",
      " 0.00374004 0.04634064 0.00951522 0.03242123 0.05424702 0.03049472] \n",
      " -0.017203074\n",
      "p [[0.00250313 0.00750939 0.00250313 0.00250313 0.82853567 0.00125156]\n",
      " [0.00250313 0.         0.         0.         0.         0.        ]\n",
      " [0.01126408 0.0387985  0.         0.         0.         0.00125156]\n",
      " [0.00250313 0.00625782 0.00375469 0.         0.01376721 0.00250313]\n",
      " [0.00125156 0.00125156 0.00250313 0.00500626 0.00750939 0.01251564]\n",
      " [0.00125156 0.01251564 0.00250313 0.00250313 0.02002503 0.00375469]]\n",
      "move 4\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0.  0.  1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00678517 0.03353547 0.01813887 0.01184099 0.0384491  0.01205633\n",
      " 0.01959887 0.02306396 0.01578832 0.00542407 0.01525985 0.00955938\n",
      " 0.01797781 0.03400904 0.00753956 0.0679262  0.0709341  0.02191312\n",
      " 0.0142651  0.04462012 0.03110066 0.00418821 0.02183311 0.00953661\n",
      " 0.01259265 0.01224064 0.01950026 0.08478729 0.0435369  0.06050469\n",
      " 0.01373767 0.03158967 0.01213427 0.0243078  0.11388833 0.01583581] \n",
      " 0.2526664\n",
      "p [[0.00625782 0.01627034 0.01251564 0.01376721 0.         0.00876095]\n",
      " [0.01376721 0.         0.         0.         0.         0.        ]\n",
      " [0.01501877 0.0387985  0.         0.         0.         0.00500626]\n",
      " [0.01877347 0.01376721 0.02503129 0.         0.62202753 0.00625782]\n",
      " [0.0175219  0.01251564 0.01376721 0.01126408 0.02628285 0.01376721]\n",
      " [0.00500626 0.02252816 0.00876095 0.02002503 0.01877347 0.01376721]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0.  0.  1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.01146359 0.02346995 0.02199108 0.02601579 0.03726051 0.00433513\n",
      " 0.01778697 0.07149882 0.01013305 0.00701038 0.0368805  0.02042798\n",
      " 0.04552035 0.00180545 0.03430444 0.04923283 0.01968597 0.07254311\n",
      " 0.005292   0.02742898 0.0376828  0.01504994 0.00180252 0.01734632\n",
      " 0.02623094 0.0113332  0.03006622 0.00993547 0.02588207 0.03242085\n",
      " 0.00365324 0.06799837 0.03807314 0.03365196 0.08050346 0.02428283] \n",
      " -0.9752244\n",
      "p [[0.00625782 0.06132666 0.02377972 0.00375469 0.         0.01251564]\n",
      " [0.05006258 0.         0.         0.         0.         0.        ]\n",
      " [0.05381727 0.21902378 0.         0.         0.         0.02753442]\n",
      " [0.12265332 0.05506884 0.00876095 0.         0.         0.01001252]\n",
      " [0.00876095 0.00375469 0.00750939 0.08886108 0.05506884 0.07884856]\n",
      " [0.00750939 0.01877347 0.0175219  0.00750939 0.04005006 0.01126408]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00246151 0.02816497 0.01331869 0.01682299 0.02149663 0.01707974\n",
      " 0.02606346 0.01121868 0.01114657 0.00719906 0.02043388 0.00399362\n",
      " 0.04336221 0.00440301 0.00964701 0.06890287 0.08346532 0.07589162\n",
      " 0.01295951 0.08060705 0.01957207 0.00295437 0.00597723 0.00550959\n",
      " 0.00711165 0.01057739 0.01945839 0.07791743 0.02236858 0.03275568\n",
      " 0.00992251 0.01319788 0.0078773  0.02829355 0.16939624 0.00847199] \n",
      " -0.7586025\n",
      "p [[0.00125156 0.01001252 0.00500626 0.58698373 0.         0.00125156]\n",
      " [0.00750939 0.         0.         0.         0.         0.        ]\n",
      " [0.02002503 0.         0.         0.         0.         0.01376721]\n",
      " [0.00250313 0.01001252 0.01001252 0.         0.         0.00375469]\n",
      " [0.00625782 0.00500626 0.00750939 0.00250313 0.00500626 0.20650814]\n",
      " [0.00125156 0.04130163 0.00876095 0.01251564 0.02753442 0.00375469]]\n",
      "move 3\n",
      "board\n",
      " [[ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01293371 0.01822715 0.03545761 0.01560833 0.04061052 0.00398813\n",
      " 0.01300314 0.02537926 0.01019487 0.0055204  0.05643488 0.01333921\n",
      " 0.04597935 0.00127538 0.02094513 0.06066382 0.01539676 0.09744819\n",
      " 0.00411323 0.05297509 0.05239013 0.00619265 0.00123933 0.01751425\n",
      " 0.02128343 0.01613806 0.06259189 0.00883558 0.0244574  0.02571014\n",
      " 0.00320767 0.06009112 0.02186872 0.03789422 0.06883256 0.02225869] \n",
      " -0.9602363\n",
      "p [[0.00750939 0.17772215 0.00876095 0.         0.         0.01501877]\n",
      " [0.06883605 0.         0.         0.         0.         0.        ]\n",
      " [0.05882353 0.         0.         0.         0.         0.06633292]\n",
      " [0.24405507 0.04005006 0.00375469 0.         0.         0.00876095]\n",
      " [0.01126408 0.00375469 0.00876095 0.03754693 0.02753442 0.06257822]\n",
      " [0.00500626 0.01001252 0.00876095 0.01877347 0.0951189  0.01126408]]\n",
      "move 18\n",
      "board\n",
      " [[ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [-1.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00354481 0.01813089 0.00761518 0.03494669 0.0112684  0.0175969\n",
      " 0.00794344 0.00857645 0.00969273 0.00511508 0.02511628 0.00329107\n",
      " 0.05551735 0.00555014 0.015513   0.03406673 0.12126417 0.07008421\n",
      " 0.01121532 0.11079589 0.01725029 0.00279973 0.00468468 0.00502754\n",
      " 0.00934008 0.0073919  0.02341525 0.05531461 0.01784863 0.01083183\n",
      " 0.01221068 0.0104944  0.00995922 0.02591597 0.19735806 0.01331239] \n",
      " -0.95699507\n",
      "p [[0.00250313 0.01251564 0.0175219  0.         0.         0.00250313]\n",
      " [0.72465582 0.         0.         0.         0.         0.        ]\n",
      " [0.01501877 0.         0.         0.         0.         0.02252816]\n",
      " [0.         0.03629537 0.02252816 0.         0.         0.00375469]\n",
      " [0.00750939 0.00876095 0.0212766  0.00375469 0.00876095 0.01251564]\n",
      " [0.00250313 0.02628285 0.00500626 0.01376721 0.02628285 0.00375469]]\n",
      "move 6\n",
      "board\n",
      " [[ 0.  0.  0.  1. -1.  0.]\n",
      " [ 1. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [-1.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02852202 0.01302117 0.05673981 0.01008663 0.03859382 0.00374796\n",
      " 0.00591712 0.04981758 0.01130199 0.00568859 0.04860047 0.02048616\n",
      " 0.03875751 0.00227142 0.01444157 0.05626356 0.02308349 0.06600212\n",
      " 0.00622348 0.05393416 0.07350584 0.00676722 0.00163253 0.01986453\n",
      " 0.0186753  0.02283189 0.06241637 0.00963989 0.03738913 0.01507321\n",
      " 0.00429165 0.05910134 0.02829204 0.02238137 0.02920245 0.03543462] \n",
      " -0.8038946\n",
      "p [[0.01001252 0.16520651 0.01501877 0.         0.         0.02503129]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.06382979 0.         0.         0.         0.         0.07634543]\n",
      " [0.         0.10888611 0.00500626 0.         0.         0.01627034]\n",
      " [0.01001252 0.00375469 0.00625782 0.03754693 0.04130163 0.10137672]\n",
      " [0.01627034 0.11639549 0.00625782 0.05131414 0.10638298 0.0175219 ]]\n",
      "move 1\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 1. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [-1.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00424783 0.01270817 0.01064407 0.01941716 0.0171182  0.00693748\n",
      " 0.0052662  0.01849452 0.01692792 0.01109794 0.02502941 0.00419521\n",
      " 0.05535644 0.00931837 0.01714319 0.04360647 0.0781607  0.03110663\n",
      " 0.01247369 0.11782126 0.02956579 0.00496858 0.00603492 0.00929607\n",
      " 0.01507648 0.00490254 0.03762257 0.07031974 0.041242   0.01138469\n",
      " 0.00922475 0.01266095 0.0181908  0.04396957 0.13983405 0.0286358 ] \n",
      " -0.9943953\n",
      "p [[3.75469337e-03 0.00000000e+00 6.25782228e-03 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.00625782e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 6.25782228e-03]\n",
      " [0.00000000e+00 9.18648310e-01 8.76095119e-03 0.00000000e+00\n",
      "  0.00000000e+00 3.75469337e-03]\n",
      " [3.75469337e-03 3.75469337e-03 7.50938673e-03 2.50312891e-03\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [1.25156446e-13 6.25782228e-03 3.75469337e-03 3.75469337e-03\n",
      "  3.75469337e-03 5.00625782e-03]]\n",
      "move 19\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 1. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [-1.  1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02310467 0.0074635  0.05388456 0.00685397 0.04198515 0.00372353\n",
      " 0.00381675 0.04852315 0.00897555 0.01278875 0.03714366 0.01322408\n",
      " 0.04302105 0.00155951 0.01468326 0.05036294 0.01632967 0.07835994\n",
      " 0.01103347 0.01392624 0.08806784 0.02321519 0.00130655 0.02092037\n",
      " 0.02827155 0.01017636 0.08457937 0.01224856 0.06170912 0.01195027\n",
      " 0.00304938 0.04593709 0.01716876 0.04306731 0.0154035  0.0421658 ] \n",
      " -0.12040458\n",
      "p [[0.03754693 0.         0.03629537 0.         0.         0.01001252]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.09637046 0.         0.         0.         0.         0.02628285]\n",
      " [0.         0.         0.01877347 0.         0.         0.00876095]\n",
      " [0.06508135 0.01501877 0.02377972 0.11889862 0.09136421 0.03379224]\n",
      " [0.00876095 0.02002503 0.03003755 0.11514393 0.17146433 0.07259074]]\n",
      "move 34\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 1. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [-1.  1.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "prediction:\n",
      " [0.00627962 0.00590463 0.00787035 0.01751938 0.02098    0.01752226\n",
      " 0.01355617 0.01611689 0.01719655 0.01401867 0.02884116 0.006391\n",
      " 0.04663038 0.01603772 0.01915921 0.03133774 0.09816121 0.02569529\n",
      " 0.00505222 0.07313816 0.01518623 0.00460776 0.02141522 0.00458543\n",
      " 0.02624366 0.00303314 0.04706926 0.09147576 0.02405733 0.03542707\n",
      " 0.01105356 0.01880506 0.01444068 0.05995996 0.11643683 0.01879462] \n",
      " -0.9997277\n",
      "p [[6.25782228e-03 0.00000000e+00 3.62953692e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.12765957e-02]\n",
      " [0.00000000e+00 0.00000000e+00 5.91989987e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.00125156e-02]\n",
      " [1.88986233e-01 1.50187735e-02 5.00625782e-02 3.75469337e-03\n",
      "  1.37672090e-02 5.00625782e-03]\n",
      " [1.25156446e-13 1.37672090e-02 7.50938673e-03 1.37672090e-02\n",
      "  0.00000000e+00 1.00125156e-02]]\n",
      "move 20\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 1. -1.  1.  1. -1.  1.]\n",
      " [ 0. -1.  1. -1. -1.  0.]\n",
      " [-1.  1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]]\n",
      "1 won\n",
      "game 99 completed in 45.426902055740356 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.651399 entropy 3.058392\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6275225 entropy 3.0740538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.6666666666666666 loss 3.586587 entropy 3.0927546\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5376482 entropy 3.101963\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4854357 entropy 3.0972896\n",
      "kl 0.018676315\n",
      "completed in 0.37180280685424805 s\n",
      "game 100 completed in 8.306329250335693 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6793237 entropy 3.0983615\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.634987 entropy 3.0841432\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6000972 entropy 3.0770063\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5593612 entropy 3.0747972\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5100424 entropy 3.0752845\n",
      "kl 0.016400479\n",
      "completed in 0.2875089645385742 s\n",
      "game 101 completed in 9.358723878860474 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7620287 entropy 3.074883\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.7142317 entropy 3.076052\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6924295 entropy 3.0805588\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6416569 entropy 3.0934103\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5716279 entropy 3.1107345\n",
      "kl 0.017607734\n",
      "completed in 0.3356320858001709 s\n",
      "game 102 completed in 13.673043966293335 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7687793 entropy 3.1190436\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.739539 entropy 3.128966\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.694716 entropy 3.128516\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.624405 entropy 3.1162627\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5612743 entropy 3.0986362\n",
      "kl 0.018113945\n",
      "completed in 0.29125094413757324 s\n",
      "game 103 completed in 14.599963903427124 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7585092 entropy 3.1040516\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.730532 entropy 3.0974047\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6638598 entropy 3.0963674\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.583516 entropy 3.0974882\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.511489 entropy 3.09483\n",
      "kl 0.025519911\n",
      "completed in 0.3161327838897705 s\n",
      "game 104 completed in 10.198990106582642 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6456475 entropy 3.0693307\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6179216 entropy 3.0493188\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5794706 entropy 3.022262\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5378113 entropy 2.9959345\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4904945 entropy 2.978522\n",
      "kl 0.035050154\n",
      "completed in 0.3078432083129883 s\n",
      "game 105 completed in 11.404721975326538 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.7036567 entropy 2.9673429\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6681955 entropy 2.9715917\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6165836 entropy 2.9807644\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5606122 entropy 2.9921517\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5127223 entropy 3.0058515\n",
      "kl 0.019491922\n",
      "completed in 0.2883422374725342 s\n",
      "game 106 completed in 14.883111953735352 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.763588 entropy 3.041033\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.737856 entropy 3.0647583\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.6898332 entropy 3.0917947\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.6333265 entropy 3.1145115\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.5772767 entropy 3.128222\n",
      "kl 0.023693047\n",
      "completed in 0.33306193351745605 s\n",
      "game 107 completed in 10.298298835754395 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6553288 entropy 3.1337135\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6085994 entropy 3.1276011\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5549195 entropy 3.1134057\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5023956 entropy 3.0916479\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.453675 entropy 3.066331\n",
      "kl 0.040351085\n",
      "completed in 0.30057215690612793 s\n",
      "game 108 completed in 10.393821001052856 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6828158 entropy 3.033588\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6650577 entropy 3.0244005\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6313424 entropy 3.0196018\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5884347 entropy 3.016929\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.543048 entropy 3.0147889\n",
      "kl 0.018549804\n",
      "completed in 0.3216869831085205 s\n",
      "game 109 completed in 13.913131952285767 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7275007 entropy 3.0127378\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6811538 entropy 3.0145626\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6207483 entropy 3.0198295\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5767365 entropy 3.0271282\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5427046 entropy 3.0356205\n",
      "kl 0.012627045\n",
      "completed in 0.2801961898803711 s\n",
      "game 110 completed in 10.166627883911133 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.632276 entropy 3.0394897\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6070416 entropy 3.050473\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5742433 entropy 3.0626042\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5445867 entropy 3.0736668\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5143588 entropy 3.0826874\n",
      "kl 0.01176832\n",
      "completed in 0.30875372886657715 s\n",
      "game 111 completed in 14.00926685333252 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.714664 entropy 3.1078858\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6906059 entropy 3.1059852\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6540244 entropy 3.0972776\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.6103764 entropy 3.0849571\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5657954 entropy 3.0737827\n",
      "kl 0.018876635\n",
      "completed in 0.28580188751220703 s\n",
      "game 112 completed in 10.15866231918335 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.739463 entropy 3.0549493\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.714538 entropy 3.0557263\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6765156 entropy 3.0624933\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.635906 entropy 3.0691197\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.588475 entropy 3.0713181\n",
      "kl 0.011559114\n",
      "completed in 0.29401087760925293 s\n",
      "game 113 completed in 13.101724863052368 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6633818 entropy 3.0656877\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6370578 entropy 3.0563984\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6042366 entropy 3.046585\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.571794 entropy 3.040265\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5401733 entropy 3.038413\n",
      "kl 0.010900252\n",
      "completed in 0.27354907989501953 s\n",
      "game 114 completed in 14.57927918434143 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7598984 entropy 3.056947\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.74199 entropy 3.064488\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.7066698 entropy 3.072548\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.6619658 entropy 3.0772521\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.6168091 entropy 3.0765023\n",
      "kl 0.011432366\n",
      "completed in 0.2686119079589844 s\n",
      "game 115 completed in 12.255950212478638 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6278565 entropy 3.0559938\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6015518 entropy 3.0436053\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.559767 entropy 3.0274012\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5119936 entropy 3.0116787\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.466604 entropy 2.9998822\n",
      "kl 0.016523935\n",
      "completed in 0.3390378952026367 s\n",
      "game 116 completed in 9.513839960098267 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6918256 entropy 2.99165\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6723669 entropy 2.9955106\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.63441 entropy 3.003817\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.590734 entropy 3.0122712\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5503364 entropy 3.0183306\n",
      "kl 0.013054947\n",
      "completed in 0.28070998191833496 s\n",
      "game 117 completed in 6.58433198928833 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.702105 entropy 3.0406628\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6807501 entropy 3.0378895\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.637674 entropy 3.0304413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 3.5908399 entropy 3.0210872\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5486531 entropy 3.0134082\n",
      "kl 0.013966407\n",
      "completed in 0.2915048599243164 s\n",
      "game 118 completed in 12.934945106506348 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6131847 entropy 3.0190148\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5863218 entropy 3.0274012\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5486984 entropy 3.0412354\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5105608 entropy 3.0531561\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4743285 entropy 3.0579686\n",
      "kl 0.023907183\n",
      "completed in 0.3020668029785156 s\n",
      "game 119 completed in 13.514333963394165 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.683352 entropy 3.0551882\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.652939 entropy 3.045179\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6009972 entropy 3.031005\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5463219 entropy 3.0159655\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.496614 entropy 3.0039477\n",
      "kl 0.021662906\n",
      "completed in 0.29409289360046387 s\n",
      "game 120 completed in 10.883179187774658 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6148398 entropy 2.9904032\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6011932 entropy 2.9903188\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5745502 entropy 2.9947417\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5392768 entropy 3.0026946\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.499997 entropy 3.0116441\n",
      "kl 0.0114023965\n",
      "completed in 0.2485218048095703 s\n",
      "game 121 completed in 10.029026985168457 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6782548 entropy 3.02476\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6602178 entropy 3.0283513\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.624799 entropy 3.02829\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5810053 entropy 3.026383\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5359018 entropy 3.0244312\n",
      "kl 0.01192657\n",
      "completed in 0.2839651107788086 s\n",
      "game 122 completed in 9.170247077941895 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6635869 entropy 3.0075562\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6405482 entropy 3.0207222\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6011307 entropy 3.0401802\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5563247 entropy 3.0592136\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5149295 entropy 3.071595\n",
      "kl 0.0219166\n",
      "completed in 0.2994041442871094 s\n",
      "game 123 completed in 14.500316858291626 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6164756 entropy 3.074723\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.589867 entropy 3.063272\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5507994 entropy 3.040852\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.512095 entropy 3.0140862\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4780087 entropy 2.9920554\n",
      "kl 0.024270851\n",
      "completed in 0.28255796432495117 s\n",
      "game 124 completed in 16.3421950340271 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6950924 entropy 3.0100281\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6796343 entropy 3.0089297\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6428168 entropy 3.0127397\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.597007 entropy 3.0188339\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.551831 entropy 3.0249376\n",
      "kl 0.0138080865\n",
      "completed in 0.35453104972839355 s\n",
      "game 125 completed in 11.167423009872437 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7027092 entropy 3.037398\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6836314 entropy 3.0458856\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6478899 entropy 3.0546746\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.6054754 entropy 3.0610728\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5640733 entropy 3.0631037\n",
      "kl 0.013051847\n",
      "completed in 0.2946302890777588 s\n",
      "game 126 completed in 17.2873592376709 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7632387 entropy 3.0568585\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.7329102 entropy 3.048706\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.691971 entropy 3.038587\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.651925 entropy 3.0315828\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.60927 entropy 3.0302467\n",
      "kl 0.012065176\n",
      "completed in 0.26802682876586914 s\n",
      "game 127 completed in 12.938261985778809 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5776908 entropy 3.0241327\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5584762 entropy 3.0286338\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5247855 entropy 3.0302222\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4843297 entropy 3.0267694\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.446227 entropy 3.0175538\n",
      "kl 0.016541258\n",
      "completed in 0.2955179214477539 s\n",
      "game 128 completed in 8.2987961769104 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7116685 entropy 2.999967\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6702242 entropy 2.9910932\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6143987 entropy 2.9897988\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.568332 entropy 2.9945793\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5303657 entropy 3.001183\n",
      "kl 0.018357797\n",
      "completed in 0.30336594581604004 s\n",
      "game 129 completed in 8.303431034088135 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.731231 entropy 3.0201316\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.7120748 entropy 3.0161552\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6798444 entropy 3.0057585\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.6460729 entropy 2.9940612\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.613026 entropy 2.9871416\n",
      "kl 0.023533434\n",
      "completed in 0.2739450931549072 s\n",
      "game 130 completed in 212.46420693397522 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7371097 entropy 2.9840608\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.7080014 entropy 3.0034018\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6568696 entropy 3.032456\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.6000252 entropy 3.0605674\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5429077 entropy 3.0790813\n",
      "kl 0.026328444\n",
      "completed in 0.32871389389038086 s\n",
      "game 131 completed in 10.053428888320923 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7011356 entropy 3.0957904\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6710315 entropy 3.0833044\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6257286 entropy 3.0564728\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5772285 entropy 3.023405\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5284734 entropy 2.9962368\n",
      "kl 0.051102236\n",
      "completed in 0.30100488662719727 s\n",
      "game 132 completed in 12.902188777923584 s 14 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.6623352 entropy 2.9733903\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.6397166 entropy 2.9777884\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.6046872 entropy 2.9910142\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.5668542 entropy 3.0081434\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.5316424 entropy 3.0239706\n",
      "kl 0.019671902\n",
      "completed in 0.2742469310760498 s\n",
      "game 133 completed in 11.8457670211792 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.6847236 entropy 3.0156026\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.6729217 entropy 3.0217588\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.6455064 entropy 3.0214279\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.6092005 entropy 3.0145557\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.5699582 entropy 3.0021172\n",
      "kl 0.016593698\n",
      "completed in 0.27280473709106445 s\n",
      "game 134 completed in 8.345784187316895 s 9 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 3.749554 entropy 3.0135355\n",
      "training 1 lr_mult 0.2962962962962963 loss 3.7319286 entropy 3.0040617\n",
      "training 2 lr_mult 0.2962962962962963 loss 3.7046897 entropy 3.001383\n",
      "training 3 lr_mult 0.2962962962962963 loss 3.6739357 entropy 3.005016\n",
      "training 4 lr_mult 0.2962962962962963 loss 3.6422048 entropy 3.0129242\n",
      "kl 0.009538684\n",
      "completed in 0.3459630012512207 s\n",
      "game 135 completed in 12.146764755249023 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.669329 entropy 3.008946\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.649889 entropy 3.0207129\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6159947 entropy 3.02847\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5766256 entropy 3.0327034\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5342607 entropy 3.03404\n",
      "kl 0.013840227\n",
      "completed in 0.2820620536804199 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 136 completed in 10.246204853057861 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6500037 entropy 3.031537\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.627988 entropy 3.0178256\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5983262 entropy 2.9987135\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.566445 entropy 2.981893\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.531075 entropy 2.9734745\n",
      "kl 0.016680464\n",
      "completed in 0.2835261821746826 s\n",
      "game 137 completed in 11.918906211853027 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6616516 entropy 2.9818\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6377015 entropy 3.0011292\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6061962 entropy 3.0246308\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5730238 entropy 3.0416644\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5334437 entropy 3.0468316\n",
      "kl 0.028372142\n",
      "completed in 0.3065071105957031 s\n",
      "game 138 completed in 12.712454080581665 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7060401 entropy 3.0312345\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6751466 entropy 3.0140655\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6346526 entropy 2.9907968\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5943198 entropy 2.9686985\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5568693 entropy 2.9545898\n",
      "kl 0.026874729\n",
      "completed in 0.2875180244445801 s\n",
      "game 139 completed in 13.641084909439087 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6768436 entropy 2.9415913\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6585722 entropy 2.952697\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6241965 entropy 2.9705973\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.584182 entropy 2.9887037\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5438578 entropy 3.0004487\n",
      "kl 0.019978367\n",
      "completed in 0.311204195022583 s\n",
      "game 140 completed in 9.318934917449951 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.786525 entropy 3.0118022\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.7703705 entropy 3.0077176\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.7444499 entropy 2.9985192\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.7122622 entropy 2.9875007\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.6757631 entropy 2.9789085\n",
      "kl 0.011559646\n",
      "completed in 0.30358314514160156 s\n",
      "game 141 completed in 13.644450187683105 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6672533 entropy 2.9707365\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6430984 entropy 2.9758198\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.607564 entropy 2.9860544\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5665553 entropy 2.995942\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.524344 entropy 3.0002792\n",
      "kl 0.017123934\n",
      "completed in 0.38660621643066406 s\n",
      "game 142 completed in 14.586649894714355 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6823907 entropy 3.0077987\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6568825 entropy 2.9973876\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.612703 entropy 2.9822857\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5665622 entropy 2.967393\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.52173 entropy 2.9577885\n",
      "kl 0.022252068\n",
      "completed in 0.29680585861206055 s\n",
      "game 143 completed in 9.439048051834106 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6331294 entropy 2.9553256\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6105795 entropy 2.9652033\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5758936 entropy 2.9810855\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5370648 entropy 2.995258\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.494891 entropy 3.0020285\n",
      "kl 0.026689757\n",
      "completed in 0.2945709228515625 s\n",
      "game 144 completed in 10.978821039199829 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6962557 entropy 3.003317\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.655248 entropy 2.9959579\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6115081 entropy 2.9835649\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5809221 entropy 2.969328\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5457134 entropy 2.957302\n",
      "kl 0.022268256\n",
      "completed in 0.2561779022216797 s\n",
      "game 145 completed in 47.50419592857361 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7080286 entropy 2.9499145\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6868143 entropy 2.957869\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6486125 entropy 2.9757376\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.6046748 entropy 2.9982467\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5606062 entropy 3.0197208\n",
      "kl 0.021166\n",
      "completed in 0.33645105361938477 s\n",
      "game 146 completed in 8.902498960494995 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6018817 entropy 3.0450814\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5878205 entropy 3.0465064\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5606132 entropy 3.0358558\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5250392 entropy 3.017953\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.489222 entropy 2.9980395\n",
      "kl 0.020500049\n",
      "completed in 0.309298038482666 s\n",
      "game 147 completed in 10.51774787902832 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7096164 entropy 2.962281\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.686291 entropy 2.958396\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.645914 entropy 2.9659014\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5962298 entropy 2.980866\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5480185 entropy 2.9974315\n",
      "kl 0.020213023\n",
      "completed in 0.29560208320617676 s\n",
      "game 148 completed in 20.7416889667511 s 23 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.626001 entropy 3.0297966\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6086812 entropy 3.034436\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5768652 entropy 3.0296812\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5357814 entropy 3.016809\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4920104 entropy 2.998439\n",
      "kl 0.013379089\n",
      "completed in 0.30952906608581543 s\n",
      "prediction:\n",
      " [0.00088704 0.00950919 0.00233078 0.00296578 0.00932619 0.00171001\n",
      " 0.00878385 0.04322199 0.06035826 0.02495918 0.03763297 0.01199889\n",
      " 0.00315913 0.0087112  0.13704324 0.09042321 0.05421325 0.00349627\n",
      " 0.00313753 0.03823154 0.13734455 0.09148175 0.00862869 0.00361002\n",
      " 0.00983502 0.03572647 0.04414608 0.04765926 0.02286629 0.01070126\n",
      " 0.00119789 0.01395143 0.00376622 0.0018688  0.01354123 0.00157576] \n",
      " -0.195645\n",
      "p [[1.25156446e-13 6.25782228e-03 1.25156446e-03 3.75469337e-03\n",
      "  8.76095119e-03 1.25156446e-03]\n",
      " [8.76095119e-03 8.76095119e-03 4.38047559e-02 1.50187735e-02\n",
      "  5.00625782e-03 5.00625782e-03]\n",
      " [2.50312891e-03 2.50312891e-02 6.50813517e-02 4.63078849e-02\n",
      "  4.63078849e-02 2.50312891e-03]\n",
      " [1.25156446e-03 2.62828536e-02 5.38172716e-02 2.20275344e-01\n",
      "  2.96620776e-01 1.25156446e-03]\n",
      " [7.50938673e-03 3.75469337e-03 4.25531915e-02 1.87734668e-02\n",
      "  5.00625782e-03 3.75469337e-03]\n",
      " [1.25156446e-03 1.12640801e-02 1.25156446e-03 1.25156446e-03\n",
      "  7.50938673e-03 1.25156446e-03]]\n",
      "move 22\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.00131567 0.01495024 0.00293836 0.00317622 0.0134997  0.00126241\n",
      " 0.01280634 0.03177935 0.05040817 0.0273749  0.02002135 0.01298729\n",
      " 0.00437288 0.01425    0.04358827 0.14806214 0.07971619 0.00498259\n",
      " 0.00478911 0.05029009 0.20283058 0.03379392 0.01580702 0.00529527\n",
      " 0.01269298 0.02387262 0.04377975 0.04588209 0.02292418 0.01280088\n",
      " 0.00080412 0.01269628 0.00248366 0.00219185 0.0182342  0.0013395 ] \n",
      " 0.10631222\n",
      "p [[0.00125156 0.00125156 0.00750939 0.00125156 0.01251564 0.00125156]\n",
      " [0.00250313 0.04380476 0.02377972 0.03254068 0.01627034 0.00500626]\n",
      " [0.00375469 0.00500626 0.04630788 0.05506884 0.04505632 0.00125156]\n",
      " [0.00876095 0.02252816 0.11389237 0.2853567  0.         0.00125156]\n",
      " [0.00750939 0.04255319 0.02628285 0.12515645 0.00876095 0.01501877]\n",
      " [0.00125156 0.00750939 0.01877347 0.00125156 0.00750939 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0029588  0.0110762  0.00414307 0.008086   0.01362291 0.00236905\n",
      " 0.00610566 0.13971661 0.01894371 0.04194911 0.06247674 0.02794697\n",
      " 0.00584568 0.00459163 0.03971101 0.06591659 0.14152652 0.01205147\n",
      " 0.00610014 0.03668291 0.07945779 0.01950595 0.00349961 0.00512684\n",
      " 0.00931535 0.03564994 0.08202042 0.01727325 0.02748822 0.00790401\n",
      " 0.00182024 0.01949215 0.01299522 0.0032115  0.01713379 0.00628512] \n",
      " -0.80755544\n",
      "p [[1.25156446e-13 3.75469337e-03 1.25156446e-03 1.25156446e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [2.50312891e-03 8.76095119e-03 7.73466834e-01 7.50938673e-03\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [1.25156446e-03 6.25782228e-03 1.00125156e-02 3.25406758e-02\n",
      "  3.50438048e-02 1.25156446e-03]\n",
      " [1.25156446e-03 6.25782228e-03 4.75594493e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-03 6.25782228e-03 1.00125156e-02 1.12640801e-02\n",
      "  3.75469337e-03 7.50938673e-03]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-03 1.25156446e-03\n",
      "  3.75469337e-03 1.25156446e-13]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.0012305  0.0197288  0.00635522 0.0054026  0.01030941 0.00159373\n",
      " 0.01075082 0.07539671 0.01376995 0.10528325 0.01258112 0.01846875\n",
      " 0.00433565 0.01199297 0.02049248 0.16072045 0.01935334 0.01314147\n",
      " 0.00563679 0.00944617 0.13252586 0.01054808 0.02958207 0.00826616\n",
      " 0.01269697 0.02074304 0.1520087  0.0119503  0.03237052 0.02242524\n",
      " 0.00068293 0.01013856 0.00440351 0.00414417 0.01983093 0.001693  ] \n",
      " 0.12676646\n",
      "p [[0.00125156 0.00500626 0.00125156 0.00375469 0.01126408 0.00125156]\n",
      " [0.00375469 0.08886108 0.         0.08385482 0.0350438  0.0387985 ]\n",
      " [0.01376721 0.11889862 0.01251564 0.05006258 0.26658323 0.06132666]\n",
      " [0.0350438  0.01501877 0.03754693 0.         0.         0.00125156]\n",
      " [0.00250313 0.03254068 0.02377972 0.00500626 0.01376721 0.00250313]\n",
      " [0.00125156 0.00750939 0.01627034 0.00125156 0.00500626 0.00250313]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00215015 0.00969483 0.00707711 0.01207204 0.02870299 0.00745835\n",
      " 0.0069992  0.06780559 0.0104378  0.06120869 0.04386262 0.08919382\n",
      " 0.00941742 0.01508554 0.05820326 0.0337529  0.02385475 0.04078403\n",
      " 0.01471961 0.00886692 0.03723725 0.01592822 0.03374947 0.00841685\n",
      " 0.01452175 0.01827938 0.18033268 0.01301962 0.01305483 0.01866765\n",
      " 0.0042879  0.03047535 0.02319433 0.0045854  0.02179224 0.01110964] \n",
      " -0.92450047\n",
      "p [[1.25156446e-13 8.76095119e-03 2.50312891e-03 1.25156446e-03\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [5.00625782e-03 2.25281602e-02 0.00000000e+00 3.37922403e-02\n",
      "  2.50312891e-03 2.50312891e-03]\n",
      " [1.25156446e-13 6.25782228e-03 3.75469337e-03 7.95994994e-01\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [1.25156446e-03 1.25156446e-03 2.00250313e-02 0.00000000e+00\n",
      "  0.00000000e+00 7.50938673e-03]\n",
      " [2.50312891e-03 6.25782228e-03 2.87859825e-02 8.76095119e-03\n",
      "  1.75219024e-02 7.50938673e-03]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-13\n",
      "  5.00625782e-03 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00113914 0.04546909 0.00872079 0.01675673 0.01624389 0.01038196\n",
      " 0.02574285 0.06014366 0.03913421 0.02078831 0.02226025 0.02650175\n",
      " 0.00953515 0.02293602 0.01323173 0.03678642 0.01718158 0.01786114\n",
      " 0.00700694 0.01105442 0.02592173 0.00326022 0.07118021 0.02643693\n",
      " 0.01871843 0.03416836 0.03361239 0.02088165 0.02953285 0.16601074\n",
      " 0.00285065 0.01668134 0.01196739 0.00676172 0.10149815 0.00164136] \n",
      " -0.40258983\n",
      "p [[0.00375469 0.00876095 0.02252816 0.01501877 0.04005006 0.00500626]\n",
      " [0.0350438  0.06883605 0.         0.05381727 0.04380476 0.10763454]\n",
      " [0.00750939 0.01001252 0.05256571 0.         0.         0.06257822]\n",
      " [0.01251564 0.00625782 0.03379224 0.         0.         0.02377972]\n",
      " [0.00876095 0.03629537 0.12015019 0.03629537 0.01001252 0.05131414]\n",
      " [0.00500626 0.04255319 0.03754693 0.00500626 0.02628285 0.00750939]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00293554 0.00977072 0.01311234 0.01641547 0.04467802 0.00588692\n",
      " 0.00319825 0.18416244 0.02561095 0.0122132  0.03738325 0.1284308\n",
      " 0.01247337 0.01324925 0.03945346 0.02925345 0.02556819 0.0604754\n",
      " 0.00650994 0.00788512 0.02783129 0.01473784 0.01788788 0.01586861\n",
      " 0.01007949 0.04362017 0.02977551 0.03417735 0.04278636 0.00311714\n",
      " 0.0024485  0.02954368 0.01593922 0.01201796 0.01367063 0.00783259] \n",
      " -0.93118197\n",
      "p [[1.25156446e-13 1.98998748e-01 2.50312891e-03 2.50312891e-03\n",
      "  3.75469337e-03 2.50312891e-03]\n",
      " [3.75469337e-03 6.25782228e-03 0.00000000e+00 1.25156446e-03\n",
      "  3.75469337e-03 5.00625782e-03]\n",
      " [2.50312891e-03 2.50312891e-03 1.25156446e-03 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-03 2.50312891e-03 0.00000000e+00\n",
      "  0.00000000e+00 3.75469337e-03]\n",
      " [3.75469337e-03 3.75469337e-03 0.00000000e+00 2.50312891e-03\n",
      "  2.50312891e-03 7.27158949e-01]\n",
      " [1.25156446e-13 2.50312891e-03 2.50312891e-03 1.25156446e-13\n",
      "  1.00125156e-02 1.25156446e-13]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 149 completed in 22.079025983810425 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6089833 entropy 2.9642916\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5917137 entropy 2.9461055\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5609205 entropy 2.933949\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5209272 entropy 2.92891\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4776254 entropy 2.9305744\n",
      "kl 0.013842481\n",
      "completed in 0.27666568756103516 s\n",
      "game 150 completed in 18.76594090461731 s 20 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5966563 entropy 2.9263783\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5723553 entropy 2.9303498\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5336485 entropy 2.9311714\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.489567 entropy 2.9275584\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.444866 entropy 2.9203954\n",
      "kl 0.012097023\n",
      "completed in 0.32765984535217285 s\n",
      "game 151 completed in 8.388418912887573 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6398509 entropy 2.9393635\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6167736 entropy 2.9425583\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5755582 entropy 2.9543626\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5260797 entropy 2.9692307\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4787438 entropy 2.9805267\n",
      "kl 0.017403701\n",
      "completed in 0.3037428855895996 s\n",
      "game 152 completed in 12.598872900009155 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5988977 entropy 2.99642\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5793264 entropy 2.9914107\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5425947 entropy 2.9805615\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4977138 entropy 2.9687452\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.45113 entropy 2.9599514\n",
      "kl 0.022272479\n",
      "completed in 0.28866076469421387 s\n",
      "game 153 completed in 11.896672010421753 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.7061312 entropy 2.945047\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6701946 entropy 2.954904\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.6139936 entropy 2.9724846\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5592515 entropy 2.991754\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.5129178 entropy 3.0072422\n",
      "kl 0.016289346\n",
      "completed in 0.2932400703430176 s\n",
      "game 154 completed in 9.993304252624512 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.633325 entropy 3.0121412\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.596748 entropy 3.008885\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.548895 entropy 2.9987128\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5064604 entropy 2.9888246\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.466711 entropy 2.983833\n",
      "kl 0.018313032\n",
      "completed in 0.26772570610046387 s\n",
      "game 155 completed in 12.801701068878174 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5822265 entropy 2.9834657\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5613198 entropy 2.9926348\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5251215 entropy 3.0049348\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4836392 entropy 3.0146518\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4425626 entropy 3.0176163\n",
      "kl 0.014058308\n",
      "completed in 0.29095983505249023 s\n",
      "game 156 completed in 14.22753620147705 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5874658 entropy 3.0223079\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5609093 entropy 3.010212\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5200915 entropy 2.9934843\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4694836 entropy 2.976554\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4191456 entropy 2.9645288\n",
      "kl 0.011994848\n",
      "completed in 0.8982391357421875 s\n",
      "game 157 completed in 8.057822942733765 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5595644 entropy 2.9597108\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5331125 entropy 2.9632382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.4444444444444444 loss 3.5001988 entropy 2.9692755\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4679427 entropy 2.9735413\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4340067 entropy 2.9723454\n",
      "kl 0.017350048\n",
      "completed in 0.30712294578552246 s\n",
      "game 158 completed in 8.985490083694458 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6106558 entropy 2.9442306\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5853329 entropy 2.928565\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5474517 entropy 2.9094517\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5098162 entropy 2.8941894\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.472995 entropy 2.8893704\n",
      "kl 0.02060672\n",
      "completed in 0.31517791748046875 s\n",
      "game 159 completed in 12.817610025405884 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5892305 entropy 2.9029853\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.569226 entropy 2.9233282\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.537714 entropy 2.9463007\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5003488 entropy 2.96353\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.458853 entropy 2.9705768\n",
      "kl 0.021121208\n",
      "completed in 0.3705599308013916 s\n",
      "game 160 completed in 8.169503927230835 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.616001 entropy 2.966717\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5928307 entropy 2.9550204\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5556076 entropy 2.939581\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5106797 entropy 2.9249992\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4618087 entropy 2.915152\n",
      "kl 0.024780532\n",
      "completed in 0.2819688320159912 s\n",
      "game 161 completed in 10.086864948272705 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5621603 entropy 2.9173489\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5399725 entropy 2.9244466\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5084264 entropy 2.9354823\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4718018 entropy 2.945991\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.434069 entropy 2.9519596\n",
      "kl 0.014950783\n",
      "completed in 0.36217594146728516 s\n",
      "game 162 completed in 11.906867027282715 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6204267 entropy 2.9538264\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.595741 entropy 2.9477177\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5545304 entropy 2.9380205\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5093095 entropy 2.9312274\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4667833 entropy 2.9307942\n",
      "kl 0.016747046\n",
      "completed in 0.3037288188934326 s\n",
      "game 163 completed in 13.921746253967285 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.674896 entropy 2.9409697\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.643489 entropy 2.9520726\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5898564 entropy 2.9631114\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5305607 entropy 2.971272\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4737885 entropy 2.9743576\n",
      "kl 0.016736826\n",
      "completed in 0.28296399116516113 s\n",
      "game 164 completed in 12.799255847930908 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6124423 entropy 2.9850864\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5924995 entropy 2.9860158\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5598378 entropy 2.987857\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5178864 entropy 2.989311\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4732022 entropy 2.9872997\n",
      "kl 0.010551443\n",
      "completed in 0.29594993591308594 s\n",
      "game 165 completed in 13.392823219299316 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5706968 entropy 2.9740596\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5558987 entropy 2.96229\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5238743 entropy 2.946633\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4847445 entropy 2.9293437\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4456925 entropy 2.9134707\n",
      "kl 0.011325797\n",
      "completed in 0.31356215476989746 s\n",
      "game 166 completed in 10.871363162994385 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6447992 entropy 2.9035838\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6167862 entropy 2.9023962\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5787232 entropy 2.907999\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5383358 entropy 2.9164557\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4972281 entropy 2.9237957\n",
      "kl 0.021413028\n",
      "completed in 0.31894612312316895 s\n",
      "game 167 completed in 8.335308074951172 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6258886 entropy 2.925786\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5996952 entropy 2.917221\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5574532 entropy 2.9004424\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5123854 entropy 2.8842738\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4679446 entropy 2.8790774\n",
      "kl 0.030166408\n",
      "completed in 0.2840099334716797 s\n",
      "game 168 completed in 21.734060049057007 s 24 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6080863 entropy 2.898033\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5726962 entropy 2.9230738\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5253994 entropy 2.9488945\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.4750736 entropy 2.9660013\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4264832 entropy 2.9694543\n",
      "kl 0.020105563\n",
      "completed in 0.3447401523590088 s\n",
      "game 169 completed in 13.68035888671875 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.5430639 entropy 2.9191246\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.5184646 entropy 2.9091501\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.4781785 entropy 2.9020624\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.435318 entropy 2.901163\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.3937263 entropy 2.905942\n",
      "kl 0.017051576\n",
      "completed in 0.31206488609313965 s\n",
      "game 170 completed in 8.571890830993652 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6340697 entropy 2.9281597\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6081994 entropy 2.9317036\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.569285 entropy 2.931412\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5282216 entropy 2.9274821\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.490495 entropy 2.9206874\n",
      "kl 0.010675117\n",
      "completed in 0.3492460250854492 s\n",
      "game 171 completed in 10.053322315216064 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.6382442 entropy 2.9377992\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.6153257 entropy 2.9311976\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.5767508 entropy 2.9277914\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.5326028 entropy 2.9292684\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.4885037 entropy 2.9358783\n",
      "kl 0.009767998\n",
      "completed in 0.29555511474609375 s\n",
      "game 172 completed in 11.868659973144531 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5544333 entropy 2.9407222\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5268834 entropy 2.9573975\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4767106 entropy 2.9672637\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4208257 entropy 2.9653387\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.371064 entropy 2.9517422\n",
      "kl 0.03196512\n",
      "completed in 0.3028128147125244 s\n",
      "game 173 completed in 12.889374017715454 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5817075 entropy 2.934793\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5546012 entropy 2.908416\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5035682 entropy 2.8858755\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4416692 entropy 2.8758018\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3808923 entropy 2.8793707\n",
      "kl 0.01736531\n",
      "completed in 0.2835242748260498 s\n",
      "game 174 completed in 9.218536138534546 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.568093 entropy 2.8879519\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5378976 entropy 2.8938498\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4904642 entropy 2.8888626\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4398274 entropy 2.8778706\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3876765 entropy 2.8687396\n",
      "kl 0.02511512\n",
      "completed in 0.3008720874786377 s\n",
      "game 175 completed in 12.752930164337158 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.606128 entropy 2.8814702\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5597222 entropy 2.8872938\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4994206 entropy 2.8939486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.6666666666666666 loss 3.448649 entropy 2.899023\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4010315 entropy 2.8991168\n",
      "kl 0.021850247\n",
      "completed in 0.2825310230255127 s\n",
      "game 176 completed in 12.683628797531128 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.611625 entropy 2.8875775\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5455334 entropy 2.8893216\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.505007 entropy 2.8998847\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4644296 entropy 2.9154131\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4058318 entropy 2.930036\n",
      "kl 0.019883046\n",
      "completed in 0.3313610553741455 s\n",
      "game 177 completed in 11.091958999633789 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.680292 entropy 2.9299397\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6458628 entropy 2.933855\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5951123 entropy 2.9336176\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5358787 entropy 2.929473\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.47495 entropy 2.9219995\n",
      "kl 0.021354139\n",
      "completed in 0.31222987174987793 s\n",
      "game 178 completed in 18.907654762268066 s 22 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6906734 entropy 2.9252427\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6574368 entropy 2.9208946\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.602399 entropy 2.917677\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5410519 entropy 2.9142766\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4780464 entropy 2.9097133\n",
      "kl 0.022567404\n",
      "completed in 0.32985901832580566 s\n",
      "game 179 completed in 7.690902948379517 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5573301 entropy 2.9079986\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5312192 entropy 2.900803\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4895017 entropy 2.8946123\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4375198 entropy 2.8950086\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3860936 entropy 2.902546\n",
      "kl 0.027293768\n",
      "completed in 0.27533578872680664 s\n",
      "game 180 completed in 11.695198774337769 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6181026 entropy 2.9123526\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5881388 entropy 2.9083047\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5398695 entropy 2.8911898\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4899278 entropy 2.8693953\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4395924 entropy 2.8536515\n",
      "kl 0.034084845\n",
      "completed in 0.33675694465637207 s\n",
      "game 181 completed in 10.188903093338013 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.65267 entropy 2.853922\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6205735 entropy 2.8711662\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5680962 entropy 2.8942509\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5065658 entropy 2.909389\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4439192 entropy 2.9094462\n",
      "kl 0.024096228\n",
      "completed in 0.3622889518737793 s\n",
      "game 182 completed in 9.240328788757324 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.60055 entropy 2.9000432\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5669854 entropy 2.8831425\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5114744 entropy 2.8757932\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.455194 entropy 2.8818507\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4024365 entropy 2.8944385\n",
      "kl 0.035591953\n",
      "completed in 0.37140679359436035 s\n",
      "game 183 completed in 10.271154880523682 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5834513 entropy 2.9008193\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5543532 entropy 2.905781\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5043612 entropy 2.8999774\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4413352 entropy 2.884182\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3774657 entropy 2.8615346\n",
      "kl 0.0335869\n",
      "completed in 0.31806397438049316 s\n",
      "game 184 completed in 7.291202068328857 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5464752 entropy 2.820332\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.517108 entropy 2.8083458\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4626205 entropy 2.8105328\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4011612 entropy 2.824394\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3476555 entropy 2.8421068\n",
      "kl 0.029397113\n",
      "completed in 0.2996647357940674 s\n",
      "game 185 completed in 11.857095003128052 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5850453 entropy 2.8866987\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5593326 entropy 2.8888497\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.509822 entropy 2.881746\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.456259 entropy 2.8739276\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.4091525 entropy 2.8718648\n",
      "kl 0.020890098\n",
      "completed in 0.2746741771697998 s\n",
      "game 186 completed in 12.399047374725342 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5773864 entropy 2.8539848\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5385203 entropy 2.8675203\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4754965 entropy 2.8810155\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4149873 entropy 2.8849032\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.361505 entropy 2.873087\n",
      "kl 0.02490222\n",
      "completed in 0.27641987800598145 s\n",
      "game 187 completed in 6.569491863250732 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5015209 entropy 2.8626094\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4688792 entropy 2.8368483\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4092143 entropy 2.820761\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3533218 entropy 2.8195882\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3086636 entropy 2.8292894\n",
      "kl 0.019447796\n",
      "completed in 0.3750269412994385 s\n",
      "game 188 completed in 8.469700813293457 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.571765 entropy 2.835383\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5465636 entropy 2.8419933\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4991286 entropy 2.84374\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4420216 entropy 2.8442678\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3844454 entropy 2.8462918\n",
      "kl 0.028138746\n",
      "completed in 0.2931530475616455 s\n",
      "game 189 completed in 14.582772970199585 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5445569 entropy 2.8521242\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5065966 entropy 2.8519619\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.450414 entropy 2.8481278\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3948867 entropy 2.8412013\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3437064 entropy 2.831253\n",
      "kl 0.024127718\n",
      "completed in 0.3138852119445801 s\n",
      "game 190 completed in 22.33438515663147 s 25 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.6577866 entropy 2.840581\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.6311657 entropy 2.83328\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.5804179 entropy 2.831794\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.5227122 entropy 2.838547\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.462603 entropy 2.8508236\n",
      "kl 0.02392762\n",
      "completed in 0.28191089630126953 s\n",
      "game 191 completed in 12.808649063110352 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5855603 entropy 2.8381107\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5506012 entropy 2.8525631\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4951885 entropy 2.8644264\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.431644 entropy 2.8678997\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.370955 entropy 2.861156\n",
      "kl 0.023958396\n",
      "completed in 0.28795504570007324 s\n",
      "game 192 completed in 10.227806091308594 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.513108 entropy 2.859416\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.476094 entropy 2.850112\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4201863 entropy 2.8490324\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3657107 entropy 2.8560412\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.311591 entropy 2.863972\n",
      "kl 0.017181575\n",
      "completed in 0.31900811195373535 s\n",
      "game 193 completed in 10.21104097366333 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.515556 entropy 2.8711262\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4844568 entropy 2.863658\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4305205 entropy 2.8463986\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3735592 entropy 2.8222542\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3257637 entropy 2.7974887\n",
      "kl 0.037810132\n",
      "completed in 0.2781498432159424 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 194 completed in 8.148400783538818 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5349095 entropy 2.76522\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.510897 entropy 2.7655046\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.464225 entropy 2.7777865\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.408115 entropy 2.792668\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3538396 entropy 2.8035882\n",
      "kl 0.03217465\n",
      "completed in 0.3612809181213379 s\n",
      "game 195 completed in 9.654743194580078 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5324495 entropy 2.8212895\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4991522 entropy 2.8153958\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4486482 entropy 2.8041425\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.390785 entropy 2.7969737\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3287435 entropy 2.7994719\n",
      "kl 0.021672616\n",
      "completed in 0.30336499214172363 s\n",
      "game 196 completed in 8.096312046051025 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.515026 entropy 2.8013563\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.481068 entropy 2.8191934\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.429326 entropy 2.832347\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3720417 entropy 2.8348749\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3183355 entropy 2.8277688\n",
      "kl 0.03164275\n",
      "completed in 0.314896821975708 s\n",
      "game 197 completed in 12.274078845977783 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5397243 entropy 2.8327699\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5131102 entropy 2.8357704\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4625254 entropy 2.850718\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.406737 entropy 2.8682117\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3478158 entropy 2.878169\n",
      "kl 0.023203023\n",
      "completed in 0.3987298011779785 s\n",
      "game 198 completed in 13.332176685333252 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5257895 entropy 2.8754225\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4862576 entropy 2.855509\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4278917 entropy 2.8283672\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3658175 entropy 2.8058093\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.30084 entropy 2.7945852\n",
      "kl 0.032296926\n",
      "completed in 0.29420995712280273 s\n",
      "prediction:\n",
      " [0.00028215 0.00390385 0.00133255 0.0014069  0.00321146 0.00035601\n",
      " 0.00370425 0.03593313 0.12245113 0.03664513 0.04098181 0.00437131\n",
      " 0.00145928 0.0076779  0.13113569 0.1109985  0.04688639 0.00197924\n",
      " 0.00134953 0.04942619 0.11295914 0.06352199 0.01015891 0.00100553\n",
      " 0.00226136 0.06126373 0.05617414 0.04988414 0.02191848 0.00402851\n",
      " 0.0003053  0.00488692 0.00169347 0.0007307  0.00332745 0.00038808] \n",
      " -0.25043494\n",
      "p [[1.25156446e-13 7.50938673e-03 1.25156446e-03 3.75469337e-03\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [2.50312891e-03 2.00250313e-02 9.01126408e-02 5.38172716e-02\n",
      "  1.75219024e-02 2.50312891e-03]\n",
      " [1.25156446e-03 8.01001252e-02 3.50438048e-02 3.62953692e-02\n",
      "  4.25531915e-02 1.25156446e-03]\n",
      " [1.25156446e-03 7.63454318e-02 5.75719650e-02 3.12891114e-02\n",
      "  2.30287860e-01 7.50938673e-03]\n",
      " [2.50312891e-03 7.50938673e-03 8.88610763e-02 5.25657071e-02\n",
      "  1.37672090e-02 8.76095119e-03]\n",
      " [1.25156446e-13 8.76095119e-03 1.25156446e-03 2.50312891e-03\n",
      "  6.25782228e-03 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.00168944 0.01348661 0.00523333 0.00287428 0.00874112 0.00081691\n",
      " 0.01324723 0.05278586 0.04147668 0.07173455 0.02224703 0.00525976\n",
      " 0.00596058 0.01367431 0.09617548 0.07927927 0.07629316 0.00489815\n",
      " 0.00527588 0.06635674 0.08606972 0.0572572  0.01325532 0.00540518\n",
      " 0.0079462  0.04267038 0.06906261 0.03787014 0.04649093 0.01408661\n",
      " 0.00067899 0.00637841 0.00292164 0.00494479 0.01602985 0.00142595] \n",
      " -0.4824372\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00250313 0.00125156 0.00125156]\n",
      " [0.00125156 0.01001252 0.05381727 0.0175219  0.03379224 0.00125156]\n",
      " [0.00250313 0.00375469 0.04255319 0.06257822 0.0175219  0.00125156]\n",
      " [0.00250313 0.02503129 0.07259074 0.03003755 0.         0.00250313]\n",
      " [0.00125156 0.0212766  0.03754693 0.52941176 0.01126408 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00063516 0.018786   0.00406783 0.00242171 0.0073749  0.00053242\n",
      " 0.00709474 0.06554999 0.00278875 0.03759135 0.10894067 0.00550437\n",
      " 0.00273986 0.03536049 0.06937917 0.09158359 0.0451926  0.00394656\n",
      " 0.00331565 0.04931873 0.08999343 0.04742122 0.02822047 0.00144311\n",
      " 0.00552082 0.11419484 0.07656227 0.0018407  0.03501496 0.00459519\n",
      " 0.00047672 0.01098463 0.00501864 0.00249618 0.01342422 0.00066827] \n",
      " -0.8496701\n",
      "p [[1.25156446e-13 7.50938673e-03 2.50312891e-03 2.50312891e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [6.25782228e-03 4.38047559e-02 4.04255319e-01 4.13016270e-02\n",
      "  1.87734668e-02 2.50312891e-03]\n",
      " [2.50312891e-03 7.50938673e-03 9.38673342e-02 4.38047559e-02\n",
      "  7.88485607e-02 2.50312891e-03]\n",
      " [2.50312891e-03 2.25281602e-02 4.25531915e-02 3.12891114e-02\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [2.50312891e-03 1.50187735e-02 5.88235294e-02 0.00000000e+00\n",
      "  2.37797247e-02 2.75344180e-02]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-03 2.50312891e-03\n",
      "  5.00625782e-03 1.25156446e-13]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00124672 0.02637793 0.00582644 0.00335249 0.00866283 0.00048083\n",
      " 0.03015301 0.01515336 0.00464675 0.07478298 0.02511506 0.00691808\n",
      " 0.00387661 0.01310393 0.11646779 0.1837484  0.04566091 0.00476182\n",
      " 0.00347471 0.03376453 0.12815572 0.04934946 0.0093922  0.00284297\n",
      " 0.01351317 0.03841431 0.04439343 0.00539773 0.01023807 0.02671194\n",
      " 0.00042668 0.00780642 0.00271703 0.0080589  0.04333258 0.00167439] \n",
      " -0.5255164\n",
      "p [[0.00125156 0.00625782 0.00250313 0.00375469 0.00876095 0.00125156]\n",
      " [0.00125156 0.15894869 0.         0.01376721 0.10763454 0.00250313]\n",
      " [0.00250313 0.08886108 0.04255319 0.08886108 0.02002503 0.00375469]\n",
      " [0.00250313 0.03379224 0.11889862 0.02503129 0.         0.00250313]\n",
      " [0.00125156 0.12140175 0.0350438  0.         0.08135169 0.00125156]\n",
      " [0.00125156 0.00500626 0.00876095 0.00250313 0.00375469 0.00125156]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00065642 0.02994972 0.005123   0.00943425 0.01126332 0.00497052\n",
      " 0.01340522 0.00835962 0.00167689 0.05568839 0.14022854 0.01774311\n",
      " 0.00359015 0.0438934  0.10836153 0.0341569  0.06258989 0.02103377\n",
      " 0.00819999 0.03719742 0.0178681  0.0451072  0.03870235 0.00196708\n",
      " 0.00566181 0.08657126 0.0864405  0.00198412 0.00396172 0.01254371\n",
      " 0.00248    0.01801894 0.0148511  0.00455062 0.03951992 0.00224969] \n",
      " -0.47206306\n",
      "p [[1.25156446e-13 2.00250313e-02 3.75469337e-03 1.25156446e-13\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [6.25782228e-03 0.00000000e+00 0.00000000e+00 2.25281602e-02\n",
      "  7.50938673e-03 2.50312891e-03]\n",
      " [1.25156446e-13 5.00625782e-03 2.87859825e-02 7.87234043e-01\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 2.62828536e-02 2.12765957e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [3.75469337e-03 6.25782228e-03 8.76095119e-03 0.00000000e+00\n",
      "  5.00625782e-03 8.76095119e-03]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 3.75469337e-03\n",
      "  1.00125156e-02 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.72422185e-04 6.48426190e-02 2.38553924e-03 7.59977056e-03\n",
      " 1.16787478e-02 2.56702467e-03 9.48432907e-02 3.07141221e-03\n",
      " 8.55133217e-03 1.37345223e-02 1.39483754e-02 6.55882573e-03\n",
      " 2.59467936e-03 1.84929632e-02 7.15608224e-02 1.98262166e-02\n",
      " 3.49302329e-02 5.90062141e-03 8.77671689e-03 1.97234564e-02\n",
      " 2.87513826e-02 1.64078977e-02 6.30404335e-03 2.53461488e-03\n",
      " 1.29042417e-02 1.23343449e-02 2.40614507e-02 4.08414751e-03\n",
      " 3.59710841e-03 1.75969139e-01 1.90300087e-03 1.07888095e-02\n",
      " 3.97220720e-03 7.86813349e-03 2.75782228e-01 8.77704239e-04] \n",
      " 0.43692002\n",
      "p [[0.00750939 0.02002503 0.00750939 0.01251564 0.01501877 0.00750939]\n",
      " [0.01126408 0.         0.         0.07133917 0.10888611 0.0212766 ]\n",
      " [0.00250313 0.06007509 0.10638298 0.         0.07133917 0.02252816]\n",
      " [0.01376721 0.04755945 0.03254068 0.06257822 0.         0.00750939]\n",
      " [0.00750939 0.09136421 0.06758448 0.         0.00876095 0.02252816]\n",
      " [0.00876095 0.02252816 0.0175219  0.01001252 0.02252816 0.01126408]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00187951 0.03782654 0.00614851 0.01142158 0.01247022 0.00994693\n",
      " 0.00864746 0.01020576 0.00401253 0.09146303 0.05232849 0.01907718\n",
      " 0.00693758 0.06382131 0.13385954 0.0722789  0.0496031  0.03056638\n",
      " 0.00881219 0.01396322 0.04630657 0.04013498 0.03134551 0.00478927\n",
      " 0.00588902 0.03914712 0.09700641 0.0041121  0.00592402 0.00329032\n",
      " 0.0053155  0.01918518 0.01320039 0.00442337 0.03145785 0.00320278] \n",
      " -0.7852129\n",
      "p [[1.25156446e-13 1.98998748e-01 1.25156446e-13 2.50312891e-03\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [2.25281602e-02 0.00000000e+00 0.00000000e+00 2.50312891e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.12640801e-02 0.00000000e+00\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-03 2.50312891e-03 6.25782228e-03 6.25782228e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [3.75469337e-03 1.25156446e-03 7.50938673e-03 0.00000000e+00\n",
      "  1.25156446e-13 5.40675845e-01]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-03\n",
      "  1.76470588e-01 1.25156446e-13]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0. -1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 199 completed in 27.190408945083618 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4154093 entropy 2.7862296\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3821468 entropy 2.7912936\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3384748 entropy 2.7911425\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2905293 entropy 2.783832\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.244976 entropy 2.771541\n",
      "kl 0.028392276\n",
      "completed in 0.3748490810394287 s\n",
      "game 200 completed in 8.277931928634644 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4948566 entropy 2.7670083\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.468708 entropy 2.7611027\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4192019 entropy 2.763317\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3629434 entropy 2.7709045\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3057294 entropy 2.7800317\n",
      "kl 0.022959752\n",
      "completed in 0.331341028213501 s\n",
      "game 201 completed in 11.045358896255493 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5786576 entropy 2.8076823\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5492463 entropy 2.818818\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4992764 entropy 2.8297772\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.4375596 entropy 2.8375158\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3744977 entropy 2.83889\n",
      "kl 0.02167555\n",
      "completed in 0.3273329734802246 s\n",
      "game 202 completed in 13.351391077041626 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.502132 entropy 2.8303688\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4751773 entropy 2.8185415\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4229176 entropy 2.8069518\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3611605 entropy 2.8033373\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.302993 entropy 2.8090281\n",
      "kl 0.02514391\n",
      "completed in 0.3237161636352539 s\n",
      "game 203 completed in 15.071417093276978 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4849524 entropy 2.8216972\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.458307 entropy 2.8348782\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.41563 entropy 2.8406672\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3645804 entropy 2.8351507\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3131452 entropy 2.8199763\n",
      "kl 0.024898238\n",
      "completed in 0.2845749855041504 s\n",
      "game 204 completed in 8.236642122268677 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.451586 entropy 2.8081963\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4025533 entropy 2.7846503\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3467155 entropy 2.7680745\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2897282 entropy 2.764512\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.230055 entropy 2.769319\n",
      "kl 0.03308876\n",
      "completed in 0.3481001853942871 s\n",
      "game 205 completed in 10.934778213500977 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.478621 entropy 2.7621293\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4479506 entropy 2.7732306\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3994744 entropy 2.7841377\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3464744 entropy 2.7883444\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2959695 entropy 2.7841918\n",
      "kl 0.027775697\n",
      "completed in 0.30410337448120117 s\n",
      "game 206 completed in 10.184384107589722 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4299479 entropy 2.7808852\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.398288 entropy 2.7785273\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.353849 entropy 2.7825196\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3045788 entropy 2.790361\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2576065 entropy 2.7962885\n",
      "kl 0.027798485\n",
      "completed in 0.2847771644592285 s\n",
      "game 207 completed in 7.468958139419556 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.441977 entropy 2.7774725\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4079068 entropy 2.7746959\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.352379 entropy 2.7695308\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2911584 entropy 2.7620938\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2356055 entropy 2.75378\n",
      "kl 0.031672645\n",
      "completed in 0.2911250591278076 s\n",
      "game 208 completed in 10.60005521774292 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.5501213 entropy 2.7706041\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.5130122 entropy 2.7700887\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4581742 entropy 2.7746723\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.403558 entropy 2.781436\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.3515363 entropy 2.7880616\n",
      "kl 0.029905502\n",
      "completed in 0.29047489166259766 s\n",
      "game 209 completed in 14.187347173690796 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.421175 entropy 2.8004947\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3997488 entropy 2.794006\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.360631 entropy 2.7845423\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3117378 entropy 2.7810125\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2577133 entropy 2.7872252\n",
      "kl 0.028575076\n",
      "completed in 0.28514814376831055 s\n",
      "game 210 completed in 12.15412712097168 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4711223 entropy 2.799734\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4473474 entropy 2.8225775\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.4069924 entropy 2.8404722\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3562121 entropy 2.8426354\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.303904 entropy 2.8274016\n",
      "kl 0.026859561\n",
      "completed in 0.29018402099609375 s\n",
      "game 211 completed in 10.41669774055481 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3773036 entropy 2.7784467\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3420508 entropy 2.756882\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.285169 entropy 2.7494564\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2246442 entropy 2.755368\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.172742 entropy 2.7659163\n",
      "kl 0.024412159\n",
      "completed in 0.3147110939025879 s\n",
      "game 212 completed in 6.640807867050171 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4545379 entropy 2.7698016\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.418898 entropy 2.7575314\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3612018 entropy 2.734952\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.3051422 entropy 2.7157662\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.252026 entropy 2.7097073\n",
      "kl 0.03991851\n",
      "completed in 0.27782177925109863 s\n",
      "game 213 completed in 8.278234958648682 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.429705 entropy 2.7388382\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.393746 entropy 2.7577474\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3537831 entropy 2.7774448\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.318628 entropy 2.7886643\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.279475 entropy 2.7899783\n",
      "kl 0.028360602\n",
      "completed in 0.3029959201812744 s\n",
      "game 214 completed in 6.5851898193359375 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4057062 entropy 2.7805882\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3737943 entropy 2.7684517\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3266504 entropy 2.7613673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.6666666666666666 loss 3.2688081 entropy 2.7629747\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2096279 entropy 2.7697086\n",
      "kl 0.031298272\n",
      "completed in 0.27762699127197266 s\n",
      "game 215 completed in 8.405232906341553 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.429261 entropy 2.7771425\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3942893 entropy 2.7776124\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3394122 entropy 2.7717018\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.274909 entropy 2.7625482\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2142217 entropy 2.7553666\n",
      "kl 0.02516229\n",
      "completed in 0.30814409255981445 s\n",
      "game 216 completed in 9.432042837142944 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3618662 entropy 2.7724261\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3344998 entropy 2.7940528\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2917736 entropy 2.8190172\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2432444 entropy 2.8265765\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1905541 entropy 2.8084826\n",
      "kl 0.026872553\n",
      "completed in 0.36720800399780273 s\n",
      "game 217 completed in 9.284447193145752 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3979716 entropy 2.800263\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3639884 entropy 2.7504973\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.320926 entropy 2.710812\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2689102 entropy 2.697761\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2123468 entropy 2.7060537\n",
      "kl 0.030668944\n",
      "completed in 0.330599308013916 s\n",
      "game 218 completed in 11.938033819198608 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3712344 entropy 2.6759276\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3394897 entropy 2.6933382\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2809906 entropy 2.7017279\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2114813 entropy 2.6968226\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.151882 entropy 2.6890771\n",
      "kl 0.038353957\n",
      "completed in 0.27988362312316895 s\n",
      "game 219 completed in 9.152585983276367 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3882031 entropy 2.6948955\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3552833 entropy 2.7013679\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.296272 entropy 2.7135766\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2399871 entropy 2.730125\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1966274 entropy 2.74715\n",
      "kl 0.023795849\n",
      "completed in 0.27231788635253906 s\n",
      "game 220 completed in 7.236207723617554 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.288687 entropy 2.7516747\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2644677 entropy 2.7637894\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2241797 entropy 2.7712054\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.180497 entropy 2.7704716\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1393182 entropy 2.760993\n",
      "kl 0.0257652\n",
      "completed in 0.2709779739379883 s\n",
      "game 221 completed in 7.327250242233276 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3803587 entropy 2.7611852\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3573987 entropy 2.7509413\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3168902 entropy 2.7501836\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2684734 entropy 2.7559903\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.219598 entropy 2.7622652\n",
      "kl 0.015950616\n",
      "completed in 0.33799123764038086 s\n",
      "game 222 completed in 17.14716601371765 s 19 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.307531 entropy 2.7522166\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2673385 entropy 2.7495615\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2211223 entropy 2.741916\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1802485 entropy 2.7343538\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1312113 entropy 2.727798\n",
      "kl 0.023856185\n",
      "completed in 0.34503912925720215 s\n",
      "game 223 completed in 9.087383031845093 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4065337 entropy 2.740299\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3435712 entropy 2.7295241\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2967925 entropy 2.717592\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2531314 entropy 2.7076013\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1889613 entropy 2.7052505\n",
      "kl 0.0182603\n",
      "completed in 0.31102681159973145 s\n",
      "game 224 completed in 9.36250901222229 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3956103 entropy 2.7147167\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3447185 entropy 2.7166395\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2968752 entropy 2.7101216\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2541883 entropy 2.6990304\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1988485 entropy 2.6878016\n",
      "kl 0.025277961\n",
      "completed in 0.35259485244750977 s\n",
      "game 225 completed in 9.630447149276733 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3984287 entropy 2.7144914\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3739932 entropy 2.7141173\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3336363 entropy 2.7173033\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2833657 entropy 2.7212687\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2288926 entropy 2.7224631\n",
      "kl 0.026410919\n",
      "completed in 0.3128979206085205 s\n",
      "game 226 completed in 10.210614919662476 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.4629805 entropy 2.7028065\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.4252322 entropy 2.7130857\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.362147 entropy 2.7308164\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2936778 entropy 2.7485528\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2300177 entropy 2.7609725\n",
      "kl 0.035803124\n",
      "completed in 0.3492567539215088 s\n",
      "game 227 completed in 8.584314107894897 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2997622 entropy 2.7642732\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2811632 entropy 2.7539\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2476122 entropy 2.7374868\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2056427 entropy 2.725113\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1584678 entropy 2.7224684\n",
      "kl 0.018096838\n",
      "completed in 0.2798647880554199 s\n",
      "game 228 completed in 8.968394994735718 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3869412 entropy 2.6994605\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3387191 entropy 2.7118063\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.278007 entropy 2.717313\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2212229 entropy 2.7086604\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.165543 entropy 2.689322\n",
      "kl 0.02938822\n",
      "completed in 0.33296990394592285 s\n",
      "game 229 completed in 10.088674068450928 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.400931 entropy 2.6819263\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3680809 entropy 2.6886935\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3083339 entropy 2.7109323\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2423396 entropy 2.7271876\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1801891 entropy 2.7259083\n",
      "kl 0.026343167\n",
      "completed in 0.268604040145874 s\n",
      "game 230 completed in 8.191815853118896 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.40332 entropy 2.706005\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3754237 entropy 2.6829357\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.3317392 entropy 2.6757193\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.2776065 entropy 2.6938896\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.2249253 entropy 2.7282617\n",
      "kl 0.023728892\n",
      "completed in 0.28949904441833496 s\n",
      "game 231 completed in 8.369073152542114 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.3562393 entropy 2.7890625\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.3306391 entropy 2.8045678\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.281068 entropy 2.8029025\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.221084 entropy 2.7902994\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.1602752 entropy 2.775701\n",
      "kl 0.019566482\n",
      "completed in 0.2837378978729248 s\n",
      "game 232 completed in 9.255675792694092 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2639554 entropy 2.7387931\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2308426 entropy 2.7407455\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1827257 entropy 2.7445478\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1356585 entropy 2.7391288\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0864272 entropy 2.7165468\n",
      "kl 0.041892756\n",
      "completed in 0.31148219108581543 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 233 completed in 14.97261095046997 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.3811355 entropy 2.718213\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.3640828 entropy 2.7011337\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.3269384 entropy 2.693827\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.2803304 entropy 2.6961808\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.2340512 entropy 2.7046027\n",
      "kl 0.017244823\n",
      "completed in 0.2846951484680176 s\n",
      "game 234 completed in 9.406855344772339 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.332026 entropy 2.7187397\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.3078125 entropy 2.7245271\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.273476 entropy 2.7247763\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.2341642 entropy 2.720995\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1945057 entropy 2.7145944\n",
      "kl 0.017199414\n",
      "completed in 0.30281710624694824 s\n",
      "game 235 completed in 8.358428955078125 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.362968 entropy 2.6950068\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.3353982 entropy 2.6913462\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.289885 entropy 2.6903706\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.241631 entropy 2.691878\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1961305 entropy 2.6939178\n",
      "kl 0.012850467\n",
      "completed in 0.3694789409637451 s\n",
      "game 236 completed in 9.202078342437744 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.360965 entropy 2.701883\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.336338 entropy 2.694317\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.295959 entropy 2.6812866\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.2534966 entropy 2.6686518\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.2139492 entropy 2.6620684\n",
      "kl 0.017098472\n",
      "completed in 0.2935469150543213 s\n",
      "game 237 completed in 8.34600305557251 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.217384 entropy 2.637578\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1949792 entropy 2.646564\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1609123 entropy 2.6578112\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.123544 entropy 2.6658077\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0880215 entropy 2.6673355\n",
      "kl 0.020135315\n",
      "completed in 0.28656625747680664 s\n",
      "game 238 completed in 12.921459913253784 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2909195 entropy 2.687289\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.268735 entropy 2.6790698\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.229983 entropy 2.670551\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.184749 entropy 2.664937\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1406717 entropy 2.6636627\n",
      "kl 0.011998391\n",
      "completed in 0.30508899688720703 s\n",
      "game 239 completed in 11.985023975372314 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.3482966 entropy 2.6915555\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.324853 entropy 2.702976\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.284277 entropy 2.7157674\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.2405748 entropy 2.7238019\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1970642 entropy 2.723548\n",
      "kl 0.014773194\n",
      "completed in 0.33894991874694824 s\n",
      "game 240 completed in 6.565207004547119 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.3233445 entropy 2.7027884\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.2954006 entropy 2.6912851\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.2559922 entropy 2.6804442\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.215915 entropy 2.676268\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1773276 entropy 2.6818082\n",
      "kl 0.011976674\n",
      "completed in 0.32441234588623047 s\n",
      "game 241 completed in 8.30669093132019 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.3438578 entropy 2.6948092\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.3204956 entropy 2.7107522\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.2808301 entropy 2.723052\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.2353642 entropy 2.7279925\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.190935 entropy 2.7250676\n",
      "kl 0.012723228\n",
      "completed in 0.29921603202819824 s\n",
      "game 242 completed in 14.45847487449646 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2757275 entropy 2.7436237\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.256549 entropy 2.7342212\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.2237978 entropy 2.726883\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1830444 entropy 2.721737\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.140405 entropy 2.7166736\n",
      "kl 0.012656841\n",
      "completed in 0.2703537940979004 s\n",
      "game 243 completed in 8.22158408164978 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2922823 entropy 2.7004986\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.265742 entropy 2.6870565\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.2204993 entropy 2.667885\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1720855 entropy 2.6495314\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1270936 entropy 2.6381311\n",
      "kl 0.016906947\n",
      "completed in 0.30355000495910645 s\n",
      "game 244 completed in 10.110166072845459 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1748788 entropy 2.5933797\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1528425 entropy 2.601949\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1195943 entropy 2.6161697\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0810103 entropy 2.6298788\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0445032 entropy 2.637226\n",
      "kl 0.01613947\n",
      "completed in 0.31560707092285156 s\n",
      "game 245 completed in 6.46507716178894 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.3156497 entropy 2.674871\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.2909791 entropy 2.66991\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.247844 entropy 2.6658814\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.2029312 entropy 2.665621\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1651762 entropy 2.6709266\n",
      "kl 0.014294979\n",
      "completed in 0.3075120449066162 s\n",
      "game 246 completed in 8.119132041931152 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.205718 entropy 2.673274\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1830838 entropy 2.680635\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1470141 entropy 2.6847277\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1055944 entropy 2.6848888\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0658793 entropy 2.680201\n",
      "kl 0.011204263\n",
      "completed in 0.28626298904418945 s\n",
      "game 247 completed in 9.902449131011963 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1880674 entropy 2.6544194\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1655865 entropy 2.643158\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.13258 entropy 2.632978\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.097796 entropy 2.626884\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0611966 entropy 2.6271906\n",
      "kl 0.014184777\n",
      "completed in 0.2742030620574951 s\n",
      "game 248 completed in 11.04291319847107 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2407885 entropy 2.6536355\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.2015607 entropy 2.6652172\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1502652 entropy 2.6761096\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1036913 entropy 2.6813426\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.062486 entropy 2.6772385\n",
      "kl 0.016527867\n",
      "completed in 0.2829768657684326 s\n",
      "prediction:\n",
      " [0.00028475 0.00288584 0.00187224 0.00163476 0.00335256 0.00065862\n",
      " 0.00276899 0.02146701 0.05412771 0.01029006 0.02633869 0.00289616\n",
      " 0.00170387 0.04299939 0.10042327 0.08966331 0.08742291 0.00098808\n",
      " 0.00130229 0.12898868 0.10222709 0.12386931 0.04897001 0.00122873\n",
      " 0.00281462 0.03213115 0.00845981 0.04687993 0.03843584 0.00373514\n",
      " 0.00040162 0.00306332 0.00161567 0.00090967 0.00302336 0.00016571] \n",
      " -0.37627327\n",
      "p [[1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 5.00625782e-03 4.50563204e-02 1.38923655e-01\n",
      "  3.75469337e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.06382979e-01 1.28911139e-01 4.63078849e-02\n",
      "  3.37922403e-02 1.25156446e-13]\n",
      " [1.25156446e-13 5.50688360e-02 5.50688360e-02 6.00750939e-02\n",
      "  7.25907384e-02 1.25156446e-13]\n",
      " [1.25156446e-03 3.75469337e-03 1.92740926e-01 4.00500626e-02\n",
      "  2.50312891e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]]\n",
      "move 26\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00059193 0.00394273 0.0016246  0.00422478 0.01603831 0.000905\n",
      " 0.00825699 0.01348106 0.06255358 0.01355516 0.04043624 0.01227196\n",
      " 0.00227353 0.09260082 0.08728167 0.06348974 0.07411592 0.00158073\n",
      " 0.00169115 0.05847909 0.07786875 0.08415283 0.08277591 0.00300291\n",
      " 0.00876257 0.04274169 0.01199691 0.0666776  0.03192552 0.00529121\n",
      " 0.00085585 0.01236108 0.00281583 0.00207748 0.00673533 0.00056379] \n",
      " 0.41505298\n",
      "p [[0.00125156 0.00125156 0.00375469 0.00375469 0.00125156 0.00125156]\n",
      " [0.00125156 0.02878598 0.0350438  0.00500626 0.00500626 0.00125156]\n",
      " [0.00375469 0.10638298 0.08135169 0.08010013 0.05006258 0.00250313]\n",
      " [0.00125156 0.18147685 0.05757196 0.10387985 0.02377972 0.10387985]\n",
      " [0.00125156 0.02002503 0.         0.02753442 0.0563204  0.00250313]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0007934  0.00442622 0.00393804 0.00647008 0.01156565 0.00095899\n",
      " 0.00509961 0.02688331 0.00967524 0.02465906 0.06841764 0.00912925\n",
      " 0.00220409 0.08269896 0.0980901  0.04996717 0.0104955  0.0029079\n",
      " 0.00196846 0.01924301 0.03438555 0.13791648 0.13908857 0.00291293\n",
      " 0.01175704 0.08531843 0.02423297 0.01016613 0.08423137 0.00960829\n",
      " 0.0006762  0.010578   0.0023852  0.00136416 0.00517179 0.0006153 ] \n",
      " -0.64553595\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 2.50312891e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-03 2.50312891e-03 1.12640801e-02 2.50312891e-03\n",
      "  5.00625782e-03 2.50312891e-03]\n",
      " [1.25156446e-13 5.25657071e-02 3.37922403e-02 1.75219024e-02\n",
      "  9.38673342e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 2.50312891e-02 2.00250313e-02\n",
      "  2.87859825e-02 1.25156446e-13]\n",
      " [3.75469337e-03 1.87734668e-02 0.00000000e+00 6.47058824e-01\n",
      "  2.25281602e-02 1.25156446e-03]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-13\n",
      "  2.50312891e-03 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00056323 0.00492276 0.00456599 0.00818192 0.02013595 0.00108405\n",
      " 0.023591   0.04905831 0.003453   0.0053595  0.00901518 0.01633674\n",
      " 0.00322692 0.1274284  0.03228464 0.08586414 0.01418799 0.00141032\n",
      " 0.00302888 0.01689077 0.06677232 0.06106418 0.08882617 0.00585191\n",
      " 0.03042867 0.02986038 0.01157806 0.00366274 0.22167318 0.01117468\n",
      " 0.00064693 0.01454431 0.00465521 0.00524286 0.01270354 0.00072523] \n",
      " -0.55573165\n",
      "p [[0.00250313 0.00375469 0.03128911 0.10262829 0.00500626 0.00250313]\n",
      " [0.00500626 0.02753442 0.00375469 0.06257822 0.03379224 0.00500626]\n",
      " [0.00500626 0.06758448 0.08635795 0.04881101 0.01877347 0.00500626]\n",
      " [0.00750939 0.         0.03629537 0.10888611 0.08760951 0.00625782]\n",
      " [0.00625782 0.12891114 0.         0.         0.07008761 0.00750939]\n",
      " [0.00375469 0.00500626 0.00625782 0.00250313 0.00250313 0.00375469]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00095257 0.01311549 0.00535774 0.00898995 0.11493643 0.00351418\n",
      " 0.01257681 0.01687505 0.00550103 0.01028074 0.00833647 0.01651225\n",
      " 0.00332195 0.04889103 0.03874739 0.05661996 0.00234897 0.00342489\n",
      " 0.00230414 0.00608505 0.04992834 0.10518946 0.19616982 0.0112401\n",
      " 0.02572224 0.01042518 0.01101643 0.00568641 0.09088815 0.0227151\n",
      " 0.00196424 0.06958638 0.00271095 0.00149652 0.015248   0.0013207 ] \n",
      " -0.8223297\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [2.50312891e-03 6.25782228e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 5.25657071e-02 7.50938673e-03 1.12640801e-02\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 6.13266583e-02 1.00125156e-02\n",
      "  1.62703379e-02 1.25156446e-13]\n",
      " [8.76095119e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.13516896e-01 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0008046  0.00864023 0.00667096 0.01216656 0.02787731 0.00044062\n",
      " 0.07305658 0.00159104 0.00206033 0.00914472 0.03760242 0.02382333\n",
      " 0.00129316 0.01072462 0.08377462 0.04695541 0.01516382 0.00143834\n",
      " 0.00364054 0.02469826 0.03133724 0.1001948  0.01542876 0.00312739\n",
      " 0.02375323 0.16654845 0.0504439  0.00413268 0.00714817 0.16785958\n",
      " 0.00109681 0.01497108 0.00741065 0.00130715 0.01154554 0.00212735] \n",
      " 0.58120483\n",
      "p [[0.00125156 0.00876095 0.00750939 0.01126408 0.09762203 0.00250313]\n",
      " [0.00750939 0.01627034 0.00375469 0.01627034 0.00625782 0.01001252]\n",
      " [0.00375469 0.06633292 0.03379224 0.05256571 0.00500626 0.00500626]\n",
      " [0.00375469 0.         0.077597   0.13266583 0.18272841 0.01001252]\n",
      " [0.02628285 0.         0.         0.         0.         0.10638298]\n",
      " [0.00250313 0.08886108 0.00250313 0.00125156 0.00876095 0.00125156]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0. -1.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00053748 0.02253249 0.00716496 0.01097664 0.14288324 0.00529042\n",
      " 0.00696579 0.01921165 0.01171501 0.00842137 0.01164829 0.01898755\n",
      " 0.00266879 0.007055   0.06358045 0.06894821 0.00195025 0.00475332\n",
      " 0.006158   0.00881774 0.03222369 0.25455132 0.03951131 0.02084387\n",
      " 0.02023909 0.0159795  0.00722524 0.01943338 0.03765044 0.02070368\n",
      " 0.00317194 0.07911156 0.00283076 0.00098565 0.01455925 0.00071272] \n",
      " -0.8567541\n",
      "p [[1.25156446e-13 3.75469337e-03 1.25156446e-13 6.25782228e-03\n",
      "  1.25156446e-02 1.25156446e-13]\n",
      " [3.75469337e-02 1.25156446e-13 1.25156446e-13 6.25782228e-03\n",
      "  1.12640801e-02 7.50938673e-03]\n",
      " [1.25156446e-13 1.00125156e-02 8.88610763e-02 2.37797247e-02\n",
      "  2.12765957e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.87734668e-02 1.15143930e-01\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [3.12891114e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.93241552e-01]\n",
      " [1.25156446e-13 7.50938673e-03 1.25156446e-13 1.25156446e-13\n",
      "  5.00625782e-03 1.25156446e-13]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0. -1.  0.]\n",
      " [ 0. -1.  1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 249 completed in 21.48858118057251 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2294621 entropy 2.652264\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.2062604 entropy 2.634617\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.173136 entropy 2.617511\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1374571 entropy 2.6065645\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.1001763 entropy 2.60418\n",
      "kl 0.010698257\n",
      "completed in 0.31723904609680176 s\n",
      "game 250 completed in 6.488465070724487 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.2118905 entropy 2.6233425\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1901739 entropy 2.6352758\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.156086 entropy 2.647758\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1158085 entropy 2.6559377\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0774388 entropy 2.6581578\n",
      "kl 0.018245637\n",
      "completed in 0.2972290515899658 s\n",
      "game 251 completed in 6.566555023193359 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.218917 entropy 2.6828763\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.195254 entropy 2.681842\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1556728 entropy 2.6825936\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.1113617 entropy 2.684434\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0695643 entropy 2.6859422\n",
      "kl 0.01838288\n",
      "completed in 0.31497907638549805 s\n",
      "game 252 completed in 12.048688173294067 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1908247 entropy 2.666525\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1716301 entropy 2.6688907\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1382525 entropy 2.671637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 3.10256 entropy 2.6734843\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0699105 entropy 2.6738486\n",
      "kl 0.009282004\n",
      "completed in 0.3315761089324951 s\n",
      "game 253 completed in 19.286153078079224 s 21 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.224401 entropy 2.6726618\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.19512 entropy 2.6621885\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1543655 entropy 2.6516995\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1048498 entropy 2.6515498\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.054365 entropy 2.661375\n",
      "kl 0.015595285\n",
      "completed in 0.28951311111450195 s\n",
      "game 254 completed in 14.722854137420654 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.190583 entropy 2.6690278\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1667626 entropy 2.6790137\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.124983 entropy 2.6780753\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0819545 entropy 2.6661339\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0383263 entropy 2.6470175\n",
      "kl 0.016232207\n",
      "completed in 0.28600502014160156 s\n",
      "game 255 completed in 13.755389928817749 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2563925 entropy 2.6631215\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2246282 entropy 2.6562402\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.171049 entropy 2.662663\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1156847 entropy 2.6763897\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0646138 entropy 2.6837041\n",
      "kl 0.020292867\n",
      "completed in 0.31504011154174805 s\n",
      "game 256 completed in 8.387859106063843 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.232692 entropy 2.6699855\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2051792 entropy 2.6522315\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1694257 entropy 2.6352715\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1319582 entropy 2.6266253\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0938544 entropy 2.625584\n",
      "kl 0.019721065\n",
      "completed in 0.2772059440612793 s\n",
      "game 257 completed in 7.524164915084839 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.25405 entropy 2.6191223\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.218119 entropy 2.612412\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1635022 entropy 2.6023471\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1110003 entropy 2.599824\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0640626 entropy 2.6117663\n",
      "kl 0.022326674\n",
      "completed in 0.30940961837768555 s\n",
      "game 258 completed in 7.475783109664917 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1987438 entropy 2.6290486\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1644611 entropy 2.6571016\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1151662 entropy 2.6757972\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0563943 entropy 2.6786394\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0007787 entropy 2.6662104\n",
      "kl 0.019935034\n",
      "completed in 0.24784612655639648 s\n",
      "game 259 completed in 14.670641899108887 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.217487 entropy 2.6480775\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1760082 entropy 2.6302047\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1359782 entropy 2.6208584\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.097646 entropy 2.6216638\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0503883 entropy 2.626224\n",
      "kl 0.027978193\n",
      "completed in 0.29453420639038086 s\n",
      "game 260 completed in 9.919025182723999 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2278535 entropy 2.6317205\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1759193 entropy 2.6356087\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1273446 entropy 2.632279\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.072834 entropy 2.6213593\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0106986 entropy 2.6087508\n",
      "kl 0.030438773\n",
      "completed in 0.2793588638305664 s\n",
      "game 261 completed in 7.340660095214844 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.320942 entropy 2.6184688\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.276166 entropy 2.6249776\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.2148836 entropy 2.638032\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1495893 entropy 2.6468291\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.09965 entropy 2.6487174\n",
      "kl 0.037375476\n",
      "completed in 0.3790602684020996 s\n",
      "game 262 completed in 12.436387062072754 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2360795 entropy 2.6424959\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.207512 entropy 2.6327412\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1573522 entropy 2.6254358\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0958643 entropy 2.6286902\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0358827 entropy 2.6439538\n",
      "kl 0.026137415\n",
      "completed in 0.3388180732727051 s\n",
      "game 263 completed in 14.358107805252075 s 16 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.22143 entropy 2.6763997\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1847901 entropy 2.6900191\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1347709 entropy 2.6925535\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0915082 entropy 2.6839328\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0501332 entropy 2.6683757\n",
      "kl 0.026040817\n",
      "completed in 0.3266019821166992 s\n",
      "game 264 completed in 9.938225984573364 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2704375 entropy 2.653895\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.226136 entropy 2.6427882\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1570954 entropy 2.6385167\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.096849 entropy 2.637361\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0466003 entropy 2.63479\n",
      "kl 0.02633743\n",
      "completed in 0.26994895935058594 s\n",
      "game 265 completed in 7.345933675765991 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2415452 entropy 2.6298165\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.203218 entropy 2.6211226\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1446445 entropy 2.6121213\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.089384 entropy 2.6063914\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.043745 entropy 2.6056585\n",
      "kl 0.02707275\n",
      "completed in 0.33777904510498047 s\n",
      "game 266 completed in 8.822302103042603 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1969292 entropy 2.5702927\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.171737 entropy 2.5737529\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1264834 entropy 2.576745\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0726585 entropy 2.5806212\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0201113 entropy 2.5838978\n",
      "kl 0.025236221\n",
      "completed in 0.29993605613708496 s\n",
      "game 267 completed in 9.181169033050537 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1734548 entropy 2.5837574\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1356323 entropy 2.6002283\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0951045 entropy 2.6155145\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0548658 entropy 2.6180353\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0115073 entropy 2.6051087\n",
      "kl 0.027327243\n",
      "completed in 0.3220100402832031 s\n",
      "game 268 completed in 6.354100227355957 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.255986 entropy 2.6141257\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2083569 entropy 2.5927794\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.141655 entropy 2.5821753\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0810046 entropy 2.5923204\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.030962 entropy 2.6129465\n",
      "kl 0.019271351\n",
      "completed in 0.3174920082092285 s\n",
      "game 269 completed in 12.732879877090454 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1412272 entropy 2.6155539\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1113827 entropy 2.6153646\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0632305 entropy 2.6024694\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0129704 entropy 2.588614\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9679503 entropy 2.584573\n",
      "kl 0.02404552\n",
      "completed in 0.2733922004699707 s\n",
      "game 270 completed in 6.481870889663696 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.240206 entropy 2.612135\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.205198 entropy 2.6195807\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1432629 entropy 2.6199584\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0744398 entropy 2.6094415\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.015845 entropy 2.5912437\n",
      "kl 0.020415617\n",
      "completed in 0.27949070930480957 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 271 completed in 6.572465896606445 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.188706 entropy 2.5599248\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1494443 entropy 2.5548124\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0934021 entropy 2.5609226\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0446029 entropy 2.570363\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.003855 entropy 2.5752096\n",
      "kl 0.02284014\n",
      "completed in 0.3030421733856201 s\n",
      "game 272 completed in 11.120978116989136 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1903934 entropy 2.5666924\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1616688 entropy 2.5567474\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1136904 entropy 2.5543423\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0617514 entropy 2.5654974\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0136318 entropy 2.586688\n",
      "kl 0.034572646\n",
      "completed in 0.34215211868286133 s\n",
      "game 273 completed in 10.692086935043335 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1843653 entropy 2.6154888\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1467772 entropy 2.6341152\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0809178 entropy 2.6428468\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0125082 entropy 2.6406379\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.956556 entropy 2.63295\n",
      "kl 0.028628243\n",
      "completed in 0.27269983291625977 s\n",
      "game 274 completed in 16.618337869644165 s 18 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1829908 entropy 2.6136868\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1552196 entropy 2.6031322\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1160944 entropy 2.5950632\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.066296 entropy 2.5905943\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.01245 entropy 2.5886774\n",
      "kl 0.02323005\n",
      "completed in 0.2857069969177246 s\n",
      "game 275 completed in 9.203114986419678 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2212563 entropy 2.6307683\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.18521 entropy 2.628222\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1366272 entropy 2.620622\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0867763 entropy 2.6118321\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0383534 entropy 2.607758\n",
      "kl 0.020311143\n",
      "completed in 0.29555702209472656 s\n",
      "game 276 completed in 7.572354078292847 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1462846 entropy 2.570713\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1210225 entropy 2.5656319\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.079044 entropy 2.557118\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0336056 entropy 2.5496986\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9900959 entropy 2.546796\n",
      "kl 0.021917745\n",
      "completed in 0.32817888259887695 s\n",
      "game 277 completed in 8.635282754898071 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1419082 entropy 2.5239277\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1098847 entropy 2.5285182\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0608535 entropy 2.5320904\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.011343 entropy 2.531235\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9709692 entropy 2.5256853\n",
      "kl 0.01845121\n",
      "completed in 0.357943058013916 s\n",
      "game 278 completed in 8.480569839477539 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1463494 entropy 2.5476542\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1174128 entropy 2.5371404\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0719724 entropy 2.531835\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0214849 entropy 2.5356464\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9791203 entropy 2.5458424\n",
      "kl 0.020159854\n",
      "completed in 0.2776811122894287 s\n",
      "game 279 completed in 10.431705236434937 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2380402 entropy 2.5826886\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2054174 entropy 2.592037\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1515222 entropy 2.5942726\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0951402 entropy 2.589703\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0472267 entropy 2.5820818\n",
      "kl 0.022880856\n",
      "completed in 0.3708629608154297 s\n",
      "game 280 completed in 10.427767992019653 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2317169 entropy 2.5577073\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.191865 entropy 2.5657275\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1341276 entropy 2.5809042\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0852156 entropy 2.5952587\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0451338 entropy 2.601882\n",
      "kl 0.021061113\n",
      "completed in 0.2734391689300537 s\n",
      "game 281 completed in 8.355087995529175 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2810912 entropy 2.6037488\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2102945 entropy 2.6022286\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1440752 entropy 2.6010103\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0873759 entropy 2.6001992\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0371273 entropy 2.598344\n",
      "kl 0.02377782\n",
      "completed in 0.3403751850128174 s\n",
      "game 282 completed in 10.066901922225952 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2444663 entropy 2.6104646\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2140064 entropy 2.6005561\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.175721 entropy 2.5872152\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1309352 entropy 2.5773702\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0820847 entropy 2.5727596\n",
      "kl 0.022609752\n",
      "completed in 0.31432294845581055 s\n",
      "game 283 completed in 6.554720163345337 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1845927 entropy 2.58325\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1607363 entropy 2.5925074\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1169443 entropy 2.6032329\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0627885 entropy 2.6082363\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0130448 entropy 2.6054554\n",
      "kl 0.022605298\n",
      "completed in 0.28401684761047363 s\n",
      "game 284 completed in 8.380671977996826 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2697833 entropy 2.5928736\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.2412055 entropy 2.5850654\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1950321 entropy 2.5775244\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.1432648 entropy 2.571305\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0936632 entropy 2.5644336\n",
      "kl 0.031063093\n",
      "completed in 0.2980809211730957 s\n",
      "game 285 completed in 6.565078973770142 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1542654 entropy 2.584308\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1230543 entropy 2.570788\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0731804 entropy 2.5550504\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0159194 entropy 2.5430617\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9610925 entropy 2.5381737\n",
      "kl 0.024972681\n",
      "completed in 0.31278181076049805 s\n",
      "game 286 completed in 12.651419162750244 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2154045 entropy 2.5096347\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.183279 entropy 2.5158973\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1325152 entropy 2.521719\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.080418 entropy 2.5244188\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0346105 entropy 2.5248854\n",
      "kl 0.027695512\n",
      "completed in 0.35079193115234375 s\n",
      "game 287 completed in 6.343210935592651 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1454644 entropy 2.5101383\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1196907 entropy 2.5167413\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0805001 entropy 2.5249646\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0373473 entropy 2.5289147\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9892576 entropy 2.5250914\n",
      "kl 0.015682757\n",
      "completed in 0.280210018157959 s\n",
      "game 288 completed in 11.857290029525757 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.099851 entropy 2.5597398\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0642946 entropy 2.5470884\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.018025 entropy 2.5409145\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9707394 entropy 2.5456648\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9264002 entropy 2.5578365\n",
      "kl 0.029646799\n",
      "completed in 0.30225205421447754 s\n",
      "game 289 completed in 8.341749906539917 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.1403244 entropy 2.5433936\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1107526 entropy 2.542461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.6666666666666666 loss 3.0597584 entropy 2.532612\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.011808 entropy 2.5201056\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.969052 entropy 2.512454\n",
      "kl 0.020643812\n",
      "completed in 0.32325291633605957 s\n",
      "game 290 completed in 7.2246458530426025 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.2213705 entropy 2.545236\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.1821232 entropy 2.5621605\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.1238086 entropy 2.5809884\n",
      "training 3 lr_mult 0.6666666666666666 loss 3.0704877 entropy 2.5911913\n",
      "training 4 lr_mult 0.6666666666666666 loss 3.0194185 entropy 2.5886805\n",
      "kl 0.034671254\n",
      "completed in 0.312028169631958 s\n",
      "game 291 completed in 12.95711064338684 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.104727 entropy 2.5651278\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0826511 entropy 2.5557833\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0423548 entropy 2.5544662\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.995986 entropy 2.562017\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9574008 entropy 2.572552\n",
      "kl 0.027406901\n",
      "completed in 0.3509039878845215 s\n",
      "game 292 completed in 6.3966591358184814 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0513785 entropy 2.5854201\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0250664 entropy 2.572425\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9866126 entropy 2.5509744\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.944256 entropy 2.5314853\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9061353 entropy 2.519947\n",
      "kl 0.0441401\n",
      "completed in 0.32836198806762695 s\n",
      "game 293 completed in 8.359290838241577 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.160762 entropy 2.4997478\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1354423 entropy 2.5063717\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1000566 entropy 2.5167773\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0654294 entropy 2.5273938\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0323257 entropy 2.535879\n",
      "kl 0.014635851\n",
      "completed in 0.28297901153564453 s\n",
      "game 294 completed in 6.637387990951538 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.152927 entropy 2.5467343\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.1215928 entropy 2.5406284\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.07639 entropy 2.5285888\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0355608 entropy 2.51677\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0027049 entropy 2.5109568\n",
      "kl 0.023250977\n",
      "completed in 0.31455183029174805 s\n",
      "game 295 completed in 6.534265756607056 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0702317 entropy 2.5189939\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0465121 entropy 2.5281565\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0175176 entropy 2.538559\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9894724 entropy 2.5453305\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.961626 entropy 2.546052\n",
      "kl 0.015618327\n",
      "completed in 0.33864712715148926 s\n",
      "game 296 completed in 8.363433837890625 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1733723 entropy 2.5552156\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.153601 entropy 2.5487542\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.1210291 entropy 2.543117\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0798507 entropy 2.5412793\n",
      "training 4 lr_mult 0.4444444444444444 loss 3.0346785 entropy 2.5428994\n",
      "kl 0.017435782\n",
      "completed in 0.275007963180542 s\n",
      "game 297 completed in 8.201879978179932 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0803213 entropy 2.5277402\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.051352 entropy 2.526671\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0147872 entropy 2.5208364\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9863985 entropy 2.5123892\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9563441 entropy 2.5032983\n",
      "kl 0.015199039\n",
      "completed in 0.31250596046447754 s\n",
      "game 298 completed in 6.540421009063721 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0240016 entropy 2.5157137\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.001021 entropy 2.5141354\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9684646 entropy 2.517006\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9370635 entropy 2.5209343\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9102151 entropy 2.5228665\n",
      "kl 0.01606566\n",
      "completed in 0.27673888206481934 s\n",
      "prediction:\n",
      " [0.00175695 0.00331345 0.00396121 0.00230429 0.00454797 0.00074468\n",
      " 0.00337868 0.01952116 0.12757139 0.05121579 0.01497101 0.00462885\n",
      " 0.00425688 0.08503283 0.04250925 0.09966957 0.04628021 0.00317686\n",
      " 0.00265593 0.03813648 0.0803488  0.05093717 0.11410131 0.00365738\n",
      " 0.00437369 0.00863058 0.03440436 0.09257021 0.03176942 0.00421006\n",
      " 0.00075648 0.00426433 0.0025698  0.00355481 0.00275463 0.00146362] \n",
      " -0.07744894\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 2.87859825e-02 3.62953692e-02\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 2.25281602e-02 5.63204005e-02 5.38172716e-02\n",
      "  3.12891114e-02 1.25156446e-13]\n",
      " [1.25156446e-13 3.50438048e-02 2.85356696e-01 2.90362954e-01\n",
      "  7.63454318e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 3.25406758e-02 4.50563204e-02\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [0.0013926  0.0067733  0.00144555 0.00234191 0.00420968 0.00032207\n",
      " 0.004019   0.0236864  0.04871108 0.06826843 0.0070009  0.00723279\n",
      " 0.00360506 0.08542774 0.04571293 0.11052846 0.07953265 0.00306473\n",
      " 0.00212224 0.05445584 0.1421376  0.04260207 0.04972751 0.00182148\n",
      " 0.00563423 0.00570671 0.08295175 0.05102489 0.03575542 0.00447709\n",
      " 0.00055524 0.00398689 0.00219652 0.00275983 0.00709401 0.0017154 ] \n",
      " 0.15716434\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00500626 0.17396746 0.02252816 0.00500626 0.00125156]\n",
      " [0.00125156 0.077597   0.26282854 0.07008761 0.0175219  0.00250313]\n",
      " [0.00125156 0.01376721 0.14392991 0.         0.08385482 0.00250313]\n",
      " [0.00125156 0.00250313 0.01251564 0.05757196 0.0212766  0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00483111 0.00407066 0.00370231 0.0041351  0.00601307 0.0012578\n",
      " 0.00426617 0.02899224 0.12050132 0.16546364 0.01326237 0.00509542\n",
      " 0.00514199 0.06059739 0.00729704 0.02926321 0.04142037 0.00441352\n",
      " 0.00476907 0.05292139 0.03020992 0.00833887 0.08188652 0.00503566\n",
      " 0.00543883 0.01146093 0.09704217 0.11172367 0.04863097 0.00608888\n",
      " 0.00103137 0.00583908 0.0065019  0.00488926 0.00432898 0.00413794] \n",
      " -0.89468956\n",
      "p [[1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.50187735e-02 1.75219024e-02\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 2.37797247e-02 0.00000000e+00 4.31789737e-01\n",
      "  2.95369212e-01 1.25156446e-13]\n",
      " [1.25156446e-13 8.76095119e-03 5.75719650e-02 0.00000000e+00\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [2.50312891e-03 2.50312891e-03 1.08886108e-01 1.00125156e-02\n",
      "  3.75469337e-03 2.50312891e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  2.50312891e-03 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00334035 0.00435077 0.00251551 0.00610382 0.00613642 0.0008024\n",
      " 0.00248791 0.01879363 0.18783294 0.14889908 0.01131536 0.00668208\n",
      " 0.0030401  0.02450493 0.00524897 0.00669052 0.01982832 0.00173955\n",
      " 0.00175742 0.02204871 0.00655511 0.00652714 0.01983449 0.00233336\n",
      " 0.00660944 0.01000501 0.07647566 0.3269493  0.02752118 0.00563158\n",
      " 0.00122825 0.00541188 0.00619687 0.00760538 0.00573401 0.00126265] \n",
      " -0.9616358\n",
      "p [[0.00125156 0.00125156 0.00876095 0.01001252 0.00375469 0.00125156]\n",
      " [0.00250313 0.01126408 0.11639549 0.11889862 0.00375469 0.00500626]\n",
      " [0.00375469 0.04255319 0.         0.         0.04630788 0.00625782]\n",
      " [0.03003755 0.09261577 0.13141427 0.         0.04755945 0.00250313]\n",
      " [0.00250313 0.01251564 0.06883605 0.06257822 0.02377972 0.03629537]\n",
      " [0.00125156 0.00125156 0.09136421 0.01001252 0.00125156 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.01173904 0.00755928 0.03267944 0.01004538 0.00469016 0.0048984\n",
      " 0.00871112 0.0097214  0.03833952 0.35555324 0.01558099 0.00354991\n",
      " 0.00329809 0.02689761 0.00584402 0.00214134 0.02816268 0.00729666\n",
      " 0.00292067 0.03780636 0.00323558 0.00468816 0.02818508 0.00581669\n",
      " 0.01056017 0.01812175 0.21056448 0.01892925 0.01267787 0.01148121\n",
      " 0.00525931 0.00202252 0.02092758 0.01035063 0.00947593 0.01026864] \n",
      " 0.30034667\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 2.25281602e-02 3.25406758e-02\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 3.75469337e-03 0.00000000e+00 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.12640801e-02 9.14893617e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.0178296e-02 1.1465559e-02 6.0324453e-02 6.0994369e-03 8.8893073e-03\n",
      " 1.3390873e-04 7.5827898e-03 7.5189851e-02 4.8944307e-03 6.9121808e-02\n",
      " 6.1041680e-03 1.6842563e-02 3.4559204e-03 2.2720868e-02 8.4771095e-03\n",
      " 3.7493096e-03 1.2552643e-01 3.3775098e-03 2.4322141e-03 5.0507456e-02\n",
      " 4.7057588e-03 1.0734779e-02 4.3149106e-02 1.4703933e-03 9.2982957e-03\n",
      " 1.5266599e-02 7.2627716e-02 8.4361043e-03 3.5426866e-02 1.4156549e-02\n",
      " 6.7241676e-04 4.4782986e-03 1.0916000e-02 2.3823638e-01 1.9995436e-02\n",
      " 3.3560488e-03] \n",
      " 0.16140877\n",
      "p [[0.00750939 0.00500626 0.06132666 0.01501877 0.00375469 0.00375469]\n",
      " [0.00625782 0.00625782 0.077597   0.40425532 0.01001252 0.00250313]\n",
      " [0.00375469 0.02878598 0.         0.         0.02002503 0.01126408]\n",
      " [0.00250313 0.02753442 0.         0.         0.0175219  0.00750939]\n",
      " [0.01001252 0.01251564 0.15894869 0.         0.01251564 0.0212766 ]\n",
      " [0.00250313 0.00250313 0.03128911 0.01251564 0.00625782 0.00750939]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.04706277 0.0038004  0.0409555  0.00703209 0.02556076 0.00260811\n",
      " 0.00602656 0.02672425 0.06401581 0.01583472 0.04358584 0.00664204\n",
      " 0.00331279 0.03765214 0.00725738 0.00154149 0.22536623 0.00907238\n",
      " 0.00574447 0.17062615 0.00210162 0.00419518 0.01933109 0.00696141\n",
      " 0.05123912 0.03149132 0.00857958 0.01385117 0.02620475 0.00390949\n",
      " 0.00128338 0.02275672 0.01987066 0.01020312 0.00505832 0.02254146] \n",
      " 0.41224453\n",
      "p [[1.25156446e-03 1.25156446e-03 1.00125156e-02 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 1.50187735e-02 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  2.00250313e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.00125156e-02 0.00000000e+00 0.00000000e+00\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-03 1.25156446e-03 5.25657071e-02 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 8.71088861e-01\n",
      "  1.25156446e-03 1.25156446e-13]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]]\n",
      "1 won\n",
      "game 299 completed in 25.747307062149048 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0423403 entropy 2.4786184\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0190187 entropy 2.4727068\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9746413 entropy 2.4635458\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9239295 entropy 2.4553597\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8829682 entropy 2.4519958\n",
      "kl 0.030721579\n",
      "completed in 0.2866518497467041 s\n",
      "training pipeline completed in 3840.0620419979095 s\n"
     ]
    }
   ],
   "source": [
    "model = Train()\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44974b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 9.026176929473877 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.094229 entropy 2.4553971\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0804331 entropy 2.461153\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0460992 entropy 2.468775\n",
      "training 3 lr_mult 0.4444444444444444 loss 3.0024881 entropy 2.4735408\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.96221 entropy 2.4722147\n",
      "kl 0.019545441\n",
      "completed in 0.29179811477661133 s\n",
      "game 1 completed in 6.601289987564087 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0083284 entropy 2.4812946\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9982338 entropy 2.472268\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9779449 entropy 2.4659348\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9491947 entropy 2.4639454\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9149377 entropy 2.4665737\n",
      "kl 0.012923163\n",
      "completed in 0.30759406089782715 s\n",
      "game 2 completed in 12.0640230178833 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.067191 entropy 2.4629478\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.03498 entropy 2.468132\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.994029 entropy 2.4703355\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.956487 entropy 2.4684658\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9220886 entropy 2.4633632\n",
      "kl 0.012412042\n",
      "completed in 0.2992208003997803 s\n",
      "game 3 completed in 8.978596925735474 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0214372 entropy 2.4577196\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0038924 entropy 2.4496126\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9760015 entropy 2.4430614\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9416187 entropy 2.4414062\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9123392 entropy 2.4457235\n",
      "kl 0.016280761\n",
      "completed in 0.349031925201416 s\n",
      "game 4 completed in 12.826491832733154 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9987388 entropy 2.483346\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.984785 entropy 2.4974065\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9581566 entropy 2.5097804\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.927876 entropy 2.516636\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8980815 entropy 2.5157568\n",
      "kl 0.012737266\n",
      "completed in 0.3085298538208008 s\n",
      "game 5 completed in 12.911685943603516 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0049193 entropy 2.5059338\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.98794 entropy 2.4939833\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9589467 entropy 2.4826417\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9265754 entropy 2.4757042\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8926933 entropy 2.4733706\n",
      "kl 0.011951264\n",
      "completed in 0.267225980758667 s\n",
      "game 6 completed in 6.582551002502441 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1099577 entropy 2.4832196\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0811524 entropy 2.4857602\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.034818 entropy 2.487562\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9844632 entropy 2.484807\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9422824 entropy 2.4785848\n",
      "kl 0.019070242\n",
      "completed in 0.3283562660217285 s\n",
      "game 7 completed in 6.6313769817352295 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.1036074 entropy 2.4951391\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0819364 entropy 2.4930267\n",
      "training 2 lr_mult 0.4444444444444444 loss 3.0424085 entropy 2.4969215\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.999482 entropy 2.5061996\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.9599745 entropy 2.5184178\n",
      "kl 0.012087094\n",
      "completed in 0.2744629383087158 s\n",
      "game 8 completed in 9.26862382888794 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 3.0175326 entropy 2.5061765\n",
      "training 1 lr_mult 0.4444444444444444 loss 3.0008497 entropy 2.5080833\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9719505 entropy 2.501396\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.9401815 entropy 2.4923887\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.909262 entropy 2.4871044\n",
      "kl 0.022405326\n",
      "completed in 0.277972936630249 s\n",
      "game 9 completed in 8.371675968170166 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9828417 entropy 2.4802146\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9626157 entropy 2.4866467\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9315073 entropy 2.4956632\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8973224 entropy 2.502625\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8629391 entropy 2.5040336\n",
      "kl 0.015161623\n",
      "completed in 0.3512918949127197 s\n",
      "game 10 completed in 11.006102085113525 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.997509 entropy 2.5043616\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9666886 entropy 2.4941015\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9220698 entropy 2.4849107\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8826723 entropy 2.481243\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8510149 entropy 2.4849596\n",
      "kl 0.018457893\n",
      "completed in 0.37451601028442383 s\n",
      "game 11 completed in 8.266420841217041 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.967875 entropy 2.4959326\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.946161 entropy 2.5049846\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.914363 entropy 2.5100336\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.883521 entropy 2.5076582\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.852969 entropy 2.4979353\n",
      "kl 0.009614976\n",
      "completed in 0.283099889755249 s\n",
      "game 12 completed in 10.189265012741089 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0172627 entropy 2.4877024\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9967706 entropy 2.4727983\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9621992 entropy 2.4655616\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9199 entropy 2.467927\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8820183 entropy 2.4757106\n",
      "kl 0.023187991\n",
      "completed in 0.28355884552001953 s\n",
      "game 13 completed in 10.27906084060669 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0082405 entropy 2.4848309\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9743612 entropy 2.48106\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9228485 entropy 2.4666448\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.876468 entropy 2.4478507\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8440745 entropy 2.4329684\n",
      "kl 0.025976224\n",
      "completed in 0.29847216606140137 s\n",
      "game 14 completed in 6.666940212249756 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0555356 entropy 2.4539769\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0229657 entropy 2.4699998\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9782372 entropy 2.4936688\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9380078 entropy 2.5093632\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9008636 entropy 2.5110285\n",
      "kl 0.031327073\n",
      "completed in 0.30875205993652344 s\n",
      "game 15 completed in 6.667909145355225 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0819833 entropy 2.4863687\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0405836 entropy 2.4804125\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9843926 entropy 2.4829779\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9304366 entropy 2.4967923\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8870692 entropy 2.5149202\n",
      "kl 0.023522364\n",
      "completed in 0.31111907958984375 s\n",
      "game 16 completed in 6.588065147399902 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.011324 entropy 2.5301719\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9856637 entropy 2.53213\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9387162 entropy 2.5244002\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8913255 entropy 2.5079062\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8505242 entropy 2.4867375\n",
      "kl 0.027030064\n",
      "completed in 0.31258296966552734 s\n",
      "game 17 completed in 7.686126708984375 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0942895 entropy 2.4652731\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.055691 entropy 2.4502313\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9956954 entropy 2.4405947\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9321327 entropy 2.4347405\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8804884 entropy 2.4298997\n",
      "kl 0.021807823\n",
      "completed in 0.3154120445251465 s\n",
      "game 18 completed in 6.737205982208252 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.975702 entropy 2.422485\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9497206 entropy 2.4150572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.6666666666666666 loss 2.904401 entropy 2.4090385\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8553898 entropy 2.4068408\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8143163 entropy 2.4099774\n",
      "kl 0.025351774\n",
      "completed in 0.32304883003234863 s\n",
      "game 19 completed in 13.030799150466919 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9384475 entropy 2.4159372\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9071538 entropy 2.4348125\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.866565 entropy 2.4546928\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8321247 entropy 2.4684856\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8054445 entropy 2.4753957\n",
      "kl 0.023606826\n",
      "completed in 0.32593798637390137 s\n",
      "game 20 completed in 8.218488693237305 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.077183 entropy 2.5422583\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.052214 entropy 2.5400295\n",
      "training 2 lr_mult 0.6666666666666666 loss 3.0107024 entropy 2.537404\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9625638 entropy 2.5348396\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9208207 entropy 2.5312572\n",
      "kl 0.022392415\n",
      "completed in 0.3465092182159424 s\n",
      "game 21 completed in 12.877222061157227 s 14 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9501188 entropy 2.463851\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9217148 entropy 2.451572\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.884801 entropy 2.4392037\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8493688 entropy 2.4316\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8112152 entropy 2.4306464\n",
      "kl 0.020656392\n",
      "completed in 0.3330039978027344 s\n",
      "game 22 completed in 10.2672119140625 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9938953 entropy 2.4365993\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9696527 entropy 2.450123\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9299457 entropy 2.46582\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.891338 entropy 2.476642\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.855572 entropy 2.4794545\n",
      "kl 0.020030625\n",
      "completed in 0.3780050277709961 s\n",
      "game 23 completed in 10.267374992370605 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9110646 entropy 2.4763587\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8890371 entropy 2.464771\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8554933 entropy 2.4501176\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.81738 entropy 2.4380136\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7817547 entropy 2.4297762\n",
      "kl 0.01857585\n",
      "completed in 0.27850794792175293 s\n",
      "game 24 completed in 7.584902763366699 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.93068 entropy 2.4070716\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9063883 entropy 2.3980725\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8664534 entropy 2.3833864\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.83365 entropy 2.3656552\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8075297 entropy 2.3499353\n",
      "kl 0.030516954\n",
      "completed in 0.3066880702972412 s\n",
      "game 25 completed in 8.602948904037476 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.034699 entropy 2.3999195\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9968557 entropy 2.4028358\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9480636 entropy 2.4133384\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9070842 entropy 2.4234233\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8622859 entropy 2.426302\n",
      "kl 0.02259586\n",
      "completed in 0.28957486152648926 s\n",
      "game 26 completed in 7.658271074295044 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9869845 entropy 2.391716\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.962679 entropy 2.3825884\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9223027 entropy 2.3824806\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8799882 entropy 2.3977494\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8370233 entropy 2.4250188\n",
      "kl 0.025315776\n",
      "completed in 0.30861687660217285 s\n",
      "game 27 completed in 21.021785974502563 s 23 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0658352 entropy 2.485171\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0334167 entropy 2.4997406\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9787142 entropy 2.4979243\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.9292457 entropy 2.4852676\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8946102 entropy 2.473594\n",
      "kl 0.024488347\n",
      "completed in 0.36695075035095215 s\n",
      "game 28 completed in 7.061348915100098 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.004627 entropy 2.4340236\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9732594 entropy 2.4327934\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.926032 entropy 2.4298453\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8819444 entropy 2.4245477\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8474946 entropy 2.4161308\n",
      "kl 0.02423155\n",
      "completed in 0.3394010066986084 s\n",
      "game 29 completed in 10.641248941421509 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9977672 entropy 2.4460826\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9654891 entropy 2.4374454\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9152145 entropy 2.4310248\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8736 entropy 2.4273663\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8397229 entropy 2.4272923\n",
      "kl 0.02341234\n",
      "completed in 0.2863349914550781 s\n",
      "game 30 completed in 13.09598994255066 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0592341 entropy 2.4242067\n",
      "training 1 lr_mult 0.6666666666666666 loss 3.0320818 entropy 2.42953\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9964378 entropy 2.435358\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.954687 entropy 2.44177\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.9105942 entropy 2.446556\n",
      "kl 0.026115313\n",
      "completed in 0.3013570308685303 s\n",
      "game 31 completed in 9.816894054412842 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9085827 entropy 2.3818636\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8793316 entropy 2.3844347\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8309312 entropy 2.3851874\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.782961 entropy 2.3800218\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7417207 entropy 2.3682637\n",
      "kl 0.035291053\n",
      "completed in 0.2833888530731201 s\n",
      "game 32 completed in 11.49998688697815 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0028484 entropy 2.397222\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9740362 entropy 2.3850062\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9282625 entropy 2.3820071\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8785522 entropy 2.3931894\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8339543 entropy 2.4130704\n",
      "kl 0.028363228\n",
      "completed in 0.2824831008911133 s\n",
      "game 33 completed in 11.68860912322998 s 12 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.946877 entropy 2.4135556\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9265313 entropy 2.423627\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8992786 entropy 2.4253087\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8706403 entropy 2.4199204\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8414001 entropy 2.4113731\n",
      "kl 0.027804933\n",
      "completed in 0.28728699684143066 s\n",
      "game 34 completed in 7.863282918930054 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9395235 entropy 2.4133813\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9078147 entropy 2.4099631\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8726006 entropy 2.4088817\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.839419 entropy 2.4036827\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8023028 entropy 2.3899393\n",
      "kl 0.019774698\n",
      "completed in 0.27591514587402344 s\n",
      "game 35 completed in 10.50145673751831 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9533212 entropy 2.3655758\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9178588 entropy 2.346772\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8578186 entropy 2.3349714\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.80236 entropy 2.3333795\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7520316 entropy 2.338877\n",
      "kl 0.031361364\n",
      "completed in 0.3278079032897949 s\n",
      "game 36 completed in 10.393372058868408 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9315968 entropy 2.3389323\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9032757 entropy 2.3506064\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.858301 entropy 2.3642116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.6666666666666666 loss 2.8087015 entropy 2.376173\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7660782 entropy 2.386223\n",
      "kl 0.0249204\n",
      "completed in 0.28464317321777344 s\n",
      "game 37 completed in 10.432674884796143 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.94059 entropy 2.4478843\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9181545 entropy 2.452827\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8792448 entropy 2.4509876\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8375323 entropy 2.4425857\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.796828 entropy 2.4298775\n",
      "kl 0.022993855\n",
      "completed in 0.33160996437072754 s\n",
      "game 38 completed in 6.680757999420166 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9082592 entropy 2.4169016\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8817656 entropy 2.4050043\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.838505 entropy 2.3943005\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.7935636 entropy 2.385439\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7545614 entropy 2.3779707\n",
      "kl 0.024646733\n",
      "completed in 0.2713930606842041 s\n",
      "game 39 completed in 8.597474098205566 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9191732 entropy 2.3521981\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8933983 entropy 2.346266\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8540702 entropy 2.3429263\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8104088 entropy 2.3468323\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.774275 entropy 2.3599594\n",
      "kl 0.020529581\n",
      "completed in 0.29442715644836426 s\n",
      "game 40 completed in 9.492371082305908 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9517004 entropy 2.3777714\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.9312994 entropy 2.3994725\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8967915 entropy 2.4132805\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8605323 entropy 2.4161663\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.828055 entropy 2.4109511\n",
      "kl 0.025891319\n",
      "completed in 0.28227710723876953 s\n",
      "game 41 completed in 17.9691960811615 s 19 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 3.0052392 entropy 2.3959136\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.977682 entropy 2.3925042\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.9268212 entropy 2.3899121\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.8689167 entropy 2.3833952\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.8198462 entropy 2.369864\n",
      "kl 0.047960483\n",
      "completed in 0.29126787185668945 s\n",
      "game 42 completed in 10.44037413597107 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9581096 entropy 2.369826\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9405005 entropy 2.3670168\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9017675 entropy 2.3730073\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8547275 entropy 2.3855128\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8146772 entropy 2.3997564\n",
      "kl 0.012784429\n",
      "completed in 0.283372163772583 s\n",
      "game 43 completed in 12.99061107635498 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8307736 entropy 2.3838625\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.810359 entropy 2.3897552\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7785113 entropy 2.388153\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7436442 entropy 2.384197\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7091036 entropy 2.3815262\n",
      "kl 0.023979386\n",
      "completed in 0.3050999641418457 s\n",
      "game 44 completed in 10.565127849578857 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9306333 entropy 2.3892694\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9126296 entropy 2.3961263\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8866365 entropy 2.4051597\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8593569 entropy 2.4114761\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8336587 entropy 2.4113255\n",
      "kl 0.015642747\n",
      "completed in 0.3961300849914551 s\n",
      "game 45 completed in 10.337311029434204 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9536068 entropy 2.4123182\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9337428 entropy 2.3961663\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8954098 entropy 2.3774529\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.851468 entropy 2.3632736\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8130558 entropy 2.3582458\n",
      "kl 0.019724647\n",
      "completed in 0.3532280921936035 s\n",
      "game 46 completed in 12.13669490814209 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8286085 entropy 2.3142524\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8133912 entropy 2.3197744\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7847219 entropy 2.32367\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7474318 entropy 2.321395\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7126908 entropy 2.3118184\n",
      "kl 0.023360286\n",
      "completed in 0.2724339962005615 s\n",
      "game 47 completed in 21.233730792999268 s 22 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8260682 entropy 2.3283691\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8071077 entropy 2.3176818\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7786586 entropy 2.3117456\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7539444 entropy 2.3129025\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7313902 entropy 2.319058\n",
      "kl 0.01445201\n",
      "completed in 0.3004910945892334 s\n",
      "game 48 completed in 12.315875768661499 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9020782 entropy 2.3522\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8890076 entropy 2.3615282\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.865037 entropy 2.366114\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.836047 entropy 2.3649826\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8062928 entropy 2.3598568\n",
      "kl 0.021248229\n",
      "completed in 0.27342796325683594 s\n",
      "prediction:\n",
      " [0.0005166  0.00099941 0.00334505 0.00195551 0.00178967 0.00024674\n",
      " 0.00121614 0.01874002 0.08332912 0.02753186 0.00597013 0.00130023\n",
      " 0.00235216 0.09761477 0.08999334 0.12982875 0.0236475  0.00158286\n",
      " 0.00162025 0.0359217  0.18110427 0.06641803 0.07126136 0.00228375\n",
      " 0.00108589 0.00681179 0.03381497 0.07690526 0.01973449 0.00089454\n",
      " 0.00046973 0.00155737 0.00198533 0.00466671 0.00086005 0.00064465] \n",
      " -0.34886333\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.25782228e-03 6.25782228e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 3.02878598e-01 1.77722153e-01\n",
      "  1.62703379e-02 1.25156446e-13]\n",
      " [1.25156446e-13 8.76095119e-03 2.17772215e-01 2.29036295e-01\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.76095119e-03 1.37672090e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [8.4204698e-04 8.3122868e-04 1.7188475e-03 9.9730887e-04 3.3668007e-03\n",
      " 1.3936234e-04 8.8617514e-04 2.6066788e-02 5.4851472e-02 7.8897588e-02\n",
      " 4.4891723e-03 3.6786643e-03 1.4666526e-03 2.9598942e-02 6.9327749e-02\n",
      " 1.0769463e-01 8.4936015e-02 8.4438547e-04 1.6774428e-03 1.3960309e-01\n",
      " 9.3336873e-02 5.2744236e-02 5.3420935e-02 1.6361146e-03 3.3694892e-03\n",
      " 5.0155665e-03 9.2877984e-02 5.2983392e-02 2.2086147e-02 8.2872115e-04\n",
      " 7.4476295e-05 4.1032517e-03 2.1961238e-03 1.3963315e-03 1.1837408e-03\n",
      " 8.3236466e-04] \n",
      " 0.8222937\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00750939 0.04130163 0.01126408 0.00250313 0.00125156]\n",
      " [0.00125156 0.06382979 0.         0.12140175 0.00876095 0.00125156]\n",
      " [0.00125156 0.01376721 0.1301627  0.47934919 0.03254068 0.00125156]\n",
      " [0.00125156 0.00250313 0.01376721 0.0387985  0.00750939 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.1207381e-03 3.0098723e-03 3.9821239e-03 3.1247346e-03 5.6356476e-03\n",
      " 2.0675316e-04 2.4313699e-03 2.2809017e-02 4.6574544e-02 2.1124808e-01\n",
      " 4.3982440e-03 3.5972816e-03 6.4482638e-03 3.5981894e-02 2.0472791e-02\n",
      " 9.6745342e-02 1.3012622e-02 2.7687629e-03 3.3787759e-03 1.3318965e-02\n",
      " 1.0094382e-01 2.1049585e-02 2.7164113e-02 5.0467681e-03 4.8181266e-03\n",
      " 6.0210219e-03 1.7430541e-01 1.0387600e-01 3.1380925e-02 1.4990396e-03\n",
      " 5.3799705e-04 3.8185320e-03 2.9636577e-03 7.8216437e-03 3.1679303e-03\n",
      " 3.3198262e-03] \n",
      " -0.96557057\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 3.75469337e-03 1.37672090e-02 2.06508135e-01\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 5.00625782e-03 0.00000000e+00 5.75719650e-02\n",
      "  1.75219024e-02 1.25156446e-13]\n",
      " [1.25156446e-13 6.02002503e-01 3.25406758e-02 0.00000000e+00\n",
      "  1.37672090e-02 1.25156446e-13]\n",
      " [3.75469337e-03 1.25156446e-03 1.50187735e-02 1.12640801e-02\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00336446 0.00172487 0.00349357 0.0017654  0.03146284 0.00018638\n",
      " 0.00159049 0.06387119 0.04245533 0.11335321 0.00871331 0.05219903\n",
      " 0.00571777 0.03208628 0.00437505 0.10672527 0.00785058 0.00362661\n",
      " 0.00367008 0.00944979 0.0723919  0.00899553 0.07643837 0.00528296\n",
      " 0.07525904 0.00836452 0.04736133 0.04808377 0.11747164 0.00091022\n",
      " 0.0001824  0.02205388 0.00583649 0.00882554 0.00255826 0.00230284] \n",
      " 0.9996216\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00375469 0.01501877 0.72340426 0.00125156 0.00125156]\n",
      " [0.00125156 0.01376721 0.         0.07509387 0.00250313 0.00125156]\n",
      " [0.00125156 0.         0.02503129 0.         0.00500626 0.00125156]\n",
      " [0.00125156 0.00125156 0.0738423  0.02878598 0.00625782 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00511102 0.00502883 0.00707692 0.00596703 0.0137222  0.00100158\n",
      " 0.00620773 0.04043422 0.1693919  0.04352337 0.01449761 0.00789572\n",
      " 0.00439527 0.05740439 0.01356162 0.06164368 0.01583893 0.00251884\n",
      " 0.00344816 0.0218424  0.05411297 0.0145423  0.03181267 0.0050995\n",
      " 0.00869501 0.02634433 0.02471855 0.23748453 0.05523575 0.00482111\n",
      " 0.00244064 0.00404092 0.00666805 0.01490532 0.00480972 0.00375737] \n",
      " -0.86632895\n",
      "p [[1.00125156e-02 1.25156446e-13 2.62828536e-02 1.25156446e-13\n",
      "  2.37797247e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.12640801e-02 8.76095119e-03 0.00000000e+00\n",
      "  1.25156446e-03 2.00250313e-02]\n",
      " [1.00125156e-02 3.50438048e-02 0.00000000e+00 6.44555695e-01\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-03 0.00000000e+00 2.25281602e-02 0.00000000e+00\n",
      "  1.62703379e-02 1.12640801e-02]\n",
      " [1.50187735e-02 1.00125156e-02 1.75219024e-02 3.62953692e-02\n",
      "  2.87859825e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.37672090e-02 1.12640801e-02 1.00125156e-02\n",
      "  1.12640801e-02 1.25156446e-03]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00234979 0.0031863  0.00157818 0.00091336 0.01617932 0.00139887\n",
      " 0.0019077  0.02386053 0.0023264  0.05415952 0.04398189 0.02737983\n",
      " 0.00487338 0.15450801 0.00086462 0.00855071 0.00969952 0.00417467\n",
      " 0.00652189 0.01767611 0.00549259 0.00146441 0.42440152 0.00775452\n",
      " 0.01398625 0.04737858 0.02753013 0.00310249 0.05808388 0.00068399\n",
      " 0.0005385  0.0110401  0.00151014 0.00452584 0.00411404 0.00230257] \n",
      " 0.9991687\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00625782 0.00125156]\n",
      " [0.00125156 0.10012516 0.2853567  0.         0.00750939 0.00125156]\n",
      " [0.00125156 0.26783479 0.         0.         0.01251564 0.00125156]\n",
      " [0.00125156 0.         0.10763454 0.         0.02628285 0.00125156]\n",
      " [0.00125156 0.00750939 0.05506884 0.077597   0.01627034 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00750939 0.00125156 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00120566 0.00409803 0.00515706 0.00257046 0.01876126 0.00033414\n",
      " 0.00622606 0.29973432 0.008984   0.00832246 0.19747415 0.00499525\n",
      " 0.00185586 0.00362139 0.00098246 0.01635447 0.00733097 0.00102608\n",
      " 0.00292244 0.01391386 0.00348677 0.00087267 0.00340354 0.00226824\n",
      " 0.00630044 0.20305341 0.00133457 0.0051625  0.14008935 0.00450823\n",
      " 0.00037956 0.00305161 0.0057027  0.00879313 0.00512307 0.00059988] \n",
      " -0.9849842\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 0.00000000e+00 0.00000000e+00\n",
      "  3.75469337e-03 2.50312891e-03]\n",
      " [1.25156446e-13 9.21151439e-01 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  4.63078849e-02 1.25156446e-03]\n",
      " [1.25156446e-03 3.75469337e-03 2.50312891e-03 1.25156446e-13\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.13120631e-03 7.52017554e-03 5.07085177e-04 5.87429677e-04\n",
      " 4.80752885e-02 1.16154342e-03 6.15107547e-03 4.16590180e-03\n",
      " 3.64383031e-03 9.64595843e-03 4.42803085e-01 9.09677986e-03\n",
      " 6.37738332e-02 1.25747151e-03 1.42212564e-04 1.86671149e-02\n",
      " 4.15374450e-02 6.37552235e-03 1.32931732e-02 3.63023020e-02\n",
      " 4.07495769e-03 1.82319171e-04 5.98240132e-03 4.76091802e-02\n",
      " 9.99182463e-03 1.40317827e-01 7.62521615e-03 7.76855368e-03\n",
      " 1.00268144e-02 9.50038782e-04 3.42688494e-04 3.02040949e-02\n",
      " 1.08894543e-03 2.62056710e-03 1.10956235e-02 1.28060242e-03] \n",
      " 0.99665123\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.01001252 0.00125156]\n",
      " [0.12891114 0.33166458 0.         0.         0.24155194 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.00500626 0.00125156]\n",
      " [0.00125156 0.         0.03003755 0.         0.00125156 0.00125156]\n",
      " [0.00750939 0.14643304 0.00125156 0.00125156 0.06633292 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.00625782 0.00125156 0.00125156]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.9992390e-03 2.8814035e-03 2.1848881e-03 4.5695938e-03 1.7707208e-02\n",
      " 2.2755150e-04 7.2942071e-02 7.0010498e-03 5.8241514e-03 9.8492838e-03\n",
      " 3.3651337e-01 2.8785348e-03 7.9292760e-05 1.3410074e-03 3.1108802e-04\n",
      " 6.3745161e-03 1.0741998e-03 5.2403496e-04 9.5289433e-04 5.1966514e-03\n",
      " 6.0788391e-04 5.5660499e-04 8.4065687e-04 2.5234706e-04 5.1708804e-03\n",
      " 4.6769291e-01 5.4553326e-04 3.9079678e-03 2.8018462e-03 2.3768589e-02\n",
      " 1.0676237e-04 7.6333905e-04 3.2152857e-03 5.7808175e-03 2.6660943e-03\n",
      " 8.9055055e-04] \n",
      " -0.98315036\n",
      "p [[1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-13\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.13016270e-02 3.75469337e-03]\n",
      " [5.49436796e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.56695870e-01 1.25156446e-13]\n",
      " [3.75469337e-03 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 6.25782228e-03]\n",
      " [2.50312891e-03 1.25156446e-02 1.25156446e-03 2.50312891e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.25156446e-13 1.25156446e-13\n",
      "  3.75469337e-03 1.25156446e-13]]\n",
      "move 12\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1.  0.  0.]\n",
      " [ 1.  1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 49 completed in 24.570116996765137 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9671118 entropy 2.3164525\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.950674 entropy 2.3144445\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9211855 entropy 2.316257\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8838854 entropy 2.3218403\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8427649 entropy 2.32865\n",
      "kl 0.015672348\n",
      "completed in 0.282520055770874 s\n",
      "game 50 completed in 9.45896601676941 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8250313 entropy 2.325434\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8049688 entropy 2.325368\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7743247 entropy 2.3214073\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7451425 entropy 2.3153281\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7185853 entropy 2.3091502\n",
      "kl 0.012930764\n",
      "completed in 0.303333044052124 s\n",
      "game 51 completed in 12.285629987716675 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8153958 entropy 2.361509\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7880704 entropy 2.3623993\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7507455 entropy 2.3649626\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.719212 entropy 2.3665757\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.695511 entropy 2.365573\n",
      "kl 0.01826082\n",
      "completed in 0.34436988830566406 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 52 completed in 7.636742115020752 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9286628 entropy 2.3562784\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.911796 entropy 2.3545432\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8772652 entropy 2.3548484\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.837936 entropy 2.3571613\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8007948 entropy 2.3602736\n",
      "kl 0.01388003\n",
      "completed in 0.3223140239715576 s\n",
      "game 53 completed in 6.78870701789856 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8105145 entropy 2.3254688\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7837477 entropy 2.3301353\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7471964 entropy 2.334608\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7077968 entropy 2.3352358\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6711268 entropy 2.33072\n",
      "kl 0.018993214\n",
      "completed in 0.27364301681518555 s\n",
      "game 54 completed in 10.300014019012451 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8067858 entropy 2.3483946\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7864425 entropy 2.336394\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7585418 entropy 2.3244686\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.731185 entropy 2.3166656\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7023535 entropy 2.3144517\n",
      "kl 0.021736603\n",
      "completed in 0.29193711280822754 s\n",
      "game 55 completed in 12.515074014663696 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8147066 entropy 2.2961535\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7906306 entropy 2.2969203\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7554922 entropy 2.2946856\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7225945 entropy 2.2911232\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6969686 entropy 2.2886996\n",
      "kl 0.0124948025\n",
      "completed in 0.33647680282592773 s\n",
      "game 56 completed in 9.625858068466187 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.921517 entropy 2.337702\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9013238 entropy 2.3391867\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8673685 entropy 2.341641\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8287268 entropy 2.3435898\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7909248 entropy 2.343278\n",
      "kl 0.020436086\n",
      "completed in 0.3043811321258545 s\n",
      "game 57 completed in 7.6720051765441895 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8791804 entropy 2.3370652\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8655443 entropy 2.3447309\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.843564 entropy 2.3567898\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.817678 entropy 2.3671906\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7917137 entropy 2.371319\n",
      "kl 0.02156142\n",
      "completed in 0.3423912525177002 s\n",
      "game 58 completed in 10.311224222183228 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9518025 entropy 2.3169475\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9303102 entropy 2.3031735\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.9000664 entropy 2.2894473\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.868262 entropy 2.2832572\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8363183 entropy 2.2881598\n",
      "kl 0.025663273\n",
      "completed in 0.38172197341918945 s\n",
      "game 59 completed in 13.046607971191406 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.883232 entropy 2.3180952\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.855928 entropy 2.3440886\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8238244 entropy 2.3688593\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7968333 entropy 2.3828623\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7680159 entropy 2.382763\n",
      "kl 0.023371398\n",
      "completed in 0.2880580425262451 s\n",
      "game 60 completed in 8.568969964981079 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9549525 entropy 2.3959537\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.9327657 entropy 2.3726423\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.902585 entropy 2.3506875\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8698409 entropy 2.339758\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.835161 entropy 2.3423774\n",
      "kl 0.026464729\n",
      "completed in 0.2786400318145752 s\n",
      "game 61 completed in 11.91472578048706 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8005579 entropy 2.3174322\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7779355 entropy 2.3355427\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.749577 entropy 2.3511865\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7198231 entropy 2.355919\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6891167 entropy 2.344542\n",
      "kl 0.026552774\n",
      "completed in 0.2862551212310791 s\n",
      "game 62 completed in 11.081427097320557 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8090193 entropy 2.3283968\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7743287 entropy 2.2940657\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7405984 entropy 2.2606797\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7173831 entropy 2.23902\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6921337 entropy 2.2334056\n",
      "kl 0.034908004\n",
      "completed in 0.29218101501464844 s\n",
      "game 63 completed in 6.5127880573272705 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.9059005 entropy 2.249405\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8916743 entropy 2.2728653\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8661022 entropy 2.300345\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.8350549 entropy 2.3197541\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.8000371 entropy 2.324183\n",
      "kl 0.02914365\n",
      "completed in 0.3293468952178955 s\n",
      "game 64 completed in 7.536940097808838 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8824816 entropy 2.3300333\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8601427 entropy 2.3197572\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8307233 entropy 2.3151712\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7978816 entropy 2.3213964\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.759602 entropy 2.3377237\n",
      "kl 0.01631045\n",
      "completed in 0.3022000789642334 s\n",
      "game 65 completed in 8.389285802841187 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7982016 entropy 2.3310547\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.779878 entropy 2.340346\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7528424 entropy 2.3349123\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.72377 entropy 2.3166614\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6968193 entropy 2.292324\n",
      "kl 0.023354422\n",
      "completed in 0.31099510192871094 s\n",
      "game 66 completed in 8.525073051452637 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.783969 entropy 2.279216\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7667933 entropy 2.269391\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7383578 entropy 2.2676883\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7087712 entropy 2.2677605\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6811767 entropy 2.2637928\n",
      "kl 0.02688549\n",
      "completed in 0.27471423149108887 s\n",
      "game 67 completed in 12.177636861801147 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.83663 entropy 2.2950807\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8180747 entropy 2.277773\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.789929 entropy 2.2596488\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7605207 entropy 2.2492652\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7311478 entropy 2.2515087\n",
      "kl 0.024968456\n",
      "completed in 0.31626439094543457 s\n",
      "game 68 completed in 13.165866136550903 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.830094 entropy 2.235774\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8110783 entropy 2.2575622\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7818806 entropy 2.2786956\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.75319 entropy 2.2919674\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7249405 entropy 2.2958653\n",
      "kl 0.020785727\n",
      "completed in 0.303203821182251 s\n",
      "game 69 completed in 8.511216163635254 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.846609 entropy 2.2947311\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8354664 entropy 2.2961326\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8162613 entropy 2.3016732\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7919047 entropy 2.3102765\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.765406 entropy 2.3197448\n",
      "kl 0.016999643\n",
      "completed in 0.27738189697265625 s\n",
      "game 70 completed in 8.552645206451416 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7935967 entropy 2.320015\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.779772 entropy 2.321811\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7555046 entropy 2.31667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.7304802 entropy 2.3053522\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.704828 entropy 2.289742\n",
      "kl 0.009706693\n",
      "completed in 0.29884886741638184 s\n",
      "game 71 completed in 8.507209062576294 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.836922 entropy 2.3369634\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8115277 entropy 2.3176608\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.7766786 entropy 2.3089962\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.739038 entropy 2.3069081\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7040722 entropy 2.3039358\n",
      "kl 0.021749923\n",
      "completed in 0.33730602264404297 s\n",
      "game 72 completed in 12.336266994476318 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7421408 entropy 2.253891\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7210376 entropy 2.2334452\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.690558 entropy 2.215569\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6625235 entropy 2.210813\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6334422 entropy 2.221229\n",
      "kl 0.026958968\n",
      "completed in 0.2750060558319092 s\n",
      "game 73 completed in 17.850748777389526 s 19 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7744792 entropy 2.214693\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.752149 entropy 2.2292142\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.716528 entropy 2.2348123\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6769645 entropy 2.2314038\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6422863 entropy 2.2262957\n",
      "kl 0.030762453\n",
      "completed in 0.29070210456848145 s\n",
      "game 74 completed in 14.192425966262817 s 15 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.8744006 entropy 2.2352695\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8416946 entropy 2.2503319\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.7973459 entropy 2.2680414\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.7562296 entropy 2.2765102\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7175167 entropy 2.2724838\n",
      "kl 0.03289899\n",
      "completed in 0.2650868892669678 s\n",
      "game 75 completed in 9.684377908706665 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.8488374 entropy 2.3176012\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8278036 entropy 2.3066688\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.7969387 entropy 2.308782\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.7626553 entropy 2.3261485\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7302215 entropy 2.3492975\n",
      "kl 0.025688266\n",
      "completed in 0.31410717964172363 s\n",
      "game 76 completed in 6.579697132110596 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.846768 entropy 2.3498132\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.805663 entropy 2.3482413\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.764679 entropy 2.3329191\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.730895 entropy 2.3129134\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.696522 entropy 2.2957544\n",
      "kl 0.023170648\n",
      "completed in 0.3435099124908447 s\n",
      "game 77 completed in 9.587800025939941 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.8610628 entropy 2.2847576\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.842805 entropy 2.2858415\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.8143132 entropy 2.2882226\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.7801435 entropy 2.2864046\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7446778 entropy 2.2795568\n",
      "kl 0.027828299\n",
      "completed in 0.2900519371032715 s\n",
      "game 78 completed in 8.597120761871338 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.742693 entropy 2.2496972\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7254026 entropy 2.242298\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.7000318 entropy 2.2346704\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.670447 entropy 2.227395\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6372647 entropy 2.2193003\n",
      "kl 0.02750958\n",
      "completed in 0.2879819869995117 s\n",
      "game 79 completed in 6.703062057495117 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.772811 entropy 2.1956317\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7377536 entropy 2.1889935\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.69384 entropy 2.184081\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6599503 entropy 2.1802073\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.627004 entropy 2.1779075\n",
      "kl 0.036437456\n",
      "completed in 0.3386721611022949 s\n",
      "game 80 completed in 16.086568117141724 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.9155364 entropy 2.225434\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.8877847 entropy 2.2337997\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.844267 entropy 2.2449174\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.796876 entropy 2.2522686\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.7538586 entropy 2.2537522\n",
      "kl 0.04104747\n",
      "completed in 0.30489015579223633 s\n",
      "game 81 completed in 6.717931032180786 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8732538 entropy 2.2814522\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.85564 entropy 2.2818594\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.8211997 entropy 2.2862525\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.783047 entropy 2.294985\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7496192 entropy 2.3072617\n",
      "kl 0.01544291\n",
      "completed in 0.3572957515716553 s\n",
      "game 82 completed in 10.200363874435425 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.816322 entropy 2.2831407\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7975032 entropy 2.2919033\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7693205 entropy 2.2955046\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7387824 entropy 2.2955694\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7102847 entropy 2.2938652\n",
      "kl 0.021249175\n",
      "completed in 0.2733030319213867 s\n",
      "game 83 completed in 8.434003114700317 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7790287 entropy 2.3089824\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.762172 entropy 2.3022974\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7368486 entropy 2.291533\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7100394 entropy 2.2784524\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6842682 entropy 2.264718\n",
      "kl 0.011426118\n",
      "completed in 0.27414441108703613 s\n",
      "game 84 completed in 14.00546932220459 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.692673 entropy 2.2327828\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6776516 entropy 2.227509\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6542304 entropy 2.2268996\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.625847 entropy 2.2275229\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5954094 entropy 2.2254176\n",
      "kl 0.018304875\n",
      "completed in 0.2996022701263428 s\n",
      "game 85 completed in 6.548512935638428 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7602575 entropy 2.1918612\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7368789 entropy 2.1797917\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7069266 entropy 2.1659813\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6834471 entropy 2.156798\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6601954 entropy 2.1567733\n",
      "kl 0.025315668\n",
      "completed in 0.3548710346221924 s\n",
      "game 86 completed in 14.519742012023926 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6789658 entropy 2.1480255\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6547747 entropy 2.1659007\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6286159 entropy 2.1844227\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.609717 entropy 2.195217\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5912437 entropy 2.1928744\n",
      "kl 0.021607859\n",
      "completed in 0.2857537269592285 s\n",
      "game 87 completed in 8.372425079345703 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7850564 entropy 2.2466764\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.764033 entropy 2.2219863\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7384572 entropy 2.2020438\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7138095 entropy 2.195272\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6861217 entropy 2.2028835\n",
      "kl 0.02420985\n",
      "completed in 0.3195047378540039 s\n",
      "game 88 completed in 10.920759916305542 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.851171 entropy 2.2133236\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8412 entropy 2.2302184\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.812152 entropy 2.2413301\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7776535 entropy 2.2439537\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.748403 entropy 2.239417\n",
      "kl 0.012408605\n",
      "completed in 0.29682397842407227 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 89 completed in 11.701786041259766 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7385364 entropy 2.2314167\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.72219 entropy 2.2314065\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6945925 entropy 2.2384276\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.662739 entropy 2.2475798\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6338508 entropy 2.253244\n",
      "kl 0.022443939\n",
      "completed in 0.2988321781158447 s\n",
      "game 90 completed in 7.3523290157318115 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.752215 entropy 2.2637966\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7293117 entropy 2.2450867\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6983862 entropy 2.2202215\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6735866 entropy 2.2017484\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6493359 entropy 2.1991227\n",
      "kl 0.03231035\n",
      "completed in 0.28608202934265137 s\n",
      "game 91 completed in 9.206064701080322 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.792464 entropy 2.1694775\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7751887 entropy 2.1981664\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7496095 entropy 2.23266\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7228663 entropy 2.2611198\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.696758 entropy 2.2769876\n",
      "kl 0.02584785\n",
      "completed in 0.29247093200683594 s\n",
      "game 92 completed in 6.634372711181641 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8063393 entropy 2.3271935\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7876716 entropy 2.3147323\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7628965 entropy 2.2981596\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7371132 entropy 2.286475\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7107234 entropy 2.2840896\n",
      "kl 0.02120325\n",
      "completed in 0.2767829895019531 s\n",
      "game 93 completed in 6.539832830429077 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7759268 entropy 2.2680674\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7564127 entropy 2.2724092\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7318132 entropy 2.2712533\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7086406 entropy 2.263219\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.683525 entropy 2.248953\n",
      "kl 0.014870501\n",
      "completed in 0.2898380756378174 s\n",
      "game 94 completed in 10.328991174697876 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7984517 entropy 2.2255244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7867892 entropy 2.2175717\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7623527 entropy 2.2183313\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.732474 entropy 2.2256675\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7049954 entropy 2.2363267\n",
      "kl 0.01799398\n",
      "completed in 0.2980818748474121 s\n",
      "game 95 completed in 8.418586730957031 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8233738 entropy 2.252377\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8086014 entropy 2.2574797\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7847307 entropy 2.256814\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7578824 entropy 2.2516456\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7287486 entropy 2.2432384\n",
      "kl 0.014103331\n",
      "completed in 0.2999558448791504 s\n",
      "game 96 completed in 6.701482057571411 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7597752 entropy 2.2409184\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7472303 entropy 2.2197988\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7282584 entropy 2.194886\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7070913 entropy 2.173933\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6839113 entropy 2.1622763\n",
      "kl 0.022621673\n",
      "completed in 0.26979613304138184 s\n",
      "game 97 completed in 8.43504285812378 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.718371 entropy 2.1515567\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.695801 entropy 2.1680014\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6683495 entropy 2.1905918\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6454096 entropy 2.20745\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6218007 entropy 2.211996\n",
      "kl 0.027378086\n",
      "completed in 0.3498849868774414 s\n",
      "game 98 completed in 12.063414096832275 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6285098 entropy 2.1792202\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6098278 entropy 2.1560326\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5874143 entropy 2.1311736\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.562582 entropy 2.115383\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5324574 entropy 2.1132476\n",
      "kl 0.02742333\n",
      "completed in 0.316281795501709 s\n",
      "prediction:\n",
      " [0.00054799 0.0015672  0.00191923 0.00303085 0.00143787 0.00065779\n",
      " 0.00107472 0.01012545 0.02943468 0.06076124 0.01998237 0.00115707\n",
      " 0.00185751 0.03233659 0.12872972 0.14254358 0.06222226 0.00403078\n",
      " 0.00461931 0.06198628 0.15546472 0.1163487  0.02298387 0.00310605\n",
      " 0.00134542 0.0190149  0.06908751 0.02472911 0.00902507 0.00171265\n",
      " 0.00044546 0.00101325 0.00303729 0.00136795 0.00088999 0.00040577] \n",
      " -0.72198844\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 7.50938673e-03 6.25782228e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 7.50938673e-03 1.60200250e-01 1.37672090e-01\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 8.76095119e-03 5.65707134e-01 7.13391740e-02\n",
      "  8.76095119e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 7.50938673e-03 1.37672090e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [1.32424075e-05 6.39677106e-04 4.35872789e-04 2.18652014e-04\n",
      " 1.22805402e-04 6.30768409e-05 6.17652200e-04 6.22898282e-04\n",
      " 6.00443594e-02 5.55386813e-03 5.34492172e-03 2.31008424e-04\n",
      " 1.58272989e-04 1.01709895e-01 2.68399328e-01 6.68557882e-02\n",
      " 2.66385395e-02 4.39018098e-04 5.99135645e-04 1.35331275e-02\n",
      " 9.63410810e-02 1.58345222e-01 1.06528297e-01 3.45840293e-04\n",
      " 1.06058498e-04 5.84113365e-03 1.49117755e-02 6.27697557e-02\n",
      " 7.22765864e-04 7.70813844e-04 5.73967991e-05 1.85848083e-04\n",
      " 2.70950230e-04 2.99942330e-04 2.33566141e-04 2.84864345e-05] \n",
      " 0.6684178\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00500626 0.01501877 0.02377972 0.00750939 0.00125156]\n",
      " [0.00125156 0.01251564 0.05757196 0.68210263 0.02628285 0.00250313]\n",
      " [0.00125156 0.03128911 0.         0.05131414 0.01001252 0.00125156]\n",
      " [0.00125156 0.00750939 0.02878598 0.01001252 0.00375469 0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00074766 0.00197725 0.00284233 0.00500557 0.00293305 0.00198152\n",
      " 0.00114877 0.0068942  0.17164668 0.08392079 0.0111446  0.00254227\n",
      " 0.00151416 0.05864337 0.05976936 0.00995213 0.01600585 0.00459559\n",
      " 0.00677375 0.02163291 0.01610507 0.04301932 0.0752739  0.0040372\n",
      " 0.00195028 0.02798224 0.08437423 0.2501622  0.00534028 0.00348616\n",
      " 0.00141636 0.00199299 0.00513098 0.00435094 0.00319407 0.00051201] \n",
      " -0.9645286\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 7.50938673e-03 2.50312891e-03\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 8.63579474e-02 3.37922403e-01 0.00000000e+00\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.76470588e-01\n",
      "  5.88235294e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 2.50312891e-03 3.11639549e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.5913026e-04 1.9036906e-03 1.7431336e-03 1.9030735e-03 6.0505827e-04\n",
      " 2.4241472e-04 1.4694723e-03 5.0523519e-03 1.5299933e-02 1.2255651e-01\n",
      " 1.5732447e-03 9.9144364e-04 3.9456692e-04 5.9992015e-02 9.4263859e-02\n",
      " 3.9195907e-03 2.5960445e-02 4.0388681e-04 1.0435304e-03 2.1383693e-02\n",
      " 3.7917655e-03 3.7447840e-02 9.7805545e-02 6.3718599e-04 8.2326418e-04\n",
      " 3.7109796e-03 4.5464322e-01 2.3140047e-02 6.7488509e-03 1.4525630e-03\n",
      " 2.2318047e-04 1.4222342e-03 3.9099026e-03 1.5806551e-03 1.2875979e-03\n",
      " 4.1413915e-04] \n",
      " -0.07825009\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00250313 0.47934919 0.05131414 0.00500626 0.00125156]\n",
      " [0.00125156 0.02628285 0.         0.         0.00625782 0.00125156]\n",
      " [0.00250313 0.00876095 0.         0.06382979 0.12265332 0.00125156]\n",
      " [0.00125156 0.01126408 0.06257822 0.13266583 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00057334 0.02317281 0.00693331 0.01190294 0.0023882  0.00673865\n",
      " 0.0074823  0.02574373 0.00623024 0.00802946 0.00899272 0.00383041\n",
      " 0.00193852 0.2803412  0.0087991  0.00184979 0.00602527 0.00205869\n",
      " 0.00691021 0.01035571 0.00087209 0.00304299 0.41746652 0.00554595\n",
      " 0.00170438 0.0166541  0.01102688 0.00528721 0.02075222 0.03863575\n",
      " 0.00149211 0.00146086 0.01355495 0.0044824  0.02664509 0.00107993] \n",
      " 0.7612684\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.50187735e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.37672090e-02 0.00000000e+00 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 7.50938673e-03\n",
      "  1.50187735e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 9.36170213e-01 5.00625782e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.60989424e-04 3.62776942e-03 1.42208375e-02 2.57435739e-02\n",
      " 3.13707232e-03 1.08903530e-03 5.48877334e-03 1.22873830e-02\n",
      " 7.96555877e-02 7.93551002e-03 1.46778114e-02 5.44474833e-03\n",
      " 9.21393745e-04 6.07834682e-02 1.59728348e-01 7.10531091e-03\n",
      " 3.71115059e-02 1.31784217e-03 3.59503529e-03 2.83088740e-02\n",
      " 5.74200740e-03 5.74635975e-02 1.44987419e-01 1.22751028e-03\n",
      " 2.14972976e-03 4.58656475e-02 4.19350527e-02 1.73048809e-01\n",
      " 1.43680507e-02 6.62114145e-03 6.93007081e-04 5.40209608e-03\n",
      " 1.62409842e-02 8.96927714e-03 2.30439752e-03 6.40668266e-04] \n",
      " 0.57787174\n",
      "p [[0.00125156 0.01501877 0.00625782 0.01877347 0.00375469 0.00500626]\n",
      " [0.00750939 0.03128911 0.         0.00876095 0.01001252 0.00625782]\n",
      " [0.01501877 0.13516896 0.         0.         0.00375469 0.00625782]\n",
      " [0.0212766  0.00750939 0.         0.00250313 0.21401752 0.00625782]\n",
      " [0.00625782 0.00625782 0.         0.01376721 0.01627034 0.03254068]\n",
      " [0.00625782 0.00876095 0.35669587 0.00625782 0.0175219  0.00375469]]\n",
      "move 32\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00082921 0.04508641 0.02443731 0.0153056  0.00642242 0.01457094\n",
      " 0.03335933 0.02773549 0.02337507 0.0102984  0.04614867 0.00737754\n",
      " 0.0043149  0.15943867 0.01595962 0.00387842 0.0326152  0.00888338\n",
      " 0.02587504 0.03307633 0.00223583 0.01263642 0.14230096 0.00984066\n",
      " 0.00223487 0.04538527 0.01108884 0.02110851 0.02240347 0.12181903\n",
      " 0.00843894 0.00501624 0.01324139 0.00907163 0.03012085 0.00406934] \n",
      " 0.42006266\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-03 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-03 1.25156446e-03 0.00000000e+00 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.75219024e-02 0.00000000e+00 0.00000000e+00\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 0.00000000e+00 8.76095119e-03\n",
      "  9.16145181e-01 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 0.00000000e+00 2.12765957e-02\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.3526618e-04 1.0607656e-02 2.3417592e-03 3.7790493e-03 1.4621689e-02\n",
      " 8.6993590e-04 2.5919972e-03 1.1563344e-02 1.4813076e-02 1.3929803e-03\n",
      " 1.0837783e-02 5.6109894e-03 2.4449828e-03 1.7760406e-04 2.7187094e-01\n",
      " 2.3643600e-03 1.7512868e-01 5.6100236e-03 1.8953228e-02 2.3215024e-01\n",
      " 3.1646660e-03 8.9451008e-02 2.0341093e-04 7.9102051e-03 1.8030958e-03\n",
      " 4.6319656e-02 5.7788417e-03 1.4653503e-02 1.4540973e-02 4.4542970e-03\n",
      " 4.9469183e-04 1.1212292e-02 5.4649613e-03 2.7072837e-03 3.5955803e-03\n",
      " 3.8009507e-04] \n",
      " 0.781634\n",
      "p [[0.00125156 0.02628285 0.02252816 0.01376721 0.00750939 0.01376721]\n",
      " [0.02002503 0.02628285 0.         0.12015019 0.05131414 0.00876095]\n",
      " [0.01376721 0.36295369 0.         0.         0.02002503 0.01001252]\n",
      " [0.01877347 0.05131414 0.         0.03003755 0.         0.00500626]\n",
      " [0.00125156 0.02002503 0.         0.02878598 0.01376721 0.06132666]\n",
      " [0.00625782 0.00750939 0.         0.0175219  0.01877347 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00192625 0.06769946 0.01473744 0.02979546 0.01368083 0.01395911\n",
      " 0.01948364 0.05985834 0.0091567  0.00355159 0.03807191 0.00736303\n",
      " 0.0206916  0.00704416 0.00148974 0.00456223 0.06945686 0.03064373\n",
      " 0.06849727 0.14107391 0.00121948 0.00056706 0.0169389  0.03192821\n",
      " 0.00369429 0.03431574 0.00612406 0.00714141 0.07446624 0.10573433\n",
      " 0.009298   0.01503713 0.02188435 0.00568429 0.03768352 0.00553991] \n",
      " 0.95641446\n",
      "p [[1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.26157697e-02 1.25156446e-13]\n",
      " [1.25156446e-03 1.41426783e-01 0.00000000e+00 7.34668335e-01\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-13 1.75219024e-02 0.00000000e+00 3.75469337e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.3135247e-03 2.1471113e-02 1.4813252e-03 5.3234058e-03 6.2308814e-02\n",
      " 3.0850878e-04 1.7595333e-03 1.3501050e-01 1.6729663e-03 2.8376258e-04\n",
      " 7.3332349e-03 2.5240419e-02 5.4570425e-02 2.1904951e-05 4.0389222e-04\n",
      " 2.4419418e-04 6.9817111e-02 1.5526953e-03 6.7330073e-03 1.3927750e-01\n",
      " 1.9739797e-04 1.4432966e-04 1.9236853e-05 1.1195379e-01 5.6672846e-03\n",
      " 1.7391013e-02 3.4579118e-03 5.1376881e-04 2.7928314e-01 1.8338579e-03\n",
      " 3.5157421e-04 2.7662139e-02 4.1354932e-03 7.7023369e-04 2.3292918e-03\n",
      " 7.1617896e-03] \n",
      " 0.6883079\n",
      "p [[0.00125156 0.0563204  0.0212766  0.07509387 0.02002503 0.01877347]\n",
      " [0.02878598 0.04005006 0.         0.00250313 0.04630788 0.00500626]\n",
      " [0.02002503 0.         0.         0.         0.08260325 0.0212766 ]\n",
      " [0.08635795 0.18523154 0.         0.         0.         0.03629537]\n",
      " [0.00250313 0.03128911 0.         0.00750939 0.05506884 0.07884856]\n",
      " [0.00625782 0.01376721 0.         0.02377972 0.03003755 0.00375469]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.45207264e-03 7.89675340e-02 7.03978445e-03 8.67296755e-03\n",
      " 3.94816399e-02 5.08356467e-03 1.17685832e-02 2.11715892e-01\n",
      " 1.74466707e-03 1.68477756e-03 9.28641632e-02 4.79363604e-03\n",
      " 1.37926172e-02 2.18219240e-03 1.73369786e-04 1.66888756e-04\n",
      " 3.74175119e-03 1.96289849e-02 7.71581754e-02 1.58165791e-03\n",
      " 5.74828591e-05 1.27795007e-04 1.09662935e-02 1.00516733e-02\n",
      " 1.28763355e-03 2.96437163e-02 2.53964029e-03 6.03930617e-04\n",
      " 2.02670991e-01 7.35572428e-02 4.34789015e-03 3.30905318e-02\n",
      " 7.90213421e-03 2.50349985e-03 3.46331261e-02 2.32172245e-03] \n",
      " 0.9725337\n",
      "p [[1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 7.13391740e-02 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [7.50938673e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  4.00500626e-02 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.95619524e-01]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.25156446e-13\n",
      "  3.70463079e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1. -1.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]]\n",
      "1 won\n",
      "game 99 completed in 29.05358099937439 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7727022 entropy 2.161596\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7497933 entropy 2.183642\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7157564 entropy 2.206554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.675843 entropy 2.2213554\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6358988 entropy 2.223607\n",
      "kl 0.020515632\n",
      "completed in 0.28266096115112305 s\n",
      "game 100 completed in 8.434484958648682 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6509488 entropy 2.1954265\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6350589 entropy 2.1805274\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.613631 entropy 2.1672158\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5940604 entropy 2.1607466\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5750916 entropy 2.16259\n",
      "kl 0.014459899\n",
      "completed in 0.2908918857574463 s\n",
      "game 101 completed in 8.425009965896606 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.830429 entropy 2.2250006\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.8180392 entropy 2.230311\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7908304 entropy 2.2295158\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7565753 entropy 2.2235696\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.7208483 entropy 2.215731\n",
      "kl 0.013298564\n",
      "completed in 0.28011107444763184 s\n",
      "game 102 completed in 8.472671031951904 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.686338 entropy 2.1552477\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6692173 entropy 2.158368\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.647084 entropy 2.1670537\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6215694 entropy 2.1770854\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.596738 entropy 2.1829827\n",
      "kl 0.017653331\n",
      "completed in 0.31512880325317383 s\n",
      "game 103 completed in 8.508316040039062 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6965497 entropy 2.2216344\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6792943 entropy 2.2143831\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.653256 entropy 2.2010167\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6232047 entropy 2.1843147\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5913923 entropy 2.167982\n",
      "kl 0.016703857\n",
      "completed in 0.3064301013946533 s\n",
      "game 104 completed in 8.50859522819519 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.78266 entropy 2.2015738\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7661283 entropy 2.195119\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7406244 entropy 2.1950598\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.7117052 entropy 2.198266\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.681592 entropy 2.2024155\n",
      "kl 0.015014207\n",
      "completed in 0.27503204345703125 s\n",
      "game 105 completed in 9.61512017250061 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7575877 entropy 2.1684942\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7433014 entropy 2.1712687\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7199717 entropy 2.1742678\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.691329 entropy 2.1781151\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6593413 entropy 2.1830087\n",
      "kl 0.016956434\n",
      "completed in 0.3482980728149414 s\n",
      "game 106 completed in 12.445329904556274 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6937256 entropy 2.170516\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6831973 entropy 2.1724772\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6642153 entropy 2.1723917\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6397896 entropy 2.171239\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6129236 entropy 2.1697817\n",
      "kl 0.009704972\n",
      "completed in 0.30657219886779785 s\n",
      "game 107 completed in 9.477957248687744 s 10 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.6857216 entropy 2.181849\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6639128 entropy 2.1861084\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6305113 entropy 2.1911244\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5909023 entropy 2.1909056\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5533257 entropy 2.1827545\n",
      "kl 0.031088747\n",
      "completed in 0.2782309055328369 s\n",
      "game 108 completed in 15.432549953460693 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7730372 entropy 2.1992369\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7445996 entropy 2.1742797\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.703918 entropy 2.153256\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6640785 entropy 2.1508944\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.624139 entropy 2.165956\n",
      "kl 0.022132978\n",
      "completed in 0.30954718589782715 s\n",
      "game 109 completed in 7.45470118522644 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7096066 entropy 2.1342955\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6709368 entropy 2.1525433\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6286566 entropy 2.1577778\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5918584 entropy 2.1505022\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5502658 entropy 2.1366422\n",
      "kl 0.035689145\n",
      "completed in 0.2779378890991211 s\n",
      "game 110 completed in 9.767768859863281 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7044501 entropy 2.136747\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.683928 entropy 2.1233923\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6479986 entropy 2.1144419\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.606822 entropy 2.1120577\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5695105 entropy 2.115033\n",
      "kl 0.032759305\n",
      "completed in 0.33179521560668945 s\n",
      "game 111 completed in 6.631806135177612 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.6921766 entropy 2.150899\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.678751 entropy 2.1515887\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6493378 entropy 2.144446\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6138995 entropy 2.1313765\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5771918 entropy 2.1172295\n",
      "kl 0.030284148\n",
      "completed in 0.3543860912322998 s\n",
      "game 112 completed in 7.373440980911255 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.8266327 entropy 2.1212893\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7967477 entropy 2.1292062\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.7551992 entropy 2.1470628\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.708832 entropy 2.1615992\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6652744 entropy 2.1630082\n",
      "kl 0.031723715\n",
      "completed in 0.29378509521484375 s\n",
      "game 113 completed in 6.570660829544067 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.696943 entropy 2.1238804\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6744652 entropy 2.1060557\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6405227 entropy 2.0963588\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5988157 entropy 2.1060572\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5536888 entropy 2.1326709\n",
      "kl 0.030179283\n",
      "completed in 0.316864013671875 s\n",
      "game 114 completed in 10.141808986663818 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7907174 entropy 2.1962166\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7736418 entropy 2.2206151\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.74486 entropy 2.2250814\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.7012208 entropy 2.2104301\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6483026 entropy 2.188816\n",
      "kl 0.020825379\n",
      "completed in 0.31896495819091797 s\n",
      "game 115 completed in 9.948354005813599 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7771783 entropy 2.1726835\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7516344 entropy 2.1666384\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.709757 entropy 2.1687984\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.666609 entropy 2.1753507\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6287377 entropy 2.1793897\n",
      "kl 0.030013194\n",
      "completed in 0.2986280918121338 s\n",
      "game 116 completed in 8.242552995681763 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7562368 entropy 2.185922\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.7436504 entropy 2.1782022\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.719019 entropy 2.1704376\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6884787 entropy 2.166092\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.6553018 entropy 2.1666138\n",
      "kl 0.022260353\n",
      "completed in 0.3244941234588623 s\n",
      "game 117 completed in 8.366966009140015 s 9 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.7022243 entropy 2.1577978\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.674486 entropy 2.1658404\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6446347 entropy 2.1694329\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.6178582 entropy 2.1641686\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.584163 entropy 2.1499186\n",
      "kl 0.025145356\n",
      "completed in 0.325059175491333 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 118 completed in 6.589400053024292 s 7 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.693217 entropy 2.1277018\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6577468 entropy 2.1145716\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.616456 entropy 2.1136887\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5842245 entropy 2.122107\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5524595 entropy 2.130887\n",
      "kl 0.018267334\n",
      "completed in 0.2708110809326172 s\n",
      "game 119 completed in 7.4996020793914795 s 8 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.6687293 entropy 2.160571\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6358423 entropy 2.1497097\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.602455 entropy 2.1339567\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.575135 entropy 2.118146\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5456207 entropy 2.1073546\n",
      "kl 0.037292704\n",
      "completed in 0.2805771827697754 s\n",
      "game 120 completed in 10.119139671325684 s 11 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.656746 entropy 2.0671747\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.615341 entropy 2.0745082\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.5729177 entropy 2.0869634\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5440197 entropy 2.0972614\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5148072 entropy 2.0985982\n",
      "kl 0.03575101\n",
      "completed in 0.26514291763305664 s\n",
      "game 121 completed in 15.56423807144165 s 17 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.6871767 entropy 2.0841613\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6599445 entropy 2.0647407\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.6218197 entropy 2.0474675\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5815246 entropy 2.0423632\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.5421538 entropy 2.052668\n",
      "kl 0.041526824\n",
      "completed in 0.2925450801849365 s\n",
      "game 122 completed in 7.658275127410889 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6322436 entropy 2.1100667\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.622739 entropy 2.1261578\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6008205 entropy 2.136426\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.569905 entropy 2.1390643\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5359204 entropy 2.1357708\n",
      "kl 0.016898714\n",
      "completed in 0.31835174560546875 s\n",
      "game 123 completed in 6.504929065704346 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6530573 entropy 2.1195748\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6368148 entropy 2.1174507\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6106853 entropy 2.1189332\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5792701 entropy 2.1233954\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5474033 entropy 2.1284604\n",
      "kl 0.01267436\n",
      "completed in 0.270460844039917 s\n",
      "game 124 completed in 7.565092086791992 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6968386 entropy 2.134656\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6828685 entropy 2.1392817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6545005 entropy 2.1409333\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6166785 entropy 2.1394792\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5783668 entropy 2.1357813\n",
      "kl 0.019550636\n",
      "completed in 0.30076003074645996 s\n",
      "game 125 completed in 10.286931037902832 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6622405 entropy 2.1353054\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6477313 entropy 2.1338632\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6222813 entropy 2.1357791\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5930905 entropy 2.1405094\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5642452 entropy 2.1462445\n",
      "kl 0.013197647\n",
      "completed in 0.2855358123779297 s\n",
      "game 126 completed in 13.002150058746338 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7233357 entropy 2.189272\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.709733 entropy 2.1911292\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6837895 entropy 2.187899\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6509087 entropy 2.179552\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6156898 entropy 2.1674314\n",
      "kl 0.01581078\n",
      "completed in 0.3208959102630615 s\n",
      "game 127 completed in 6.72616720199585 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6559455 entropy 2.1325006\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.637727 entropy 2.1169605\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6095443 entropy 2.1023517\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5762527 entropy 2.092208\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5428305 entropy 2.0880375\n",
      "kl 0.014951218\n",
      "completed in 0.27907276153564453 s\n",
      "game 128 completed in 7.632296085357666 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6485953 entropy 2.1251054\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6367075 entropy 2.1274028\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6150372 entropy 2.1281977\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5866807 entropy 2.1245742\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5549011 entropy 2.116331\n",
      "kl 0.01526528\n",
      "completed in 0.31727004051208496 s\n",
      "game 129 completed in 11.970134019851685 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6611855 entropy 2.0964065\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6437278 entropy 2.0859437\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.618263 entropy 2.0769596\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5910003 entropy 2.0730033\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.562728 entropy 2.0754604\n",
      "kl 0.019010536\n",
      "completed in 0.2608621120452881 s\n",
      "game 130 completed in 8.431006908416748 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5481393 entropy 2.0577216\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5308602 entropy 2.0683851\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.507352 entropy 2.0779824\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4836805 entropy 2.08171\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4582405 entropy 2.0761838\n",
      "kl 0.020406663\n",
      "completed in 0.27944493293762207 s\n",
      "game 131 completed in 10.199660062789917 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6149776 entropy 2.0760703\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5984764 entropy 2.0580986\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5715294 entropy 2.04256\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5409143 entropy 2.0359046\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5102286 entropy 2.040467\n",
      "kl 0.022996532\n",
      "completed in 0.2915959358215332 s\n",
      "game 132 completed in 18.96803617477417 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6764004 entropy 2.0676723\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.660879 entropy 2.0917304\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.638997 entropy 2.1149304\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6101925 entropy 2.1287096\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5748649 entropy 2.130785\n",
      "kl 0.016248304\n",
      "completed in 0.3255901336669922 s\n",
      "game 133 completed in 11.815224885940552 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6325 entropy 2.0970898\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6197963 entropy 2.0887861\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5998652 entropy 2.083167\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5728836 entropy 2.0835884\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5406418 entropy 2.0901647\n",
      "kl 0.017937077\n",
      "completed in 0.33623790740966797 s\n",
      "game 134 completed in 9.389815092086792 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6672816 entropy 2.142081\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.641698 entropy 2.1562204\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.60661 entropy 2.1639247\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.567804 entropy 2.1620805\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5277946 entropy 2.1501174\n",
      "kl 0.017107762\n",
      "completed in 0.31424617767333984 s\n",
      "game 135 completed in 7.705888986587524 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6563218 entropy 2.1367197\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6434886 entropy 2.1221359\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.619818 entropy 2.1121564\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5900548 entropy 2.1067421\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5599575 entropy 2.1032686\n",
      "kl 0.017068759\n",
      "completed in 0.3177061080932617 s\n",
      "game 136 completed in 6.596212148666382 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7047963 entropy 2.0695834\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6840572 entropy 2.069044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.4444444444444444 loss 2.6570482 entropy 2.0669775\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6301692 entropy 2.06213\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5978682 entropy 2.0549896\n",
      "kl 0.016928794\n",
      "completed in 0.3343391418457031 s\n",
      "game 137 completed in 8.385682821273804 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.631903 entropy 2.0836549\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6130373 entropy 2.0793538\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5868206 entropy 2.0806825\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5609274 entropy 2.088091\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5356553 entropy 2.0996275\n",
      "kl 0.019313462\n",
      "completed in 0.2782018184661865 s\n",
      "game 138 completed in 10.086472034454346 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6028886 entropy 2.1056488\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5850778 entropy 2.1158237\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5594125 entropy 2.1211371\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5312734 entropy 2.1206212\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5027664 entropy 2.1156602\n",
      "kl 0.0134682935\n",
      "completed in 0.3115389347076416 s\n",
      "game 139 completed in 10.050091028213501 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6255538 entropy 2.0660663\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6052709 entropy 2.061571\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5749109 entropy 2.0571618\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5423818 entropy 2.0541458\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.511863 entropy 2.0525281\n",
      "kl 0.02311087\n",
      "completed in 0.3357398509979248 s\n",
      "game 140 completed in 7.611901044845581 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6725316 entropy 2.0787613\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6626964 entropy 2.0800512\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.641194 entropy 2.0814195\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6137593 entropy 2.0822513\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5869322 entropy 2.083243\n",
      "kl 0.013227188\n",
      "completed in 0.3035109043121338 s\n",
      "game 141 completed in 9.347095012664795 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6451406 entropy 2.0768986\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6315963 entropy 2.089228\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6080515 entropy 2.1081607\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5792131 entropy 2.1258476\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5499618 entropy 2.1357226\n",
      "kl 0.025557673\n",
      "completed in 0.30680084228515625 s\n",
      "game 142 completed in 10.184937000274658 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.605685 entropy 2.1729581\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5945578 entropy 2.158115\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5738282 entropy 2.13623\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.549472 entropy 2.1142077\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5230968 entropy 2.0974975\n",
      "kl 0.0296996\n",
      "completed in 0.35013484954833984 s\n",
      "game 143 completed in 9.42490291595459 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6395626 entropy 2.0763664\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6234813 entropy 2.0777864\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5988479 entropy 2.0830243\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5719316 entropy 2.0858285\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.547071 entropy 2.0811012\n",
      "kl 0.026480336\n",
      "completed in 0.27655601501464844 s\n",
      "game 144 completed in 10.35042929649353 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5845597 entropy 2.0253587\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5643814 entropy 2.0116642\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.533125 entropy 1.9992203\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5080905 entropy 1.9911423\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4885564 entropy 1.9883184\n",
      "kl 0.017019048\n",
      "completed in 0.31704020500183105 s\n",
      "game 145 completed in 7.620818853378296 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6246734 entropy 2.0224206\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.614291 entropy 2.0213525\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5925896 entropy 2.0194287\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.56384 entropy 2.018389\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5330045 entropy 2.0200648\n",
      "kl 0.016775131\n",
      "completed in 0.27561211585998535 s\n",
      "game 146 completed in 8.41072416305542 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5255442 entropy 2.0244908\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.504043 entropy 2.0336943\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4824154 entropy 2.0443301\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.460575 entropy 2.052917\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4352956 entropy 2.0566444\n",
      "kl 0.017686613\n",
      "completed in 0.3052952289581299 s\n",
      "game 147 completed in 11.996442794799805 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.564798 entropy 2.0828137\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.554574 entropy 2.0768356\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5365405 entropy 2.0682585\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.515647 entropy 2.0597925\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4917178 entropy 2.0541084\n",
      "kl 0.016753431\n",
      "completed in 0.3134000301361084 s\n",
      "game 148 completed in 11.211696863174438 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5364475 entropy 2.018427\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.524066 entropy 2.0222554\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5023642 entropy 2.0286684\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4779892 entropy 2.0340118\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4534235 entropy 2.034495\n",
      "kl 0.019875724\n",
      "completed in 0.25760722160339355 s\n",
      "prediction:\n",
      " [0.00040579 0.00050529 0.00146439 0.00154993 0.00118028 0.00056121\n",
      " 0.00095073 0.00735283 0.04918653 0.01690103 0.00457763 0.00109833\n",
      " 0.00170927 0.04966358 0.1965507  0.11928428 0.01852818 0.00155477\n",
      " 0.00163305 0.01261113 0.0926184  0.278179   0.0571095  0.00194019\n",
      " 0.00068538 0.00252137 0.0178637  0.04915477 0.00717251 0.00088185\n",
      " 0.00051975 0.00081652 0.001384   0.00114779 0.00039893 0.00033744] \n",
      " -0.4802721\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.00625782e-03 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.75469337e-03 8.26032541e-02 2.17772215e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 9.76220275e-02 5.60700876e-01\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.00625782e-03 6.25782228e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [4.4389986e-04 5.0222408e-04 3.2932326e-04 8.2987663e-04 5.2890280e-04\n",
      " 1.0814928e-04 4.9981021e-04 3.0008696e-03 8.6408192e-03 8.1352003e-02\n",
      " 4.7192816e-04 9.2220516e-04 4.5661806e-04 1.1132207e-02 4.7273743e-03\n",
      " 2.1795410e-01 1.8558423e-01 6.1671546e-04 5.4168759e-04 1.2894480e-01\n",
      " 1.5774801e-01 3.8311859e-03 8.6331172e-03 6.5254967e-04 3.1459448e-04\n",
      " 4.1466160e-04 1.6573782e-01 9.4048148e-03 2.9167938e-03 5.2523019e-04\n",
      " 1.0516562e-04 2.8479521e-04 7.3047291e-04 2.9753154e-04 4.9554714e-04\n",
      " 3.1997738e-04] \n",
      " 0.047458082\n",
      "p [[0.00125156 0.00125156 0.00375469 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00500626 0.03754693 0.00750939 0.00250313 0.00125156]\n",
      " [0.00125156 0.0212766  0.68210263 0.07133917 0.00750939 0.00125156]\n",
      " [0.00125156 0.00500626 0.04881101 0.         0.03128911 0.00250313]\n",
      " [0.00125156 0.00250313 0.00750939 0.0350438  0.00375469 0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.00250313 0.00125156 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.1197808e-03 6.4856163e-04 2.1106750e-03 1.2552363e-03 5.4838473e-04\n",
      " 7.0589676e-04 6.7731267e-04 4.3884502e-03 2.6297778e-02 2.7333996e-01\n",
      " 2.6279336e-03 1.0585373e-03 1.6681708e-03 1.5908951e-02 7.4105227e-04\n",
      " 5.8062583e-02 8.4783994e-03 1.3442079e-03 6.5336912e-04 9.1073215e-03\n",
      " 5.3961374e-02 6.9491012e-04 1.8138744e-02 2.1783374e-03 1.4505114e-03\n",
      " 1.1976322e-03 4.8105925e-01 1.8443370e-02 6.0582706e-03 4.2929142e-04\n",
      " 1.9355226e-04 6.4669974e-04 1.1189107e-03 1.2537002e-03 5.9077726e-04\n",
      " 8.4218796e-04] \n",
      " -0.76981854\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 1.50187735e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 0.00000000e+00 8.01001252e-02\n",
      "  5.06883605e-01 1.25156446e-13]\n",
      " [1.25156446e-13 3.62953692e-02 1.78973717e-01 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.73967459e-01 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.3190347e-03 1.6601775e-03 1.7485657e-03 1.0089220e-03 3.9030141e-03\n",
      " 3.2406609e-04 5.8081688e-04 1.2261432e-02 7.3319483e-03 2.4268189e-02\n",
      " 1.4449928e-03 1.9043362e-02 1.0510928e-03 5.6832917e-03 6.3959108e-04\n",
      " 2.8501767e-01 1.8959660e-03 1.8089639e-03 2.3208270e-03 1.6249133e-03\n",
      " 5.4725677e-01 7.1615027e-04 6.9229174e-03 1.0308296e-03 6.3553103e-03\n",
      " 1.2847810e-03 4.3167505e-02 3.9216769e-03 8.1935031e-03 4.2097110e-04\n",
      " 7.5481286e-05 2.7008317e-03 7.0541189e-04 1.1328507e-03 7.3459669e-04\n",
      " 4.4361778e-04] \n",
      " -0.4169703\n",
      "p [[0.00125156 0.00125156 0.00375469 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00250313 0.03254068 0.19399249 0.00125156 0.00125156]\n",
      " [0.00125156 0.03629537 0.         0.04505632 0.         0.00125156]\n",
      " [0.00125156 0.01877347 0.04630788 0.         0.01501877 0.00125156]\n",
      " [0.00125156 0.00250313 0.56445557 0.01001252 0.00375469 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01113337 0.00321898 0.0160076  0.01215073 0.00414242 0.00460318\n",
      " 0.00394764 0.03701859 0.17048395 0.0301726  0.02887475 0.00572072\n",
      " 0.01099898 0.04442135 0.00205023 0.03165902 0.05759887 0.0146471\n",
      " 0.00496973 0.05222892 0.03667104 0.00119905 0.05653967 0.02715779\n",
      " 0.00903089 0.02079696 0.07137275 0.12421966 0.05975719 0.00575592\n",
      " 0.00056998 0.00851147 0.00836367 0.01493418 0.00375546 0.00531565] \n",
      " -0.9375645\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-13 2.50312891e-03]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 4.75594493e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 9.38673342e-01 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.4792084e-03 4.5826621e-03 1.7698396e-03 2.6783240e-03 1.4236035e-02\n",
      " 4.3067150e-03 2.7877267e-03 2.0829594e-02 1.2121026e-03 1.3399024e-02\n",
      " 2.1748737e-02 5.7639476e-02 5.9697693e-03 2.0681354e-01 1.2537977e-04\n",
      " 2.1365160e-02 1.9355869e-02 1.4988860e-02 8.0943778e-03 2.5729118e-02\n",
      " 4.8016366e-02 8.6947475e-05 3.6626965e-01 9.1936272e-03 1.9799367e-02\n",
      " 2.8346749e-02 3.4367152e-02 9.1910100e-04 1.7364116e-02 3.7019078e-03\n",
      " 7.5470563e-04 1.1220390e-02 1.9467892e-03 8.6124195e-04 1.7875871e-03\n",
      " 1.2528797e-03] \n",
      " 0.96469265\n",
      "p [[0.00500626 0.00125156 0.01001252 0.00625782 0.00125156 0.00125156]\n",
      " [0.00125156 0.02002503 0.10638298 0.01877347 0.01376721 0.00250313]\n",
      " [0.00500626 0.0350438  0.         0.0212766  0.         0.00625782]\n",
      " [0.00250313 0.07133917 0.         0.         0.02878598 0.01501877]\n",
      " [0.00500626 0.0350438  0.         0.3942428  0.16020025 0.00250313]\n",
      " [0.00125156 0.00375469 0.00375469 0.0175219  0.00125156 0.00250313]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.6327761e-03 1.7901682e-03 5.7580797e-03 6.2949476e-03 2.2370275e-03\n",
      " 2.5700559e-03 2.9277282e-03 2.1912912e-01 6.9243731e-03 4.0642964e-03\n",
      " 7.6753825e-02 1.0305402e-02 5.3626257e-03 4.9144304e-03 3.9203381e-04\n",
      " 1.9993582e-03 1.4253199e-02 4.2872233e-03 1.3072218e-03 2.7139572e-02\n",
      " 4.4005602e-03 2.2842445e-04 3.4958993e-03 2.0698765e-02 5.2949609e-03\n",
      " 1.4355978e-01 1.4287644e-02 6.2025269e-03 3.7506211e-01 5.0600455e-03\n",
      " 2.8820918e-04 3.4696483e-03 6.2916256e-03 4.3520094e-03 2.4839654e-03\n",
      " 1.7805059e-03] \n",
      " -0.9238513\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-03 7.50938673e-03]\n",
      " [1.25156446e-13 2.12765957e-02 0.00000000e+00 7.50938673e-03\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-03 5.00625782e-02 0.00000000e+00 0.00000000e+00\n",
      "  8.83604506e-01 5.00625782e-03]\n",
      " [3.75469337e-03 6.25782228e-03 0.00000000e+00 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.54982221e-03 1.14194155e-02 4.43461060e-04 1.15380134e-03\n",
      " 5.79190962e-02 4.46554692e-03 2.46149092e-03 3.60920560e-03\n",
      " 7.26889528e-04 1.51461107e-03 1.61044896e-01 7.94449449e-03\n",
      " 4.12786901e-02 1.47199701e-03 6.14209494e-05 8.42823926e-03\n",
      " 9.30508226e-03 1.07270982e-02 1.06336055e-02 3.58264223e-02\n",
      " 2.01455709e-02 2.77427353e-05 1.77045912e-03 2.16822669e-01\n",
      " 3.54460254e-03 3.47331733e-01 6.88034575e-03 5.62835892e-04\n",
      " 2.92207417e-03 6.48372993e-03 4.56317910e-04 1.52015705e-02\n",
      " 1.03052740e-03 1.17275646e-04 2.09869212e-03 1.61862385e-03] \n",
      " 0.99807566\n",
      "p [[0.00250313 0.00125156 0.00375469 0.00375469 0.00125156 0.00125156]\n",
      " [0.00125156 0.14518148 0.00375469 0.00250313 0.04630788 0.00625782]\n",
      " [0.00250313 0.00375469 0.         0.00125156 0.         0.00250313]\n",
      " [0.00125156 0.01627034 0.         0.         0.         0.03379224]\n",
      " [0.00250313 0.21902378 0.         0.         0.48435544 0.00250313]\n",
      " [0.00125156 0.00125156 0.00375469 0.00250313 0.00125156 0.00125156]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.1493218e-03 1.4540895e-04 3.2741567e-03 2.0054765e-03 3.0147025e-04\n",
      " 5.5433507e-04 5.2157147e-03 3.7812986e-04 1.0869616e-03 2.0222180e-03\n",
      " 4.2360112e-01 6.9109112e-04 1.8919614e-04 2.7196039e-04 2.3174740e-04\n",
      " 5.6626435e-05 8.0149167e-04 2.7395750e-04 1.8777771e-04 1.3591376e-03\n",
      " 1.9339856e-04 3.1808569e-05 8.9915273e-05 3.9548517e-04 4.9007661e-04\n",
      " 5.2156377e-01 1.7776106e-02 8.2961906e-04 8.4415841e-04 9.5510567e-03\n",
      " 1.2823426e-04 6.1183533e-04 1.0419775e-03 1.6762769e-03 2.5143064e-04\n",
      " 7.2773086e-04] \n",
      " 0.94549465\n",
      "p [[1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.37672090e-02 1.25156446e-03]\n",
      " [5.00625782e-03 1.25156446e-13 0.00000000e+00 1.25156446e-03\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-03 1.31414268e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.02252816e-01]\n",
      " [1.25156446e-13 3.37922403e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 149 completed in 28.969013214111328 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5762267 entropy 2.0676227\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5625393 entropy 2.0526276\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.539171 entropy 2.034196\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.511376 entropy 2.0190332\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.481735 entropy 2.0125275\n",
      "kl 0.020651402\n",
      "completed in 0.3058490753173828 s\n",
      "game 150 completed in 6.63103985786438 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6404648 entropy 2.00464\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.629332 entropy 2.0143487\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6102366 entropy 2.0251014\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5856824 entropy 2.033965\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5576131 entropy 2.0397391\n",
      "kl 0.014987107\n",
      "completed in 0.37210702896118164 s\n",
      "game 151 completed in 14.06033992767334 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5735428 entropy 2.0456088\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5610228 entropy 2.046008\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5427823 entropy 2.0474691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.5208752 entropy 2.0509877\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4984875 entropy 2.0549254\n",
      "kl 0.018998353\n",
      "completed in 0.2735579013824463 s\n",
      "game 152 completed in 11.737589120864868 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5543447 entropy 2.0843728\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5434191 entropy 2.0866818\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.521036 entropy 2.0868626\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4928875 entropy 2.083051\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4628017 entropy 2.0739834\n",
      "kl 0.019413665\n",
      "completed in 0.30977416038513184 s\n",
      "game 153 completed in 9.334385871887207 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6279364 entropy 2.0643926\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6191573 entropy 2.0569062\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6010766 entropy 2.053857\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5769465 entropy 2.0537674\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5513804 entropy 2.0541458\n",
      "kl 0.017032247\n",
      "completed in 0.3091011047363281 s\n",
      "game 154 completed in 8.414687871932983 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5579743 entropy 1.9918067\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5407786 entropy 1.9815161\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5159245 entropy 1.9662685\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4893668 entropy 1.9529016\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4628844 entropy 1.9465809\n",
      "kl 0.029140001\n",
      "completed in 0.2800109386444092 s\n",
      "game 155 completed in 6.6251771450042725 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5931797 entropy 1.9743679\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5707285 entropy 1.9888954\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5378842 entropy 2.0102813\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.515879 entropy 2.0325656\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5021076 entropy 2.0504599\n",
      "kl 0.02133642\n",
      "completed in 0.33084893226623535 s\n",
      "game 156 completed in 7.540160894393921 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6316807 entropy 2.0663495\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6132402 entropy 2.0696278\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5803218 entropy 2.0671296\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.544788 entropy 2.0617995\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5144246 entropy 2.0564551\n",
      "kl 0.020674206\n",
      "completed in 0.3070862293243408 s\n",
      "game 157 completed in 15.847087860107422 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.566026 entropy 2.0605683\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5544357 entropy 2.056514\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5300336 entropy 2.05406\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.501774 entropy 2.052374\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4753983 entropy 2.0500317\n",
      "kl 0.01797503\n",
      "completed in 0.30058789253234863 s\n",
      "game 158 completed in 6.486098051071167 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5995686 entropy 2.0702894\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5843341 entropy 2.0646873\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.555375 entropy 2.0573435\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5296326 entropy 2.0501268\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5062344 entropy 2.0442789\n",
      "kl 0.017663242\n",
      "completed in 0.3434572219848633 s\n",
      "game 159 completed in 9.441680192947388 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4722915 entropy 2.0272908\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4593663 entropy 2.023984\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4360728 entropy 2.0212727\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4104016 entropy 2.0192876\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3879411 entropy 2.0171998\n",
      "kl 0.020229913\n",
      "completed in 0.32698702812194824 s\n",
      "game 160 completed in 15.627954959869385 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.585785 entropy 2.0497737\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5749457 entropy 2.0534372\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5557096 entropy 2.0588753\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5313926 entropy 2.0631423\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.504879 entropy 2.0642414\n",
      "kl 0.014797416\n",
      "completed in 0.3022787570953369 s\n",
      "game 161 completed in 11.188553810119629 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5086358 entropy 1.9825388\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.486483 entropy 1.9825925\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.458496 entropy 1.9845184\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4375827 entropy 1.98686\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4187186 entropy 1.9879849\n",
      "kl 0.018856343\n",
      "completed in 0.27291226387023926 s\n",
      "game 162 completed in 6.616745948791504 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5425453 entropy 2.0443106\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5283067 entropy 2.038\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.507285 entropy 2.0297093\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.485028 entropy 2.0244367\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.461302 entropy 2.0250335\n",
      "kl 0.020802746\n",
      "completed in 0.31429409980773926 s\n",
      "game 163 completed in 10.506386995315552 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5294807 entropy 2.0108962\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5134304 entropy 2.024754\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4922082 entropy 2.0380976\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4669383 entropy 2.043822\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.439426 entropy 2.0385418\n",
      "kl 0.024909163\n",
      "completed in 0.29708194732666016 s\n",
      "game 164 completed in 8.541591882705688 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4929821 entropy 2.033812\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4804444 entropy 2.0098732\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4615579 entropy 1.9885856\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.440027 entropy 1.9775693\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4164646 entropy 1.9794054\n",
      "kl 0.0187888\n",
      "completed in 0.2888679504394531 s\n",
      "game 165 completed in 11.301771879196167 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5770414 entropy 2.0306385\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5670671 entropy 2.0455875\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5495656 entropy 2.0573592\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.529185 entropy 2.062716\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.505901 entropy 2.0620365\n",
      "kl 0.013543442\n",
      "completed in 0.3313558101654053 s\n",
      "game 166 completed in 11.936302185058594 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5209389 entropy 2.0046115\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.503638 entropy 1.9997946\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4745457 entropy 1.9969971\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4446461 entropy 1.997665\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4154978 entropy 2.0008223\n",
      "kl 0.016516577\n",
      "completed in 0.32095789909362793 s\n",
      "game 167 completed in 10.822500944137573 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5642161 entropy 2.0310316\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.554136 entropy 2.0400057\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.534191 entropy 2.0487523\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5121112 entropy 2.0532131\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4891703 entropy 2.050963\n",
      "kl 0.016250852\n",
      "completed in 0.27207398414611816 s\n",
      "game 168 completed in 6.480170965194702 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5346808 entropy 1.9935632\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.524807 entropy 1.9825511\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5030468 entropy 1.9715192\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4756968 entropy 1.9630388\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4465034 entropy 1.9583478\n",
      "kl 0.017608546\n",
      "completed in 0.29453301429748535 s\n",
      "game 169 completed in 12.630638837814331 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.491118 entropy 1.9860874\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.478025 entropy 1.9839015\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4585152 entropy 1.9796069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4343028 entropy 1.974662\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4082208 entropy 1.9705105\n",
      "kl 0.017386802\n",
      "completed in 0.2720987796783447 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 170 completed in 6.458950996398926 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5074334 entropy 1.9594774\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.498131 entropy 1.9649265\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4813256 entropy 1.9744551\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4604154 entropy 1.9838535\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4372718 entropy 1.989606\n",
      "kl 0.021534726\n",
      "completed in 0.3274109363555908 s\n",
      "game 171 completed in 13.406502962112427 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.517257 entropy 1.99558\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5014498 entropy 1.9876359\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4764862 entropy 1.976443\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4483066 entropy 1.9672275\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4187982 entropy 1.9627252\n",
      "kl 0.014756557\n",
      "completed in 0.32091593742370605 s\n",
      "game 172 completed in 9.380391120910645 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6112843 entropy 1.9600842\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.593923 entropy 1.9666874\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.571054 entropy 1.9741005\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5459452 entropy 1.9779711\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5182648 entropy 1.9748802\n",
      "kl 0.018471938\n",
      "completed in 0.33482813835144043 s\n",
      "game 173 completed in 19.777266025543213 s 22 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5664759 entropy 1.9610023\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5453777 entropy 1.944789\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5191374 entropy 1.9282708\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5010521 entropy 1.9186082\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4799085 entropy 1.9199386\n",
      "kl 0.024870317\n",
      "completed in 0.3921079635620117 s\n",
      "game 174 completed in 11.77311110496521 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.490596 entropy 1.9515529\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4675632 entropy 1.9717549\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4385464 entropy 1.992696\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.41084 entropy 2.0080068\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3820634 entropy 2.0136924\n",
      "kl 0.01869446\n",
      "completed in 0.3341398239135742 s\n",
      "game 175 completed in 13.504333019256592 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5221949 entropy 1.981235\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5127661 entropy 1.9784036\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.496126 entropy 1.9787476\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.475888 entropy 1.9831939\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4529393 entropy 1.9908047\n",
      "kl 0.015081979\n",
      "completed in 0.3204841613769531 s\n",
      "game 176 completed in 6.469862699508667 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5025637 entropy 2.029049\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4858963 entropy 2.0412135\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4652238 entropy 2.0531764\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4435933 entropy 2.0608423\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4204779 entropy 2.061649\n",
      "kl 0.012897618\n",
      "completed in 0.31183505058288574 s\n",
      "game 177 completed in 7.354429244995117 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5165265 entropy 2.0771284\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.498644 entropy 2.0635357\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.473017 entropy 2.0465713\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4477606 entropy 2.0316186\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4253705 entropy 2.0224576\n",
      "kl 0.017181452\n",
      "completed in 0.29949116706848145 s\n",
      "game 178 completed in 8.289806842803955 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5318418 entropy 1.961386\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5166159 entropy 1.9607712\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4920824 entropy 1.9603378\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.464957 entropy 1.9586589\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4407647 entropy 1.955327\n",
      "kl 0.011317113\n",
      "completed in 0.272899866104126 s\n",
      "game 179 completed in 8.251654863357544 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4471707 entropy 1.9579804\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.433134 entropy 1.9572875\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.407325 entropy 1.9582665\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.38188 entropy 1.9592292\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3619447 entropy 1.9575756\n",
      "kl 0.018360052\n",
      "completed in 0.27264904975891113 s\n",
      "game 180 completed in 7.361114025115967 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4996645 entropy 1.9582012\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.485796 entropy 1.949434\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4660902 entropy 1.9387765\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4445417 entropy 1.9292985\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4202924 entropy 1.9232416\n",
      "kl 0.021787528\n",
      "completed in 0.29883480072021484 s\n",
      "game 181 completed in 9.075720071792603 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.526643 entropy 1.9097563\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5039675 entropy 1.9110336\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4745367 entropy 1.91472\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.447653 entropy 1.9194026\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.417905 entropy 1.9239823\n",
      "kl 0.021525517\n",
      "completed in 0.3739311695098877 s\n",
      "game 182 completed in 10.87804102897644 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.514063 entropy 1.922775\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4990704 entropy 1.9318098\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4765089 entropy 1.9430332\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.447179 entropy 1.9536617\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4176018 entropy 1.9617436\n",
      "kl 0.022056252\n",
      "completed in 0.27178406715393066 s\n",
      "game 183 completed in 8.355628967285156 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5164073 entropy 1.9496046\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4927986 entropy 1.9529061\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4685035 entropy 1.9552734\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4478438 entropy 1.9571272\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4296505 entropy 1.9581435\n",
      "kl 0.018441863\n",
      "completed in 0.2766072750091553 s\n",
      "game 184 completed in 8.299047946929932 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5650287 entropy 2.0073419\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.550113 entropy 2.00488\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5231292 entropy 2.0014381\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4978158 entropy 2.0000556\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4754207 entropy 2.0009208\n",
      "kl 0.015777428\n",
      "completed in 0.2581770420074463 s\n",
      "game 185 completed in 9.17085313796997 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5649257 entropy 2.010797\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5443127 entropy 2.0125406\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5098476 entropy 2.0108778\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4770436 entropy 2.0043263\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4500582 entropy 1.9928862\n",
      "kl 0.018101852\n",
      "completed in 0.2541928291320801 s\n",
      "game 186 completed in 15.777281999588013 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5500696 entropy 1.990947\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5384245 entropy 1.9798625\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.514822 entropy 1.9723598\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4848883 entropy 1.969626\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.45512 entropy 1.9713509\n",
      "kl 0.021551067\n",
      "completed in 0.3007540702819824 s\n",
      "game 187 completed in 6.576903343200684 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5136292 entropy 1.9392114\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5008914 entropy 1.948292\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4834058 entropy 1.9565036\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4665143 entropy 1.960526\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4497602 entropy 1.95877\n",
      "kl 0.014657892\n",
      "completed in 0.2954671382904053 s\n",
      "game 188 completed in 8.336735963821411 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6868486 entropy 1.9367954\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6653728 entropy 1.9307063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.4444444444444444 loss 2.630588 entropy 1.9274209\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5954578 entropy 1.9297274\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5646107 entropy 1.9378735\n",
      "kl 0.029360456\n",
      "completed in 0.31229376792907715 s\n",
      "game 189 completed in 13.835817098617554 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5603397 entropy 1.9579097\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5493808 entropy 1.9732056\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5309215 entropy 1.9889369\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5092378 entropy 2.0008054\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4863632 entropy 2.0055833\n",
      "kl 0.025677526\n",
      "completed in 0.2822086811065674 s\n",
      "game 190 completed in 6.576099157333374 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6121686 entropy 2.0230322\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5965106 entropy 2.0163128\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5716574 entropy 2.006259\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5432422 entropy 1.9965935\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5127442 entropy 1.989742\n",
      "kl 0.026062934\n",
      "completed in 0.3451709747314453 s\n",
      "game 191 completed in 7.513829231262207 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6003268 entropy 1.9725096\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5776532 entropy 1.9747937\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5517492 entropy 1.9793446\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5272868 entropy 1.9815954\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5014803 entropy 1.977872\n",
      "kl 0.024499621\n",
      "completed in 0.2860829830169678 s\n",
      "game 192 completed in 8.396498918533325 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.537209 entropy 1.934984\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5259202 entropy 1.9209855\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5077841 entropy 1.9083731\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4890924 entropy 1.9018015\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4686313 entropy 1.9036485\n",
      "kl 0.019366972\n",
      "completed in 0.2646660804748535 s\n",
      "game 193 completed in 11.090810775756836 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.722477 entropy 1.9796102\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6976428 entropy 1.9975166\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6672225 entropy 2.0180755\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6409125 entropy 2.0347934\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.613594 entropy 2.0437355\n",
      "kl 0.020052407\n",
      "completed in 0.28266310691833496 s\n",
      "game 194 completed in 9.163399934768677 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6106918 entropy 2.0322862\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.592683 entropy 2.0264053\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5713367 entropy 2.0173588\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5507557 entropy 2.0097406\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5304425 entropy 2.0065682\n",
      "kl 0.021912776\n",
      "completed in 0.29387497901916504 s\n",
      "game 195 completed in 10.039163827896118 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.588005 entropy 1.9920516\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.575299 entropy 1.9954118\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5515096 entropy 1.9983491\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5208015 entropy 1.99758\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.487231 entropy 1.9911935\n",
      "kl 0.017581474\n",
      "completed in 0.30660390853881836 s\n",
      "game 196 completed in 6.549278974533081 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5759325 entropy 1.9679577\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5619633 entropy 1.954119\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.541891 entropy 1.9408121\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.519872 entropy 1.9301593\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4965167 entropy 1.9235476\n",
      "kl 0.018560942\n",
      "completed in 0.2791259288787842 s\n",
      "game 197 completed in 8.106541872024536 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.573203 entropy 1.9113274\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.557857 entropy 1.9142103\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5342984 entropy 1.919233\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.506598 entropy 1.9237766\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4787714 entropy 1.9265805\n",
      "kl 0.014806937\n",
      "completed in 0.3280656337738037 s\n",
      "game 198 completed in 15.75629997253418 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.582273 entropy 1.9249555\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5691988 entropy 1.9242172\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.547264 entropy 1.9215331\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5214646 entropy 1.9178464\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.49359 entropy 1.913765\n",
      "kl 0.014328404\n",
      "completed in 0.35724902153015137 s\n",
      "prediction:\n",
      " [0.00039991 0.00041375 0.00152518 0.00079726 0.00115858 0.00037711\n",
      " 0.00062803 0.00823333 0.02270162 0.01078972 0.00311392 0.00069363\n",
      " 0.00149612 0.02571712 0.3592841  0.06426528 0.01599015 0.00112906\n",
      " 0.00121839 0.01034486 0.05192505 0.34165865 0.02678154 0.00143063\n",
      " 0.00058971 0.00156097 0.01037702 0.0245952  0.00632234 0.00046646\n",
      " 0.00059162 0.00061804 0.0011423  0.00085175 0.00042436 0.00038728] \n",
      " -0.22776936\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 2.29036295e-01 2.60325407e-01\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 5.00625782e-03 1.31414268e-01 3.51689612e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [2.47997086e-04 3.59099358e-04 3.87833774e-04 5.95218269e-04\n",
      " 3.62726423e-04 6.32662486e-05 3.43814725e-04 2.63569294e-03\n",
      " 4.18258132e-03 1.35852829e-01 4.93323896e-04 3.55889817e-04\n",
      " 8.32070189e-04 4.34937887e-03 7.80866388e-03 2.26556912e-01\n",
      " 1.80981129e-01 4.96717752e-04 3.93088238e-04 8.51887912e-02\n",
      " 2.16721654e-01 4.28813323e-03 5.29888319e-03 5.98784653e-04\n",
      " 2.71833589e-04 5.08610567e-04 1.10204384e-01 4.84780455e-03\n",
      " 2.70315213e-03 2.60058645e-04 1.89283135e-04 1.68779516e-04\n",
      " 6.48603658e-04 2.23154289e-04 3.65680113e-04 2.14264684e-04] \n",
      " 0.3592688\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00500626 0.02377972 0.00500626 0.00250313 0.00125156]\n",
      " [0.00125156 0.01126408 0.82352941 0.02878598 0.00625782 0.00125156]\n",
      " [0.00125156 0.00375469 0.02377972 0.         0.0175219  0.00250313]\n",
      " [0.00125156 0.00125156 0.00375469 0.01251564 0.00250313 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00250313 0.00125156 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0051876  0.00094237 0.00452074 0.00422485 0.00130364 0.00126554\n",
      " 0.00063212 0.00507072 0.06785891 0.26995996 0.00284796 0.0016941\n",
      " 0.00307078 0.00867989 0.00250428 0.02248649 0.05351891 0.00173436\n",
      " 0.00089699 0.03196815 0.01794286 0.00364465 0.01306083 0.00391728\n",
      " 0.00310675 0.00145094 0.39428407 0.05071662 0.0077715  0.0009474\n",
      " 0.00060261 0.00197133 0.00528368 0.00261253 0.00070797 0.00161073] \n",
      " -0.26358852\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.87734668e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 4.06758448e-01\n",
      "  2.57822278e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.50187735e-02 1.85231539e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.16395494e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [4.0644125e-04 3.0482150e-04 2.2863599e-03 7.6419307e-04 3.5069688e-04\n",
      " 9.1059708e-05 3.5743372e-04 1.3951068e-03 4.5311946e-01 5.8942633e-03\n",
      " 2.3483667e-03 3.8434469e-04 4.1664994e-04 2.2857166e-03 9.0250623e-04\n",
      " 1.9820560e-02 7.1520351e-02 7.8349136e-04 3.6775821e-04 5.7484508e-02\n",
      " 1.6732160e-02 4.7428790e-04 3.0302666e-03 3.3019940e-04 2.9908086e-04\n",
      " 2.2859389e-03 4.6567293e-03 3.4565544e-01 9.1464637e-04 2.6709726e-04\n",
      " 1.1488061e-04 1.9425534e-04 8.8179728e-04 2.3223006e-03 3.4639335e-04\n",
      " 2.1053966e-04] \n",
      " 0.8605338\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.10012516 0.40050063 0.00125156 0.00125156]\n",
      " [0.00125156 0.00625782 0.         0.         0.0212766  0.00125156]\n",
      " [0.00125156 0.05882353 0.0951189  0.         0.00500626 0.00125156]\n",
      " [0.00125156 0.00125156 0.25531915 0.02628285 0.00250313 0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01490502 0.00081803 0.36822546 0.00471176 0.01611933 0.00090158\n",
      " 0.00157028 0.0062026  0.00684049 0.01427363 0.02558693 0.01741711\n",
      " 0.00360964 0.002554   0.00070914 0.00172467 0.22039059 0.00347355\n",
      " 0.00212849 0.12602764 0.00196101 0.00048573 0.001859   0.00227577\n",
      " 0.03908427 0.00950555 0.00892147 0.00573758 0.00636155 0.00165706\n",
      " 0.00050898 0.04003602 0.00611698 0.02873413 0.00063746 0.0079276 ] \n",
      " -0.5654227\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 5.63204005e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.87734668e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.00125156e-02 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 9.13642053e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.0386828e-03 2.1531943e-03 6.8452263e-01 7.3895871e-04 1.0500057e-03\n",
      " 6.6370347e-05 2.4910823e-03 1.5671523e-03 3.8184500e-03 2.3984222e-02\n",
      " 1.0645015e-03 5.5017676e-03 9.6588267e-04 4.1759470e-03 1.1155640e-03\n",
      " 6.4586834e-03 2.1405290e-03 7.1963371e-04 1.1755727e-03 5.2409666e-04\n",
      " 3.8645626e-03 9.8817423e-04 8.8275736e-03 2.3890488e-04 2.2736560e-03\n",
      " 2.0680118e-03 2.6517572e-02 8.4611978e-03 1.1193563e-03 3.2957147e-03\n",
      " 7.2745017e-05 2.8774561e-04 1.9186992e-03 1.9189116e-01 2.4885309e-03\n",
      " 4.1346491e-04] \n",
      " 0.9057873\n",
      "p [[0.00750939 0.00125156 0.19899875 0.00125156 0.12015019 0.00125156]\n",
      " [0.00125156 0.00375469 0.00500626 0.         0.01627034 0.01001252]\n",
      " [0.00125156 0.00125156 0.         0.         0.10888611 0.00125156]\n",
      " [0.00125156 0.21276596 0.00125156 0.         0.00125156 0.00125156]\n",
      " [0.17271589 0.00500626 0.00500626 0.         0.00250313 0.00125156]\n",
      " [0.00125156 0.01877347 0.00375469 0.08635795 0.00125156 0.00500626]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.35447244e-03 5.39696426e-04 1.41912894e-02 6.92373549e-04\n",
      " 7.47660846e-02 1.21090612e-04 7.91504630e-04 1.62965979e-03\n",
      " 1.57404831e-03 1.65041853e-02 2.37785978e-03 1.19077019e-01\n",
      " 9.62723279e-04 7.01277691e-04 1.16591495e-04 1.24978294e-04\n",
      " 1.16202259e-03 1.43405690e-03 1.45504612e-03 4.01030469e-04\n",
      " 8.37060870e-05 9.95711816e-05 2.47691962e-04 3.90126114e-03\n",
      " 4.61035699e-01 6.43925800e-04 6.22732285e-03 1.54588255e-03\n",
      " 2.82147946e-03 6.73693488e-04 9.16310819e-05 2.69525409e-01\n",
      " 1.16321235e-03 3.98098864e-03 5.53425751e-04 3.42831668e-03] \n",
      " 0.79634815\n",
      "p [[1.25156446e-13 1.25156446e-13 6.38297872e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 9.33667084e-01\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]]\n",
      "1 won\n",
      "game 199 completed in 21.0070641040802 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.684174 entropy 1.9410069\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6678734 entropy 1.9445736\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6403353 entropy 1.950057\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6074991 entropy 1.954963\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5738816 entropy 1.9583066\n",
      "kl 0.018692905\n",
      "completed in 0.3295009136199951 s\n",
      "game 200 completed in 14.446519136428833 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.568389 entropy 1.9256473\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.558913 entropy 1.9265025\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5427284 entropy 1.9277906\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5245447 entropy 1.9295268\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.501951 entropy 1.9318211\n",
      "kl 0.008432675\n",
      "completed in 0.30202293395996094 s\n",
      "game 201 completed in 11.793284893035889 s 13 steps\n",
      "training 0 lr_mult 0.6666666666666666 loss 2.671682 entropy 1.9711945\n",
      "training 1 lr_mult 0.6666666666666666 loss 2.6363297 entropy 1.9777467\n",
      "training 2 lr_mult 0.6666666666666666 loss 2.5877547 entropy 1.9827094\n",
      "training 3 lr_mult 0.6666666666666666 loss 2.5389073 entropy 1.9852749\n",
      "training 4 lr_mult 0.6666666666666666 loss 2.4926536 entropy 1.9851904\n",
      "kl 0.04956223\n",
      "completed in 0.2980468273162842 s\n",
      "game 202 completed in 9.80559778213501 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5702045 entropy 1.9409453\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.554154 entropy 1.9421356\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5197048 entropy 1.9453354\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4788325 entropy 1.9490573\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4417355 entropy 1.9507582\n",
      "kl 0.021885067\n",
      "completed in 0.3141660690307617 s\n",
      "game 203 completed in 8.37817907333374 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.623741 entropy 2.0057337\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5968657 entropy 2.0000598\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5568771 entropy 1.9895709\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5217814 entropy 1.9775577\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4940243 entropy 1.9661937\n",
      "kl 0.023147535\n",
      "completed in 0.2792339324951172 s\n",
      "game 204 completed in 7.588904857635498 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5585527 entropy 1.9508518\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5439343 entropy 1.9468577\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5197825 entropy 1.9442065\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4936733 entropy 1.9386886\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4683511 entropy 1.9272983\n",
      "kl 0.026256554\n",
      "completed in 0.28436923027038574 s\n",
      "game 205 completed in 6.744158744812012 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6161146 entropy 1.8851057\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5898516 entropy 1.8725643\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5529592 entropy 1.865894\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.525609 entropy 1.8671391\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5037618 entropy 1.8759061\n",
      "kl 0.023299867\n",
      "completed in 0.2977612018585205 s\n",
      "game 206 completed in 14.53436803817749 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6762705 entropy 1.9212635\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6588707 entropy 1.9347918\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6300561 entropy 1.9433582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.596302 entropy 1.9460986\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.565359 entropy 1.9444479\n",
      "kl 0.021461569\n",
      "completed in 0.2874124050140381 s\n",
      "game 207 completed in 8.309786081314087 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5653176 entropy 1.9009669\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5539622 entropy 1.8993216\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5339258 entropy 1.9005649\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.504907 entropy 1.9059503\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4723845 entropy 1.9151117\n",
      "kl 0.010967992\n",
      "completed in 0.2773261070251465 s\n",
      "game 208 completed in 7.49965500831604 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.561783 entropy 1.9668969\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.546373 entropy 1.9836254\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5255272 entropy 1.9988457\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5001495 entropy 2.0075643\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4720137 entropy 2.0066137\n",
      "kl 0.01575269\n",
      "completed in 0.276447057723999 s\n",
      "game 209 completed in 11.223277807235718 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5964518 entropy 2.0018358\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5779665 entropy 1.9849597\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5520942 entropy 1.9658632\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5216763 entropy 1.951031\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4884896 entropy 1.9437072\n",
      "kl 0.018455569\n",
      "completed in 0.2758469581604004 s\n",
      "game 210 completed in 9.238059997558594 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5472746 entropy 1.9046109\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5301993 entropy 1.9095055\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5034819 entropy 1.9159427\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4724877 entropy 1.9189643\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4404764 entropy 1.9149389\n",
      "kl 0.018925304\n",
      "completed in 0.28624796867370605 s\n",
      "game 211 completed in 8.27898097038269 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4992507 entropy 1.9023921\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4831967 entropy 1.8883357\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4620507 entropy 1.873849\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4375243 entropy 1.8633566\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4092352 entropy 1.85934\n",
      "kl 0.017320469\n",
      "completed in 0.29668593406677246 s\n",
      "game 212 completed in 10.092453002929688 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6617837 entropy 1.8872557\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6461442 entropy 1.8927476\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6139953 entropy 1.8992238\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5718377 entropy 1.9025352\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.528026 entropy 1.9015677\n",
      "kl 0.023640927\n",
      "completed in 0.36990880966186523 s\n",
      "game 213 completed in 6.5405519008636475 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4764407 entropy 1.8796393\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4652426 entropy 1.8799124\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4444997 entropy 1.8831857\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4198384 entropy 1.8877077\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3943324 entropy 1.8912385\n",
      "kl 0.019152263\n",
      "completed in 0.29488205909729004 s\n",
      "game 214 completed in 8.424178838729858 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5930574 entropy 1.8830607\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5779011 entropy 1.8776977\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.551325 entropy 1.8705152\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.520727 entropy 1.866008\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.488771 entropy 1.8671427\n",
      "kl 0.027879989\n",
      "completed in 0.27283787727355957 s\n",
      "game 215 completed in 8.61339807510376 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5828085 entropy 1.8973384\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5637553 entropy 1.9154017\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5393064 entropy 1.9368417\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5183835 entropy 1.9552772\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.497255 entropy 1.9658844\n",
      "kl 0.03521067\n",
      "completed in 0.32375001907348633 s\n",
      "game 216 completed in 6.526853322982788 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.514424 entropy 1.9769349\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4967015 entropy 1.9710811\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4711878 entropy 1.9608684\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4468439 entropy 1.9518633\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4215653 entropy 1.9484911\n",
      "kl 0.0275012\n",
      "completed in 0.2756831645965576 s\n",
      "game 217 completed in 12.813127756118774 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.619088 entropy 1.9844939\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5991914 entropy 1.9892788\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5710764 entropy 1.9934287\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5388954 entropy 1.9927127\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.50601 entropy 1.9851689\n",
      "kl 0.018801425\n",
      "completed in 0.3076038360595703 s\n",
      "game 218 completed in 15.495567083358765 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4289496 entropy 1.9137489\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4160166 entropy 1.9019853\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.397076 entropy 1.8915198\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3748498 entropy 1.8841335\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3507447 entropy 1.880166\n",
      "kl 0.01725958\n",
      "completed in 0.2518041133880615 s\n",
      "game 219 completed in 7.510861158370972 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5020142 entropy 1.9073532\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4892807 entropy 1.9014933\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4691281 entropy 1.8911574\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.445149 entropy 1.8774383\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4202785 entropy 1.8629458\n",
      "kl 0.019437198\n",
      "completed in 0.26474618911743164 s\n",
      "game 220 completed in 13.532945156097412 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6132941 entropy 1.845628\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5935705 entropy 1.8403388\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5627887 entropy 1.8419391\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5292423 entropy 1.8492669\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4969742 entropy 1.8601103\n",
      "kl 0.018272184\n",
      "completed in 0.3375077247619629 s\n",
      "game 221 completed in 14.386400938034058 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5302958 entropy 1.8470261\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5179245 entropy 1.8597116\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4978652 entropy 1.871095\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.474876 entropy 1.8784992\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4494812 entropy 1.881125\n",
      "kl 0.016327914\n",
      "completed in 0.3545870780944824 s\n",
      "game 222 completed in 9.026938199996948 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5854876 entropy 1.8909607\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5712626 entropy 1.8903444\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5474923 entropy 1.8927782\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5191267 entropy 1.8986564\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4898112 entropy 1.9070833\n",
      "kl 0.016370006\n",
      "completed in 0.2772221565246582 s\n",
      "game 223 completed in 7.853283166885376 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5503354 entropy 1.9030857\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.540007 entropy 1.9121349\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5206676 entropy 1.9196364\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4957511 entropy 1.923997\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4685519 entropy 1.9244211\n",
      "kl 0.017205069\n",
      "completed in 0.31600499153137207 s\n",
      "game 224 completed in 6.680330038070679 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6009407 entropy 1.9532418\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5808582 entropy 1.9471323\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5491261 entropy 1.9390061\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5136378 entropy 1.9317398\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4761477 entropy 1.9263542\n",
      "kl 0.020649996\n",
      "completed in 0.2859029769897461 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 225 completed in 6.393316984176636 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4991663 entropy 1.9108657\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4858656 entropy 1.9156811\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.465602 entropy 1.9220943\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4409888 entropy 1.924587\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.410747 entropy 1.9192758\n",
      "kl 0.019379085\n",
      "completed in 0.30483317375183105 s\n",
      "game 226 completed in 15.209891080856323 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5654564 entropy 1.9006944\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5494153 entropy 1.8864427\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5256371 entropy 1.874154\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4964068 entropy 1.8672496\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4645233 entropy 1.8672738\n",
      "kl 0.02404314\n",
      "completed in 0.2996358871459961 s\n",
      "game 227 completed in 7.348884105682373 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6046185 entropy 1.9198359\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5938385 entropy 1.9269032\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5741026 entropy 1.9325055\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5466633 entropy 1.9345818\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.516482 entropy 1.9328413\n",
      "kl 0.014053235\n",
      "completed in 0.27739787101745605 s\n",
      "game 228 completed in 11.196433067321777 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4918127 entropy 1.9071888\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4800234 entropy 1.9056041\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4600708 entropy 1.9055288\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.43493 entropy 1.9070704\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4082272 entropy 1.9096909\n",
      "kl 0.0160015\n",
      "completed in 0.28661513328552246 s\n",
      "game 229 completed in 11.817652225494385 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5589662 entropy 1.9218562\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5391083 entropy 1.9226351\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5101607 entropy 1.9200941\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4834533 entropy 1.9145434\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.459494 entropy 1.907455\n",
      "kl 0.01923676\n",
      "completed in 0.3410031795501709 s\n",
      "game 230 completed in 14.625240087509155 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5810676 entropy 1.906405\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5666683 entropy 1.9060397\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.539964 entropy 1.9108038\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.508897 entropy 1.9181447\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4785829 entropy 1.9240152\n",
      "kl 0.022859644\n",
      "completed in 0.29813098907470703 s\n",
      "game 231 completed in 6.546989917755127 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6378093 entropy 1.9125841\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6259081 entropy 1.9137452\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.604633 entropy 1.9143947\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5796137 entropy 1.9138839\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5534594 entropy 1.9123514\n",
      "kl 0.013587086\n",
      "completed in 0.34198904037475586 s\n",
      "game 232 completed in 11.191402912139893 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4582644 entropy 1.8960614\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4409332 entropy 1.8921782\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.416378 entropy 1.8877867\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3904886 entropy 1.8842934\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3628523 entropy 1.8824818\n",
      "kl 0.018594366\n",
      "completed in 0.2790088653564453 s\n",
      "game 233 completed in 12.124486923217773 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6153438 entropy 1.9382153\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5939262 entropy 1.9465301\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5662742 entropy 1.9580135\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5387108 entropy 1.9688327\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5120585 entropy 1.9768698\n",
      "kl 0.013120037\n",
      "completed in 0.2884101867675781 s\n",
      "game 234 completed in 10.006738901138306 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5504231 entropy 1.9405925\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5354092 entropy 1.9454261\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5076883 entropy 1.9508005\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4781477 entropy 1.9549986\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4500184 entropy 1.9556656\n",
      "kl 0.021353822\n",
      "completed in 0.30161190032958984 s\n",
      "game 235 completed in 13.563730239868164 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5033708 entropy 1.9264891\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4867666 entropy 1.9157486\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.45903 entropy 1.9021213\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4245012 entropy 1.8891253\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3905146 entropy 1.8791989\n",
      "kl 0.025912331\n",
      "completed in 0.29871201515197754 s\n",
      "game 236 completed in 9.402137994766235 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6075208 entropy 1.9600387\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5944033 entropy 1.956506\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5722246 entropy 1.95457\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5450659 entropy 1.9555871\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5159864 entropy 1.9600381\n",
      "kl 0.015974753\n",
      "completed in 0.3132750988006592 s\n",
      "game 237 completed in 6.675530910491943 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6581364 entropy 1.9816605\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6357968 entropy 1.9962378\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6072888 entropy 2.013237\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5778317 entropy 2.027051\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5451884 entropy 2.0334463\n",
      "kl 0.025755974\n",
      "completed in 0.32422900199890137 s\n",
      "game 238 completed in 13.699319839477539 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6037157 entropy 1.9735091\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5720246 entropy 1.9652523\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5279517 entropy 1.954746\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4853156 entropy 1.9478383\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4438338 entropy 1.9468315\n",
      "kl 0.022647098\n",
      "completed in 0.2707970142364502 s\n",
      "game 239 completed in 9.281696796417236 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.498067 entropy 1.9057279\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4801037 entropy 1.9159029\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4553115 entropy 1.9235234\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4265113 entropy 1.9238801\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3968647 entropy 1.915168\n",
      "kl 0.024483703\n",
      "completed in 0.26984071731567383 s\n",
      "game 240 completed in 9.629955768585205 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5338297 entropy 1.9192084\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.514662 entropy 1.9061341\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4826334 entropy 1.8969121\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4458358 entropy 1.8929181\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4091697 entropy 1.8924971\n",
      "kl 0.015097106\n",
      "completed in 0.35454607009887695 s\n",
      "game 241 completed in 11.366980075836182 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5906544 entropy 1.9291943\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5657046 entropy 1.9313006\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5316207 entropy 1.9333291\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5000489 entropy 1.9331775\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.467633 entropy 1.9302322\n",
      "kl 0.019592451\n",
      "completed in 0.2756209373474121 s\n",
      "game 242 completed in 17.254013776779175 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.682422 entropy 1.9324532\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6562917 entropy 1.9285599\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.620684 entropy 1.9266043\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5841172 entropy 1.9270996\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.547944 entropy 1.9296026\n",
      "kl 0.021266304\n",
      "completed in 0.3397209644317627 s\n",
      "game 243 completed in 13.51131820678711 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6221025 entropy 1.9460195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1 lr_mult 0.4444444444444444 loss 2.6094606 entropy 1.9440656\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5827973 entropy 1.9377578\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5499394 entropy 1.9299382\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5155375 entropy 1.9234649\n",
      "kl 0.022881396\n",
      "completed in 0.3625211715698242 s\n",
      "game 244 completed in 11.919777154922485 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6247814 entropy 1.87263\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6085837 entropy 1.8788085\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.579803 entropy 1.8908823\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.545654 entropy 1.9045248\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5094879 entropy 1.9156435\n",
      "kl 0.020032551\n",
      "completed in 0.2966949939727783 s\n",
      "game 245 completed in 11.766352891921997 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6051311 entropy 1.9468118\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.580579 entropy 1.9448255\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5477705 entropy 1.9410119\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5159163 entropy 1.9406962\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4798214 entropy 1.9469135\n",
      "kl 0.019858832\n",
      "completed in 0.3484621047973633 s\n",
      "game 246 completed in 9.100653171539307 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.613045 entropy 1.9806364\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5847826 entropy 1.9950452\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.553753 entropy 2.0059335\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.530697 entropy 2.0091264\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5041218 entropy 2.0034811\n",
      "kl 0.020137645\n",
      "completed in 0.3203468322753906 s\n",
      "game 247 completed in 9.280673742294312 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5684516 entropy 1.9776177\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5534153 entropy 1.9714997\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5255425 entropy 1.9700305\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.492588 entropy 1.9717087\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4601707 entropy 1.97365\n",
      "kl 0.019394923\n",
      "completed in 0.2664189338684082 s\n",
      "game 248 completed in 9.292335987091064 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6007779 entropy 1.9546852\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5781167 entropy 1.9550853\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5449257 entropy 1.953331\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5097542 entropy 1.9484977\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4763806 entropy 1.9406676\n",
      "kl 0.020800635\n",
      "completed in 0.28300905227661133 s\n",
      "prediction:\n",
      " [4.4946792e-04 8.1941549e-04 4.3070209e-03 2.5293049e-03 6.8793283e-04\n",
      " 1.1500333e-03 9.0237282e-04 1.2080150e-03 7.7344785e-03 2.6535438e-02\n",
      " 1.0026035e-02 8.2501490e-04 2.4194645e-03 9.9518597e-03 4.1218109e-02\n",
      " 3.9697620e-01 2.6657822e-02 2.7588760e-03 2.8736128e-03 2.7441669e-02\n",
      " 3.0106777e-01 4.7066655e-02 8.2745329e-03 2.0539134e-03 1.1775156e-03\n",
      " 1.1851760e-02 3.4492802e-02 1.3867494e-02 2.9342801e-03 1.0785301e-03\n",
      " 1.0616581e-03 4.6402798e-04 3.1386972e-03 2.8486110e-03 9.3206816e-04\n",
      " 2.1759383e-04] \n",
      " -0.22010393\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 7.00876095e-02 5.20650814e-01\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 2.50312891e-03 1.57697121e-01 2.31539424e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.6778154e-05 3.8414847e-04 2.5938023e-04 3.6497807e-04 1.8857217e-04\n",
      " 1.2876451e-04 2.1166586e-04 3.0291034e-04 7.3475897e-02 5.1474087e-03\n",
      " 1.4816106e-03 1.1331127e-04 3.6081369e-04 7.5489432e-02 3.6086884e-01\n",
      " 2.6965863e-03 6.3809389e-03 2.9167521e-04 3.3773389e-04 5.1934337e-03\n",
      " 3.0622561e-03 2.3098379e-01 7.1792074e-02 6.3060602e-04 1.8967182e-04\n",
      " 1.1225698e-03 3.3171410e-03 1.5375781e-01 1.3745489e-04 2.3665064e-04\n",
      " 6.0829621e-05 1.4311748e-04 1.5200947e-04 2.2033771e-04 4.5325889e-04\n",
      " 2.5673182e-05] \n",
      " 0.046243757\n",
      "p [[0.00125156 0.00125156 0.00125156 0.02878598 0.06633292 0.02252816]\n",
      " [0.00125156 0.00250313 0.00375469 0.06382979 0.03629537 0.00125156]\n",
      " [0.00125156 0.00500626 0.0350438  0.         0.05131414 0.00125156]\n",
      " [0.00125156 0.10137672 0.29411765 0.06132666 0.00375469 0.00375469]\n",
      " [0.02002503 0.07008761 0.04881101 0.0175219  0.00500626 0.00375469]\n",
      " [0.00125156 0.00125156 0.0350438  0.00500626 0.00125156 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00116431 0.00353663 0.00206943 0.00237328 0.00078972 0.00304217\n",
      " 0.00134339 0.00227503 0.02654089 0.01157952 0.00841168 0.00166581\n",
      " 0.00505037 0.45455155 0.01760037 0.00519175 0.04842179 0.00822847\n",
      " 0.0030044  0.02189985 0.00490821 0.04157331 0.23628223 0.00354218\n",
      " 0.00163233 0.01004731 0.01787401 0.04027106 0.00358939 0.00138552\n",
      " 0.00136269 0.00076606 0.00415827 0.00098547 0.0018412  0.00104042] \n",
      " -0.4171915\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.87984981e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 7.50938673e-03 8.64831039e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 4.13016270e-02\n",
      "  3.12891114e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.62703379e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.7427626e-04 7.9483667e-04 2.1965186e-04 2.2565755e-03 1.0867673e-03\n",
      " 6.6769449e-04 5.8492000e-04 9.9179121e-03 3.3280786e-02 5.7640988e-03\n",
      " 1.2337680e-03 3.5584808e-04 3.6082041e-04 5.6723515e-03 3.7980448e-03\n",
      " 3.4742343e-04 6.6535389e-01 6.4767376e-03 2.9415467e-03 1.6823763e-01\n",
      " 1.5241925e-04 4.1462840e-03 5.6490004e-03 7.4905605e-04 1.2719770e-03\n",
      " 7.8986114e-04 4.0922314e-03 6.4682305e-02 4.3726508e-03 6.5488252e-04\n",
      " 4.5078472e-04 1.1484387e-03 6.0504297e-04 1.4336227e-04 7.2947703e-04\n",
      " 4.3674535e-04] \n",
      " 0.5398466\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.01877347 0.00750939 0.00500626 0.00125156]\n",
      " [0.00250313 0.46683354 0.         0.         0.03003755 0.00500626]\n",
      " [0.00125156 0.0387985  0.         0.1301627  0.19524406 0.00250313]\n",
      " [0.00125156 0.00625782 0.01001252 0.05131414 0.00250313 0.00125156]\n",
      " [0.00125156 0.00125156 0.00375469 0.00250313 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00102105 0.03280092 0.00693794 0.00186668 0.00126141 0.00210975\n",
      " 0.04163935 0.00936388 0.14810793 0.00557853 0.00657711 0.00072961\n",
      " 0.00209505 0.00610091 0.00117405 0.00381917 0.0071144  0.31991076\n",
      " 0.0397897  0.00293063 0.00070408 0.00431926 0.00396238 0.00248251\n",
      " 0.00132977 0.00395236 0.00649439 0.26426035 0.00912901 0.03425843\n",
      " 0.00161927 0.00130605 0.00135449 0.00229672 0.02079051 0.00081163] \n",
      " -0.9444676\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 8.76095119e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  9.58698373e-01 1.25156446e-13]\n",
      " [1.25156446e-13 2.00250313e-02 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.12640801e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [7.7860354e-04 3.8189399e-03 1.6330514e-03 4.7377683e-03 4.3481183e-03\n",
      " 8.4303453e-04 5.4881268e-04 4.4626392e-02 1.2076823e-01 1.4538345e-02\n",
      " 7.1700248e-03 3.8471124e-03 2.5249163e-03 3.9323114e-02 9.9848667e-03\n",
      " 7.5697951e-04 7.1472498e-03 6.4785525e-02 1.9814072e-02 8.6288620e-03\n",
      " 2.8493296e-04 8.9488914e-03 4.2688571e-02 6.0231183e-03 8.3868699e-03\n",
      " 1.8836987e-03 2.3105150e-02 5.2462268e-01 1.2519362e-02 1.3380552e-03\n",
      " 4.2913895e-04 3.7489950e-03 1.4201300e-03 9.0888492e-04 2.4358886e-03\n",
      " 6.3174579e-04] \n",
      " 0.96724516\n",
      "p [[0.00125156 0.0212766  0.00500626 0.00125156 0.00125156 0.00125156]\n",
      " [0.03254068 0.00625782 0.10763454 0.00375469 0.00375469 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.48435544]\n",
      " [0.02628285 0.00125156 0.         0.00375469 0.00250313 0.00125156]\n",
      " [0.00125156 0.00250313 0.00375469 0.23529412 0.00625782 0.02252816]\n",
      " [0.00125156 0.00125156 0.00125156 0.00250313 0.01376721 0.00125156]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00366628 0.0922474  0.01882439 0.01433143 0.00644765 0.00234269\n",
      " 0.04056478 0.01676364 0.038057   0.01343566 0.13367648 0.01720641\n",
      " 0.00821223 0.01310928 0.01371962 0.00609697 0.01743968 0.11216517\n",
      " 0.02543869 0.0123323  0.00118216 0.03921892 0.01401877 0.01452082\n",
      " 0.02539553 0.06592429 0.01214564 0.04367868 0.02686392 0.0752995\n",
      " 0.00457088 0.00349576 0.01513724 0.00459321 0.0457008  0.00217631] \n",
      " -0.96496856\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.00125156e-02 5.13141427e-02 3.75469337e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.75469337e-03 2.50312891e-03 0.00000000e+00 1.25156446e-03\n",
      "  1.37672090e-02 2.50312891e-03]\n",
      " [2.50312891e-03 1.25156446e-13 3.75469337e-03 8.94868586e-01\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00279447 0.0084946  0.00487023 0.00896099 0.00571616 0.00302608\n",
      " 0.00320028 0.20438582 0.01265472 0.03221572 0.01516927 0.01027065\n",
      " 0.01433812 0.0844113  0.00547787 0.00176749 0.02839907 0.04027645\n",
      " 0.01586926 0.04596527 0.00129951 0.0030477  0.13611871 0.03009756\n",
      " 0.02509415 0.00511101 0.07172771 0.06059724 0.08485344 0.00971833\n",
      " 0.00112496 0.0038598  0.00701913 0.00212046 0.00641195 0.00353477] \n",
      " 0.8146745\n",
      "p [[0.00125156 0.06382979 0.00876095 0.02002503 0.00250313 0.00125156]\n",
      " [0.02002503 0.00750939 0.02503129 0.00750939 0.06382979 0.01001252]\n",
      " [0.00500626 0.         0.         0.         0.         0.        ]\n",
      " [0.01376721 0.00625782 0.         0.56070088 0.01877347 0.00625782]\n",
      " [0.01251564 0.0350438  0.02503129 0.         0.01627034 0.0350438 ]\n",
      " [0.00125156 0.00125156 0.00750939 0.00125156 0.0212766  0.00125156]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.2548827e-03 5.8009505e-02 6.9429176e-03 2.0908939e-02 7.4864756e-03\n",
      " 1.9953446e-03 5.1728755e-02 1.4127728e-02 2.3206402e-02 1.3294727e-02\n",
      " 3.4420762e-02 2.8589796e-02 6.9492008e-03 1.6932881e-03 2.2297389e-04\n",
      " 3.0042543e-03 9.0208828e-02 2.1055697e-01 9.0578198e-02 9.0393879e-02\n",
      " 1.3853719e-03 1.2003169e-04 9.0688613e-04 9.3089342e-03 2.5321603e-02\n",
      " 2.4507876e-02 1.4077005e-02 3.3763215e-02 2.2865605e-02 5.2226007e-02\n",
      " 5.0807823e-03 8.1061274e-03 7.7027930e-03 6.9669914e-04 3.7458342e-02\n",
      " 8.9894742e-04] \n",
      " -0.9724609\n",
      "p [[0.00125156 0.00750939 0.09011264 0.06257822 0.00125156 0.00125156]\n",
      " [0.00250313 0.04255319 0.00375469 0.00750939 0.00250313 0.00250313]\n",
      " [0.04255319 0.         0.         0.         0.         0.        ]\n",
      " [0.01001252 0.01501877 0.         0.         0.27909887 0.02377972]\n",
      " [0.01376721 0.00125156 0.06758448 0.         0.22277847 0.04130163]\n",
      " [0.00125156 0.00125156 0.00250313 0.00125156 0.05006258 0.00125156]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.3787981e-04 3.0553756e-02 2.3544203e-03 2.5301820e-03 4.5627179e-03\n",
      " 2.1759467e-03 1.6232066e-02 3.9899188e-01 7.8470167e-03 1.1378677e-03\n",
      " 4.6196751e-02 5.4009573e-04 4.0292041e-03 6.0712523e-04 2.7947315e-05\n",
      " 1.6841108e-05 2.2275434e-04 3.0067766e-02 4.3948688e-02 2.8131463e-04\n",
      " 2.3797153e-05 1.2710371e-05 3.1319589e-04 4.7509009e-03 1.4744754e-03\n",
      " 2.0292036e-02 4.2831409e-03 4.5782134e-02 2.6373821e-01 3.5935272e-02\n",
      " 7.5163355e-04 3.4031852e-03 1.3388958e-03 1.1670986e-03 2.3649916e-02\n",
      " 4.2137015e-04] \n",
      " 0.62231404\n",
      "p [[1.25156446e-03 7.50938673e-03 1.25156446e-03 2.50312891e-03\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [6.25782228e-03 1.25156446e-03 2.50312891e-03 1.25156446e-03\n",
      "  3.75469337e-03 2.50312891e-03]\n",
      " [1.25156446e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.75344180e-02 9.13642053e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [2.50312891e-03 2.50312891e-03 1.25156446e-03 0.00000000e+00\n",
      "  2.50312891e-03 6.25782228e-03]\n",
      " [1.25156446e-03 1.25156446e-03 1.25156446e-03 1.25156446e-13\n",
      "  5.00625782e-03 1.25156446e-13]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.08247195e-04 6.61488026e-02 3.49581079e-03 6.61514513e-03\n",
      " 5.18254144e-03 9.47731663e-04 1.37168579e-02 1.10594332e-01\n",
      " 2.12217751e-03 6.32412499e-03 2.17850432e-01 1.69139653e-02\n",
      " 2.17189663e-03 5.73678233e-04 1.01574275e-04 1.51421162e-04\n",
      " 6.77441189e-04 2.63138767e-02 2.68390272e-02 2.46306881e-04\n",
      " 1.07693850e-04 7.49239625e-05 2.23907875e-04 4.29635681e-03\n",
      " 7.43927481e-03 1.97233483e-01 7.50482548e-03 2.66970834e-03\n",
      " 1.77784428e-01 1.57770403e-02 2.76679639e-03 4.36288491e-03\n",
      " 2.14986922e-03 7.50547333e-04 6.86298758e-02 3.32988886e-04] \n",
      " -0.94329417\n",
      "p [[0.00375469 0.01251564 0.00876095 0.00500626 0.01126408 0.00375469]\n",
      " [0.00750939 0.12891114 0.00625782 0.00375469 0.02377972 0.00375469]\n",
      " [0.00500626 0.         0.         0.         0.         0.        ]\n",
      " [0.5494368  0.         0.         0.         0.         0.01501877]\n",
      " [0.00500626 0.00750939 0.01001252 0.         0.09762203 0.02628285]\n",
      " [0.01501877 0.00750939 0.00500626 0.00375469 0.03003755 0.00375469]]\n",
      "move 18\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.5671780e-04 2.9019838e-02 1.9247389e-03 5.3704078e-03 1.0115073e-02\n",
      " 7.0475363e-03 2.5958138e-02 4.4595432e-01 2.5436203e-03 1.7920806e-03\n",
      " 6.9016349e-03 6.6204497e-04 6.4084888e-03 9.9437241e-04 7.9191987e-06\n",
      " 1.5047358e-05 3.9054285e-04 1.6481284e-02 2.4118882e-02 5.7449512e-04\n",
      " 2.3306715e-05 4.7662074e-06 2.8782053e-04 6.5754256e-03 2.5957190e-03\n",
      " 3.3247403e-03 4.2152209e-03 1.6694004e-02 2.8825524e-01 5.6599729e-02\n",
      " 1.5081753e-03 6.4389049e-03 3.0579502e-03 8.0423662e-04 2.1998547e-02\n",
      " 7.7907817e-04] \n",
      " 0.4545701\n",
      "p [[1.25156446e-13 1.37672090e-02 1.25156446e-13 2.50312891e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [2.50312891e-03 6.25782228e-02 1.25156446e-13 1.25156446e-03\n",
      "  2.75344180e-02 2.50312891e-03]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-03 8.48560701e-01 1.25156446e-03 0.00000000e+00\n",
      "  2.37797247e-02 2.50312891e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  8.76095119e-03 1.25156446e-13]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [4.1235802e-03 4.7215555e-02 1.1148435e-02 6.3070590e-03 2.3364323e-01\n",
      " 3.6224984e-02 5.1956702e-02 1.5888344e-02 8.6930608e-03 3.9535942e-03\n",
      " 2.1664632e-02 5.4161273e-02 2.6121123e-03 2.0595477e-03 3.8064318e-05\n",
      " 2.1854715e-04 3.7565929e-04 3.7717089e-02 9.8224565e-02 1.5507810e-04\n",
      " 5.3355761e-04 2.9231107e-05 1.1371489e-03 1.7666448e-02 1.5024746e-02\n",
      " 2.0842036e-02 3.5565351e-03 4.9929237e-03 3.9347403e-02 3.5943154e-02\n",
      " 2.5159776e-02 1.4528312e-01 3.7140315e-03 4.5354213e-03 4.3345921e-02\n",
      " 2.5076659e-03] \n",
      " -0.9279361\n",
      "p [[0.01877347 0.04255319 0.02753442 0.03379224 0.0350438  0.00750939]\n",
      " [0.0350438  0.23529412 0.02377972 0.01001252 0.02753442 0.03128911]\n",
      " [0.0387985  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.03254068]\n",
      " [0.02753442 0.         0.00625782 0.         0.13892365 0.05381727]\n",
      " [0.02628285 0.02252816 0.02503129 0.03254068 0.04755945 0.02002503]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.2738842e-02 6.9120586e-02 1.0667744e-02 1.4432549e-02 7.2984518e-03\n",
      " 5.5500902e-03 1.6177484e-01 2.8265536e-02 6.1431699e-03 1.9082548e-03\n",
      " 3.3804163e-02 1.8492248e-03 2.7440296e-02 4.2605526e-03 3.0291800e-05\n",
      " 3.1785734e-05 1.5362019e-03 6.7375794e-02 5.5613518e-02 2.0760286e-03\n",
      " 8.9660614e-05 1.9910798e-05 7.1970711e-04 8.6965803e-03 8.0371723e-03\n",
      " 2.0329760e-02 7.3631126e-03 1.7173516e-02 2.5286756e-02 3.1885561e-01\n",
      " 6.8901293e-04 6.3490858e-03 9.4630923e-03 7.2498983e-03 4.8396748e-02\n",
      " 9.3624685e-03] \n",
      " -0.07808449\n",
      "p [[1.25156446e-13 7.50938673e-03 1.25156446e-03 1.25156446e-13\n",
      "  4.00500626e-02 3.75469337e-03]\n",
      " [6.25782228e-03 0.00000000e+00 1.25156446e-03 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-02]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [2.50312891e-03 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  2.50312891e-03 2.50312891e-03]\n",
      " [2.50312891e-03 9.04881101e-01 1.25156446e-13 1.25156446e-13\n",
      "  1.00125156e-02 1.25156446e-13]]\n",
      "move 31\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0. -1.  0.  1.  0.  0.]\n",
      " [ 0. -1.  0.  0.  0.  0.]]\n",
      "-1 won\n",
      "game 249 completed in 34.28823971748352 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.619172 entropy 1.9364188\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.607935 entropy 1.9289227\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5849493 entropy 1.9239044\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5572078 entropy 1.9232076\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.526263 entropy 1.9271576\n",
      "kl 0.017030813\n",
      "completed in 0.332690954208374 s\n",
      "game 250 completed in 7.719831228256226 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5608807 entropy 1.9378693\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5435884 entropy 1.9461747\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5166936 entropy 1.9524845\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.486449 entropy 1.9540021\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4561052 entropy 1.9500961\n",
      "kl 0.019980919\n",
      "completed in 0.30774664878845215 s\n",
      "game 251 completed in 6.753077030181885 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5729914 entropy 1.9535336\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5587063 entropy 1.9421825\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5362365 entropy 1.9321842\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.50913 entropy 1.9253012\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4790952 entropy 1.9217122\n",
      "kl 0.018225713\n",
      "completed in 0.27709197998046875 s\n",
      "game 252 completed in 8.496665000915527 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5346937 entropy 1.9462984\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5173583 entropy 1.9460626\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4895005 entropy 1.9419154\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.456122 entropy 1.9349263\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4210448 entropy 1.9272172\n",
      "kl 0.015591342\n",
      "completed in 0.27336692810058594 s\n",
      "game 253 completed in 6.59407377243042 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5149906 entropy 1.867331\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4997246 entropy 1.8689977\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4761417 entropy 1.8745259\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.448964 entropy 1.881618\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4198043 entropy 1.8880222\n",
      "kl 0.016440948\n",
      "completed in 0.2933969497680664 s\n",
      "game 254 completed in 14.792857885360718 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6425455 entropy 1.9503944\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6287475 entropy 1.9555466\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6041627 entropy 1.9608572\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5736995 entropy 1.9658425\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.540983 entropy 1.9702371\n",
      "kl 0.013687868\n",
      "completed in 0.2514657974243164 s\n",
      "game 255 completed in 6.657797813415527 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.607712 entropy 1.9814029\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5914872 entropy 1.9805037\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5654223 entropy 1.9752238\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5345063 entropy 1.9672503\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5003295 entropy 1.9585521\n",
      "kl 0.017019127\n",
      "completed in 0.2771608829498291 s\n",
      "game 256 completed in 18.408782720565796 s 20 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5354433 entropy 1.9349213\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5201263 entropy 1.9330807\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4945524 entropy 1.9339584\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.464946 entropy 1.9358015\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.434567 entropy 1.9368173\n",
      "kl 0.013777966\n",
      "completed in 0.2762432098388672 s\n",
      "game 257 completed in 12.519836187362671 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4514272 entropy 1.8865585\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4353898 entropy 1.8809164\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4114926 entropy 1.8737069\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.382859 entropy 1.8667568\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3512223 entropy 1.861405\n",
      "kl 0.023437103\n",
      "completed in 0.29099416732788086 s\n",
      "game 258 completed in 8.231259822845459 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6042948 entropy 1.9544389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5887675 entropy 1.9535608\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5584152 entropy 1.952645\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5212002 entropy 1.9513117\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4835634 entropy 1.9488959\n",
      "kl 0.017769275\n",
      "completed in 0.27092504501342773 s\n",
      "game 259 completed in 7.573559045791626 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.542984 entropy 1.8643444\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5283027 entropy 1.8667817\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4978247 entropy 1.8734225\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4565291 entropy 1.8822434\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.413934 entropy 1.8902271\n",
      "kl 0.022903115\n",
      "completed in 0.31946492195129395 s\n",
      "game 260 completed in 6.701925039291382 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.624512 entropy 1.9640529\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6044984 entropy 1.9682902\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.574857 entropy 1.9721963\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.542648 entropy 1.9759414\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5088675 entropy 1.9788718\n",
      "kl 0.02325587\n",
      "completed in 0.28130412101745605 s\n",
      "game 261 completed in 8.442107915878296 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.466859 entropy 1.8904566\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4520307 entropy 1.890013\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4247437 entropy 1.8869243\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3919084 entropy 1.8813298\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.357079 entropy 1.8744167\n",
      "kl 0.024121864\n",
      "completed in 0.2975001335144043 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 262 completed in 10.265758037567139 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5964773 entropy 1.9317849\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5819833 entropy 1.933647\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5502264 entropy 1.9402487\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5111625 entropy 1.947894\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4733603 entropy 1.9531326\n",
      "kl 0.02360173\n",
      "completed in 0.28708600997924805 s\n",
      "game 263 completed in 6.717137813568115 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.520391 entropy 1.9646741\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5016775 entropy 1.9592588\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4751496 entropy 1.951565\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4483438 entropy 1.9456602\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4208696 entropy 1.9429346\n",
      "kl 0.024529796\n",
      "completed in 0.31358909606933594 s\n",
      "game 264 completed in 6.501478910446167 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5955396 entropy 1.9220634\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.580866 entropy 1.9295173\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5534399 entropy 1.9398391\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5210366 entropy 1.9484625\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4857569 entropy 1.9523637\n",
      "kl 0.022959493\n",
      "completed in 0.3044860363006592 s\n",
      "game 265 completed in 13.81905198097229 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5843973 entropy 1.9609189\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.570769 entropy 1.9595156\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5442324 entropy 1.9579823\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.513667 entropy 1.9571148\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4838517 entropy 1.9568717\n",
      "kl 0.018670041\n",
      "completed in 0.28852295875549316 s\n",
      "game 266 completed in 10.084723234176636 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.558759 entropy 1.902087\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5419827 entropy 1.8999883\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5112693 entropy 1.8942835\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.474081 entropy 1.885462\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4364965 entropy 1.8749592\n",
      "kl 0.021954361\n",
      "completed in 0.31639695167541504 s\n",
      "game 267 completed in 7.5122129917144775 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5034146 entropy 1.89045\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4850879 entropy 1.8811272\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4589977 entropy 1.8748971\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4326038 entropy 1.8726759\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4059625 entropy 1.873383\n",
      "kl 0.018802866\n",
      "completed in 0.3683180809020996 s\n",
      "game 268 completed in 11.078291416168213 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.614392 entropy 1.9360807\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5973651 entropy 1.9338202\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5668225 entropy 1.9287777\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5319695 entropy 1.9226208\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4976988 entropy 1.9162376\n",
      "kl 0.024054848\n",
      "completed in 0.32056188583374023 s\n",
      "game 269 completed in 10.24444580078125 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4769387 entropy 1.8430693\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4598162 entropy 1.8375702\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.430411 entropy 1.8332489\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3951647 entropy 1.8308966\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3602684 entropy 1.8306358\n",
      "kl 0.022882964\n",
      "completed in 0.2949650287628174 s\n",
      "game 270 completed in 9.227256059646606 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.604894 entropy 1.8443983\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5875509 entropy 1.8484653\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.556552 entropy 1.8537295\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.520092 entropy 1.8595092\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4838672 entropy 1.8648295\n",
      "kl 0.018369747\n",
      "completed in 0.32682323455810547 s\n",
      "game 271 completed in 16.0053768157959 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5805478 entropy 1.9038082\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5632484 entropy 1.9082427\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5404408 entropy 1.9121163\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5151675 entropy 1.9151404\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4858377 entropy 1.9175775\n",
      "kl 0.022211947\n",
      "completed in 0.3224608898162842 s\n",
      "game 272 completed in 10.908167839050293 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7316651 entropy 1.9759235\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7117321 entropy 1.984552\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.677768 entropy 1.9956148\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6380491 entropy 2.0053573\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5984516 entropy 2.0104804\n",
      "kl 0.020866217\n",
      "completed in 0.2960481643676758 s\n",
      "game 273 completed in 11.260984897613525 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5792713 entropy 2.005484\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5630476 entropy 1.9981112\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5342724 entropy 1.9866239\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5006044 entropy 1.9748012\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4686532 entropy 1.9645128\n",
      "kl 0.019645162\n",
      "completed in 0.30629611015319824 s\n",
      "game 274 completed in 8.487855195999146 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.561628 entropy 1.9560739\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.544513 entropy 1.9545546\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.517757 entropy 1.9554944\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4881182 entropy 1.9558395\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.456263 entropy 1.9533525\n",
      "kl 0.021379285\n",
      "completed in 0.27961015701293945 s\n",
      "game 275 completed in 8.520599842071533 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.53069 entropy 1.8798553\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5119002 entropy 1.8795154\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4781585 entropy 1.8807104\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.440763 entropy 1.8832614\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.405511 entropy 1.8849053\n",
      "kl 0.022214457\n",
      "completed in 0.3164830207824707 s\n",
      "game 276 completed in 8.551636934280396 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5513697 entropy 1.9423308\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5388262 entropy 1.9451487\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.513613 entropy 1.9510694\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4804597 entropy 1.9578216\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.444198 entropy 1.9628421\n",
      "kl 0.016975034\n",
      "completed in 0.28835391998291016 s\n",
      "game 277 completed in 17.543735027313232 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5811608 entropy 1.9267106\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5487053 entropy 1.923007\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5029826 entropy 1.9163929\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4532266 entropy 1.9087489\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.406438 entropy 1.9012903\n",
      "kl 0.027969684\n",
      "completed in 0.30053091049194336 s\n",
      "game 278 completed in 6.55915379524231 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.650908 entropy 1.9014426\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.635435 entropy 1.9012792\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6048615 entropy 1.9036807\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5629807 entropy 1.9061046\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5181308 entropy 1.9072781\n",
      "kl 0.021927992\n",
      "completed in 0.36477017402648926 s\n",
      "game 279 completed in 14.024510383605957 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5943062 entropy 1.8897476\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5740995 entropy 1.8896058\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5412648 entropy 1.8890922\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5016725 entropy 1.8903197\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4620094 entropy 1.8936989\n",
      "kl 0.022517402\n",
      "completed in 0.2971949577331543 s\n",
      "game 280 completed in 12.720958232879639 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5591962 entropy 1.8940992\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.543848 entropy 1.907862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.4444444444444444 loss 2.5148587 entropy 1.9250381\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4815643 entropy 1.9390936\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.444028 entropy 1.9461422\n",
      "kl 0.025131822\n",
      "completed in 0.330111026763916 s\n",
      "game 281 completed in 8.417089939117432 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6470003 entropy 1.9551235\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6250541 entropy 1.9463574\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5948584 entropy 1.9345934\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5636263 entropy 1.9265845\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5307744 entropy 1.9257863\n",
      "kl 0.027513687\n",
      "completed in 0.31581902503967285 s\n",
      "game 282 completed in 6.72403883934021 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.631058 entropy 1.9742227\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6131876 entropy 1.9896891\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.585925 entropy 2.0051908\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5577106 entropy 2.0136256\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.529294 entropy 2.0103579\n",
      "kl 0.0305946\n",
      "completed in 0.2935669422149658 s\n",
      "game 283 completed in 11.29821491241455 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5911524 entropy 1.9943694\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5665092 entropy 1.9670546\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.533097 entropy 1.937423\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5005229 entropy 1.9140747\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4649544 entropy 1.9015408\n",
      "kl 0.032556854\n",
      "completed in 0.27663397789001465 s\n",
      "game 284 completed in 10.127441883087158 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5608125 entropy 1.9187467\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5449607 entropy 1.925181\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5194001 entropy 1.9326924\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4882576 entropy 1.9365346\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.454316 entropy 1.9348319\n",
      "kl 0.02383596\n",
      "completed in 0.27959394454956055 s\n",
      "game 285 completed in 10.395869970321655 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.571513 entropy 1.9004366\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5512497 entropy 1.901505\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5187728 entropy 1.9082992\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4806097 entropy 1.9180558\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4419754 entropy 1.9274728\n",
      "kl 0.030742336\n",
      "completed in 0.2793879508972168 s\n",
      "game 286 completed in 9.321036100387573 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.664344 entropy 1.9860647\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.643995 entropy 1.983298\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6095762 entropy 1.9731317\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.573911 entropy 1.9622133\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5390286 entropy 1.9555564\n",
      "kl 0.03197199\n",
      "completed in 0.2974417209625244 s\n",
      "game 287 completed in 13.383901119232178 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5392756 entropy 1.9341295\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5178435 entropy 1.9452984\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4864156 entropy 1.9604552\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4547584 entropy 1.9739395\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4236603 entropy 1.9798768\n",
      "kl 0.036311984\n",
      "completed in 0.29706382751464844 s\n",
      "game 288 completed in 9.937574863433838 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5935657 entropy 1.9862382\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.576425 entropy 1.9774846\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5481443 entropy 1.964079\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.513767 entropy 1.9487838\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4756033 entropy 1.9342024\n",
      "kl 0.022055864\n",
      "completed in 0.3424100875854492 s\n",
      "game 289 completed in 17.352417945861816 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6204188 entropy 1.9339523\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5982819 entropy 1.9250156\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5616827 entropy 1.9183643\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5206504 entropy 1.9124854\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4788451 entropy 1.9064677\n",
      "kl 0.02234932\n",
      "completed in 0.32790136337280273 s\n",
      "game 290 completed in 9.953058958053589 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.583348 entropy 1.9032781\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5677698 entropy 1.8979285\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5431674 entropy 1.8938613\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.51215 entropy 1.8925476\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4782698 entropy 1.8947787\n",
      "kl 0.025203839\n",
      "completed in 0.3204631805419922 s\n",
      "game 291 completed in 9.38455581665039 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5344155 entropy 1.8801752\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5199718 entropy 1.8928738\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4952822 entropy 1.9067266\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4665961 entropy 1.9184122\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4358552 entropy 1.9254266\n",
      "kl 0.016116127\n",
      "completed in 0.32817816734313965 s\n",
      "game 292 completed in 7.445617198944092 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5342972 entropy 1.9560835\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5214348 entropy 1.9571635\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.496739 entropy 1.9579666\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4658968 entropy 1.9591274\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.432001 entropy 1.9607942\n",
      "kl 0.020094108\n",
      "completed in 0.3415496349334717 s\n",
      "game 293 completed in 6.5472331047058105 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5599422 entropy 1.9602292\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5368516 entropy 1.9654043\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4999626 entropy 1.9714634\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4644692 entropy 1.9760673\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4333901 entropy 1.9772274\n",
      "kl 0.019860938\n",
      "completed in 0.31588101387023926 s\n",
      "game 294 completed in 10.186867237091064 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5115092 entropy 1.9716313\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4924123 entropy 1.9629482\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4633522 entropy 1.9515238\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4294279 entropy 1.9410076\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3905866 entropy 1.9338284\n",
      "kl 0.036099005\n",
      "completed in 0.28771090507507324 s\n",
      "game 295 completed in 9.214129209518433 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.602201 entropy 1.9026043\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5889394 entropy 1.9089897\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5648928 entropy 1.916768\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.533371 entropy 1.9200537\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4963596 entropy 1.9143727\n",
      "kl 0.030119825\n",
      "completed in 0.29572391510009766 s\n",
      "game 296 completed in 15.817567110061646 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5267966 entropy 1.9340659\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5100749 entropy 1.9222857\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.482412 entropy 1.9129047\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4505994 entropy 1.9088507\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.416759 entropy 1.9103775\n",
      "kl 0.021023337\n",
      "completed in 0.3011178970336914 s\n",
      "game 297 completed in 13.92037582397461 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5373054 entropy 1.8747673\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5181832 entropy 1.876963\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4860942 entropy 1.8761578\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4491622 entropy 1.8732126\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4147785 entropy 1.8704288\n",
      "kl 0.02104995\n",
      "completed in 0.30260491371154785 s\n",
      "game 298 completed in 8.544677257537842 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5531626 entropy 1.8769164\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5339472 entropy 1.8850605\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5079355 entropy 1.8978183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.476453 entropy 1.9104099\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4392602 entropy 1.9179637\n",
      "kl 0.01990429\n",
      "completed in 0.27364301681518555 s\n",
      "prediction:\n",
      " [0.00106805 0.00218956 0.00620073 0.00477872 0.00234696 0.00336887\n",
      " 0.00293443 0.002444   0.01052963 0.06382839 0.02693655 0.00221701\n",
      " 0.00335807 0.01417227 0.06538039 0.20242853 0.04644618 0.00602467\n",
      " 0.00319874 0.07000396 0.21272123 0.07139545 0.01406004 0.00291625\n",
      " 0.00214043 0.03015892 0.084039   0.01470123 0.00473528 0.00263422\n",
      " 0.00261427 0.00126762 0.00887795 0.00406601 0.0032845  0.00053198] \n",
      " -0.39416352\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 2.44055069e-01 4.25531915e-01\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 1.31414268e-01 1.82728411e-01\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [3.48024951e-05 2.81393528e-04 1.12945097e-04 1.14628572e-04\n",
      " 1.77578986e-04 7.29099702e-05 7.84974036e-05 1.25959356e-04\n",
      " 5.49064912e-02 3.32320458e-03 1.37347449e-03 7.01447207e-05\n",
      " 2.63677764e-04 2.88902745e-02 5.25147557e-01 7.13140238e-04\n",
      " 2.03077658e-03 3.77827062e-04 2.13770967e-04 2.44648033e-03\n",
      " 7.77734909e-04 1.58518285e-01 9.32080671e-02 4.55032685e-04\n",
      " 6.73840259e-05 1.00244337e-03 4.66952566e-03 1.19448543e-01\n",
      " 5.62836940e-05 1.02435872e-04 5.76810999e-05 1.37415962e-04\n",
      " 1.16245654e-04 1.74457469e-04 4.23213642e-04 2.98558607e-05] \n",
      " 0.20300241\n",
      "p [[0.00500626 0.00125156 0.00250313 0.00125156 0.00125156 0.00250313]\n",
      " [0.00125156 0.00250313 0.00625782 0.18022528 0.01627034 0.00125156]\n",
      " [0.00250313 0.04630788 0.1126408  0.         0.05882353 0.00375469]\n",
      " [0.00125156 0.0738423  0.20275344 0.11138924 0.00750939 0.00125156]\n",
      " [0.00250313 0.02628285 0.06132666 0.04630788 0.00500626 0.00250313]\n",
      " [0.00375469 0.00125156 0.00375469 0.00125156 0.00125156 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00086537 0.00287032 0.00090419 0.00174671 0.00094679 0.00280048\n",
      " 0.00143673 0.00172381 0.02606803 0.01152077 0.0062693  0.00235418\n",
      " 0.00546113 0.4475479  0.03100487 0.00144944 0.03705636 0.0072264\n",
      " 0.00191629 0.03985034 0.00205574 0.06043664 0.23597097 0.00237822\n",
      " 0.00108175 0.00645234 0.01673887 0.03028606 0.00213784 0.00070217\n",
      " 0.00093383 0.00099887 0.00417667 0.00120143 0.00218939 0.0012399 ] \n",
      " -0.5296316\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.25406758e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.75469337e-03 8.24780976e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 3.00375469e-02\n",
      "  8.76095119e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 2.12765957e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.2864381e-04 6.5466337e-04 2.1609929e-04 7.3953433e-04 8.0379267e-04\n",
      " 4.6637756e-04 4.7116884e-04 2.4479635e-03 5.1120929e-02 6.6718115e-03\n",
      " 5.0511042e-04 1.7906634e-04 7.9537233e-05 2.0013221e-03 2.4851526e-03\n",
      " 2.9923834e-04 5.7705766e-01 7.3949946e-03 1.2960518e-03 1.7854843e-01\n",
      " 1.1174130e-04 1.9460997e-03 3.6545091e-03 1.2584181e-04 5.0435471e-04\n",
      " 5.8818003e-04 4.5549967e-03 1.5011215e-01 1.5881028e-03 3.6670879e-04\n",
      " 3.3619444e-04 6.9687556e-04 3.3768028e-04 2.5786069e-04 7.3549891e-04\n",
      " 2.1574552e-04] \n",
      " 0.63056463\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00125156 0.00125156 0.00375469]\n",
      " [0.00125156 0.00125156 0.0175219  0.00750939 0.00250313 0.00125156]\n",
      " [0.00375469 0.46558198 0.         0.         0.02002503 0.00625782]\n",
      " [0.00125156 0.08886108 0.         0.08510638 0.17521902 0.00125156]\n",
      " [0.00125156 0.00375469 0.0350438  0.05381727 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.00750939 0.00125156 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.8052297e-04 9.3375193e-03 2.1211770e-03 5.9541897e-04 1.4523794e-03\n",
      " 9.8898413e-04 1.9856870e-02 1.6964845e-03 1.3358158e-01 2.2118206e-03\n",
      " 6.0481941e-03 1.2926498e-03 2.3656806e-04 1.6476326e-03 7.0351502e-04\n",
      " 2.3366974e-04 1.8656356e-03 6.4043796e-01 3.0790962e-02 1.3023671e-03\n",
      " 1.5702962e-04 2.0463206e-03 1.3886630e-03 5.4369232e-04 8.5576379e-04\n",
      " 3.7351165e-03 2.8670444e-03 1.0813289e-01 2.4633696e-03 9.9940216e-03\n",
      " 2.6036712e-04 9.7378227e-04 9.3706552e-04 1.6080944e-03 6.8682698e-03\n",
      " 4.8681800e-04] \n",
      " -0.15088907\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  8.77346683e-01 1.25156446e-03]\n",
      " [1.25156446e-13 2.12765957e-02 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 8.76095119e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.92134078e-04 1.78681582e-03 6.43720385e-04 1.91215146e-03\n",
      " 2.46450212e-03 5.20533649e-04 3.66569788e-04 2.85112648e-03\n",
      " 1.18338026e-01 2.20273864e-02 1.49399450e-03 2.16412987e-03\n",
      " 8.92360578e-04 7.08663324e-03 1.67138269e-03 1.70688276e-04\n",
      " 4.78867861e-03 4.43919264e-02 8.63877591e-03 7.50583503e-03\n",
      " 8.94982077e-05 9.63007042e-04 2.36815643e-02 1.86933472e-03\n",
      " 3.37497261e-03 7.68010155e-04 2.68237758e-02 7.03614235e-01\n",
      " 1.41181448e-03 7.23506208e-04 3.91298730e-04 2.34605675e-03\n",
      " 1.24920264e-03 6.51995419e-04 1.29454164e-03 4.39982134e-04] \n",
      " 0.8031312\n",
      "p [[0.00125156 0.00500626 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.01001252 0.00125156 0.06633292 0.00125156 0.00250313 0.00125156]\n",
      " [0.00125156 0.         0.         0.         0.         0.79599499]\n",
      " [0.01501877 0.00250313 0.         0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00250313 0.00250313 0.06633292 0.00125156 0.00500626]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00250313 0.00125156]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.0017358  0.0387848  0.01323168 0.00962816 0.00919017 0.00354265\n",
      " 0.03687287 0.00531207 0.05067582 0.0112953  0.17300269 0.04097809\n",
      " 0.00320736 0.00932352 0.01790953 0.00179618 0.01091013 0.1874804\n",
      " 0.01891929 0.00918886 0.00098997 0.06520254 0.01153751 0.00621934\n",
      " 0.02792285 0.08766828 0.01063828 0.04092714 0.01257421 0.02938402\n",
      " 0.00229084 0.00611168 0.01088491 0.00703233 0.02540602 0.00222491] \n",
      " -0.9265573\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.63078849e-02 2.50312891e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 1.25156446e-03 0.00000000e+00 1.25156446e-13\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.75469337e-03 9.39924906e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.2086938e-03 1.3967523e-02 6.6907294e-03 4.1162875e-03 1.2771874e-02\n",
      " 1.5664246e-03 3.3709195e-03 2.4165815e-02 7.0090028e-03 9.3079843e-02\n",
      " 8.9655314e-03 7.3705669e-03 7.7586882e-03 1.4945895e-02 1.9765395e-01\n",
      " 1.0633184e-04 2.0706494e-04 1.0758005e-01 2.3204304e-02 2.2622079e-04\n",
      " 1.2776855e-04 8.6299367e-02 6.8184711e-02 6.9506755e-03 1.6624575e-02\n",
      " 1.0510747e-02 1.6986054e-01 4.7703847e-02 2.2918196e-02 7.8141950e-03\n",
      " 1.6669559e-03 4.4783326e-03 5.3234897e-03 8.6028567e-03 5.9785489e-03\n",
      " 9.8977715e-04] \n",
      " 0.91726077\n",
      "p [[0.00125156 0.0563204  0.0212766  0.01126408 0.00500626 0.00125156]\n",
      " [0.02753442 0.00250313 0.04505632 0.00625782 0.11138924 0.02628285]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.01251564 0.33416771 0.         0.09261577 0.00750939 0.00375469]\n",
      " [0.02252816 0.10638298 0.02002503 0.         0.01126408 0.03754693]\n",
      " [0.00125156 0.00250313 0.01126408 0.00375469 0.01501877 0.00125156]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.0897565e-03 2.2150271e-02 7.8776199e-03 6.7602587e-04 1.7400967e-02\n",
      " 1.1253025e-03 3.6723006e-03 1.6079824e-01 1.0468167e-02 7.8213671e-03\n",
      " 2.7631970e-02 1.2002855e-02 3.2594579e-03 1.1098237e-03 1.9974588e-05\n",
      " 1.0766925e-05 1.5397478e-04 1.1689913e-01 2.3229429e-02 4.6353369e-05\n",
      " 2.3046874e-05 5.0096383e-05 1.7830930e-03 4.1389517e-03 1.0727717e-02\n",
      " 1.8338753e-02 6.8945596e-03 5.2710893e-03 4.7909933e-01 3.9966973e-03\n",
      " 1.9516596e-03 1.1230892e-02 1.1009271e-03 3.7880735e-03 3.0671913e-02\n",
      " 2.4895598e-03] \n",
      " -0.9816683\n",
      "p [[1.25156446e-13 1.12640801e-02 6.25782228e-03 1.25156446e-13\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.87734668e-02 3.75469337e-03 1.25156446e-02\n",
      "  6.25782228e-03 2.50312891e-03]\n",
      " [2.50312891e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00125156e-02 0.00000000e+00 0.00000000e+00 6.23279099e-01\n",
      "  8.26032541e-02 3.75469337e-03]\n",
      " [1.50187735e-02 5.38172716e-02 5.88235294e-02 0.00000000e+00\n",
      "  3.50438048e-02 3.87984981e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  3.75469337e-03 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.23113383e-03 4.45234729e-03 7.87175074e-02 2.38653249e-03\n",
      " 1.27149308e-02 1.41586002e-04 6.44372660e-04 1.25377206e-02\n",
      " 2.08783336e-03 1.15992956e-01 7.46517966e-04 1.09770289e-02\n",
      " 3.55197443e-03 1.34193560e-03 1.58590046e-05 5.45349894e-06\n",
      " 2.39586043e-05 3.02770571e-03 6.97545416e-04 6.19151324e-05\n",
      " 2.38246757e-05 9.14726570e-06 8.48184433e-03 2.31007976e-03\n",
      " 1.02476384e-02 2.84342270e-04 6.76768303e-01 7.64253922e-03\n",
      " 3.52195743e-03 9.89971566e-04 6.49766065e-04 2.50496971e-03\n",
      " 4.58651409e-03 2.38989200e-02 7.44525052e-04 9.78891272e-04] \n",
      " 0.9954515\n",
      "p [[0.00125156 0.02503129 0.00375469 0.00125156 0.00876095 0.00125156]\n",
      " [0.00125156 0.2428035  0.00500626 0.00375469 0.01251564 0.00625782]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.01126408 0.         0.         0.         0.00125156 0.00125156]\n",
      " [0.00500626 0.15644556 0.00250313 0.         0.35544431 0.00125156]\n",
      " [0.00125156 0.12765957 0.00125156 0.00500626 0.01501877 0.00125156]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.89439357e-03 1.25875965e-01 1.59589667e-02 3.63128283e-03\n",
      " 8.63333195e-02 2.27916706e-03 1.62486378e-02 2.47979965e-02\n",
      " 1.53495502e-02 1.10875897e-03 1.11132674e-01 4.66629378e-02\n",
      " 6.54595951e-03 1.83931645e-03 6.08649025e-05 7.83524865e-06\n",
      " 3.12949269e-04 8.20482522e-02 1.62739772e-02 1.73055101e-04\n",
      " 9.68092627e-06 1.48259496e-04 1.98268029e-03 2.27250606e-02\n",
      " 2.92093456e-02 8.23528841e-02 1.56207161e-03 7.88700115e-03\n",
      " 1.00275896e-01 3.75655219e-02 5.33893565e-03 8.43815580e-02\n",
      " 4.14441619e-03 3.88671691e-03 4.85828295e-02 9.41151753e-03] \n",
      " -0.9756349\n",
      "p [[1.25156446e-13 1.25156446e-13 5.38172716e-02 1.25156446e-13\n",
      "  1.75219024e-02 1.25156446e-13]\n",
      " [1.25156446e-13 3.12891114e-02 1.25156446e-13 2.99123905e-01\n",
      "  1.25156446e-13 1.75219024e-02]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.00250313e-02 1.25156446e-13]\n",
      " [1.75219024e-02 1.25156446e-13 4.81852315e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 6.13266583e-02\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.52450011e-03 1.47743546e-03 5.15963435e-02 3.54221184e-03\n",
      " 1.91271678e-01 1.07027416e-04 1.49377226e-03 6.15980476e-02\n",
      " 8.16405809e-04 1.32064084e-02 3.51234572e-03 1.61125094e-01\n",
      " 2.15860363e-03 4.05115483e-04 2.19332014e-06 7.20312346e-06\n",
      " 1.67042424e-04 2.07272288e-03 4.49420535e-04 4.15206305e-04\n",
      " 6.10888455e-05 9.39958625e-07 2.26821238e-03 1.77764788e-03\n",
      " 2.77434230e-01 9.61268728e-04 1.06983699e-01 4.20175167e-03\n",
      " 1.70200486e-02 1.05581305e-03 3.80580197e-04 3.83495279e-02\n",
      " 1.72509868e-02 3.11233737e-02 1.89814600e-04 9.92378220e-04] \n",
      " 0.9929289\n",
      "p [[0.00125156 0.24405507 0.01001252 0.00125156 0.05506884 0.00125156]\n",
      " [0.01001252 0.08135169 0.00876095 0.00125156 0.06883605 0.03003755]\n",
      " [0.00375469 0.         0.         0.         0.         0.        ]\n",
      " [0.01001252 0.         0.         0.         0.00125156 0.01376721]\n",
      " [0.0175219  0.22027534 0.         0.         0.         0.02252816]\n",
      " [0.00500626 0.15018773 0.00250313 0.00375469 0.03003755 0.00625782]]\n",
      "move 1\n",
      "board\n",
      " [[ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.9737518e-03 3.8187735e-02 2.1940572e-02 2.2833855e-03 7.1795017e-02\n",
      " 2.8974740e-03 2.2078544e-02 1.0227938e-01 9.5427483e-03 1.4974779e-03\n",
      " 7.8312606e-02 4.9161226e-03 7.6036309e-03 1.1993368e-03 5.0866220e-05\n",
      " 8.6688278e-06 1.1186706e-03 2.6415469e-02 8.0952616e-03 1.0568779e-03\n",
      " 1.0743805e-05 1.5601964e-04 1.5289510e-03 3.5220474e-02 5.2059866e-03\n",
      " 6.4434245e-02 1.3492006e-03 6.0136882e-03 3.3803627e-01 2.9339431e-02\n",
      " 7.9774866e-03 6.5223381e-02 3.2235617e-03 8.6564161e-03 1.1312572e-02\n",
      " 1.4058068e-02] \n",
      " -0.4896512\n",
      "p [[1.25156446e-13 0.00000000e+00 5.00625782e-03 1.25156446e-13\n",
      "  2.00250313e-02 1.25156446e-13]\n",
      " [1.25156446e-13 6.38297872e-02 1.25156446e-13 4.75594493e-02\n",
      "  1.25156446e-13 5.81977472e-01]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [2.87859825e-02 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.37672090e-01 2.50312891e-03 1.12640801e-01\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 11\n",
      "board\n",
      " [[ 0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0. -1. -1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 299 completed in 31.02677893638611 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5740926 entropy 1.9453278\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5481222 entropy 1.938843\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5106397 entropy 1.9285448\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.470363 entropy 1.9190302\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.429007 entropy 1.912785\n",
      "kl 0.0328077\n",
      "completed in 0.28284502029418945 s\n",
      "training pipeline completed in 3203.194548845291 s\n"
     ]
    }
   ],
   "source": [
    "model.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "519e6eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 14:09:38.688053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.save('600.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c2b2d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 completed in 10.095508813858032 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.513793 entropy 1.9343067\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4938896 entropy 1.9411106\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4640594 entropy 1.9489235\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.433223 entropy 1.9527619\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4015727 entropy 1.9493003\n",
      "kl 0.026626127\n",
      "completed in 0.2795288562774658 s\n",
      "game 1 completed in 6.527832746505737 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5549695 entropy 1.9087353\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5358918 entropy 1.9055998\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5033984 entropy 1.9065278\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4674277 entropy 1.9117503\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4352825 entropy 1.9200323\n",
      "kl 0.020961892\n",
      "completed in 0.2685718536376953 s\n",
      "game 2 completed in 8.347821950912476 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5884697 entropy 1.9967523\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.570407 entropy 2.0046334\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.542041 entropy 2.0094585\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5093005 entropy 2.01068\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4761772 entropy 2.0072947\n",
      "kl 0.016809806\n",
      "completed in 0.3482189178466797 s\n",
      "game 3 completed in 8.417828798294067 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5490704 entropy 1.9454882\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5271163 entropy 1.9415021\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4950018 entropy 1.9388874\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.459017 entropy 1.9364102\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4210434 entropy 1.93368\n",
      "kl 0.022783972\n",
      "completed in 0.30024194717407227 s\n",
      "game 4 completed in 6.662622928619385 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4583294 entropy 1.914123\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4370062 entropy 1.9103925\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4063685 entropy 1.9057958\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3730745 entropy 1.8999338\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3371105 entropy 1.8913972\n",
      "kl 0.020620517\n",
      "completed in 0.34383392333984375 s\n",
      "game 5 completed in 7.394124746322632 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5098183 entropy 1.9118686\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4927523 entropy 1.8975819\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4620376 entropy 1.8827553\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4247687 entropy 1.8696024\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3867326 entropy 1.8593838\n",
      "kl 0.022370866\n",
      "completed in 0.33369016647338867 s\n",
      "game 6 completed in 10.082380056381226 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5375228 entropy 1.8793482\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5198267 entropy 1.8779652\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4913027 entropy 1.8785453\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4589198 entropy 1.8799309\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.424052 entropy 1.8815084\n",
      "kl 0.015439108\n",
      "completed in 0.26151394844055176 s\n",
      "game 7 completed in 11.737818717956543 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5720003 entropy 1.874641\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5502603 entropy 1.8795278\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5172956 entropy 1.8877\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4841216 entropy 1.8986244\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4496589 entropy 1.910081\n",
      "kl 0.017822884\n",
      "completed in 0.26605987548828125 s\n",
      "game 8 completed in 10.097044944763184 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4858952 entropy 1.8873239\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.470373 entropy 1.8975339\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4460807 entropy 1.9076929\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.418241 entropy 1.916983\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.389596 entropy 1.9245213\n",
      "kl 0.01418722\n",
      "completed in 0.32651686668395996 s\n",
      "game 9 completed in 8.326518058776855 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6240382 entropy 1.9807789\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5999985 entropy 1.987359\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5674343 entropy 1.9937346\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5350084 entropy 1.9975498\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5030813 entropy 1.9978333\n",
      "kl 0.018605115\n",
      "completed in 0.3878819942474365 s\n",
      "game 10 completed in 10.04505705833435 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5978203 entropy 1.9764618\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.578034 entropy 1.9744468\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5462012 entropy 1.9725188\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.510813 entropy 1.9717212\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4752543 entropy 1.972833\n",
      "kl 0.01319412\n",
      "completed in 0.35750508308410645 s\n",
      "game 11 completed in 7.40747594833374 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6321676 entropy 1.9998496\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6094046 entropy 2.0025206\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5764687 entropy 2.0036206\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5428915 entropy 2.0041919\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5061374 entropy 2.0057588\n",
      "kl 0.019222554\n",
      "completed in 0.3500359058380127 s\n",
      "game 12 completed in 6.351275205612183 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4468813 entropy 1.9593191\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4274325 entropy 1.9626479\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3985882 entropy 1.9646821\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3686185 entropy 1.9637232\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3415818 entropy 1.9580003\n",
      "kl 0.0138720125\n",
      "completed in 0.29732489585876465 s\n",
      "game 13 completed in 14.860882997512817 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4918225 entropy 1.9753466\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4780977 entropy 1.9631225\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4461691 entropy 1.9496231\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.408409 entropy 1.9383065\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3743293 entropy 1.9308997\n",
      "kl 0.021126825\n",
      "completed in 0.3139190673828125 s\n",
      "game 14 completed in 9.979503154754639 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4756954 entropy 1.9240929\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.459449 entropy 1.9246209\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4322212 entropy 1.9252851\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3995814 entropy 1.9224303\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3654613 entropy 1.9139907\n",
      "kl 0.025879856\n",
      "completed in 0.3316981792449951 s\n",
      "game 15 completed in 6.428399085998535 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4820259 entropy 1.9117076\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4676614 entropy 1.9030123\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.442311 entropy 1.8989234\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4108245 entropy 1.9011984\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.378316 entropy 1.9087051\n",
      "kl 0.023419302\n",
      "completed in 0.29141688346862793 s\n",
      "game 16 completed in 11.985183000564575 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.416827 entropy 1.9182566\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3959563 entropy 1.9275249\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3683357 entropy 1.9342589\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3433425 entropy 1.936521\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.317752 entropy 1.9335517\n",
      "kl 0.017811427\n",
      "completed in 0.2681691646575928 s\n",
      "game 17 completed in 9.464928150177002 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5326555 entropy 1.935534\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5110743 entropy 1.9276586\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4797897 entropy 1.9225473\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4480016 entropy 1.9213719\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4174209 entropy 1.9230732\n",
      "kl 0.02883232\n",
      "completed in 0.2813560962677002 s\n",
      "game 18 completed in 11.906386852264404 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4972646 entropy 1.9182119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1 lr_mult 0.4444444444444444 loss 2.4822779 entropy 1.9162962\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4542358 entropy 1.9106786\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.420704 entropy 1.9041018\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3856668 entropy 1.899416\n",
      "kl 0.01482099\n",
      "completed in 0.3476710319519043 s\n",
      "game 19 completed in 13.581148147583008 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5000517 entropy 1.9122177\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4778726 entropy 1.9113041\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4429116 entropy 1.9079008\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4042156 entropy 1.9037268\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3681808 entropy 1.9007993\n",
      "kl 0.023973484\n",
      "completed in 0.3275270462036133 s\n",
      "game 20 completed in 6.566236257553101 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4889147 entropy 1.9249933\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4669113 entropy 1.9382288\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4421372 entropy 1.9543102\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4183226 entropy 1.965588\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3932147 entropy 1.9668384\n",
      "kl 0.030923605\n",
      "completed in 0.3751029968261719 s\n",
      "game 21 completed in 7.561199903488159 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.466307 entropy 1.9141657\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4483058 entropy 1.8980777\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4189866 entropy 1.8817909\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3837993 entropy 1.87108\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3467197 entropy 1.8692632\n",
      "kl 0.024420056\n",
      "completed in 0.2653470039367676 s\n",
      "game 22 completed in 8.470873832702637 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.491119 entropy 1.9043572\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4740143 entropy 1.9199717\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4432995 entropy 1.93612\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.404128 entropy 1.9459558\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3608272 entropy 1.9460882\n",
      "kl 0.0270818\n",
      "completed in 0.3030211925506592 s\n",
      "game 23 completed in 6.697716951370239 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.490337 entropy 1.923207\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4684525 entropy 1.9173427\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4418044 entropy 1.915401\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4156265 entropy 1.9178692\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.388375 entropy 1.92296\n",
      "kl 0.019602153\n",
      "completed in 0.29676127433776855 s\n",
      "game 24 completed in 6.668655157089233 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.488296 entropy 1.9870703\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4747264 entropy 1.9874218\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4501872 entropy 1.9815936\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4190178 entropy 1.9715822\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3864365 entropy 1.9606596\n",
      "kl 0.019141138\n",
      "completed in 0.2909057140350342 s\n",
      "game 25 completed in 7.4902660846710205 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4817646 entropy 1.922085\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.459993 entropy 1.9237194\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4269197 entropy 1.9309804\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3929658 entropy 1.9390448\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3581953 entropy 1.9429157\n",
      "kl 0.028983247\n",
      "completed in 0.28094005584716797 s\n",
      "game 26 completed in 12.700193881988525 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4926856 entropy 1.9385726\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4677393 entropy 1.9327264\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4306357 entropy 1.9262118\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3975892 entropy 1.9224744\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3673759 entropy 1.9241896\n",
      "kl 0.024888657\n",
      "completed in 0.2638728618621826 s\n",
      "game 27 completed in 8.286107778549194 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4696438 entropy 1.9260217\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4514358 entropy 1.9383857\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4300072 entropy 1.9520886\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4101527 entropy 1.9609257\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.387659 entropy 1.960711\n",
      "kl 0.018303499\n",
      "completed in 0.26667118072509766 s\n",
      "game 28 completed in 6.503868103027344 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5518372 entropy 1.9494098\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5204206 entropy 1.9354446\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4925337 entropy 1.9231172\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.468997 entropy 1.9159236\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4390388 entropy 1.9150442\n",
      "kl 0.013865126\n",
      "completed in 0.31886792182922363 s\n",
      "game 29 completed in 7.4987242221832275 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.37868 entropy 1.9025247\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3674898 entropy 1.9034419\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.345643 entropy 1.9006946\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3187187 entropy 1.8947492\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.291902 entropy 1.8873589\n",
      "kl 0.021392822\n",
      "completed in 0.3201720714569092 s\n",
      "game 30 completed in 9.413719892501831 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4931946 entropy 1.915201\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4819524 entropy 1.9145\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4588861 entropy 1.9178975\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.428408 entropy 1.9228375\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3966234 entropy 1.9268146\n",
      "kl 0.019321904\n",
      "completed in 0.32232189178466797 s\n",
      "game 31 completed in 12.13648509979248 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5308206 entropy 1.9664564\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5167935 entropy 1.9701428\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.493761 entropy 1.9749761\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4649506 entropy 1.9791408\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4335074 entropy 1.9818282\n",
      "kl 0.016838897\n",
      "completed in 0.3076610565185547 s\n",
      "game 32 completed in 12.057606935501099 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5171452 entropy 1.9346908\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4946392 entropy 1.9317672\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.465625 entropy 1.9264588\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4376733 entropy 1.9216878\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4068134 entropy 1.9195738\n",
      "kl 0.02031463\n",
      "completed in 0.3158149719238281 s\n",
      "game 33 completed in 10.619236946105957 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4677355 entropy 1.9365987\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4328756 entropy 1.9410033\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4002087 entropy 1.9445589\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.383919 entropy 1.9441485\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3519258 entropy 1.938375\n",
      "kl 0.017198758\n",
      "completed in 0.312175989151001 s\n",
      "game 34 completed in 6.568833112716675 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5368705 entropy 1.9403697\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5261068 entropy 1.9375479\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.503522 entropy 1.9389005\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4728446 entropy 1.944596\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.43943 entropy 1.9532295\n",
      "kl 0.019355442\n",
      "completed in 0.27706074714660645 s\n",
      "game 35 completed in 12.636742115020752 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5274112 entropy 2.0020661\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5091906 entropy 2.0067763\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4827018 entropy 2.0058799\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4539812 entropy 2.0004792\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4265006 entropy 1.9925194\n",
      "kl 0.02072214\n",
      "completed in 0.3328208923339844 s\n",
      "game 36 completed in 9.865393161773682 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4703417 entropy 1.9518943\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4543986 entropy 1.9489243\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.426912 entropy 1.9486091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.3954368 entropy 1.9487563\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3623896 entropy 1.9474087\n",
      "kl 0.017543662\n",
      "completed in 0.26756882667541504 s\n",
      "game 37 completed in 17.00275206565857 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.453549 entropy 1.9041284\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4373877 entropy 1.8993499\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4101129 entropy 1.8947692\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3765197 entropy 1.891593\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3422534 entropy 1.8904054\n",
      "kl 0.015505479\n",
      "completed in 0.32628297805786133 s\n",
      "game 38 completed in 16.8403217792511 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.532041 entropy 1.9073291\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.503185 entropy 1.910405\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4592497 entropy 1.915062\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4166634 entropy 1.9211853\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3823295 entropy 1.9273579\n",
      "kl 0.020468347\n",
      "completed in 0.276731014251709 s\n",
      "game 39 completed in 8.121943712234497 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5732 entropy 1.9730357\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5569336 entropy 1.9717269\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5290022 entropy 1.9686687\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.496529 entropy 1.9665844\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4644315 entropy 1.9668972\n",
      "kl 0.017492998\n",
      "completed in 0.3577229976654053 s\n",
      "game 40 completed in 13.112525224685669 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4408507 entropy 1.9516795\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4206069 entropy 1.9508555\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3878112 entropy 1.946707\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3489196 entropy 1.9390565\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3103766 entropy 1.9290463\n",
      "kl 0.019027513\n",
      "completed in 0.3277420997619629 s\n",
      "game 41 completed in 6.6729443073272705 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4137387 entropy 1.8990794\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3873947 entropy 1.8975768\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3515792 entropy 1.9019136\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3172135 entropy 1.9081835\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2884715 entropy 1.9124526\n",
      "kl 0.030744819\n",
      "completed in 0.29248714447021484 s\n",
      "game 42 completed in 6.5529091358184814 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.546273 entropy 1.955973\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5298893 entropy 1.9553413\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.499822 entropy 1.9551775\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4628918 entropy 1.9555153\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.425621 entropy 1.9555664\n",
      "kl 0.022909902\n",
      "completed in 0.3047299385070801 s\n",
      "game 43 completed in 8.569032192230225 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.472034 entropy 1.9442408\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4542623 entropy 1.9487321\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.426609 entropy 1.9571123\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.395032 entropy 1.9680274\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3634949 entropy 1.9786335\n",
      "kl 0.022384338\n",
      "completed in 0.2739858627319336 s\n",
      "game 44 completed in 8.386543035507202 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4241478 entropy 1.9589987\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4025342 entropy 1.9629594\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3793042 entropy 1.9634254\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3560014 entropy 1.9636801\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3302774 entropy 1.9654202\n",
      "kl 0.021324102\n",
      "completed in 0.3194549083709717 s\n",
      "game 45 completed in 11.122113704681396 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.473019 entropy 1.98104\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4453485 entropy 1.9853096\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4143128 entropy 1.9872029\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3868215 entropy 1.9826934\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3500695 entropy 1.9700291\n",
      "kl 0.01893907\n",
      "completed in 0.28431105613708496 s\n",
      "game 46 completed in 9.379405975341797 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5349443 entropy 1.9701364\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5160582 entropy 1.9560473\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4889612 entropy 1.9468417\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4564686 entropy 1.9424924\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.420179 entropy 1.940085\n",
      "kl 0.02475939\n",
      "completed in 0.2967207431793213 s\n",
      "game 47 completed in 10.207054138183594 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4515853 entropy 1.9186587\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.42966 entropy 1.9125861\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3971145 entropy 1.9040184\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3627467 entropy 1.89431\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3310184 entropy 1.8849528\n",
      "kl 0.01967829\n",
      "completed in 0.32509517669677734 s\n",
      "game 48 completed in 8.43708610534668 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.587435 entropy 1.8818451\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.556029 entropy 1.8819797\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5186014 entropy 1.8880727\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.486884 entropy 1.8977541\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4592233 entropy 1.9088078\n",
      "kl 0.023433922\n",
      "completed in 0.28317904472351074 s\n",
      "prediction:\n",
      " [0.00131813 0.00216695 0.00307666 0.00254078 0.00324116 0.00037507\n",
      " 0.00168499 0.02794934 0.08576585 0.01030827 0.00763353 0.00249111\n",
      " 0.00156945 0.08824207 0.13937747 0.11704222 0.01219295 0.00197766\n",
      " 0.00204621 0.00888748 0.13823825 0.15572606 0.06705479 0.00154488\n",
      " 0.00201179 0.00303727 0.00734766 0.06519106 0.02570492 0.00144301\n",
      " 0.00145335 0.00282348 0.00385832 0.00244733 0.00128588 0.00094475] \n",
      " -0.46227524\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.75469337e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.86483104e-01 2.84105131e-01\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.30287860e-01 2.86608260e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [9.4414980e-05 6.4482083e-05 8.8441018e-05 8.0584621e-05 6.7904824e-05\n",
      " 9.1981865e-06 1.5555847e-04 1.1226512e-02 2.5407784e-02 6.6909972e-03\n",
      " 1.7387861e-04 7.6344164e-05 6.1433013e-05 1.4608419e-04 3.0047916e-02\n",
      " 1.9909102e-01 6.5896995e-02 3.2072802e-04 3.9081820e-04 3.3450842e-02\n",
      " 5.5385226e-01 2.0519225e-02 7.8664969e-05 2.5875946e-05 5.1221625e-05\n",
      " 1.5538247e-04 8.3292173e-03 1.7922422e-02 2.4862140e-02 4.1640225e-05\n",
      " 3.5925776e-05 6.4284068e-05 1.6038060e-04 1.1419170e-04 1.0367410e-04\n",
      " 1.4161679e-04] \n",
      " 0.6358832\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00876095 0.06508135 0.00375469 0.00125156 0.00125156]\n",
      " [0.00125156 0.10012516 0.1864831  0.17772215 0.00750939 0.00750939]\n",
      " [0.00125156 0.00750939 0.09762203 0.         0.27033792 0.00125156]\n",
      " [0.00125156 0.00375469 0.00125156 0.02878598 0.00750939 0.00125156]\n",
      " [0.00125156 0.00250313 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00219123 0.00164885 0.01163012 0.00447071 0.00347719 0.00094539\n",
      " 0.00512237 0.01475345 0.21651526 0.0393983  0.02718742 0.002025\n",
      " 0.00400493 0.00329175 0.0080738  0.01256321 0.15086865 0.00860723\n",
      " 0.00677646 0.08751626 0.01141737 0.00759852 0.00106123 0.00224166\n",
      " 0.00230221 0.00828331 0.04890162 0.20239249 0.06769343 0.00196724\n",
      " 0.00080901 0.00381075 0.00810177 0.01725603 0.00303526 0.00206079] \n",
      " -0.8915239\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 7.50938673e-03 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.75469337e-03 4.90613267e-01\n",
      "  1.33917397e-01 1.25156446e-13]\n",
      " [1.25156446e-13 7.50938673e-03 3.36670839e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 8.76095119e-03\n",
      "  7.50938673e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [2.8015402e-04 1.4883054e-04 1.1833881e-03 6.0885807e-04 1.4196811e-04\n",
      " 3.4925350e-05 1.5226670e-04 3.0363805e-03 2.3222068e-01 3.0218518e-01\n",
      " 4.3768496e-03 6.5490407e-05 4.2538819e-04 1.5560017e-04 3.3831496e-03\n",
      " 9.3999325e-04 3.9943121e-04 2.0932101e-04 1.1090873e-04 3.9829081e-04\n",
      " 3.8292152e-03 1.0199288e-03 6.1002451e-05 2.9715779e-04 1.3165714e-04\n",
      " 1.7288313e-03 3.0270958e-01 1.2866928e-01 8.1780609e-03 9.1109745e-05\n",
      " 6.0142727e-05 1.5221386e-04 1.1150157e-03 9.7796798e-04 1.2833679e-04\n",
      " 3.9353422e-04] \n",
      " -0.44149327\n",
      "p [[0.00125156 0.00125156 0.01126408 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00876095 0.11013767 0.03254068 0.1339174  0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.         0.29662078 0.00876095]\n",
      " [0.00125156 0.04505632 0.00876095 0.         0.         0.00125156]\n",
      " [0.00125156 0.00250313 0.02628285 0.14142678 0.12640801 0.00125156]\n",
      " [0.00125156 0.00125156 0.00750939 0.01627034 0.00125156 0.00125156]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00037999 0.00640649 0.00356914 0.0094439  0.00541889 0.00089536\n",
      " 0.0056981  0.16076708 0.07180279 0.00589198 0.1594313  0.00159365\n",
      " 0.00519383 0.00775404 0.00171972 0.00256326 0.00299854 0.00195915\n",
      " 0.0031497  0.00268872 0.00456435 0.00268336 0.00221173 0.00269815\n",
      " 0.00163639 0.07345863 0.00470825 0.0613443  0.33671793 0.00369264\n",
      " 0.00163726 0.00538821 0.03015554 0.00455732 0.00402506 0.00119533] \n",
      " -0.61625105\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.87859825e-02 5.76971214e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.00375469e-02 3.61702128e-01\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.53232278e-05 6.60848978e-04 2.39014262e-04 3.95515002e-02\n",
      " 2.80089909e-04 6.86441217e-06 3.42541141e-04 8.97213395e-05\n",
      " 6.55206084e-01 1.13497932e-04 9.95968818e-04 1.06495128e-04\n",
      " 3.42120948e-05 3.35791177e-04 6.48784335e-04 3.84990162e-05\n",
      " 3.10359930e-04 6.05589048e-05 5.17631233e-05 1.71778636e-04\n",
      " 1.15524977e-04 1.55402784e-04 2.10794606e-04 6.90222660e-05\n",
      " 2.72918609e-04 1.56330923e-03 1.14877104e-04 1.70640320e-01\n",
      " 2.26301490e-04 2.18678295e-04 1.54691399e-04 2.56694504e-04\n",
      " 1.25817180e-01 2.62722198e-04 5.66567935e-04 6.53804527e-05] \n",
      " 0.8487353\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00500626 0.12515645 0.00125156]\n",
      " [0.00250313 0.09386733 0.0350438  0.         0.23279099 0.00125156]\n",
      " [0.00125156 0.00250313 0.00125156 0.         0.         0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.         0.         0.00125156]\n",
      " [0.00125156 0.05006258 0.00125156 0.04130163 0.35544431 0.00125156]\n",
      " [0.00125156 0.00250313 0.02753442 0.00125156 0.00125156 0.00125156]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.1194313e-04 2.2860973e-01 3.5548534e-03 2.8185977e-03 5.3705052e-03\n",
      " 3.6154375e-05 2.4934472e-03 1.1323462e-03 8.7753270e-04 1.5263599e-03\n",
      " 2.4911407e-01 1.5866676e-03 4.4525894e-03 9.1342907e-03 8.0478674e-04\n",
      " 2.8344584e-04 1.3732472e-03 2.0812986e-04 5.8252236e-04 1.8839736e-03\n",
      " 2.2211732e-04 1.9549821e-03 2.3660224e-03 4.1632643e-03 2.7880366e-03\n",
      " 3.5194814e-01 1.2533476e-03 1.4283468e-03 7.0934522e-04 4.7529717e-03\n",
      " 4.7953782e-04 5.5095386e-03 3.5197160e-03 2.0481802e-03 9.9171840e-02\n",
      " 1.4295788e-03] \n",
      " 0.6459648\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.72715895e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.75844806e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 7.45932416e-01\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.37672090e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 49 completed in 23.26097297668457 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.486771 entropy 1.9384954\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4675598 entropy 1.9519674\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4360046 entropy 1.9661851\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4059284 entropy 1.9780257\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.378104 entropy 1.9845753\n",
      "kl 0.020590333\n",
      "completed in 0.29239416122436523 s\n",
      "game 50 completed in 12.012099027633667 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5345876 entropy 1.974647\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.513988 entropy 1.9645452\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4811153 entropy 1.9497919\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.444153 entropy 1.9359273\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4062035 entropy 1.9267458\n",
      "kl 0.028631117\n",
      "completed in 0.2998170852661133 s\n",
      "game 51 completed in 7.428791046142578 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4764316 entropy 1.9516602\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.455485 entropy 1.9534322\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4243803 entropy 1.9546126\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3864863 entropy 1.9531796\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.349362 entropy 1.9481004\n",
      "kl 0.020678366\n",
      "completed in 0.28006672859191895 s\n",
      "game 52 completed in 6.589888095855713 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4290035 entropy 1.9203031\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4120905 entropy 1.9161339\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.385288 entropy 1.915386\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3568459 entropy 1.9161677\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3273325 entropy 1.9156787\n",
      "kl 0.018213388\n",
      "completed in 0.29307007789611816 s\n",
      "game 53 completed in 6.585608005523682 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5662909 entropy 1.9395559\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.543311 entropy 1.9374995\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5053768 entropy 1.937185\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4639134 entropy 1.9388883\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.425041 entropy 1.941674\n",
      "kl 0.02400541\n",
      "completed in 0.2732231616973877 s\n",
      "game 54 completed in 16.917086124420166 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4890084 entropy 1.920583\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.46876 entropy 1.927627\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.437118 entropy 1.9338162\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4037397 entropy 1.9377713\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3727071 entropy 1.9385233\n",
      "kl 0.027081411\n",
      "completed in 0.3084990978240967 s\n",
      "game 55 completed in 14.841453790664673 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5218284 entropy 1.9718688\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5077822 entropy 1.972358\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4834516 entropy 1.9732299\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4540737 entropy 1.9742279\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4245102 entropy 1.9750819\n",
      "kl 0.018210134\n",
      "completed in 0.3264796733856201 s\n",
      "game 56 completed in 8.298798084259033 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4749424 entropy 1.9652435\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.45492 entropy 1.962769\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4218392 entropy 1.9605322\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3856814 entropy 1.9587271\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.352982 entropy 1.9564509\n",
      "kl 0.021908099\n",
      "completed in 0.3000650405883789 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 57 completed in 7.4498131275177 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4376776 entropy 1.9193053\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4189649 entropy 1.9161454\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3898716 entropy 1.9116745\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3559954 entropy 1.9067056\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3226697 entropy 1.9020827\n",
      "kl 0.016460646\n",
      "completed in 0.31597018241882324 s\n",
      "game 58 completed in 12.579529047012329 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5899847 entropy 1.930832\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5639577 entropy 1.93309\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5318067 entropy 1.938261\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.500868 entropy 1.9443688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4722676 entropy 1.9496164\n",
      "kl 0.013998792\n",
      "completed in 0.30773091316223145 s\n",
      "game 59 completed in 11.632242918014526 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5475736 entropy 1.9567139\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.521512 entropy 1.9518061\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.49009 entropy 1.9437762\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4607563 entropy 1.9390388\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4310052 entropy 1.940197\n",
      "kl 0.022043783\n",
      "completed in 0.3073081970214844 s\n",
      "game 60 completed in 6.544840097427368 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.447052 entropy 1.9094653\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4285588 entropy 1.9155247\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4021907 entropy 1.9220133\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3747144 entropy 1.9254265\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3442755 entropy 1.9226872\n",
      "kl 0.015380131\n",
      "completed in 0.32676005363464355 s\n",
      "game 61 completed in 10.056460857391357 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.478237 entropy 1.9260998\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4451683 entropy 1.9099497\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4008048 entropy 1.8940849\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.360113 entropy 1.8865602\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3229136 entropy 1.8895679\n",
      "kl 0.028341327\n",
      "completed in 0.3503408432006836 s\n",
      "game 62 completed in 16.230650186538696 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5334313 entropy 1.8720933\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5089102 entropy 1.8913755\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4729378 entropy 1.9098699\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4360747 entropy 1.9202759\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3998063 entropy 1.9202516\n",
      "kl 0.02498987\n",
      "completed in 0.29454994201660156 s\n",
      "game 63 completed in 8.389616966247559 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5166051 entropy 1.9347384\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4872105 entropy 1.9239274\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4530933 entropy 1.9150028\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4222372 entropy 1.9112767\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.386707 entropy 1.9136137\n",
      "kl 0.018019013\n",
      "completed in 0.2950708866119385 s\n",
      "game 64 completed in 16.429518699645996 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5134447 entropy 1.9539573\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4910522 entropy 1.9596364\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.46155 entropy 1.963028\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.423414 entropy 1.9628447\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3809252 entropy 1.9583416\n",
      "kl 0.017593494\n",
      "completed in 0.35129213333129883 s\n",
      "game 65 completed in 12.883725881576538 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.521393 entropy 1.9792373\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5007215 entropy 1.9711568\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4690964 entropy 1.9662693\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4346824 entropy 1.9655412\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4036283 entropy 1.9664783\n",
      "kl 0.01730975\n",
      "completed in 0.3286399841308594 s\n",
      "game 66 completed in 12.625612020492554 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.585382 entropy 1.9256663\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5630572 entropy 1.9323332\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5273132 entropy 1.9421512\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4875379 entropy 1.9527762\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4458492 entropy 1.9610502\n",
      "kl 0.01588916\n",
      "completed in 0.3548848628997803 s\n",
      "game 67 completed in 10.142522096633911 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6562726 entropy 2.005412\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6313398 entropy 2.00606\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5898087 entropy 2.0057993\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.539745 entropy 2.0068316\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4882298 entropy 2.0101953\n",
      "kl 0.019067295\n",
      "completed in 0.2994518280029297 s\n",
      "game 68 completed in 8.469361782073975 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5457783 entropy 2.0009818\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5191453 entropy 2.006355\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4806743 entropy 2.0081587\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.440141 entropy 2.0026407\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.398427 entropy 1.9882619\n",
      "kl 0.020985581\n",
      "completed in 0.305696964263916 s\n",
      "game 69 completed in 8.462301015853882 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5608063 entropy 1.967385\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5399694 entropy 1.9499258\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5044713 entropy 1.9379058\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4661305 entropy 1.9311055\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.429372 entropy 1.9276824\n",
      "kl 0.01733366\n",
      "completed in 0.31672191619873047 s\n",
      "game 70 completed in 10.388612270355225 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6186328 entropy 1.947772\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5849645 entropy 1.9400876\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5419917 entropy 1.9278982\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5052273 entropy 1.9176557\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4712412 entropy 1.9136655\n",
      "kl 0.03156668\n",
      "completed in 0.3076798915863037 s\n",
      "game 71 completed in 6.515460014343262 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4304476 entropy 1.8473389\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.415831 entropy 1.8520699\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3875587 entropy 1.8571064\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.354314 entropy 1.860394\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3200924 entropy 1.8609697\n",
      "kl 0.021266839\n",
      "completed in 0.2912890911102295 s\n",
      "game 72 completed in 8.384965181350708 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.558177 entropy 1.9263697\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5320938 entropy 1.9366878\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.493136 entropy 1.9518952\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4557037 entropy 1.9648085\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.422306 entropy 1.9709626\n",
      "kl 0.03023073\n",
      "completed in 0.29011106491088867 s\n",
      "game 73 completed in 6.565655946731567 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5719452 entropy 1.9358485\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5466888 entropy 1.9287517\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5116405 entropy 1.9217931\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4756534 entropy 1.9215906\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4369302 entropy 1.9309263\n",
      "kl 0.03262175\n",
      "completed in 0.30773091316223145 s\n",
      "game 74 completed in 7.386613845825195 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.511641 entropy 1.9274071\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.493592 entropy 1.9473681\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4649062 entropy 1.9645076\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4302073 entropy 1.9724108\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.39228 entropy 1.9683748\n",
      "kl 0.021599974\n",
      "completed in 0.33878207206726074 s\n",
      "game 75 completed in 13.648654222488403 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4664724 entropy 1.9622574\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4420137 entropy 1.9444747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.4444444444444444 loss 2.4090774 entropy 1.9290967\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.373292 entropy 1.9210958\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3341308 entropy 1.9198066\n",
      "kl 0.02728658\n",
      "completed in 0.30228185653686523 s\n",
      "game 76 completed in 6.570264101028442 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5115938 entropy 1.9417584\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4947634 entropy 1.9450049\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4659326 entropy 1.945186\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.429768 entropy 1.9405458\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.389972 entropy 1.9324814\n",
      "kl 0.02045234\n",
      "completed in 0.32271385192871094 s\n",
      "game 77 completed in 11.911488056182861 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5781455 entropy 1.9438024\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5649886 entropy 1.9446032\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.538125 entropy 1.9533229\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5066917 entropy 1.9666753\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.476521 entropy 1.9796994\n",
      "kl 0.020435778\n",
      "completed in 0.36061978340148926 s\n",
      "game 78 completed in 8.229076862335205 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.3866305 entropy 1.949564\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.3696425 entropy 1.9495635\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.342994 entropy 1.9423422\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3131256 entropy 1.9313614\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.2817428 entropy 1.9204\n",
      "kl 0.024638629\n",
      "completed in 0.29553675651550293 s\n",
      "game 79 completed in 8.311920881271362 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.547561 entropy 1.954802\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.528268 entropy 1.9564788\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.495603 entropy 1.9618762\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4587057 entropy 1.9663036\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.420649 entropy 1.9658778\n",
      "kl 0.022037692\n",
      "completed in 0.33338499069213867 s\n",
      "game 80 completed in 7.3760740756988525 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5062122 entropy 1.945046\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4852688 entropy 1.9401708\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4521542 entropy 1.9359175\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.418321 entropy 1.9332734\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.382746 entropy 1.931679\n",
      "kl 0.020909285\n",
      "completed in 0.38136816024780273 s\n",
      "game 81 completed in 8.16527009010315 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4922638 entropy 1.8892441\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4760888 entropy 1.8889132\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4447954 entropy 1.887336\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4051201 entropy 1.8832526\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3643806 entropy 1.8774073\n",
      "kl 0.019165942\n",
      "completed in 0.3317291736602783 s\n",
      "game 82 completed in 10.821997165679932 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4221315 entropy 1.8795613\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.404756 entropy 1.8736441\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3793938 entropy 1.8668904\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3515315 entropy 1.8615401\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3231728 entropy 1.8589611\n",
      "kl 0.022079173\n",
      "completed in 0.2706136703491211 s\n",
      "game 83 completed in 15.282673835754395 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4269733 entropy 1.8955561\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4082863 entropy 1.8964133\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3763397 entropy 1.8935304\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3431652 entropy 1.8892148\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3112664 entropy 1.8854353\n",
      "kl 0.015645297\n",
      "completed in 0.3012068271636963 s\n",
      "game 84 completed in 11.74465274810791 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4329185 entropy 1.8729693\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4051647 entropy 1.8812052\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3677394 entropy 1.8942504\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3351383 entropy 1.9049559\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3062787 entropy 1.9079895\n",
      "kl 0.027491\n",
      "completed in 0.2994720935821533 s\n",
      "game 85 completed in 9.206559896469116 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.507429 entropy 1.9018226\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4738245 entropy 1.8841653\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.432934 entropy 1.8639741\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3985791 entropy 1.8513424\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3618443 entropy 1.8509889\n",
      "kl 0.033401147\n",
      "completed in 0.37240099906921387 s\n",
      "game 86 completed in 13.588895797729492 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4920979 entropy 1.9186624\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4682941 entropy 1.9441012\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4401283 entropy 1.9700258\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4117713 entropy 1.9858314\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3804986 entropy 1.9859878\n",
      "kl 0.033319212\n",
      "completed in 0.36051082611083984 s\n",
      "game 87 completed in 11.796303033828735 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4869943 entropy 1.9485233\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4637277 entropy 1.9272025\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.440553 entropy 1.9077606\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4151616 entropy 1.8991144\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3823764 entropy 1.9042125\n",
      "kl 0.025533436\n",
      "completed in 0.275101900100708 s\n",
      "game 88 completed in 17.342385053634644 s 19 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4531116 entropy 1.8901501\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4360282 entropy 1.9182488\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4120138 entropy 1.9425194\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3814764 entropy 1.9538223\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3490164 entropy 1.9503798\n",
      "kl 0.0209665\n",
      "completed in 0.3474130630493164 s\n",
      "game 89 completed in 13.90914797782898 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5307996 entropy 1.9603738\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5132048 entropy 1.9440638\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.488655 entropy 1.9296094\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4605217 entropy 1.9223046\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4284902 entropy 1.9228704\n",
      "kl 0.022867084\n",
      "completed in 0.2984309196472168 s\n",
      "game 90 completed in 11.255637884140015 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5673368 entropy 1.954717\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5494988 entropy 1.9560785\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5155647 entropy 1.9527886\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4788778 entropy 1.9452333\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4447834 entropy 1.9360273\n",
      "kl 0.022116497\n",
      "completed in 0.3199629783630371 s\n",
      "game 91 completed in 12.114126682281494 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5678267 entropy 1.8921512\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5444312 entropy 1.8912354\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5074344 entropy 1.897568\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.468378 entropy 1.9091464\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.43055 entropy 1.9218795\n",
      "kl 0.018235046\n",
      "completed in 0.29337406158447266 s\n",
      "game 92 completed in 14.68167519569397 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5827646 entropy 1.9703507\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5662363 entropy 1.9806788\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5395281 entropy 1.9883964\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.509432 entropy 1.9925946\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4795938 entropy 1.9933407\n",
      "kl 0.018316265\n",
      "completed in 0.2647817134857178 s\n",
      "game 93 completed in 9.20529580116272 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.572082 entropy 2.0240102\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.552186 entropy 2.0245252\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5206091 entropy 2.025584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.4841642 entropy 2.0254774\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4499447 entropy 2.0227172\n",
      "kl 0.026456982\n",
      "completed in 0.2888188362121582 s\n",
      "game 94 completed in 19.900413990020752 s 22 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5761552 entropy 1.9625794\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.559969 entropy 1.9602945\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5286956 entropy 1.9587833\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.492387 entropy 1.9568586\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4584765 entropy 1.9533591\n",
      "kl 0.016328804\n",
      "completed in 0.3459920883178711 s\n",
      "game 95 completed in 10.373248100280762 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4930396 entropy 1.9373245\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4691515 entropy 1.9337337\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4377751 entropy 1.9318367\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4008975 entropy 1.9322569\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.363002 entropy 1.936036\n",
      "kl 0.024302155\n",
      "completed in 0.26737380027770996 s\n",
      "game 96 completed in 12.858182907104492 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5606368 entropy 1.9865503\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5391161 entropy 1.9874508\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.514611 entropy 1.9847007\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4883938 entropy 1.978958\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4559033 entropy 1.9718131\n",
      "kl 0.013841682\n",
      "completed in 0.32544517517089844 s\n",
      "game 97 completed in 7.699655055999756 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.561416 entropy 1.9889283\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5315597 entropy 1.9748904\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4933116 entropy 1.9579756\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4527729 entropy 1.9418175\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.414586 entropy 1.9295492\n",
      "kl 0.028354872\n",
      "completed in 0.3107140064239502 s\n",
      "game 98 completed in 7.48542594909668 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.603181 entropy 1.9236457\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5832949 entropy 1.9184282\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5502415 entropy 1.9146585\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5061536 entropy 1.9109386\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4617596 entropy 1.9074435\n",
      "kl 0.01700811\n",
      "completed in 0.3089640140533447 s\n",
      "prediction:\n",
      " [0.00122828 0.00215092 0.00400709 0.00278262 0.00182667 0.00125365\n",
      " 0.00161544 0.01593542 0.08551124 0.01031158 0.00396063 0.0016878\n",
      " 0.00302487 0.09613009 0.10622998 0.14047423 0.00883738 0.0025899\n",
      " 0.00247317 0.01389462 0.1163573  0.1272264  0.07645661 0.00276355\n",
      " 0.00288336 0.00428796 0.00934208 0.12177859 0.01892856 0.00190188\n",
      " 0.00065455 0.00197546 0.00237205 0.00456992 0.00098971 0.00158655] \n",
      " -0.5890249\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.64205257e-01 2.35294118e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.50187735e-01 2.50312891e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [4.5893623e-05 7.8187564e-05 5.5599117e-05 3.3291173e-04 8.5156942e-05\n",
      " 7.9702921e-05 5.8894700e-05 2.6019150e-03 5.8143479e-03 4.3131866e-02\n",
      " 5.1700050e-04 4.0467621e-05 1.6003195e-04 4.4803363e-03 3.2854822e-01\n",
      " 6.5301426e-02 5.7646292e-03 1.9157755e-04 1.5281951e-04 1.2409195e-02\n",
      " 3.4407511e-02 4.0432513e-01 5.7559549e-03 8.2197053e-05 9.5170552e-05\n",
      " 6.1959174e-04 6.5526783e-02 1.5967080e-02 2.7025386e-03 7.0256523e-05\n",
      " 2.1540618e-05 3.2995780e-05 3.3895115e-04 1.2044541e-04 4.0894069e-05\n",
      " 4.2860782e-05] \n",
      " 0.5975695\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00500626 0.03629537 0.00625782 0.00125156 0.00125156]\n",
      " [0.00125156 0.3028786  0.         0.31914894 0.00375469 0.00125156]\n",
      " [0.00125156 0.01627034 0.10387985 0.07509387 0.03254068 0.00125156]\n",
      " [0.00125156 0.00125156 0.00250313 0.05506884 0.00876095 0.00125156]\n",
      " [0.00125156 0.00250313 0.00250313 0.00250313 0.00125156 0.00125156]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01085098 0.00751485 0.00618949 0.00558344 0.00607445 0.00626985\n",
      " 0.0031101  0.2756474  0.02728292 0.01275561 0.0156624  0.00503591\n",
      " 0.00905553 0.02731759 0.00577827 0.03991044 0.0078852  0.00171515\n",
      " 0.00266508 0.0144157  0.03767958 0.00254764 0.03734844 0.00445148\n",
      " 0.00812861 0.01084844 0.02876868 0.03786472 0.29155728 0.00522258\n",
      " 0.00353715 0.00775267 0.00719522 0.00913647 0.00653714 0.01070366] \n",
      " -0.13496472\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-03 1.62703379e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 3.37922403e-02 9.26157697e-01\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 7.50938673e-03 6.25782228e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.50865512e-02 3.58846883e-04 3.39819724e-03 2.90340860e-03\n",
      " 5.93210221e-04 3.86580650e-04 9.64427483e-04 2.45013922e-01\n",
      " 9.22721159e-03 2.68529095e-02 1.01612450e-03 5.30880236e-04\n",
      " 2.65718461e-03 4.59158234e-03 7.61953508e-03 8.18279684e-02\n",
      " 3.48330624e-02 7.77972629e-04 9.96458577e-04 4.11464907e-02\n",
      " 8.29233676e-02 7.12221023e-03 3.06397974e-02 4.34570154e-03\n",
      " 1.14683085e-03 9.99884563e-04 3.70164737e-02 1.24155525e-02\n",
      " 3.24353367e-01 6.84824539e-04 1.97582543e-04 2.91339937e-04\n",
      " 1.65306812e-03 2.24816822e-03 5.83972433e-04 1.25954431e-02] \n",
      " 0.09197523\n",
      "p [[0.01877347 0.00500626 0.00750939 0.00375469 0.02252816 0.00500626]\n",
      " [0.00250313 0.19274093 0.02002503 0.00750939 0.02628285 0.0738423 ]\n",
      " [0.01001252 0.01001252 0.         0.         0.00250313 0.00250313]\n",
      " [0.00250313 0.00500626 0.05131414 0.         0.01627034 0.00500626]\n",
      " [0.09261577 0.00375469 0.01001252 0.0175219  0.33541927 0.00375469]\n",
      " [0.00375469 0.01877347 0.00250313 0.00500626 0.00625782 0.01001252]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.0596216e-02 1.0543264e-02 2.0078104e-03 5.7706465e-03 3.6607913e-03\n",
      " 3.9051883e-03 7.0490688e-03 5.6459303e-03 1.5423428e-01 2.9368937e-02\n",
      " 1.3371426e-02 1.0929140e-03 1.2560848e-02 4.2857476e-02 3.5566589e-04\n",
      " 7.7594165e-04 1.0805279e-02 2.8682628e-03 3.4906422e-03 9.9402210e-03\n",
      " 1.4342839e-03 9.2723232e-05 1.3512139e-01 1.0097354e-02 2.4341040e-03\n",
      " 1.2220707e-02 4.6234414e-02 4.2096135e-01 4.6364116e-03 7.0724348e-03\n",
      " 2.2968433e-03 2.9038615e-03 4.4910563e-03 3.0777061e-03 7.4587362e-03\n",
      " 8.5658319e-03] \n",
      " -0.89030135\n",
      "p [[5.00625782e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 9.88735920e-02 1.25156446e-03 5.00625782e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [1.25156446e-13 3.12891114e-02 8.18523154e-01 0.00000000e+00\n",
      "  2.12765957e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.25782228e-03 2.50312891e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 6.25782228e-03]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [7.0101293e-03 2.3165261e-04 4.3599522e-03 5.2649677e-03 5.0318940e-04\n",
      " 7.3119323e-04 6.8603223e-04 4.7852206e-03 1.5176844e-02 3.0751762e-01\n",
      " 2.4571613e-04 2.6149960e-04 5.1037287e-03 2.2368656e-02 7.5475029e-03\n",
      " 4.5310374e-04 3.2470185e-02 1.1671237e-03 3.0724127e-03 6.7298524e-02\n",
      " 8.6776167e-04 6.0999896e-03 1.4518742e-01 2.2497263e-03 6.0954533e-04\n",
      " 2.1496015e-04 3.0084357e-01 3.4357581e-02 5.3386707e-03 6.4045755e-04\n",
      " 3.0949333e-04 1.0437658e-04 1.9838226e-03 3.1952499e-03 1.8858313e-04\n",
      " 1.1553694e-02] \n",
      " 0.8330138\n",
      "p [[0.00625782 0.00375469 0.00125156 0.00250313 0.00250313 0.00125156]\n",
      " [0.00250313 0.00250313 0.09261577 0.01376721 0.00625782 0.00125156]\n",
      " [0.00500626 0.04255319 0.         0.         0.00500626 0.00125156]\n",
      " [0.00125156 0.00625782 0.         0.         0.28410513 0.00500626]\n",
      " [0.00125156 0.00500626 0.05131414 0.4330413  0.         0.00375469]\n",
      " [0.00125156 0.00250313 0.00375469 0.00250313 0.00500626 0.00375469]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.7125335e-03 1.6867614e-03 9.3981531e-04 5.9488378e-03 1.6914902e-03\n",
      " 6.8998738e-04 1.9902039e-02 1.4749641e-03 9.8251214e-04 3.5247388e-01\n",
      " 2.6082845e-02 4.0906257e-04 3.5339468e-03 4.8516988e-04 5.6519071e-05\n",
      " 7.2144569e-05 6.9565175e-04 2.8956687e-04 3.5434010e-04 1.0016167e-03\n",
      " 1.6349049e-04 1.5895344e-05 6.6171482e-04 1.1204195e-03 8.6458510e-04\n",
      " 2.6803300e-02 5.1020390e-01 1.5225408e-03 1.2391061e-03 2.2509469e-02\n",
      " 6.5873447e-04 1.1928112e-03 8.0163693e-03 3.5310950e-04 1.4524965e-03\n",
      " 7.3833071e-04] \n",
      " -0.707371\n",
      "p [[2.50312891e-03 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 4.00500626e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 3.75469337e-03 0.00000000e+00 0.00000000e+00\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 3.24155194e-01 0.00000000e+00 0.00000000e+00\n",
      "  3.31664581e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.91614518e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-03]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  0. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.1283115e-03 9.3073621e-05 6.4978807e-04 2.8141256e-04 5.0068804e-04\n",
      " 3.4021903e-04 2.2866094e-04 1.3153095e-03 2.3823870e-02 9.8471319e-05\n",
      " 6.3947705e-03 1.8436488e-04 1.0901379e-01 3.8002872e-05 2.7129853e-03\n",
      " 6.5825465e-05 3.1779075e-01 1.8298485e-03 2.1584996e-03 2.4432357e-01\n",
      " 3.1606862e-04 1.2532364e-03 1.7303431e-04 2.5368565e-01 4.9354037e-04\n",
      " 1.8102229e-03 1.1217008e-04 9.4496105e-03 5.7923980e-03 4.7814957e-04\n",
      " 7.2721089e-04 3.7000122e-04 3.9043784e-04 2.3604679e-04 5.1422787e-05\n",
      " 7.6887491e-03] \n",
      " 0.11531453\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00250313 0.00125156 0.00125156]\n",
      " [0.01376721 0.00125156 0.00125156 0.25782228 0.03754693 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.01501877 0.         0.         0.         0.00125156]\n",
      " [0.00125156 0.07634543 0.47934919 0.         0.         0.08385482]\n",
      " [0.00125156 0.00125156 0.00876095 0.00125156 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.26854875e-04 2.27564509e-04 8.58069572e-04 4.03858314e-04\n",
      " 2.09091377e-04 1.49371015e-04 1.42563125e-02 1.87625730e-04\n",
      " 1.43423254e-04 7.66820813e-05 6.16346717e-01 1.36208822e-04\n",
      " 9.54019124e-05 1.46750172e-05 2.09876998e-05 7.02083938e-08\n",
      " 4.22224948e-05 9.24454889e-06 7.40105088e-06 1.51096374e-05\n",
      " 8.33413424e-07 3.63879803e-06 2.48978995e-05 2.13051590e-05\n",
      " 5.49834222e-04 2.93952286e-01 3.08608229e-04 1.66519138e-04\n",
      " 4.27033985e-04 6.82251826e-02 1.34689617e-04 1.53137560e-04\n",
      " 9.82444617e-04 1.27288338e-03 1.82499920e-04 6.73988761e-05] \n",
      " 0.85641617\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.00125156e-02 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  3.00375469e-02 1.25156446e-13]\n",
      " [1.25156446e-13 4.69336671e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.88110138e-01]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  1.  1.]\n",
      " [ 0.  0. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 99 completed in 27.016618013381958 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4844851 entropy 1.8733002\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4681177 entropy 1.8794286\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4406784 entropy 1.8912296\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.40856 entropy 1.9044667\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3775785 entropy 1.9149389\n",
      "kl 0.020990938\n",
      "completed in 0.3018620014190674 s\n",
      "game 100 completed in 6.540998935699463 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.677867 entropy 1.9811838\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6496654 entropy 1.98372\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.605321 entropy 1.9837602\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5573678 entropy 1.9840155\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5147216 entropy 1.986325\n",
      "kl 0.022118853\n",
      "completed in 0.3366212844848633 s\n",
      "game 101 completed in 11.939475059509277 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5905118 entropy 1.8997877\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5740128 entropy 1.9099877\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5460613 entropy 1.9211272\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.511647 entropy 1.9293597\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4738383 entropy 1.9324163\n",
      "kl 0.02070681\n",
      "completed in 0.3272817134857178 s\n",
      "game 102 completed in 6.602820873260498 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5868108 entropy 1.9854076\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5616417 entropy 1.9765325\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5243654 entropy 1.9654119\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4841025 entropy 1.9554307\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4419022 entropy 1.949218\n",
      "kl 0.01882595\n",
      "completed in 0.2914459705352783 s\n",
      "game 103 completed in 10.283706903457642 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6222467 entropy 1.9592247\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.60566 entropy 1.9661412\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5797842 entropy 1.9748021\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5468037 entropy 1.98135\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5088377 entropy 1.9834199\n",
      "kl 0.02028195\n",
      "completed in 0.3029601573944092 s\n",
      "game 104 completed in 6.574908971786499 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.544937 entropy 1.9778504\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5269637 entropy 1.9782643\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4976568 entropy 1.9802487\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4632642 entropy 1.983713\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.429689 entropy 1.9861286\n",
      "kl 0.019349165\n",
      "completed in 0.2979109287261963 s\n",
      "game 105 completed in 15.426285028457642 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5378816 entropy 1.9631999\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.518972 entropy 1.9543962\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.488034 entropy 1.9378679\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.455968 entropy 1.9200687\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4252372 entropy 1.9068618\n",
      "kl 0.027562156\n",
      "completed in 0.32099294662475586 s\n",
      "game 106 completed in 8.665180921554565 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.597506 entropy 1.9461623\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5791385 entropy 1.9471686\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5481088 entropy 1.9511199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.5128179 entropy 1.9556304\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4775136 entropy 1.957709\n",
      "kl 0.021075625\n",
      "completed in 0.29099392890930176 s\n",
      "game 107 completed in 6.473235845565796 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6049101 entropy 1.9630377\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5697966 entropy 1.961241\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5292606 entropy 1.9612882\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4961083 entropy 1.9636112\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4650095 entropy 1.9670177\n",
      "kl 0.019380946\n",
      "completed in 0.38451385498046875 s\n",
      "game 108 completed in 11.368750095367432 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5498493 entropy 1.9366689\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5243056 entropy 1.9398568\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.488363 entropy 1.9412446\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4519877 entropy 1.940325\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4139426 entropy 1.937518\n",
      "kl 0.018184006\n",
      "completed in 0.2941131591796875 s\n",
      "game 109 completed in 8.547109842300415 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.628534 entropy 1.9855103\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6013548 entropy 1.9897555\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.558471 entropy 1.9978558\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5110018 entropy 2.0051167\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.462917 entropy 2.008366\n",
      "kl 0.02724028\n",
      "completed in 0.29355692863464355 s\n",
      "game 110 completed in 6.5240278244018555 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5608327 entropy 1.9542757\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5452096 entropy 1.9501145\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.518317 entropy 1.9464266\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4833772 entropy 1.9449356\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4466588 entropy 1.9442718\n",
      "kl 0.016154211\n",
      "completed in 0.3545989990234375 s\n",
      "game 111 completed in 10.298901796340942 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.49241 entropy 1.9483969\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.472501 entropy 1.9446367\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4391766 entropy 1.9370416\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.404424 entropy 1.9267099\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3709102 entropy 1.9160814\n",
      "kl 0.026887365\n",
      "completed in 0.34227490425109863 s\n",
      "game 112 completed in 7.019628047943115 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6128104 entropy 1.9390962\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5876975 entropy 1.9320872\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.545247 entropy 1.9282854\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5031416 entropy 1.9279269\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4625301 entropy 1.9311634\n",
      "kl 0.023003235\n",
      "completed in 0.32756686210632324 s\n",
      "game 113 completed in 8.813468933105469 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5810761 entropy 1.9781199\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5641432 entropy 1.9834721\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5329733 entropy 1.9872124\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5008614 entropy 1.9899125\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4718034 entropy 1.9923735\n",
      "kl 0.018150842\n",
      "completed in 0.31137919425964355 s\n",
      "game 114 completed in 7.675559997558594 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5843773 entropy 1.9352776\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.557171 entropy 1.9435313\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.519819 entropy 1.953543\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.481122 entropy 1.9632881\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4434698 entropy 1.9697258\n",
      "kl 0.027072925\n",
      "completed in 0.30652642250061035 s\n",
      "game 115 completed in 7.915874004364014 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5944507 entropy 2.0038214\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5633836 entropy 2.0051117\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5235047 entropy 2.0033617\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4863863 entropy 1.9994009\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4561286 entropy 1.9933922\n",
      "kl 0.024738342\n",
      "completed in 0.3577609062194824 s\n",
      "game 116 completed in 12.250661134719849 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6144233 entropy 1.9705616\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.597914 entropy 1.9637967\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.566889 entropy 1.9597259\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5310135 entropy 1.9593798\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4965913 entropy 1.9615016\n",
      "kl 0.02059877\n",
      "completed in 0.27303123474121094 s\n",
      "game 117 completed in 7.822609186172485 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.619256 entropy 1.9701147\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6002424 entropy 1.9741594\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.569685 entropy 1.9789455\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.531289 entropy 1.9836034\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4927404 entropy 1.9874955\n",
      "kl 0.021980142\n",
      "completed in 0.3035769462585449 s\n",
      "game 118 completed in 6.826315879821777 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5800188 entropy 1.989827\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5601702 entropy 1.9925523\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.529686 entropy 1.995036\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4966574 entropy 1.9958568\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4628127 entropy 1.9943048\n",
      "kl 0.021362185\n",
      "completed in 0.2668030261993408 s\n",
      "game 119 completed in 16.825130939483643 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5890584 entropy 1.9893293\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.572867 entropy 1.9864169\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5462606 entropy 1.9846965\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5149925 entropy 1.9834805\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4805946 entropy 1.9808664\n",
      "kl 0.018548556\n",
      "completed in 0.3345210552215576 s\n",
      "game 120 completed in 8.572685718536377 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.622719 entropy 2.0388014\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.600277 entropy 2.0303583\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5616798 entropy 2.0184386\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.515369 entropy 2.0071864\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4699786 entropy 1.9985548\n",
      "kl 0.02678553\n",
      "completed in 0.2757108211517334 s\n",
      "game 121 completed in 10.224608898162842 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5915818 entropy 1.9748038\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5763988 entropy 1.9719489\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5487056 entropy 1.9704633\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5133495 entropy 1.96992\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4779658 entropy 1.9696007\n",
      "kl 0.019527404\n",
      "completed in 0.3396890163421631 s\n",
      "game 122 completed in 6.568903923034668 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5863335 entropy 1.9019485\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5653815 entropy 1.9030681\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5297787 entropy 1.9061403\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4864535 entropy 1.9099848\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4420888 entropy 1.9142766\n",
      "kl 0.027506325\n",
      "completed in 0.591240406036377 s\n",
      "game 123 completed in 6.721163034439087 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5705674 entropy 1.9463749\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5535634 entropy 1.9467876\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5255344 entropy 1.9465036\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4940324 entropy 1.9448442\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4580789 entropy 1.9413929\n",
      "kl 0.018742152\n",
      "completed in 0.30486392974853516 s\n",
      "game 124 completed in 14.070795059204102 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5713944 entropy 1.9414935\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.55538 entropy 1.9450829\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.530017 entropy 1.9527113\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5006633 entropy 1.9608862\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4672403 entropy 1.9661504\n",
      "kl 0.024865136\n",
      "completed in 0.296583890914917 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 125 completed in 9.553906202316284 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.681237 entropy 1.910917\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6588602 entropy 1.9092948\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6213737 entropy 1.907963\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5788934 entropy 1.9087343\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5365038 entropy 1.912935\n",
      "kl 0.023055324\n",
      "completed in 0.3371388912200928 s\n",
      "game 126 completed in 8.809553146362305 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6100302 entropy 2.008499\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5933728 entropy 2.016326\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5679274 entropy 2.0217156\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5384195 entropy 2.022399\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5052173 entropy 2.0170655\n",
      "kl 0.018707918\n",
      "completed in 0.36006617546081543 s\n",
      "game 127 completed in 22.437023878097534 s 24 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5834787 entropy 1.9849411\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.562068 entropy 1.9686608\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.528562 entropy 1.9515886\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4929922 entropy 1.9376733\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4585557 entropy 1.9301682\n",
      "kl 0.02247016\n",
      "completed in 0.3160209655761719 s\n",
      "game 128 completed in 8.701738834381104 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.559359 entropy 1.9341877\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5346634 entropy 1.9451036\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4986188 entropy 1.9607651\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4635966 entropy 1.9746201\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4281783 entropy 1.9821364\n",
      "kl 0.033565216\n",
      "completed in 0.2948429584503174 s\n",
      "game 129 completed in 13.49527382850647 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6305494 entropy 1.9842684\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6141129 entropy 1.9822156\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5896318 entropy 1.9779823\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.562491 entropy 1.9771162\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5319438 entropy 1.9817661\n",
      "kl 0.023386376\n",
      "completed in 0.3063960075378418 s\n",
      "game 130 completed in 11.64302682876587 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6192482 entropy 2.030168\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6009746 entropy 2.046953\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.572013 entropy 2.0605593\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.537944 entropy 2.0650363\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.499458 entropy 2.0581484\n",
      "kl 0.017852552\n",
      "completed in 0.3018312454223633 s\n",
      "game 131 completed in 10.788782835006714 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.692148 entropy 1.9898621\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.664076 entropy 1.9788984\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6188161 entropy 1.9740933\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5679953 entropy 1.976079\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5177433 entropy 1.981815\n",
      "kl 0.01904701\n",
      "completed in 0.33855509757995605 s\n",
      "game 132 completed in 9.502577781677246 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.654513 entropy 2.0246296\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6296055 entropy 2.0202236\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.588008 entropy 2.0055354\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5426874 entropy 1.9862498\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.497104 entropy 1.9686643\n",
      "kl 0.028899532\n",
      "completed in 0.33844995498657227 s\n",
      "game 133 completed in 10.693397998809814 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6446161 entropy 1.9055524\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6221538 entropy 1.9025267\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5781069 entropy 1.9050353\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.529666 entropy 1.9099016\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.488469 entropy 1.9115458\n",
      "kl 0.022464076\n",
      "completed in 0.3142390251159668 s\n",
      "game 134 completed in 7.795593023300171 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5090997 entropy 1.8679763\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4841983 entropy 1.8600185\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4489474 entropy 1.8507363\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4123385 entropy 1.8442221\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3753319 entropy 1.8429601\n",
      "kl 0.020239718\n",
      "completed in 0.318601131439209 s\n",
      "game 135 completed in 8.77728271484375 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5994775 entropy 1.9275064\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5798364 entropy 1.9373782\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.549037 entropy 1.9474354\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5131078 entropy 1.9534664\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4770207 entropy 1.954627\n",
      "kl 0.015693707\n",
      "completed in 0.290496826171875 s\n",
      "game 136 completed in 9.637119054794312 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.528752 entropy 1.9552252\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.510953 entropy 1.9466462\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4819927 entropy 1.9346356\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4473987 entropy 1.9240878\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4097548 entropy 1.917907\n",
      "kl 0.018818272\n",
      "completed in 0.3177199363708496 s\n",
      "game 137 completed in 6.89982795715332 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5407426 entropy 1.9007363\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5161817 entropy 1.906065\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4805467 entropy 1.9120082\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4417539 entropy 1.9143757\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4016097 entropy 1.9112502\n",
      "kl 0.015368523\n",
      "completed in 0.41669487953186035 s\n",
      "game 138 completed in 6.888145208358765 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5625446 entropy 1.9087639\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5362935 entropy 1.9029945\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4970338 entropy 1.9026732\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4539402 entropy 1.909589\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4122477 entropy 1.9226482\n",
      "kl 0.02024053\n",
      "completed in 0.2909541130065918 s\n",
      "game 139 completed in 6.593913793563843 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5438375 entropy 1.9863899\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.522567 entropy 1.9978536\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4920676 entropy 2.0028393\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4582837 entropy 2.0011506\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.42056 entropy 1.9941695\n",
      "kl 0.017623225\n",
      "completed in 0.33351993560791016 s\n",
      "game 140 completed in 13.463823080062866 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.574545 entropy 1.9975921\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5545783 entropy 1.9928825\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.52063 entropy 1.9895875\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4813576 entropy 1.9869913\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4397295 entropy 1.9831219\n",
      "kl 0.01687836\n",
      "completed in 0.3179008960723877 s\n",
      "game 141 completed in 11.043487071990967 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5832217 entropy 1.9646688\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5544736 entropy 1.9642487\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.514347 entropy 1.9632422\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4693496 entropy 1.9581854\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4248137 entropy 1.9482558\n",
      "kl 0.02649966\n",
      "completed in 0.28397369384765625 s\n",
      "game 142 completed in 8.690455198287964 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.64172 entropy 1.9639907\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6172993 entropy 1.9474036\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5791018 entropy 1.9319606\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5341535 entropy 1.9237028\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4883544 entropy 1.9244318\n",
      "kl 0.028734595\n",
      "completed in 0.3338029384613037 s\n",
      "game 143 completed in 8.233658075332642 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.56018 entropy 1.8849155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1 lr_mult 0.4444444444444444 loss 2.546637 entropy 1.8943284\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.522081 entropy 1.9018576\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4878259 entropy 1.9038504\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4506779 entropy 1.9001904\n",
      "kl 0.02128706\n",
      "completed in 0.3647952079772949 s\n",
      "game 144 completed in 9.141424179077148 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6097975 entropy 1.9390146\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5841544 entropy 1.9350295\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5462415 entropy 1.9316363\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5022964 entropy 1.9309464\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4568632 entropy 1.9321215\n",
      "kl 0.03314183\n",
      "completed in 0.3819739818572998 s\n",
      "game 145 completed in 9.008222818374634 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5320914 entropy 1.9023244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5121114 entropy 1.9036387\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4806998 entropy 1.90348\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4451964 entropy 1.9000618\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4081104 entropy 1.8944631\n",
      "kl 0.016830157\n",
      "completed in 0.3155539035797119 s\n",
      "game 146 completed in 8.990522146224976 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5896144 entropy 1.9000138\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5652103 entropy 1.89962\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.527772 entropy 1.9032282\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4889188 entropy 1.9093083\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4525306 entropy 1.915001\n",
      "kl 0.03152509\n",
      "completed in 0.29455995559692383 s\n",
      "game 147 completed in 8.464830875396729 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6430812 entropy 1.958809\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6216211 entropy 1.9599322\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.574729 entropy 1.9607697\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5238533 entropy 1.962918\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.480939 entropy 1.9680719\n",
      "kl 0.030237185\n",
      "completed in 0.3680598735809326 s\n",
      "game 148 completed in 11.46192216873169 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5850163 entropy 1.9694848\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5672288 entropy 1.9810753\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5361981 entropy 1.9934133\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5038087 entropy 2.0017924\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4740586 entropy 2.002252\n",
      "kl 0.03432434\n",
      "completed in 0.24845099449157715 s\n",
      "prediction:\n",
      " [0.00360861 0.00282041 0.00553703 0.00283594 0.00454925 0.00162392\n",
      " 0.00271836 0.01568339 0.12727118 0.01082996 0.00855265 0.00369018\n",
      " 0.00333416 0.13652048 0.05071145 0.09480956 0.00930083 0.0031048\n",
      " 0.00406925 0.00951849 0.10626768 0.04761495 0.13293386 0.00375055\n",
      " 0.00286134 0.00633741 0.01167203 0.14315939 0.0157652  0.00355869\n",
      " 0.00418834 0.00596702 0.004338   0.00412468 0.00267345 0.00369781] \n",
      " -0.35222825\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.02753442e-01 2.42803504e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.37672090e-01 4.16770964e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [4.41610871e-04 1.11762289e-04 5.28727076e-04 3.17924801e-04\n",
      " 1.36907125e-04 2.07235717e-05 1.44243808e-04 3.79485339e-02\n",
      " 8.28924682e-03 1.17029082e-02 3.48436268e-04 1.15743765e-04\n",
      " 1.62751254e-04 1.22884492e-04 3.85759324e-02 3.05205494e-01\n",
      " 4.55120690e-02 2.53128499e-04 9.78894532e-04 6.21741153e-02\n",
      " 3.89430553e-01 2.34059542e-02 7.16437862e-05 1.88970385e-04\n",
      " 3.58219768e-05 3.14994657e-04 1.01956073e-02 1.42944520e-02\n",
      " 4.64887656e-02 2.05203090e-04 8.35623578e-05 3.38515703e-04\n",
      " 2.33945553e-04 3.66494642e-04 3.55688622e-04 8.97931226e-04] \n",
      " 0.174486\n",
      "p [[0.00125156 0.00125156 0.00250313 0.00125156 0.00750939 0.00125156]\n",
      " [0.00125156 0.00625782 0.11013767 0.00750939 0.01126408 0.00750939]\n",
      " [0.00125156 0.12265332 0.04255319 0.06132666 0.00750939 0.00125156]\n",
      " [0.01126408 0.00625782 0.05381727 0.         0.24530663 0.00375469]\n",
      " [0.00250313 0.00625782 0.08010013 0.16395494 0.00750939 0.00375469]\n",
      " [0.00250313 0.00250313 0.00250313 0.00250313 0.00125156 0.00876095]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02744717 0.0031224  0.0094394  0.00201004 0.00897282 0.00122341\n",
      " 0.00458434 0.00447721 0.13353436 0.01326427 0.01438103 0.00640255\n",
      " 0.00291132 0.01404707 0.10945246 0.07814398 0.02185182 0.00596112\n",
      " 0.01206479 0.02359282 0.05282586 0.05664659 0.00591735 0.00438525\n",
      " 0.00427463 0.00999679 0.01118693 0.29307017 0.00604962 0.00410411\n",
      " 0.00145646 0.01618065 0.00267273 0.00336937 0.0044418  0.02653738] \n",
      " -0.7413893\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.50187735e-02 1.25156446e-03 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.22653317e-01 1.10137672e-01\n",
      "  1.40175219e-01 1.25156446e-13]\n",
      " [1.25156446e-13 3.50438048e-02 2.25281602e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.75469337e-03 5.00625782e-03\n",
      "  3.40425532e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.6099853e-03 1.4465612e-04 2.0907761e-03 2.5641997e-04 4.1624423e-04\n",
      " 4.6813257e-05 1.7953829e-04 5.4670358e-04 2.0893412e-02 1.5638378e-01\n",
      " 4.1002085e-04 5.3316873e-04 3.4015367e-04 1.3732216e-04 5.8449171e-03\n",
      " 2.5588515e-01 2.3702538e-02 2.8153363e-04 5.3084682e-04 3.3091139e-02\n",
      " 3.4756714e-01 1.3208342e-03 5.0587809e-05 4.2819662e-04 3.4082925e-04\n",
      " 3.0623234e-04 9.3303628e-02 4.6581306e-02 5.3708686e-04 2.5226478e-04\n",
      " 6.4770400e-05 8.7411737e-04 1.2365509e-04 9.9869142e-04 3.1104914e-04\n",
      " 1.6146116e-03] \n",
      " 0.011618474\n",
      "p [[0.01001252 0.00250313 0.00375469 0.00250313 0.01877347 0.00125156]\n",
      " [0.00375469 0.00250313 0.08010013 0.00375469 0.00500626 0.00375469]\n",
      " [0.00125156 0.00625782 0.61326658 0.03003755 0.00876095 0.00250313]\n",
      " [0.00625782 0.00750939 0.01877347 0.         0.         0.00125156]\n",
      " [0.00375469 0.00375469 0.00500626 0.12515645 0.         0.00250313]\n",
      " [0.00125156 0.00876095 0.00125156 0.00125156 0.00125156 0.01251564]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00703536 0.00279273 0.00215631 0.00368471 0.00470461 0.00132957\n",
      " 0.00159814 0.00077562 0.02444673 0.3667211  0.00198741 0.00693907\n",
      " 0.00234519 0.00651002 0.00114051 0.13535056 0.00531311 0.00308059\n",
      " 0.00398143 0.00478534 0.09670784 0.00153612 0.00258614 0.00274047\n",
      " 0.00437967 0.00214442 0.23009112 0.05364019 0.00111939 0.00220785\n",
      " 0.00121099 0.00337256 0.00261822 0.00101517 0.00306455 0.00488728] \n",
      " -0.97308475\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 8.76095119e-03 6.75844806e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.83979975e-01\n",
      "  4.24280350e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.37672090e-02 2.51564456e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 4.00500626e-02 1.00125156e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.5486639e-03 6.1885710e-04 3.3573085e-03 4.5921621e-04 2.3984758e-03\n",
      " 7.0746033e-04 2.2350039e-04 3.6974039e-04 8.8098701e-03 2.1227015e-02\n",
      " 1.6330677e-03 1.3072973e-02 1.9580047e-03 1.7371187e-04 7.0095342e-04\n",
      " 1.2426788e-01 1.2983924e-03 5.1355228e-04 7.0206128e-04 8.7949273e-04\n",
      " 7.7770811e-01 5.1311468e-04 8.6384622e-05 1.5609912e-03 2.1597887e-03\n",
      " 1.2906457e-03 1.7726040e-02 6.0828347e-03 3.5502980e-04 2.6322855e-04\n",
      " 3.7742121e-04 4.2930045e-03 3.7831726e-04 7.4109819e-04 7.7972410e-04\n",
      " 7.6411036e-04] \n",
      " 0.9809359\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.02377972 0.1902378  0.00125156 0.00250313]\n",
      " [0.00125156 0.16645807 0.         0.20025031 0.         0.00125156]\n",
      " [0.00125156 0.00125156 0.1339174  0.         0.         0.00125156]\n",
      " [0.00125156 0.00125156 0.23153942 0.02252816 0.         0.00125156]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]]\n",
      "move 26\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00489339 0.00692363 0.02306116 0.01012622 0.00620585 0.01193197\n",
      " 0.00585253 0.00161721 0.12495507 0.01574186 0.0171895  0.00610302\n",
      " 0.00303178 0.07039535 0.00021305 0.06188474 0.04277145 0.0237641\n",
      " 0.02775552 0.10208891 0.09774058 0.00050362 0.02342366 0.00772967\n",
      " 0.00648545 0.01417192 0.02355034 0.1988893  0.00250172 0.01327872\n",
      " 0.00634241 0.0076385  0.01094035 0.00884425 0.00703061 0.00442277] \n",
      " -0.97331166\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 8.76095119e-03\n",
      "  1.25156446e-13 8.76095119e-03]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 5.88235294e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 9.17396746e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 3.75469337e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.03672542 0.00200737 0.00557888 0.00688184 0.02603932 0.00465497\n",
      " 0.00131367 0.00183473 0.0008386  0.05560846 0.07097235 0.22009625\n",
      " 0.01155097 0.01958938 0.00079993 0.028576   0.03073016 0.03449434\n",
      " 0.03914579 0.04474734 0.06702896 0.0009067  0.00728799 0.02987768\n",
      " 0.03957927 0.05479049 0.06851261 0.00144292 0.00155424 0.00341125\n",
      " 0.0056757  0.04784109 0.01488293 0.00116128 0.00250726 0.01135392] \n",
      " 0.323137\n",
      "p [[0.00125156 0.00125156 0.00750939 0.00250313 0.00125156 0.00250313]\n",
      " [0.00125156 0.00125156 0.04005006 0.00500626 0.00500626 0.00250313]\n",
      " [0.00125156 0.03254068 0.         0.05006258 0.         0.00876095]\n",
      " [0.01126408 0.04505632 0.         0.         0.         0.00125156]\n",
      " [0.00125156 0.00375469 0.         0.75969962 0.         0.00375469]\n",
      " [0.00125156 0.00125156 0.00250313 0.00250313 0.00125156 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.55616708e-03 1.27888527e-02 1.38301104e-02 4.13811877e-02\n",
      " 4.75581689e-03 6.06887043e-03 6.89186435e-03 3.18886340e-03\n",
      " 3.10318940e-03 1.31219374e-02 5.64055406e-02 4.43829186e-02\n",
      " 1.44991674e-03 3.73637932e-03 5.97503167e-05 2.83645419e-03\n",
      " 1.25222758e-03 2.12132156e-01 4.05309260e-01 1.49061868e-03\n",
      " 2.49065575e-03 4.00014615e-05 3.70654790e-03 7.05873594e-03\n",
      " 2.91686207e-02 2.25883964e-02 1.07572684e-02 5.33132162e-03\n",
      " 3.23934783e-03 1.43599678e-02 2.84424191e-03 9.41862445e-03\n",
      " 3.34220938e-02 4.33237711e-03 1.16757015e-02 2.82411231e-03] \n",
      " -0.9987822\n",
      "p [[1.50187735e-02 1.25156446e-13 6.25782228e-03 2.50312891e-03\n",
      "  2.00250313e-02 1.00125156e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.08886108e-01\n",
      "  1.75219024e-02 1.23904881e-01]\n",
      " [1.12640801e-02 6.25782228e-03 0.00000000e+00 3.62953692e-02\n",
      "  0.00000000e+00 7.50938673e-03]\n",
      " [2.12765957e-02 4.04255319e-01 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.76095119e-03]\n",
      " [1.50187735e-02 2.75344180e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [5.00625782e-03 1.75219024e-02 3.62953692e-02 1.25156446e-13\n",
      "  1.25156446e-13 9.88735920e-02]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00870862 0.00193423 0.00113206 0.00729288 0.01501232 0.0025831\n",
      " 0.00119052 0.00125101 0.00101648 0.02277466 0.0303108  0.17244804\n",
      " 0.02100483 0.30595326 0.00041615 0.01419147 0.00047468 0.02693158\n",
      " 0.05863182 0.00056774 0.01775632 0.00084625 0.07023677 0.05497789\n",
      " 0.04820414 0.01528992 0.03285887 0.00233728 0.00069219 0.00122014\n",
      " 0.00656091 0.02941909 0.01387121 0.00042271 0.00410475 0.00737545] \n",
      " 0.23066273\n",
      "p [[0.00125156 0.00375469 0.00375469 0.01251564 0.00250313 0.00125156]\n",
      " [0.00250313 0.00125156 0.00250313 0.00500626 0.01627034 0.0175219 ]\n",
      " [0.00125156 0.00125156 0.         0.00125156 0.         0.05506884]\n",
      " [0.82728411 0.         0.         0.         0.         0.00125156]\n",
      " [0.00750939 0.01126408 0.         0.         0.         0.00250313]\n",
      " [0.00125156 0.00375469 0.01001252 0.00125156 0.00375469 0.00125156]]\n",
      "move 18\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.33845974e-03 3.10751051e-02 1.86389163e-02 5.13388924e-02\n",
      " 1.19655272e-02 6.44200668e-03 1.11619029e-02 3.36950854e-03\n",
      " 1.01288045e-02 1.88534595e-02 7.28637502e-02 3.29486802e-02\n",
      " 5.56839164e-03 1.60430167e-02 2.50752957e-04 8.36113933e-03\n",
      " 1.17664668e-03 1.77670896e-01 1.93756491e-01 1.08943204e-03\n",
      " 9.91963409e-03 7.91763159e-05 1.40850553e-02 4.38208729e-02\n",
      " 2.12855339e-02 5.02414554e-02 1.45935770e-02 2.20722388e-02\n",
      " 3.39274737e-03 2.23851036e-02 4.10582358e-03 1.64565016e-02\n",
      " 6.51796162e-02 9.27232392e-03 1.79328341e-02 7.13576702e-03] \n",
      " -0.9721404\n",
      "p [[6.25782228e-03 1.25156446e-13 1.25156446e-13 2.50312891e-03\n",
      "  7.38423029e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.22653317e-01\n",
      "  1.50187735e-02 2.29036295e-01]\n",
      " [1.75219024e-02 1.63954944e-01 0.00000000e+00 1.51439299e-01\n",
      "  0.00000000e+00 1.50187735e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.87734668e-02]\n",
      " [5.13141427e-02 6.88360451e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [3.75469337e-03 1.62703379e-02 3.37922403e-02 1.25156446e-13\n",
      "  2.50312891e-03 7.50938673e-03]]\n",
      "move 11\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.03342279 0.00215984 0.0016846  0.02591331 0.01439108 0.00321983\n",
      " 0.00249052 0.00223236 0.00182055 0.17218933 0.02531796 0.01606388\n",
      " 0.02372402 0.1005072  0.00346879 0.01760585 0.00120456 0.03001637\n",
      " 0.05947525 0.0012453  0.03310351 0.00353476 0.05114863 0.0836193\n",
      " 0.00387829 0.00898105 0.1467188  0.00780905 0.00059522 0.00111083\n",
      " 0.01819303 0.02399564 0.05721913 0.00176491 0.00230571 0.01786906] \n",
      " 0.8420276\n",
      "p [[0.00125156 0.01126408 0.00625782 0.04005006 0.00500626 0.00250313]\n",
      " [0.00500626 0.00125156 0.00625782 0.01376721 0.06633292 0.        ]\n",
      " [0.00250313 0.00500626 0.         0.01501877 0.         0.28911139]\n",
      " [0.         0.         0.         0.         0.         0.01376721]\n",
      " [0.05256571 0.16520651 0.         0.         0.         0.00625782]\n",
      " [0.00125156 0.00500626 0.27659574 0.00250313 0.00500626 0.00125156]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.78092660e-02 2.95632277e-02 5.07441498e-02 4.47711460e-02\n",
      " 1.85976028e-02 5.45464875e-03 1.86417904e-02 1.89109659e-03\n",
      " 1.42171485e-02 2.45995913e-02 1.13420852e-01 5.99980503e-02\n",
      " 7.19035510e-03 1.45507315e-02 1.11012436e-04 9.19517875e-03\n",
      " 9.79098026e-04 3.89478467e-02 4.34516892e-02 9.56409029e-04\n",
      " 1.30091291e-02 4.16625880e-05 2.32836399e-02 4.58428748e-02\n",
      " 2.52207424e-02 1.40035093e-01 2.48972848e-02 1.94049589e-02\n",
      " 3.35966563e-03 4.92888466e-02 5.83319832e-03 1.84822828e-02\n",
      " 5.12764566e-02 1.12837600e-02 2.84166150e-02 1.52329747e-02] \n",
      " -0.9964719\n",
      "p [[5.00625782e-03 1.25156446e-13 1.25156446e-13 3.75469337e-03\n",
      "  2.50312891e-03 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 2.00250313e-02\n",
      "  3.75469337e-03 0.00000000e+00]\n",
      " [3.75469337e-03 1.25156446e-02 0.00000000e+00 3.75469337e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.12640801e-02]\n",
      " [1.25156446e-13 2.50312891e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [3.75469337e-03 5.00625782e-03 9.18648310e-01 1.25156446e-13\n",
      "  1.25156446e-13 3.75469337e-03]]\n",
      "move 32\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.02094707 0.00286017 0.00738363 0.00496897 0.05314294 0.00266576\n",
      " 0.0042318  0.00185587 0.00779714 0.02850107 0.09948041 0.02427261\n",
      " 0.02863587 0.16947281 0.00363928 0.01669187 0.0137066  0.02040823\n",
      " 0.02407226 0.01023712 0.02197405 0.00381412 0.06254616 0.08284263\n",
      " 0.00589189 0.05454813 0.02397501 0.01108496 0.00070057 0.00338947\n",
      " 0.01521448 0.11990216 0.01674226 0.00585613 0.00569042 0.02085627] \n",
      " 0.36767444\n",
      "p [[0.01251564 0.01501877 0.02503129 0.03379224 0.00876095 0.00250313]\n",
      " [0.01001252 0.00125156 0.00750939 0.29662078 0.07634543 0.        ]\n",
      " [0.00250313 0.00625782 0.         0.00750939 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.0212766 ]\n",
      " [0.19148936 0.22152691 0.         0.         0.         0.02252816]\n",
      " [0.00250313 0.00876095 0.         0.00625782 0.01376721 0.00625782]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  0. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.1030182e-02 9.0209795e-03 5.8205843e-02 2.2712857e-02 1.1062875e-01\n",
      " 2.2455046e-03 2.4079174e-02 4.3514515e-03 1.3704724e-02 1.4942752e-03\n",
      " 9.7608306e-02 6.1557043e-02 3.1333049e-03 3.1889285e-04 7.4096919e-05\n",
      " 1.1183255e-03 5.0105895e-03 2.6679663e-02 1.2766759e-02 5.4908940e-03\n",
      " 8.7415567e-04 1.0237649e-04 7.6106243e-04 2.6339851e-02 8.1234202e-02\n",
      " 1.9519855e-01 1.2093908e-03 3.5070058e-02 3.5391189e-03 3.1812210e-02\n",
      " 1.2172709e-03 9.0154327e-02 1.3795183e-02 1.1011765e-02 7.1046231e-03\n",
      " 1.9344386e-02] \n",
      " -0.97729623\n",
      "p [[1.37672090e-02 1.25156446e-13 1.25156446e-02 1.25156446e-13\n",
      "  1.37672090e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 0.00000000e+00\n",
      "  3.25406758e-02 0.00000000e+00]\n",
      " [1.50187735e-02 7.32165207e-01 0.00000000e+00 1.00125156e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.12765957e-02]\n",
      " [3.75469337e-03 5.50688360e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [5.00625782e-03 6.00750939e-02 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 2.25281602e-02]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.01604944 0.03560246 0.02205333 0.0090437  0.05307972 0.0049754\n",
      " 0.05224252 0.01475761 0.01399936 0.04083855 0.00851549 0.11705352\n",
      " 0.01236651 0.0065831  0.00050283 0.00157732 0.01477889 0.02381996\n",
      " 0.02742925 0.02238048 0.00240964 0.00124151 0.00120115 0.08785941\n",
      " 0.0243887  0.00942239 0.01006843 0.01744959 0.00520443 0.02089568\n",
      " 0.00921937 0.20132972 0.00454223 0.00469943 0.04814691 0.0542721 ] \n",
      " 0.9676014\n",
      "p [[0.01001252 0.00500626 0.03128911 0.02002503 0.06758448 0.00125156]\n",
      " [0.02878598 0.00250313 0.01126408 0.         0.25031289 0.        ]\n",
      " [0.00125156 0.         0.         0.00125156 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01376721]\n",
      " [0.11764706 0.28911139 0.         0.         0.         0.0175219 ]\n",
      " [0.00125156 0.05506884 0.         0.06007509 0.00500626 0.01001252]]\n",
      "move 25\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 0. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.9323192e-02 1.5397382e-02 5.2838534e-02 4.0318873e-02 2.2689874e-01\n",
      " 8.5289553e-03 1.6136134e-02 7.5239488e-03 3.7855826e-02 2.6544884e-03\n",
      " 3.5145807e-03 3.8543690e-02 3.0951591e-03 1.7678970e-04 3.2332318e-05\n",
      " 1.2983305e-03 4.3675057e-03 5.5673271e-03 3.0480770e-03 6.0789264e-03\n",
      " 7.2851346e-04 3.6407509e-05 4.4888663e-04 2.1550946e-02 4.7091328e-02\n",
      " 9.0489397e-03 1.7444608e-03 6.1480891e-02 9.8372679e-03 2.2038376e-02\n",
      " 5.0628404e-03 1.6273330e-01 2.1881370e-02 8.0542285e-03 6.6103525e-03\n",
      " 8.8453047e-02] \n",
      " -0.9931514\n",
      "p [[2.50312891e-03 3.75469337e-03 3.75469337e-03 2.50312891e-03\n",
      "  5.00625782e-03 1.25156446e-13]\n",
      " [5.00625782e-03 2.50312891e-03 2.50312891e-03 0.00000000e+00\n",
      "  2.50312891e-03 0.00000000e+00]\n",
      " [2.50312891e-03 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 8.76095119e-03]\n",
      " [9.23654568e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [2.50312891e-03 1.87734668e-02 0.00000000e+00 1.25156446e-13\n",
      "  5.00625782e-03 6.25782228e-03]]\n",
      "move 24\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.03298617 0.05679306 0.01446465 0.00952416 0.01508246 0.0077752\n",
      " 0.06870763 0.04781717 0.01045443 0.05491595 0.00400113 0.01939514\n",
      " 0.02974369 0.00226079 0.0054152  0.0029265  0.01435403 0.03526409\n",
      " 0.03173148 0.0264032  0.00570772 0.01411357 0.00070692 0.14819929\n",
      " 0.00379756 0.00468415 0.01644572 0.00556878 0.01116416 0.03559445\n",
      " 0.01049104 0.06889381 0.00508071 0.00517259 0.07450463 0.099859  ] \n",
      " 0.99809164\n",
      "p [[0.06508135 0.02002503 0.06132666 0.12015019 0.26282854 0.00876095]\n",
      " [0.01877347 0.00876095 0.04130163 0.         0.00375469 0.        ]\n",
      " [0.00375469 0.         0.         0.01501877 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.02252816]\n",
      " [0.         0.         0.         0.         0.         0.02377972]\n",
      " [0.00500626 0.18773467 0.         0.01251564 0.00876095 0.11013767]]\n",
      "move 4\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  0.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.02099586 0.02825515 0.23212777 0.06565826 0.04085112 0.02346955\n",
      " 0.02827089 0.00624803 0.05826215 0.00588465 0.0012052  0.01877774\n",
      " 0.00068953 0.00047415 0.00043076 0.00371449 0.00969162 0.00298251\n",
      " 0.00224364 0.01208899 0.00227542 0.00030877 0.00271537 0.00332936\n",
      " 0.019327   0.00319453 0.00270595 0.09490595 0.00464415 0.02568138\n",
      " 0.02005704 0.03599603 0.03171221 0.14022851 0.01250166 0.03809481] \n",
      " -0.99111825\n",
      "p [[4.50563204e-02 9.51188986e-02 2.37797247e-02 1.62703379e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.01376721e-01 8.01001252e-02 1.12640801e-02 0.00000000e+00\n",
      "  1.25156446e-13 0.00000000e+00]\n",
      " [2.75344180e-02 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.62703379e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.88235294e-02]\n",
      " [1.62703379e-02 1.13892365e-01 0.00000000e+00 1.25156446e-13\n",
      "  1.11389237e-01 1.36420526e-01]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1.  0.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.03651824 0.09611716 0.00925723 0.00672486 0.00702273 0.02066065\n",
      " 0.18656169 0.1115981  0.00235171 0.02773474 0.00105407 0.01310464\n",
      " 0.00175807 0.00941806 0.00292799 0.00483705 0.00504855 0.02245254\n",
      " 0.04076498 0.00502993 0.00483409 0.01071377 0.00139655 0.00849857\n",
      " 0.00505349 0.00057314 0.01473905 0.00240832 0.03075101 0.06992387\n",
      " 0.02954241 0.03395771 0.00588127 0.00442527 0.12614515 0.04021344] \n",
      " 0.66584504\n",
      "p [[0.01126408 0.02002503 0.23153942 0.0387985  0.         0.01376721]\n",
      " [0.01627034 0.00250313 0.0350438  0.         0.45682103 0.        ]\n",
      " [0.00125156 0.         0.         0.01001252 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01501877]\n",
      " [0.01126408 0.0212766  0.         0.08510638 0.00750939 0.02252816]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  0.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.6796246e-02 6.4462103e-02 2.0134592e-01 5.7349943e-02 2.4361094e-02\n",
      " 1.9849960e-02 1.1813365e-02 1.3288927e-03 6.0659368e-02 4.5166840e-03\n",
      " 2.1981994e-04 3.7475795e-02 8.3068188e-04 1.0881170e-04 2.5584351e-04\n",
      " 6.4051466e-04 5.0268578e-03 1.0745139e-03 1.1683163e-03 4.5587816e-03\n",
      " 5.8645406e-04 1.8050364e-04 1.0051875e-03 3.6564805e-03 2.4356795e-02\n",
      " 3.3628647e-04 2.2806488e-03 1.6012320e-01 7.1549322e-04 1.5357266e-02\n",
      " 2.5185915e-02 3.6628623e-02 3.1898107e-02 1.4990582e-01 2.2698808e-02\n",
      " 1.1241066e-02] \n",
      " -0.9675843\n",
      "p [[8.76095119e-03 5.25657071e-02 3.75469337e-03 2.42803504e-01\n",
      "  0.00000000e+00 3.75469337e-03]\n",
      " [6.38297872e-02 4.58072591e-01 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.38047559e-02]\n",
      " [6.25782228e-03 2.62828536e-02 0.00000000e+00 1.25156446e-13\n",
      "  5.38172716e-02 3.62953692e-02]]\n",
      "move 7\n",
      "board\n",
      " [[ 0.  0.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.23870394 0.03057793 0.01711048 0.00276149 0.01384267 0.01240812\n",
      " 0.07626595 0.00115044 0.00126089 0.03489417 0.00146795 0.0091421\n",
      " 0.00166137 0.00900174 0.00948648 0.0070474  0.00651438 0.00676623\n",
      " 0.02030662 0.00683011 0.00278929 0.02395545 0.00292333 0.00203816\n",
      " 0.00455055 0.00045028 0.03076113 0.00266763 0.0004224  0.03725558\n",
      " 0.01051964 0.07110208 0.00492564 0.01233363 0.06927872 0.21682611] \n",
      " 0.7766881\n",
      "p [[0.00500626 0.69336671 0.11013767 0.0212766  0.         0.00625782]\n",
      " [0.01627034 0.         0.02753442 0.         0.         0.        ]\n",
      " [0.00125156 0.         0.         0.00500626 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00500626]\n",
      " [0.00876095 0.01251564 0.         0.07509387 0.00750939 0.00500626]]\n",
      "move 1\n",
      "board\n",
      " [[ 0. -1.  0.  0. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.03044003e-02 4.12808126e-03 1.69126004e-01 8.18905793e-03\n",
      " 5.14164679e-02 1.16124274e-02 1.52597865e-02 8.66301823e-04\n",
      " 6.52799904e-02 9.51252296e-04 8.73987738e-04 5.69266416e-02\n",
      " 6.36850018e-04 1.48227555e-04 2.17266410e-04 6.81889651e-04\n",
      " 1.73106522e-03 1.03055290e-03 3.81592195e-03 2.13514548e-03\n",
      " 4.85563098e-04 1.60697833e-04 6.81270205e-04 1.62799773e-03\n",
      " 2.40029115e-02 8.99027975e-04 5.71116456e-04 1.84499800e-01\n",
      " 4.85980039e-04 1.13726994e-02 1.70919765e-02 6.18156679e-02\n",
      " 4.62721940e-03 2.50600159e-01 2.15724646e-03 1.35893673e-02] \n",
      " -0.9981524\n",
      "p [[1.42678348e-01 0.00000000e+00 3.87984981e-02 2.32790989e-01\n",
      "  0.00000000e+00 1.12640801e-02]\n",
      " [5.75719650e-02 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 4.50563204e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.75719650e-02]\n",
      " [2.75344180e-02 4.88110138e-02 0.00000000e+00 1.10137672e-01\n",
      "  6.13266583e-02 1.66458073e-01]]\n",
      "move 3\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n",
      "prediction:\n",
      " [6.28815591e-02 4.19771262e-02 2.08807806e-03 2.21472394e-04\n",
      " 1.04668047e-02 4.35282942e-03 4.87821177e-02 9.68241831e-04\n",
      " 2.98148458e-04 2.68505290e-02 8.75079888e-04 7.48893199e-03\n",
      " 3.77561804e-03 2.95091583e-03 5.64650670e-02 1.33564249e-02\n",
      " 7.06616463e-03 1.03995586e-02 1.46496817e-02 6.33631973e-03\n",
      " 5.43095870e-03 2.12479845e-01 8.74213234e-04 4.39550774e-03\n",
      " 2.59187748e-03 2.57897569e-04 2.53411345e-02 1.08525157e-03\n",
      " 4.54906636e-04 2.39835251e-02 2.91182869e-03 3.35029289e-02\n",
      " 3.25676228e-04 2.81852391e-03 1.24119595e-01 2.37175822e-01] \n",
      " 0.9992252\n",
      "p [[0.02377972 0.         0.13516896 0.         0.         0.00876095]\n",
      " [0.01126408 0.         0.05882353 0.         0.         0.        ]\n",
      " [0.00125156 0.         0.         0.00125156 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00750939]\n",
      " [0.01251564 0.04755945 0.         0.68085106 0.00125156 0.01001252]]\n",
      "move 33\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  0.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [4.05173264e-02 5.09557035e-03 5.35467416e-02 1.87579542e-02\n",
      " 9.30011421e-02 1.24823805e-02 2.64075901e-02 1.24542648e-03\n",
      " 5.57208620e-02 1.81215920e-03 2.28821603e-03 8.67993087e-02\n",
      " 6.86323782e-03 2.58306914e-04 1.64515816e-03 1.75146954e-04\n",
      " 1.07546626e-02 8.35643965e-04 4.11783485e-03 1.69254225e-02\n",
      " 1.10868859e-04 1.74570736e-03 1.66018622e-03 1.21416776e-02\n",
      " 4.05197218e-02 1.66804669e-03 5.62442816e-04 1.88993067e-01\n",
      " 9.74139373e-04 1.16001908e-02 1.07077807e-02 1.45575061e-01\n",
      " 1.10888956e-02 1.06586784e-01 1.92737475e-03 2.48880871e-02] \n",
      " -0.9987896\n",
      "p [[8.76095119e-02 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [4.88110138e-02 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 5.04380476e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.00876095e-02]\n",
      " [1.25156446e-13 7.25907384e-02 0.00000000e+00 0.00000000e+00\n",
      "  9.76220275e-02 1.18898623e-01]]\n",
      "move 15\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [7.35144615e-02 5.17939143e-02 1.94473506e-03 2.52467900e-04\n",
      " 3.79524590e-03 6.36649365e-03 1.17401155e-02 2.54571816e-04\n",
      " 1.37249241e-03 1.45921083e-02 3.33948666e-03 2.76825461e-03\n",
      " 2.44420650e-03 6.78874727e-04 3.75751941e-03 1.27031980e-03\n",
      " 3.89858149e-03 1.84416156e-02 1.69421937e-02 4.93531441e-03\n",
      " 4.93616855e-04 2.13845763e-02 2.86877563e-04 2.98930728e-03\n",
      " 1.12777890e-03 8.64578120e-04 5.04625477e-02 2.76102102e-03\n",
      " 2.14538668e-04 1.02770040e-02 2.02722871e-03 1.63889118e-02\n",
      " 5.66126662e-04 1.72763399e-03 4.26491082e-01 2.37834305e-01] \n",
      " 0.8534362\n",
      "p [[0.04380476 0.         0.11764706 0.         0.         0.01251564]\n",
      " [0.04881101 0.         0.12140175 0.         0.         0.        ]\n",
      " [0.00750939 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01501877]\n",
      " [0.01126408 0.17146433 0.         0.         0.00250313 0.44806008]]\n",
      "move 35\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  0.  1. -1.  0. -1.]]\n",
      "prediction:\n",
      " [5.2708812e-02 4.1579474e-03 8.3875626e-02 2.5950581e-02 1.8286744e-02\n",
      " 1.8936612e-02 1.9310314e-02 7.7926653e-04 6.1340842e-02 3.8745929e-03\n",
      " 4.8362855e-03 7.0708588e-02 7.2578918e-03 3.5535888e-04 9.2916825e-04\n",
      " 2.2503946e-04 9.3870824e-03 6.1518175e-04 3.6874244e-03 1.3703089e-02\n",
      " 6.9500027e-05 1.3287596e-03 2.2718103e-03 1.4110271e-02 3.4442130e-02\n",
      " 3.1633943e-03 1.0484117e-03 2.3451567e-01 4.3881530e-04 8.0418913e-03\n",
      " 9.2193699e-03 3.4834608e-02 1.1892498e-02 2.2636247e-01 2.3139252e-03\n",
      " 1.5020147e-02] \n",
      " -0.99136966\n",
      "p [[7.50938673e-02 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 3.75469337e-03]\n",
      " [7.88485607e-02 0.00000000e+00 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.90237797e-01]\n",
      " [1.25156446e-13 3.32916145e-01 0.00000000e+00 0.00000000e+00\n",
      "  3.19148936e-01 0.00000000e+00]]\n",
      "move 31\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1.  0. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  0. -1.]]\n",
      "prediction:\n",
      " [4.1041970e-02 4.9459111e-02 8.8562053e-03 3.6017131e-04 4.7488781e-04\n",
      " 6.5936488e-03 1.5532752e-02 1.3320399e-03 6.8047702e-05 1.9411029e-02\n",
      " 5.9022200e-03 4.9797040e-03 1.3002449e-03 2.8626034e-03 1.5554690e-03\n",
      " 7.0619205e-04 2.4830583e-03 6.9450304e-02 8.8854112e-02 2.8287175e-03\n",
      " 1.8606836e-04 1.1890269e-02 7.0782984e-04 3.2231512e-03 1.8633862e-03\n",
      " 2.1210718e-03 4.3151524e-02 2.6664932e-04 9.2345354e-04 2.1759883e-02\n",
      " 6.2956112e-03 2.2766395e-03 6.8993738e-04 4.5842729e-03 4.2525771e-01\n",
      " 1.5075018e-01] \n",
      " 0.99094\n",
      "p [[0.02503129 0.         0.04005006 0.         0.         0.00876095]\n",
      " [0.00876095 0.         0.90613267 0.         0.         0.        ]\n",
      " [0.00250313 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00375469]\n",
      " [0.00375469 0.         0.         0.         0.00125156 0.        ]]\n",
      "move 8\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  0. -1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [3.6604878e-02 3.4710318e-03 1.2016783e-01 2.2764273e-02 2.0925945e-02\n",
      " 9.6497955e-03 2.3635773e-02 1.5658839e-03 1.9896431e-03 7.7070398e-03\n",
      " 2.4128745e-03 2.3456547e-01 9.8546203e-03 8.7092415e-04 3.6345774e-04\n",
      " 1.6911287e-04 4.4195405e-03 8.8257215e-04 3.8368788e-03 1.6747583e-02\n",
      " 1.1354871e-04 4.6125322e-04 1.0897771e-03 1.2639358e-02 7.9155222e-02\n",
      " 3.3946957e-03 3.7246691e-03 5.1914006e-03 1.0602871e-03 1.6744947e-02\n",
      " 1.8032377e-03 5.1486500e-02 1.2179548e-02 2.6682216e-01 1.9759471e-03\n",
      " 1.9552533e-02] \n",
      " -0.99873847\n",
      "p [[1.37672090e-01 0.00000000e+00 1.51439299e-01 0.00000000e+00\n",
      "  0.00000000e+00 2.50312891e-03]\n",
      " [9.63704631e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.02628285e-01]\n",
      " [1.30162703e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  3.79224030e-01 0.00000000e+00]]\n",
      "move 34\n",
      "board\n",
      " [[ 0. -1.  0.  1. -1.  0.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [0.09643415 0.02149996 0.00919596 0.00098509 0.00035255 0.02020041\n",
      " 0.02441747 0.00109122 0.00043799 0.00322327 0.00932306 0.00578894\n",
      " 0.00174923 0.0036611  0.00148287 0.00173812 0.00373339 0.19920151\n",
      " 0.18201864 0.0041196  0.00037658 0.01098065 0.00127564 0.01264797\n",
      " 0.00215638 0.00385608 0.00519913 0.00246626 0.00081301 0.03113798\n",
      " 0.01273801 0.00293665 0.00068276 0.00262135 0.0848852  0.23457184] \n",
      " 0.99971896\n",
      "p [[0.00750939 0.         0.98122653 0.         0.         0.00125156]\n",
      " [0.00500626 0.         0.         0.         0.         0.        ]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00250313]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]]\n",
      "move 2\n",
      "board\n",
      " [[ 0. -1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [2.5425019e-02 7.5271316e-03 5.3335160e-02 4.1094873e-02 2.9174665e-02\n",
      " 2.6492024e-02 4.0496051e-02 2.3345868e-03 2.9548893e-03 4.8616710e-03\n",
      " 1.3144506e-03 2.8159106e-01 3.7570689e-02 1.3950949e-03 2.4915466e-04\n",
      " 1.2696155e-04 3.5366642e-03 7.2195678e-04 2.9699050e-03 1.0511349e-02\n",
      " 6.9478287e-05 4.6008240e-04 1.7709775e-03 1.7055942e-02 1.2752061e-01\n",
      " 1.5408575e-03 2.5697066e-03 7.8706769e-03 1.5048421e-03 2.7163569e-02\n",
      " 7.3307981e-03 7.4619628e-02 3.2637823e-02 9.6818559e-02 3.7433503e-03\n",
      " 2.3639841e-02] \n",
      " -0.9999423\n",
      "p [[0.25156446 0.         0.         0.         0.         0.08635795]\n",
      " [0.17521902 0.         0.         0.         0.         0.        ]\n",
      " [0.077597   0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.17521902]\n",
      " [0.23404255 0.         0.         0.         0.         0.        ]]\n",
      "move 0\n",
      "board\n",
      " [[ 1. -1. -1.  1. -1.  0.]\n",
      " [ 0.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [0.12911776 0.01301293 0.00958203 0.0030596  0.00081343 0.0596314\n",
      " 0.00976833 0.00661115 0.00036841 0.00858358 0.01774446 0.0091049\n",
      " 0.00344866 0.00435984 0.00767642 0.00201432 0.00890674 0.10718647\n",
      " 0.14609241 0.00804918 0.00058822 0.02691682 0.00182118 0.01753218\n",
      " 0.00468464 0.00700126 0.02783945 0.00132738 0.00378425 0.01579013\n",
      " 0.01690583 0.00455738 0.00192283 0.00631322 0.06040483 0.24747856] \n",
      " 0.9993497\n",
      "p [[0.         0.         0.         0.         0.         0.00375469]\n",
      " [0.96996245 0.         0.         0.         0.         0.        ]\n",
      " [0.00876095 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.01627034]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]]\n",
      "move 6\n",
      "board\n",
      " [[ 1. -1. -1.  1. -1.  0.]\n",
      " [-1.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [1.7339956e-02 3.7786094e-03 4.7240991e-02 1.5660953e-02 3.9802901e-02\n",
      " 9.7558415e-03 8.4214099e-03 4.0597832e-03 9.3808398e-04 1.9641090e-03\n",
      " 9.9600630e-04 3.2387736e-01 7.1824960e-02 1.5742277e-03 2.2088137e-04\n",
      " 1.7646914e-04 2.2277113e-03 1.2913924e-03 6.9676456e-03 4.9419105e-03\n",
      " 8.7910325e-05 3.5178568e-04 1.7647445e-03 2.4088738e-02 9.3473159e-02\n",
      " 1.2905946e-03 1.2105984e-03 2.4578176e-03 2.6778860e-03 6.4809327e-03\n",
      " 1.7067649e-03 1.2627448e-01 1.2109195e-02 1.4610173e-01 2.1017033e-03\n",
      " 1.4760912e-02] \n",
      " -0.99925303\n",
      "p [[0.         0.         0.         0.         0.         0.3767209 ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.19399249 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.21276596]\n",
      " [0.21652065 0.         0.         0.         0.         0.        ]]\n",
      "move 5\n",
      "board\n",
      " [[ 1. -1. -1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  1.]\n",
      " [ 0.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [1.13584273e-01 8.74487124e-03 1.18268859e-02 2.55964440e-03\n",
      " 5.56087412e-04 2.92878039e-02 2.04671011e-03 2.11185473e-03\n",
      " 3.20888008e-04 7.20639480e-03 2.09602378e-02 9.96311288e-03\n",
      " 7.30825821e-04 1.85528549e-03 1.28923897e-02 3.26627080e-04\n",
      " 2.07149959e-03 1.36642769e-01 1.10121600e-01 2.48435163e-03\n",
      " 1.05176558e-04 1.20404996e-01 7.47970655e-04 5.54456702e-03\n",
      " 3.02983029e-03 1.57695357e-02 1.33152949e-02 1.11791340e-03\n",
      " 1.20031182e-03 4.49791877e-03 6.82670157e-03 3.56803485e-03\n",
      " 1.45558047e-03 5.91901457e-03 4.15496081e-02 2.98653543e-01] \n",
      " 0.48050898\n",
      "p [[0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.9612015  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.03629537]\n",
      " [0.00250313 0.         0.         0.         0.         0.        ]]\n",
      "move 12\n",
      "board\n",
      " [[ 1. -1. -1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 0.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [9.92263295e-03 2.17269012e-03 1.60049900e-01 3.44263613e-02\n",
      " 4.07666638e-02 7.99471419e-03 1.16574885e-02 6.30527874e-03\n",
      " 2.18513398e-03 2.22007302e-03 2.71948724e-04 2.47956559e-01\n",
      " 9.73140821e-03 8.74277018e-03 1.70666142e-04 1.67948281e-04\n",
      " 2.06452399e-03 2.53124628e-03 7.87004642e-03 9.21627972e-03\n",
      " 1.32266126e-04 3.00196436e-04 1.30262421e-02 4.10542823e-03\n",
      " 6.58775344e-02 3.14379140e-04 5.29497862e-03 4.32235701e-03\n",
      " 2.31308118e-03 6.74290955e-03 1.22296368e-03 9.30579230e-02\n",
      " 3.21907029e-02 1.83003977e-01 1.42764684e-03 2.02432182e-02] \n",
      " -0.99756664\n",
      "p [[0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.4543179]\n",
      " [0.5456821 0.        0.        0.        0.        0.       ]]\n",
      "move 30\n",
      "board\n",
      " [[ 1. -1. -1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  0.]\n",
      " [ 1.  1.  1. -1.  1. -1.]]\n",
      "prediction:\n",
      " [1.24728851e-01 9.21219401e-03 8.28842912e-03 3.25008691e-03\n",
      " 4.09270171e-04 4.85467259e-03 4.57148999e-04 3.98905901e-03\n",
      " 3.41589388e-04 1.13707520e-02 9.82174464e-03 4.78918804e-03\n",
      " 1.18842314e-03 1.37467019e-03 1.05596520e-02 2.15991109e-04\n",
      " 1.94922381e-03 1.91142678e-01 1.01404086e-01 1.01750589e-03\n",
      " 2.87590992e-05 9.70961154e-02 1.03963015e-03 9.43315495e-03\n",
      " 1.32197211e-03 8.56280606e-03 7.21332943e-03 1.29829708e-03\n",
      " 1.23457599e-03 6.68944675e-04 1.45463191e-03 3.45753576e-03\n",
      " 1.61077501e-03 2.61095678e-03 4.58204299e-02 3.26783061e-01] \n",
      " -0.19057062\n",
      "p [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "move 29\n",
      "board\n",
      " [[ 1. -1. -1.  1. -1.  1.]\n",
      " [-1.  1. -1. -1. -1.  1.]\n",
      " [-1.  1. -1.  1.  1. -1.]\n",
      " [-1.  1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1. -1.]\n",
      " [ 1.  1.  1. -1.  1. -1.]]\n",
      "-1 won\n",
      "game 149 completed in 72.09932899475098 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5757303 entropy 2.0177608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 1 lr_mult 0.4444444444444444 loss 2.5590172 entropy 2.0050137\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.531574 entropy 1.9873214\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5017405 entropy 1.9691622\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4710972 entropy 1.9538348\n",
      "kl 0.029071633\n",
      "completed in 0.345322847366333 s\n",
      "game 150 completed in 8.394978046417236 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5254154 entropy 1.8685901\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5086806 entropy 1.8598917\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4763663 entropy 1.8547783\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4400077 entropy 1.8517212\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4047694 entropy 1.8496711\n",
      "kl 0.018892992\n",
      "completed in 0.3385889530181885 s\n",
      "game 151 completed in 10.509577989578247 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5355313 entropy 1.8659934\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5154235 entropy 1.8671968\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4839706 entropy 1.8700683\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.448702 entropy 1.8739127\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4149787 entropy 1.8778422\n",
      "kl 0.021708246\n",
      "completed in 0.2941250801086426 s\n",
      "game 152 completed in 6.27171778678894 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5688317 entropy 1.9177692\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5347352 entropy 1.9238694\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4906843 entropy 1.9314711\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4528153 entropy 1.9388882\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.414644 entropy 1.9434878\n",
      "kl 0.021324491\n",
      "completed in 0.40433382987976074 s\n",
      "game 153 completed in 14.075793743133545 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7251716 entropy 1.9787605\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.705283 entropy 1.9763405\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6705904 entropy 1.9740574\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6323378 entropy 1.974872\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5914783 entropy 1.9786304\n",
      "kl 0.016335491\n",
      "completed in 0.3618760108947754 s\n",
      "game 154 completed in 6.942529678344727 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6271286 entropy 1.9296688\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6057842 entropy 1.9358408\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5694954 entropy 1.9401984\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5285635 entropy 1.9429319\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.486942 entropy 1.9448118\n",
      "kl 0.013896611\n",
      "completed in 0.38558483123779297 s\n",
      "game 155 completed in 11.760765075683594 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6782293 entropy 1.957376\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.651178 entropy 1.954736\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6129444 entropy 1.9501402\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5689123 entropy 1.9463372\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5229206 entropy 1.9457715\n",
      "kl 0.023444153\n",
      "completed in 0.3623619079589844 s\n",
      "game 156 completed in 12.27471113204956 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5991857 entropy 1.9336278\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5783684 entropy 1.9364257\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.543854 entropy 1.938205\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5041156 entropy 1.9372216\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.46494 entropy 1.9332793\n",
      "kl 0.017973311\n",
      "completed in 0.2703380584716797 s\n",
      "game 157 completed in 5.915673732757568 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6155457 entropy 1.9274564\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.584815 entropy 1.9286689\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5425947 entropy 1.9342523\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4985836 entropy 1.9401922\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4573214 entropy 1.9423807\n",
      "kl 0.027100738\n",
      "completed in 0.34872913360595703 s\n",
      "game 158 completed in 10.047857999801636 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6620672 entropy 1.9616289\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6238055 entropy 1.9471862\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.56729 entropy 1.9278593\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5132387 entropy 1.9096925\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4634979 entropy 1.8976433\n",
      "kl 0.03776265\n",
      "completed in 0.29401111602783203 s\n",
      "game 159 completed in 12.430973052978516 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5925581 entropy 1.916853\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5717456 entropy 1.9223537\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.537479 entropy 1.9339097\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4983935 entropy 1.9463469\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4573152 entropy 1.9550692\n",
      "kl 0.02548479\n",
      "completed in 0.2941880226135254 s\n",
      "game 160 completed in 14.758481740951538 s 18 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.630321 entropy 1.9249793\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.597023 entropy 1.9256731\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5488014 entropy 1.9239209\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4998837 entropy 1.9232684\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4540288 entropy 1.9256023\n",
      "kl 0.029588291\n",
      "completed in 0.3841211795806885 s\n",
      "game 161 completed in 8.43671202659607 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.594793 entropy 1.9342151\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5751002 entropy 1.9449811\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5419145 entropy 1.9582068\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5019705 entropy 1.9704542\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4607632 entropy 1.9792138\n",
      "kl 0.021128591\n",
      "completed in 0.32588696479797363 s\n",
      "game 162 completed in 7.436969995498657 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6969197 entropy 1.9899592\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6752264 entropy 1.9901875\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6426606 entropy 1.9879365\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.60566 entropy 1.9863777\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5649288 entropy 1.9866031\n",
      "kl 0.025569577\n",
      "completed in 0.3417327404022217 s\n",
      "game 163 completed in 8.604378938674927 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.715346 entropy 2.0172806\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.684604 entropy 2.021015\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6330504 entropy 2.0267205\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5758822 entropy 2.0315206\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5243797 entropy 2.0306737\n",
      "kl 0.03455447\n",
      "completed in 0.37603020668029785 s\n",
      "game 164 completed in 16.580811977386475 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7209895 entropy 1.996098\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.697622 entropy 1.9883639\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6620903 entropy 1.9800549\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6210773 entropy 1.9724588\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5764973 entropy 1.9661632\n",
      "kl 0.024454646\n",
      "completed in 0.32765722274780273 s\n",
      "game 165 completed in 9.177892208099365 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7279253 entropy 1.9818171\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6890347 entropy 1.9777751\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.641164 entropy 1.97493\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5980396 entropy 1.9734352\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.559554 entropy 1.9714322\n",
      "kl 0.03100743\n",
      "completed in 0.3119161128997803 s\n",
      "game 166 completed in 7.5034706592559814 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6833596 entropy 1.9507341\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6511817 entropy 1.9460018\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.610882 entropy 1.9422002\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5739625 entropy 1.9402512\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5406363 entropy 1.9399121\n",
      "kl 0.020449147\n",
      "completed in 0.30183887481689453 s\n",
      "game 167 completed in 13.739500045776367 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7321987 entropy 1.9366345\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7038405 entropy 1.9375029\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6601217 entropy 1.9384556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.612931 entropy 1.9402666\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5678008 entropy 1.9426546\n",
      "kl 0.025621016\n",
      "completed in 0.2594449520111084 s\n",
      "game 168 completed in 9.847259998321533 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6561263 entropy 1.995616\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6369464 entropy 2.0015543\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6083903 entropy 2.0083022\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5753171 entropy 2.0129838\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5388308 entropy 2.0129786\n",
      "kl 0.021986159\n",
      "completed in 0.3082578182220459 s\n",
      "game 169 completed in 16.108472108840942 s 20 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7461386 entropy 1.9881008\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7126343 entropy 1.9767804\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6596963 entropy 1.9620214\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6060927 entropy 1.9491785\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5612144 entropy 1.940698\n",
      "kl 0.028862134\n",
      "completed in 0.29283714294433594 s\n",
      "game 170 completed in 7.752599000930786 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.773615 entropy 1.9699569\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7370846 entropy 1.9715997\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6887112 entropy 1.9738662\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6425712 entropy 1.973356\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5982387 entropy 1.9694426\n",
      "kl 0.022323549\n",
      "completed in 0.2667520046234131 s\n",
      "game 171 completed in 9.971369981765747 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.8205032 entropy 1.9646018\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7838364 entropy 1.9644971\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.7357666 entropy 1.971837\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.691969 entropy 1.9865997\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.6420407 entropy 2.0062456\n",
      "kl 0.021865731\n",
      "completed in 0.2949180603027344 s\n",
      "game 172 completed in 12.540332794189453 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6908865 entropy 2.0052867\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6555984 entropy 2.0225224\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6054282 entropy 2.0343323\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5551405 entropy 2.0404131\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.511213 entropy 2.0416732\n",
      "kl 0.02907497\n",
      "completed in 0.30614328384399414 s\n",
      "game 173 completed in 8.629658937454224 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6612384 entropy 2.025744\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6449528 entropy 2.027728\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6145542 entropy 2.032528\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5768132 entropy 2.0371134\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5365434 entropy 2.037093\n",
      "kl 0.023445236\n",
      "completed in 0.3283350467681885 s\n",
      "game 174 completed in 12.561122179031372 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7413325 entropy 2.0263696\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7074385 entropy 2.014913\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6521385 entropy 2.0004745\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.591786 entropy 1.9859043\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.534363 entropy 1.9732468\n",
      "kl 0.024389971\n",
      "completed in 0.34008288383483887 s\n",
      "game 175 completed in 11.20753812789917 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6448107 entropy 2.0081818\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6228566 entropy 1.9988213\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5848355 entropy 1.9877522\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5387528 entropy 1.9767218\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4943788 entropy 1.9665792\n",
      "kl 0.030578252\n",
      "completed in 0.30034780502319336 s\n",
      "game 176 completed in 9.193459033966064 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7060099 entropy 1.8864579\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6886315 entropy 1.8817859\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6496105 entropy 1.8819335\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.600072 entropy 1.8866152\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5521355 entropy 1.8944817\n",
      "kl 0.029593434\n",
      "completed in 0.31711411476135254 s\n",
      "game 177 completed in 6.121984958648682 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7383487 entropy 1.9846437\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7094016 entropy 1.9897225\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.664877 entropy 1.9900799\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.61461 entropy 1.9871253\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5644343 entropy 1.9836944\n",
      "kl 0.035644423\n",
      "completed in 0.33170509338378906 s\n",
      "game 178 completed in 6.744971990585327 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7235541 entropy 1.9544916\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6996646 entropy 1.9649218\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.662522 entropy 1.9796488\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6208057 entropy 1.9926634\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.575094 entropy 1.9997772\n",
      "kl 0.024759937\n",
      "completed in 0.32613706588745117 s\n",
      "game 179 completed in 7.427446126937866 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6802716 entropy 1.9906578\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6483476 entropy 1.9858916\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6050887 entropy 1.9791768\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.563698 entropy 1.9734018\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5234706 entropy 1.9706957\n",
      "kl 0.026078684\n",
      "completed in 0.26244401931762695 s\n",
      "game 180 completed in 10.708279609680176 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.708346 entropy 1.9660958\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6874843 entropy 1.9704212\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6510193 entropy 1.9756451\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6060724 entropy 1.9787626\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5574713 entropy 1.978311\n",
      "kl 0.018001154\n",
      "completed in 0.33524298667907715 s\n",
      "game 181 completed in 9.189805030822754 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7389834 entropy 2.0151238\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7103405 entropy 2.0105617\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6664314 entropy 2.0061877\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.622853 entropy 2.0041182\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5823364 entropy 2.0057902\n",
      "kl 0.027043764\n",
      "completed in 0.2624490261077881 s\n",
      "game 182 completed in 10.723374128341675 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.73607 entropy 1.9951684\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7146525 entropy 2.0073514\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6813154 entropy 2.0232363\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6419773 entropy 2.0370417\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5999262 entropy 2.044709\n",
      "kl 0.020977963\n",
      "completed in 0.31380200386047363 s\n",
      "game 183 completed in 7.613418102264404 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7521398 entropy 2.0422196\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7112424 entropy 2.0282629\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.657876 entropy 2.007428\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6088793 entropy 1.9892931\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5622528 entropy 1.9813856\n",
      "kl 0.029850043\n",
      "completed in 0.3353710174560547 s\n",
      "game 184 completed in 6.7551960945129395 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6475542 entropy 2.0364442\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6206906 entropy 2.045637\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5838614 entropy 2.0524597\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5478644 entropy 2.0504174\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5069475 entropy 2.0364108\n",
      "kl 0.028244939\n",
      "completed in 0.3547549247741699 s\n",
      "game 185 completed in 6.022037029266357 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.660589 entropy 1.9636182\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.639533 entropy 1.9413977\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6059697 entropy 1.9239829\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5656867 entropy 1.914903\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5219967 entropy 1.9148304\n",
      "kl 0.014269768\n",
      "completed in 0.3799631595611572 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 186 completed in 11.551299095153809 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7727628 entropy 1.9333496\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7465036 entropy 1.9463394\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6955802 entropy 1.9591933\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6354082 entropy 1.9681305\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5798965 entropy 1.9721546\n",
      "kl 0.016830709\n",
      "completed in 0.29830503463745117 s\n",
      "game 187 completed in 8.531388998031616 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7696598 entropy 1.9771326\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7370756 entropy 1.9716923\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6935194 entropy 1.964982\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6462858 entropy 1.9628211\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5972028 entropy 1.9696772\n",
      "kl 0.02935213\n",
      "completed in 0.3791170120239258 s\n",
      "game 188 completed in 12.500485181808472 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6993604 entropy 2.0019612\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6721442 entropy 2.029521\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6331954 entropy 2.0582592\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.597084 entropy 2.0789866\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5633416 entropy 2.086214\n",
      "kl 0.035500467\n",
      "completed in 0.3025400638580322 s\n",
      "game 189 completed in 11.694792985916138 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7297266 entropy 2.0955217\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.7086675 entropy 2.0789742\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6718838 entropy 2.0571089\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6276183 entropy 2.0366983\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5836194 entropy 2.0224552\n",
      "kl 0.028850863\n",
      "completed in 0.3414158821105957 s\n",
      "game 190 completed in 12.178760290145874 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.634963 entropy 1.9896798\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6113727 entropy 1.992001\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.577301 entropy 1.9973803\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5393038 entropy 2.000504\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.498418 entropy 1.9975961\n",
      "kl 0.02100885\n",
      "completed in 0.2976257801055908 s\n",
      "game 191 completed in 5.861947774887085 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6737435 entropy 2.0317929\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6457345 entropy 2.0129333\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6093316 entropy 1.9916506\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5718246 entropy 1.9761155\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5325558 entropy 1.9712737\n",
      "kl 0.02232913\n",
      "completed in 0.3113999366760254 s\n",
      "game 192 completed in 6.8588011264801025 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5975592 entropy 1.9217155\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5695565 entropy 1.934579\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5316305 entropy 1.9520319\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4902377 entropy 1.9664652\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4475212 entropy 1.9724021\n",
      "kl 0.0253648\n",
      "completed in 0.28516578674316406 s\n",
      "game 193 completed in 7.582007884979248 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6547472 entropy 1.9830096\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6323771 entropy 1.9688379\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5978956 entropy 1.9515008\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.559984 entropy 1.9379025\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.521642 entropy 1.9324429\n",
      "kl 0.021281263\n",
      "completed in 0.3264639377593994 s\n",
      "game 194 completed in 7.690001964569092 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6703553 entropy 1.9591312\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6448057 entropy 1.9616811\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6060424 entropy 1.9614966\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5634909 entropy 1.9575135\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5237503 entropy 1.950434\n",
      "kl 0.018421397\n",
      "completed in 0.3313727378845215 s\n",
      "game 195 completed in 8.45254397392273 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.674568 entropy 1.9464097\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6589568 entropy 1.9445204\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6287372 entropy 1.9498086\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5921378 entropy 1.9598143\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.554956 entropy 1.9713938\n",
      "kl 0.014426117\n",
      "completed in 0.3298461437225342 s\n",
      "game 196 completed in 9.263106107711792 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6015768 entropy 1.935064\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.572944 entropy 1.9437144\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.528489 entropy 1.9493388\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4863844 entropy 1.9513168\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.449449 entropy 1.9494014\n",
      "kl 0.020095095\n",
      "completed in 0.3237321376800537 s\n",
      "game 197 completed in 16.252013206481934 s 20 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6522741 entropy 1.9724422\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6332428 entropy 1.9689587\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5980434 entropy 1.9667287\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5572789 entropy 1.965965\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5183492 entropy 1.9662027\n",
      "kl 0.016484171\n",
      "completed in 0.30169200897216797 s\n",
      "game 198 completed in 13.446454048156738 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6625645 entropy 1.9295624\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6389315 entropy 1.9347464\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6011255 entropy 1.9427121\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5570984 entropy 1.9502629\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.515725 entropy 1.9541314\n",
      "kl 0.020487916\n",
      "completed in 0.37015485763549805 s\n",
      "prediction:\n",
      " [0.00188047 0.00242208 0.00381067 0.00631743 0.00220643 0.00361686\n",
      " 0.00186253 0.00595177 0.01295914 0.16404362 0.0110129  0.00190487\n",
      " 0.00329112 0.01323102 0.07360582 0.03232847 0.15510926 0.00463893\n",
      " 0.00277586 0.1519974  0.05293497 0.06199502 0.01487795 0.0068365\n",
      " 0.00295114 0.01037303 0.15454143 0.01097354 0.00636551 0.00222393\n",
      " 0.00396263 0.00165784 0.00401182 0.00409493 0.00372134 0.00351195] \n",
      " -0.111560024\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.58948686e-01 2.04005006e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.54192741e-01 2.82853567e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 20\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [2.3293350e-04 4.2829567e-04 1.1103383e-03 6.8154378e-04 5.6419283e-04\n",
      " 7.4610871e-04 8.0816197e-04 6.3899544e-04 1.0064091e-02 3.3763152e-02\n",
      " 8.0664478e-02 5.3772365e-04 9.2366053e-04 4.5357294e-02 1.6296028e-01\n",
      " 9.2701048e-02 2.2399714e-04 1.1144544e-03 7.2239240e-04 4.5754350e-04\n",
      " 6.6128515e-02 3.1462660e-01 5.1902376e-02 3.3248689e-03 7.3784537e-04\n",
      " 9.5664196e-02 1.4853590e-02 1.0920644e-02 7.0796249e-04 6.8441487e-04\n",
      " 9.1627595e-04 4.7874387e-04 5.2762165e-04 2.1057341e-03 1.3115838e-03\n",
      " 4.0845931e-04] \n",
      " 0.14197966\n",
      "p [[0.00125156 0.02377972 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.01251564 0.08886108 0.00625782 0.00125156]\n",
      " [0.00125156 0.00625782 0.02002503 0.13642053 0.1301627  0.00750939]\n",
      " [0.03003755 0.28785982 0.         0.02002503 0.01627034 0.01376721]\n",
      " [0.00125156 0.03128911 0.12765957 0.00625782 0.00250313 0.00375469]\n",
      " [0.00250313 0.00125156 0.00250313 0.00500626 0.00375469 0.00125156]]\n",
      "move 19\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00228285 0.01066053 0.00388145 0.00643774 0.00707269 0.00469302\n",
      " 0.01222027 0.00382412 0.12467881 0.24402393 0.00985963 0.00386669\n",
      " 0.0297472  0.00201838 0.05557603 0.01322879 0.01256268 0.01802214\n",
      " 0.00384467 0.01876757 0.00709452 0.03864643 0.00259824 0.02961396\n",
      " 0.00803393 0.02213713 0.10933209 0.14421949 0.00454332 0.01375738\n",
      " 0.00298409 0.01055477 0.00379728 0.00612812 0.00697234 0.00231789] \n",
      " -0.731251\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 6.25782228e-03\n",
      "  1.87734668e-02 1.25156446e-13]\n",
      " [1.25156446e-13 7.24655820e-01 5.50688360e-02 4.13016270e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 7.50938673e-02\n",
      "  3.37922403e-02 1.25156446e-13]\n",
      " [1.25156446e-13 2.75344180e-02 1.25156446e-03 1.37672090e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [7.6265214e-04 5.6565665e-03 2.9071700e-03 6.1369278e-03 7.2836096e-04\n",
      " 6.2331453e-04 3.5974808e-02 1.4565545e-03 1.2494094e-02 4.2946938e-02\n",
      " 1.2373395e-02 1.9336104e-03 1.5068181e-03 9.3197357e-03 1.9129607e-01\n",
      " 4.4964608e-02 2.0209919e-03 3.3206954e-03 5.6134403e-04 1.9853690e-03\n",
      " 3.5259955e-02 4.2285427e-01 3.6064722e-02 6.8135825e-03 2.8742144e-03\n",
      " 1.4584415e-02 1.2488864e-02 3.4544576e-02 1.2498808e-03 4.0276214e-02\n",
      " 1.0842750e-03 3.3655902e-04 4.0982128e-03 3.7492185e-03 4.3805079e-03\n",
      " 3.7055014e-04] \n",
      " 0.54711795\n",
      "p [[0.00125156 0.02878598 0.00125156 0.00125156 0.00500626 0.00125156]\n",
      " [0.07008761 0.00125156 0.0563204  0.11764706 0.01001252 0.00125156]\n",
      " [0.01251564 0.         0.02878598 0.00500626 0.00500626 0.03379224]\n",
      " [0.00250313 0.         0.         0.0350438  0.00125156 0.02002503]\n",
      " [0.0387985  0.01877347 0.06758448 0.39924906 0.00125156 0.00625782]\n",
      " [0.00250313 0.00500626 0.01251564 0.00250313 0.00500626 0.00125156]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.6974627e-04 7.3146209e-04 2.0309500e-03 8.7408358e-03 1.3034301e-03\n",
      " 7.7857124e-04 3.1120700e-03 1.1296950e-02 2.1012726e-03 6.3505602e-01\n",
      " 4.2611905e-03 1.1735822e-03 5.6499004e-02 7.0648338e-04 1.2390180e-03\n",
      " 7.7668834e-03 2.3130891e-03 8.6216070e-04 1.8230909e-04 1.7364247e-03\n",
      " 1.1022157e-02 1.6971658e-03 9.5845934e-04 1.6399458e-02 1.5156283e-03\n",
      " 7.7455984e-03 1.8927443e-01 3.3941437e-03 5.5121058e-03 3.0526223e-03\n",
      " 8.3292089e-04 6.5344735e-04 5.5597504e-03 7.7401418e-03 1.0733959e-03\n",
      " 7.0722122e-04] \n",
      " -0.8300027\n",
      "p [[1.25156446e-13 2.50312891e-03 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.50187735e-02 1.25156446e-13 3.75469337e-03 6.25782228e-03\n",
      "  6.25782228e-03 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 6.19524406e-01 1.37672090e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 2.44055069e-01\n",
      "  4.13016270e-02 2.50312891e-03]\n",
      " [1.25156446e-13 2.50312891e-03 3.75469337e-03 0.00000000e+00\n",
      "  1.25156446e-13 3.62953692e-02]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-03 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [7.1887334e-04 6.8270660e-04 1.2924587e-02 6.3251957e-02 1.9982486e-04\n",
      " 2.2575268e-04 2.6372657e-03 3.5722023e-03 3.2907885e-02 2.4045536e-01\n",
      " 1.6334010e-03 8.7176135e-04 2.8815644e-02 6.7115435e-04 1.8782500e-02\n",
      " 4.5665663e-02 5.1952959e-03 2.6164779e-03 2.1611454e-04 1.9027160e-03\n",
      " 3.6636937e-02 6.2614411e-02 1.7764379e-03 7.0746444e-02 5.3874124e-04\n",
      " 3.2164005e-03 4.8915237e-02 2.6581535e-01 3.0956611e-03 3.6386335e-03\n",
      " 1.2121586e-04 9.5605654e-05 8.0235591e-03 2.9132925e-02 1.2658953e-03\n",
      " 4.1955811e-04] \n",
      " 0.65824926\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00250313 0.00125156 0.00125156]\n",
      " [0.00125156 0.00375469 0.02377972 0.3379224  0.00125156 0.00125156]\n",
      " [0.24155194 0.         0.         0.00250313 0.00125156 0.00250313]\n",
      " [0.00250313 0.         0.         0.00125156 0.00125156 0.01501877]\n",
      " [0.00125156 0.04755945 0.17521902 0.         0.04255319 0.00250313]\n",
      " [0.00125156 0.00125156 0.077597   0.00250313 0.00125156 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  1.  1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00301514 0.00603618 0.00604755 0.01834079 0.00699488 0.00854903\n",
      " 0.01290766 0.02823212 0.01145057 0.1129331  0.08284918 0.00530528\n",
      " 0.22892126 0.00128224 0.00400688 0.00101624 0.0455955  0.00267644\n",
      " 0.00097914 0.02462581 0.00031797 0.00366561 0.00120685 0.08702473\n",
      " 0.00567766 0.18767291 0.01830993 0.01148072 0.01348132 0.01517156\n",
      " 0.0038747  0.00811986 0.00712926 0.01955508 0.00397696 0.00156998] \n",
      " -0.954276\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-02 3.12891114e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.20150188e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [8.51063830e-02 0.00000000e+00 0.00000000e+00 6.22027534e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 3.75469337e-02\n",
      "  1.25156446e-13 2.50312891e-02]\n",
      " [1.25156446e-13 1.25156446e-13 5.38172716e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.50312891e-03 1.00125156e-02\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.2106157e-03 1.5095783e-03 4.8969217e-02 1.6834518e-02 3.5040634e-04\n",
      " 1.9876808e-02 1.1698679e-02 1.4241866e-03 1.2013379e-02 8.9370966e-02\n",
      " 1.2967937e-01 9.3435094e-04 1.1091286e-02 2.2477233e-03 2.3846454e-03\n",
      " 1.6536546e-04 1.3287540e-01 3.5544027e-02 5.7866173e-03 7.0171840e-02\n",
      " 5.3712964e-04 4.7220662e-03 6.6702147e-03 4.6662495e-02 5.7536253e-04\n",
      " 1.8959485e-01 3.9729256e-02 7.1684197e-02 6.5039936e-04 3.4979952e-03\n",
      " 9.3859090e-03 2.0926632e-04 2.0352630e-03 2.7553475e-02 1.2544286e-03\n",
      " 1.0988943e-03] \n",
      " 0.33912247\n",
      "p [[0.00125156 0.00876095 0.01126408 0.0175219  0.01001252 0.00625782]\n",
      " [0.01627034 0.01877347 0.02503129 0.         0.06382979 0.00750939]\n",
      " [0.31163955 0.         0.         0.         0.07509387 0.00250313]\n",
      " [0.00125156 0.         0.         0.00125156 0.00125156 0.05882353]\n",
      " [0.00876095 0.17271589 0.06758448 0.         0.01376721 0.0212766 ]\n",
      " [0.00625782 0.01001252 0.0350438  0.02002503 0.00500626 0.00125156]]\n",
      "move 12\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [-1.  1.  1.  1.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [2.3596149e-03 4.1837106e-03 3.4919884e-02 2.3753202e-02 4.3470673e-03\n",
      " 1.0583864e-02 2.2657830e-02 2.8326536e-02 8.3806580e-03 3.5061264e-01\n",
      " 7.3300049e-02 4.5482726e-03 1.4611011e-02 1.1605734e-03 2.4370120e-03\n",
      " 2.1872125e-04 1.6907612e-03 1.6183808e-02 2.2741547e-03 1.4533049e-03\n",
      " 1.8867703e-04 3.3160860e-03 2.4142209e-03 7.4152630e-03 8.8002095e-03\n",
      " 1.0233180e-01 1.1088236e-01 1.1928362e-02 1.2803246e-02 2.3373432e-02\n",
      " 9.3514035e-03 2.4688623e-03 1.9172123e-02 7.0136219e-02 6.5168119e-03\n",
      " 8.9852529e-04] \n",
      " -0.24913943\n",
      "p [[1.25156446e-13 1.25156446e-13 6.25782228e-03 3.75469337e-03\n",
      "  1.25156446e-13 5.00625782e-03]\n",
      " [3.75469337e-03 1.25156446e-13 5.00625782e-03 0.00000000e+00\n",
      "  1.13892365e-01 1.25156446e-13]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.52190238e-01 1.25156446e-02]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 5.00625782e-03]\n",
      " [1.25156446e-13 5.63204005e-02 2.75344180e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [5.00625782e-03 1.25156446e-13 1.25156446e-13 3.75469337e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [-1.  1.  1.  1.  1.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 199 completed in 21.461416244506836 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6461291 entropy 1.9901474\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6262903 entropy 1.982168\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5924962 entropy 1.9711274\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.551726 entropy 1.9607129\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5102935 entropy 1.9549675\n",
      "kl 0.020072233\n",
      "completed in 0.38516998291015625 s\n",
      "game 200 completed in 14.411097049713135 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7157235 entropy 1.9689628\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6852486 entropy 1.9720006\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6384468 entropy 1.9755839\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5855978 entropy 1.9783444\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.537518 entropy 1.9790213\n",
      "kl 0.019647984\n",
      "completed in 0.3469579219818115 s\n",
      "game 201 completed in 10.915753364562988 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5698571 entropy 1.947392\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5407162 entropy 1.9443306\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.496993 entropy 1.9401646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.4521942 entropy 1.9370693\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4063447 entropy 1.9351059\n",
      "kl 0.025396692\n",
      "completed in 0.26677513122558594 s\n",
      "game 202 completed in 6.946922063827515 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6068645 entropy 1.9518712\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5868304 entropy 1.9559095\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.547885 entropy 1.961719\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4998927 entropy 1.9675469\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.451029 entropy 1.9710914\n",
      "kl 0.018278087\n",
      "completed in 0.33565521240234375 s\n",
      "game 203 completed in 10.20423412322998 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7127466 entropy 1.9650099\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.677457 entropy 1.9691975\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6308029 entropy 1.9753351\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5818377 entropy 1.9814694\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5341291 entropy 1.9879425\n",
      "kl 0.016221004\n",
      "completed in 0.3471262454986572 s\n",
      "game 204 completed in 11.587240934371948 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.710398 entropy 2.0120244\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.682058 entropy 2.018961\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.635113 entropy 2.0240283\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5831149 entropy 2.024521\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5365345 entropy 2.0192213\n",
      "kl 0.022808623\n",
      "completed in 0.3753070831298828 s\n",
      "game 205 completed in 6.1661388874053955 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.7053566 entropy 2.0142095\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.680585 entropy 2.0008698\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.642808 entropy 1.9851546\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.6026816 entropy 1.9706111\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5620515 entropy 1.9596188\n",
      "kl 0.019101903\n",
      "completed in 0.3707141876220703 s\n",
      "game 206 completed in 7.611438035964966 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5985374 entropy 1.9856106\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5730655 entropy 1.9835514\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.540018 entropy 1.9826589\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5026932 entropy 1.9809608\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.465407 entropy 1.9774504\n",
      "kl 0.020360844\n",
      "completed in 0.30705904960632324 s\n",
      "game 207 completed in 7.539815187454224 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.614491 entropy 1.9563054\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5998302 entropy 1.9549134\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5708282 entropy 1.9560924\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5349681 entropy 1.9592981\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4984155 entropy 1.9634576\n",
      "kl 0.016244583\n",
      "completed in 0.31894779205322266 s\n",
      "game 208 completed in 7.742218971252441 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6031806 entropy 1.940919\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5747244 entropy 1.9423685\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5307837 entropy 1.9404509\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4835637 entropy 1.9371877\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4384713 entropy 1.9340321\n",
      "kl 0.021579342\n",
      "completed in 0.34546518325805664 s\n",
      "game 209 completed in 7.736659049987793 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.500606 entropy 1.9308271\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4842238 entropy 1.9326651\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4526906 entropy 1.9358635\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4147382 entropy 1.9396064\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3775344 entropy 1.9436398\n",
      "kl 0.016161265\n",
      "completed in 0.322551965713501 s\n",
      "game 210 completed in 6.014893054962158 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5683231 entropy 1.917707\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5454977 entropy 1.9254392\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5058975 entropy 1.9329059\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4596655 entropy 1.9381955\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.414115 entropy 1.9397378\n",
      "kl 0.017710317\n",
      "completed in 0.26320695877075195 s\n",
      "game 211 completed in 6.557839870452881 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5471523 entropy 1.9874518\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5277147 entropy 1.984742\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4944417 entropy 1.9826506\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.456452 entropy 1.9810879\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.419358 entropy 1.9795461\n",
      "kl 0.018966366\n",
      "completed in 0.3483157157897949 s\n",
      "game 212 completed in 6.024981737136841 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5211706 entropy 1.9778068\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4998357 entropy 1.9710739\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.46396 entropy 1.9613714\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.424336 entropy 1.9512463\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3869655 entropy 1.9432387\n",
      "kl 0.01894334\n",
      "completed in 0.3118610382080078 s\n",
      "game 213 completed in 6.9935479164123535 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5278692 entropy 1.8850068\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.50099 entropy 1.8841155\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4619365 entropy 1.8838342\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4221408 entropy 1.8853722\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3834531 entropy 1.887716\n",
      "kl 0.023133323\n",
      "completed in 0.3492391109466553 s\n",
      "game 214 completed in 8.05499792098999 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5826561 entropy 1.9260283\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5582328 entropy 1.9281493\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.516308 entropy 1.9292234\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4673305 entropy 1.9278834\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4271352 entropy 1.9246516\n",
      "kl 0.017482951\n",
      "completed in 0.3372178077697754 s\n",
      "game 215 completed in 7.950688123703003 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6053967 entropy 1.9635909\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5763376 entropy 1.9651341\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.535003 entropy 1.9720609\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4954019 entropy 1.9799112\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4581933 entropy 1.9858897\n",
      "kl 0.017051222\n",
      "completed in 0.3340950012207031 s\n",
      "game 216 completed in 15.568532943725586 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.63659 entropy 1.9470091\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6059766 entropy 1.9491255\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5634062 entropy 1.9503767\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.515689 entropy 1.9509025\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.470287 entropy 1.9501116\n",
      "kl 0.022700764\n",
      "completed in 0.3218207359313965 s\n",
      "game 217 completed in 8.155491828918457 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4763408 entropy 1.9486742\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4570816 entropy 1.9458783\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4227962 entropy 1.942282\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3815358 entropy 1.9387038\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.337911 entropy 1.9357018\n",
      "kl 0.017986666\n",
      "completed in 0.2722771167755127 s\n",
      "game 218 completed in 6.901823997497559 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4988265 entropy 1.9138429\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4781284 entropy 1.9182835\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4452121 entropy 1.926093\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.409676 entropy 1.934745\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3756301 entropy 1.9402726\n",
      "kl 0.017296623\n",
      "completed in 0.3069031238555908 s\n",
      "game 219 completed in 8.200889825820923 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5766935 entropy 2.0042872\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.548866 entropy 1.9979336\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5100565 entropy 1.9866114\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4710174 entropy 1.9744675\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4332588 entropy 1.9665024\n",
      "kl 0.035267282\n",
      "completed in 0.2758631706237793 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 220 completed in 12.051996946334839 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6321745 entropy 1.922545\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6033158 entropy 1.9318058\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5545034 entropy 1.945127\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5021625 entropy 1.9566138\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.455573 entropy 1.9622786\n",
      "kl 0.033102423\n",
      "completed in 0.3200650215148926 s\n",
      "game 221 completed in 6.788951873779297 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.591998 entropy 1.9650502\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5622318 entropy 1.9606111\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.513728 entropy 1.9550575\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.465505 entropy 1.9485452\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.426506 entropy 1.9433005\n",
      "kl 0.021420928\n",
      "completed in 0.3226301670074463 s\n",
      "game 222 completed in 10.65110182762146 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5611496 entropy 1.940712\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5480812 entropy 1.9378626\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5188336 entropy 1.9338747\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4820092 entropy 1.9297798\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4471917 entropy 1.9264562\n",
      "kl 0.01864045\n",
      "completed in 0.2735862731933594 s\n",
      "game 223 completed in 5.921422243118286 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6248791 entropy 1.9317204\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.601814 entropy 1.9390867\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5712218 entropy 1.9485825\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5382628 entropy 1.9556425\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.504525 entropy 1.9573172\n",
      "kl 0.026505131\n",
      "completed in 0.3169059753417969 s\n",
      "game 224 completed in 7.69144606590271 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5291193 entropy 1.8559012\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.509336 entropy 1.8503053\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4772122 entropy 1.8460786\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4411852 entropy 1.8427576\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4027328 entropy 1.8409798\n",
      "kl 0.022899672\n",
      "completed in 0.3239099979400635 s\n",
      "game 225 completed in 6.737704038619995 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6360247 entropy 1.9342405\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6019206 entropy 1.9327245\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.56387 entropy 1.9324567\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.533699 entropy 1.9378169\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5035105 entropy 1.9493055\n",
      "kl 0.02057723\n",
      "completed in 0.24733805656433105 s\n",
      "game 226 completed in 12.49589991569519 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5825844 entropy 1.9598315\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.559395 entropy 1.9738704\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5161493 entropy 1.983571\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4655137 entropy 1.9870872\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.419318 entropy 1.9840851\n",
      "kl 0.016050706\n",
      "completed in 0.25486302375793457 s\n",
      "game 227 completed in 10.595265865325928 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.54799 entropy 1.9463711\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5243888 entropy 1.9442266\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4887223 entropy 1.9466548\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4498453 entropy 1.9529543\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4121494 entropy 1.9598341\n",
      "kl 0.0230642\n",
      "completed in 0.2916598320007324 s\n",
      "game 228 completed in 7.506737947463989 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.588327 entropy 1.9824326\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5589476 entropy 1.9782577\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.51207 entropy 1.9682751\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4703605 entropy 1.9544234\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4361184 entropy 1.938689\n",
      "kl 0.029090697\n",
      "completed in 0.30923891067504883 s\n",
      "game 229 completed in 8.352772235870361 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.593389 entropy 1.9361746\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5629408 entropy 1.922626\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5224924 entropy 1.9127538\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4871814 entropy 1.9098288\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4542491 entropy 1.9136561\n",
      "kl 0.02051308\n",
      "completed in 0.32175207138061523 s\n",
      "game 230 completed in 13.573764085769653 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6404326 entropy 1.9162885\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6121101 entropy 1.928724\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5683007 entropy 1.9393082\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.523959 entropy 1.9428763\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4835007 entropy 1.9381217\n",
      "kl 0.024910398\n",
      "completed in 0.35416603088378906 s\n",
      "game 231 completed in 9.911937952041626 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.609191 entropy 1.9541199\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.577237 entropy 1.936268\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5344296 entropy 1.9192066\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4890478 entropy 1.9092346\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4444687 entropy 1.9101286\n",
      "kl 0.023698065\n",
      "completed in 0.2616581916809082 s\n",
      "game 232 completed in 6.011886835098267 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.609401 entropy 1.9098523\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5831177 entropy 1.9201838\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5454783 entropy 1.930048\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.511416 entropy 1.936142\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4808207 entropy 1.936363\n",
      "kl 0.029992169\n",
      "completed in 0.32270383834838867 s\n",
      "game 233 completed in 5.902712106704712 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.520743 entropy 1.9389625\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5036883 entropy 1.9324737\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.47347 entropy 1.9250932\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4381065 entropy 1.9195688\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4026425 entropy 1.9176791\n",
      "kl 0.02468029\n",
      "completed in 0.2966270446777344 s\n",
      "game 234 completed in 10.828826904296875 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5747411 entropy 1.9226495\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.549133 entropy 1.9334133\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5170767 entropy 1.946751\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4818573 entropy 1.9573349\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4444907 entropy 1.9613323\n",
      "kl 0.01801887\n",
      "completed in 0.32788705825805664 s\n",
      "game 235 completed in 9.10263180732727 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6052039 entropy 1.9549341\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5732722 entropy 1.9448106\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.538299 entropy 1.9346786\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5098178 entropy 1.9298855\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4762914 entropy 1.9326093\n",
      "kl 0.018635873\n",
      "completed in 0.29622483253479004 s\n",
      "game 236 completed in 11.702587842941284 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.608634 entropy 1.9287806\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5723813 entropy 1.949523\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5325818 entropy 1.9753447\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4988382 entropy 1.9969064\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.464364 entropy 2.0065563\n",
      "kl 0.033656124\n",
      "completed in 0.278353214263916 s\n",
      "game 237 completed in 6.952697992324829 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5518873 entropy 1.9750165\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5293272 entropy 1.9542942\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4972456 entropy 1.924772\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4619632 entropy 1.896239\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4255364 entropy 1.8767928\n",
      "kl 0.04549756\n",
      "completed in 0.30213403701782227 s\n",
      "game 238 completed in 13.948754072189331 s 17 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.7593875 entropy 1.9157908\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.7326128 entropy 1.919459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 2 lr_mult 0.2962962962962963 loss 2.6875975 entropy 1.9284692\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.639129 entropy 1.9401863\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5950696 entropy 1.9519348\n",
      "kl 0.030781083\n",
      "completed in 0.3784058094024658 s\n",
      "game 239 completed in 6.155202150344849 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6058009 entropy 1.9706309\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5913432 entropy 1.9774976\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.566011 entropy 1.9790134\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5333815 entropy 1.9758322\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4995782 entropy 1.9694612\n",
      "kl 0.014722828\n",
      "completed in 0.304610013961792 s\n",
      "game 240 completed in 13.387956857681274 s 16 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.5786963 entropy 1.9725553\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.5599442 entropy 1.9636202\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5369964 entropy 1.9555478\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5128682 entropy 1.949219\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.486631 entropy 1.9452718\n",
      "kl 0.013145201\n",
      "completed in 0.3342714309692383 s\n",
      "game 241 completed in 6.0201451778411865 s 7 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.6244469 entropy 1.8756993\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.6067262 entropy 1.8770018\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5769615 entropy 1.8802807\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5436049 entropy 1.8848438\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.5130966 entropy 1.8899336\n",
      "kl 0.014499586\n",
      "completed in 0.2831380367279053 s\n",
      "game 242 completed in 10.8917818069458 s 13 steps\n",
      "training 0 lr_mult 0.2962962962962963 loss 2.586877 entropy 1.9029016\n",
      "training 1 lr_mult 0.2962962962962963 loss 2.57612 entropy 1.9078683\n",
      "training 2 lr_mult 0.2962962962962963 loss 2.5531104 entropy 1.9122416\n",
      "training 3 lr_mult 0.2962962962962963 loss 2.5237188 entropy 1.9151362\n",
      "training 4 lr_mult 0.2962962962962963 loss 2.4935033 entropy 1.9162223\n",
      "kl 0.009126751\n",
      "completed in 0.30904603004455566 s\n",
      "game 243 completed in 7.598088026046753 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6331758 entropy 1.9911363\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6139877 entropy 1.9924421\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5838413 entropy 1.9963617\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5509272 entropy 2.0037313\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5190032 entropy 2.0138943\n",
      "kl 0.015718713\n",
      "completed in 0.3281106948852539 s\n",
      "game 244 completed in 7.639599800109863 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5614538 entropy 1.988733\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.545466 entropy 1.998236\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5124044 entropy 2.0025735\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.472305 entropy 2.0005546\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4337726 entropy 1.992742\n",
      "kl 0.013679434\n",
      "completed in 0.3012721538543701 s\n",
      "game 245 completed in 9.750679016113281 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6394143 entropy 2.0027313\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6166604 entropy 1.9903731\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5757492 entropy 1.9773667\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.532651 entropy 1.9663131\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4901853 entropy 1.9582129\n",
      "kl 0.01780943\n",
      "completed in 0.2596249580383301 s\n",
      "game 246 completed in 5.957986116409302 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6319914 entropy 1.9662383\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.607787 entropy 1.9639302\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.566914 entropy 1.9626694\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5211105 entropy 1.9598083\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.477512 entropy 1.9531188\n",
      "kl 0.018802034\n",
      "completed in 0.29871392250061035 s\n",
      "game 247 completed in 9.096392154693604 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.546105 entropy 1.8995317\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5165029 entropy 1.8887964\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4762273 entropy 1.8816804\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4346197 entropy 1.8798902\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3949478 entropy 1.8826054\n",
      "kl 0.014783548\n",
      "completed in 0.3106098175048828 s\n",
      "game 248 completed in 16.629703044891357 s 21 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6982388 entropy 1.9654382\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.674254 entropy 1.9764647\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.6357133 entropy 1.9871814\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5946765 entropy 1.9947602\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5586066 entropy 1.9991192\n",
      "kl 0.018870642\n",
      "completed in 0.3277549743652344 s\n",
      "prediction:\n",
      " [0.00182124 0.00309208 0.00332659 0.00255547 0.00286371 0.00214417\n",
      " 0.00200851 0.00403045 0.01700173 0.15023239 0.01054532 0.00248745\n",
      " 0.00286257 0.02219581 0.0380653  0.06497137 0.14588112 0.00693943\n",
      " 0.00432402 0.16030015 0.06958353 0.04712456 0.01948873 0.004797\n",
      " 0.0025992  0.01312935 0.1473834  0.01678084 0.00802904 0.00228838\n",
      " 0.00236034 0.00260759 0.00655631 0.00413917 0.00432663 0.00115726] \n",
      " -0.6610728\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.75219024e-01 3.00375469e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.80350438e-01 2.44055069e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "prediction:\n",
      " [2.2486140e-04 3.0368872e-04 5.9138576e-04 4.9349049e-04 2.4493985e-04\n",
      " 1.7304206e-04 4.0827357e-04 6.5842287e-05 1.7829050e-01 1.8560836e-03\n",
      " 1.2330675e-03 1.3319573e-04 2.8310303e-04 7.1460098e-02 2.4828076e-01\n",
      " 5.3027709e-04 3.9410754e-03 6.7877403e-04 3.2244300e-04 5.2453419e-03\n",
      " 7.2734890e-04 7.2869971e-02 1.8623780e-01 1.1665662e-03 1.2556309e-04\n",
      " 1.2738173e-03 3.0620387e-03 2.1695961e-01 6.8362519e-05 2.2011278e-04\n",
      " 9.3356488e-05 2.4212268e-04 8.6514885e-04 7.7641464e-04 4.2566701e-04\n",
      " 1.2601991e-04] \n",
      " 0.2833548\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00375469]\n",
      " [0.00250313 0.00125156 0.0175219  0.0951189  0.00500626 0.00125156]\n",
      " [0.00125156 0.00750939 0.01001252 0.         0.1339174  0.00375469]\n",
      " [0.00125156 0.12765957 0.2252816  0.01376721 0.03128911 0.00375469]\n",
      " [0.00125156 0.08635795 0.19774718 0.00375469 0.00375469 0.00375469]\n",
      " [0.00125156 0.00125156 0.00125156 0.00125156 0.00500626 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [3.0163620e-04 1.4133319e-03 4.0281206e-04 5.8735800e-03 8.5924263e-04\n",
      " 5.8269128e-04 4.2067915e-03 6.6530012e-04 3.6266476e-01 2.2525603e-02\n",
      " 2.6384243e-03 6.2464067e-04 4.0905262e-04 6.4390674e-03 7.6499499e-02\n",
      " 5.7485439e-03 2.4361221e-02 1.9717605e-03 2.0000085e-03 3.1836491e-02\n",
      " 2.6448295e-03 1.5123516e-01 3.1971277e-03 1.0812603e-03 9.6588407e-04\n",
      " 4.1976124e-03 1.6676683e-02 2.4405693e-01 1.4112585e-03 3.5303677e-03\n",
      " 1.0852764e-03 1.0584464e-03 1.2466119e-02 4.4809320e-04 3.7760502e-03\n",
      " 1.4460798e-04] \n",
      " -0.8384671\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.75844806e-02 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.37672090e-02 6.63329161e-02 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 4.50563204e-02\n",
      "  7.47183980e-01 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 5.88235294e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.3146218e-04 2.5621196e-03 4.4634711e-04 4.4607901e-04 2.1130202e-04\n",
      " 4.8890328e-05 4.5157019e-03 2.7304539e-04 8.8958126e-03 1.0094076e-03\n",
      " 3.1490456e-03 1.4664266e-04 4.5577536e-04 2.9059337e-03 6.1119866e-01\n",
      " 2.8796124e-03 2.4160671e-03 9.4729930e-04 5.4561626e-04 8.9445226e-03\n",
      " 3.8563303e-04 3.2084173e-01 1.8563048e-03 2.0350155e-04 1.5029611e-04\n",
      " 4.4180909e-03 3.3405155e-03 2.8303934e-03 1.8226076e-04 9.2551354e-03\n",
      " 5.4704306e-05 5.4509775e-04 8.9696492e-04 8.0439157e-04 2.0153390e-03\n",
      " 9.0380810e-05] \n",
      " 0.4618541\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00250313 0.00125156 0.66082603 0.00876095 0.00125156 0.00125156]\n",
      " [0.00125156 0.00250313 0.08260325 0.         0.01126408 0.00125156]\n",
      " [0.00125156 0.01376721 0.         0.06633292 0.         0.00125156]\n",
      " [0.00250313 0.00375469 0.01251564 0.10012516 0.00125156 0.00625782]\n",
      " [0.00125156 0.00125156 0.00250313 0.00125156 0.00125156 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00175346 0.00481343 0.00151748 0.01688289 0.00295001 0.00178217\n",
      " 0.00426932 0.01793713 0.03217344 0.10644799 0.01459569 0.00525239\n",
      " 0.00280688 0.32754937 0.02538021 0.00659661 0.01980966 0.00733709\n",
      " 0.00283265 0.0186045  0.00460406 0.03492469 0.14013518 0.0037664\n",
      " 0.00509936 0.017315   0.10204659 0.01001761 0.0215791  0.00287157\n",
      " 0.00204232 0.00271458 0.02408673 0.00046745 0.00574547 0.00129173] \n",
      " -0.9655187\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 9.52440551e-01 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 4.38047559e-02\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 2.50312891e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.4705538e-03 9.4993785e-03 5.4346758e-04 8.9096129e-03 1.8171285e-03\n",
      " 4.5611148e-04 1.6975429e-02 7.1311002e-03 2.3044646e-02 2.3610783e-03\n",
      " 2.6739906e-03 1.6187544e-03 4.0913827e-04 6.1904010e-04 1.9209310e-02\n",
      " 2.7131973e-04 1.6602544e-01 1.6786528e-01 1.6559644e-02 4.6765861e-01\n",
      " 9.4960036e-05 1.0328785e-02 3.7658151e-04 7.8778638e-04 1.6817155e-03\n",
      " 5.3759827e-03 6.0336879e-03 1.4818799e-02 6.8674348e-03 2.0831663e-02\n",
      " 6.0759846e-04 1.8933361e-03 8.3442479e-03 6.7055650e-04 4.7029369e-03\n",
      " 1.4650519e-03] \n",
      " 0.6258241\n",
      "p [[0.00125156 0.00125156 0.00125156 0.00500626 0.00125156 0.00125156]\n",
      " [0.00125156 0.05131414 0.         0.1126408  0.00375469 0.01627034]\n",
      " [0.00125156 0.61952441 0.         0.         0.01251564 0.00125156]\n",
      " [0.00125156 0.01251564 0.         0.05381727 0.         0.00125156]\n",
      " [0.00125156 0.01126408 0.06257822 0.00250313 0.00625782 0.00125156]\n",
      " [0.00125156 0.00125156 0.00876095 0.00125156 0.00125156 0.00125156]]\n",
      "move 13\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  0.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [9.9281031e-05 3.9580707e-03 2.3503104e-04 2.0728484e-03 1.2840566e-03\n",
      " 1.3159451e-04 3.1858464e-03 1.3995598e-02 6.8534990e-03 2.1443446e-03\n",
      " 1.9417597e-03 5.6711934e-04 1.4610705e-04 2.9860175e-04 2.5567228e-03\n",
      " 4.8653255e-05 5.2556791e-04 7.4222285e-01 1.6648373e-01 1.3487831e-03\n",
      " 4.1678722e-05 3.8529246e-03 1.7017419e-04 1.8568918e-04 1.0076220e-03\n",
      " 3.6228099e-03 4.1527282e-03 6.1112130e-03 9.8299012e-03 3.0601164e-03\n",
      " 3.6676246e-04 1.6320978e-03 1.2872383e-02 1.0432184e-04 2.8469760e-03\n",
      " 4.2796615e-05] \n",
      " -0.78955984\n",
      "p [[1.25156446e-13 3.75469337e-03 1.25156446e-13 1.12640801e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [8.76095119e-03 5.00625782e-03 0.00000000e+00 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  6.77096370e-01 1.53942428e-01]\n",
      " [3.75469337e-03 9.88735920e-02 0.00000000e+00 5.00625782e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-03 2.50312891e-03 1.25156446e-02\n",
      "  6.25782228e-03 6.25782228e-03]\n",
      " [1.25156446e-13 1.25156446e-13 3.75469337e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1.  0.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.9760262e-03 4.1530505e-02 6.5740931e-04 3.2214134e-03 4.5816093e-03\n",
      " 4.6362411e-04 9.9023888e-03 1.8783079e-01 1.3131395e-02 1.9007210e-03\n",
      " 1.7389467e-01 1.6864591e-03 2.4727338e-03 5.5945135e-04 1.0336067e-02\n",
      " 1.4161856e-04 4.2192549e-03 3.1643499e-02 1.4172273e-02 9.4906176e-03\n",
      " 4.1558025e-05 9.8232059e-03 3.2329871e-04 1.9933714e-03 3.1581298e-03\n",
      " 2.4859425e-01 2.5113120e-03 3.8203716e-03 1.5731885e-01 1.9321846e-02\n",
      " 7.3124829e-04 1.3397925e-02 7.9555828e-03 1.0015370e-03 1.1742002e-02\n",
      " 4.4529634e-03] \n",
      " 0.8163172\n",
      "p [[0.00250313 0.00375469 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00375469 0.00750939 0.         0.00500626 0.00125156 0.00250313]\n",
      " [0.00125156 0.         0.         0.         0.         0.83604506]\n",
      " [0.06758448 0.00125156 0.         0.00750939 0.         0.00375469]\n",
      " [0.00375469 0.00375469 0.00750939 0.01376721 0.00375469 0.00125156]\n",
      " [0.00125156 0.00500626 0.00375469 0.00250313 0.00250313 0.00250313]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.5362304e-03 1.7498092e-01 4.0700138e-03 1.3155260e-02 1.1631901e-02\n",
      " 5.9332763e-04 2.1465585e-02 2.8829992e-02 1.4466537e-02 9.3335621e-03\n",
      " 5.9793558e-02 8.5979514e-03 1.6261248e-03 1.0988078e-03 1.2561777e-02\n",
      " 1.3785805e-04 6.0024750e-03 6.9818959e-02 6.1982285e-02 3.0731168e-02\n",
      " 7.9023404e-05 3.7091754e-02 1.6058683e-03 1.9316733e-03 1.8342480e-02\n",
      " 6.2970102e-02 2.6956139e-02 3.0176252e-02 1.8776026e-02 2.7466444e-02\n",
      " 4.0444862e-03 6.7975451e-03 1.6863906e-01 2.5948291e-03 5.8973253e-02\n",
      " 1.1409373e-03] \n",
      " -0.7235135\n",
      "p [[1.25156446e-13 7.50938673e-03 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-03 6.75844806e-02 0.00000000e+00 1.25156446e-13\n",
      "  3.75469337e-01 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.75469337e-03 7.50938673e-03 0.00000000e+00 3.75469337e-03\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 5.25657071e-02 1.25156446e-13 1.25156446e-13\n",
      "  4.50563204e-01 1.12640801e-02]\n",
      " [1.25156446e-13 1.25156446e-03 2.50312891e-03 1.25156446e-13\n",
      "  1.50187735e-02 1.25156446e-13]]\n",
      "move 28\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.53340768e-04 5.78925788e-01 1.08284630e-05 5.56882151e-05\n",
      " 5.13536623e-04 1.91023028e-05 2.31683545e-04 4.35453979e-03\n",
      " 7.20686512e-05 4.64423538e-05 1.52167529e-01 2.38958193e-04\n",
      " 7.28866071e-05 6.35996330e-05 2.09824866e-04 1.59404988e-06\n",
      " 1.15869560e-04 1.28581258e-03 3.59749596e-04 6.71106973e-04\n",
      " 7.24413312e-08 1.13495444e-04 3.37589299e-05 1.22853089e-04\n",
      " 2.26845354e-04 1.63886666e-01 1.82439355e-04 8.93563847e-05\n",
      " 2.35906499e-03 1.19158148e-03 4.81692259e-05 5.48282464e-04\n",
      " 2.40847294e-04 3.92379770e-05 8.96266401e-02 1.32084428e-03] \n",
      " 0.98208755\n",
      "p [[0.00125156 0.10763454 0.00125156 0.06508135 0.00625782 0.00125156]\n",
      " [0.14893617 0.02377972 0.         0.01376721 0.03254068 0.00500626]\n",
      " [0.00125156 0.         0.         0.         0.         0.        ]\n",
      " [0.0951189  0.02252816 0.         0.04380476 0.         0.00125156]\n",
      " [0.01126408 0.03379224 0.01501877 0.13767209 0.         0.0175219 ]\n",
      " [0.00125156 0.00375469 0.09762203 0.00125156 0.10888611 0.00125156]]\n",
      "move 6\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0. -1.  0.  0.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [0.00964776 0.20665705 0.00355887 0.02873594 0.02308655 0.00135135\n",
      " 0.00991805 0.03368733 0.03610748 0.00378036 0.00334137 0.00505084\n",
      " 0.00232631 0.00103974 0.00429826 0.00110015 0.00376923 0.09324216\n",
      " 0.028661   0.01069242 0.00034927 0.01191724 0.00065624 0.00324038\n",
      " 0.0057381  0.0035395  0.0098649  0.03782888 0.06661819 0.00878145\n",
      " 0.00617913 0.02006702 0.13874432 0.00206268 0.16777919 0.00658137] \n",
      " 0.8633132\n",
      "p [[1.25156446e-13 5.50688360e-02 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  5.81977472e-01 1.25156446e-13]\n",
      " [1.25156446e-13 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 2.12765957e-02 1.25156446e-13 1.25156446e-13\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  3.41677096e-01 1.25156446e-13]]\n",
      "move 10\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0. -1.  0.  1.  0.]\n",
      " [ 0. -1.  1.  1.  1. -1.]\n",
      " [ 0.  0. -1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "1 won\n",
      "game 249 completed in 26.000646829605103 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.595164 entropy 1.9531627\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5707862 entropy 1.9569702\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5241714 entropy 1.9627357\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4810677 entropy 1.9699475\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4463658 entropy 1.976121\n",
      "kl 0.017127685\n",
      "completed in 0.31366896629333496 s\n",
      "game 250 completed in 5.737498044967651 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.63704 entropy 2.0013976\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6147144 entropy 2.0027308\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5782905 entropy 1.9999318\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5373194 entropy 1.9938401\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.50023 entropy 1.9856355\n",
      "kl 0.015031148\n",
      "completed in 0.2714362144470215 s\n",
      "game 251 completed in 8.83853268623352 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5368664 entropy 1.9664015\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5174208 entropy 1.9578094\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4827428 entropy 1.9493762\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4406672 entropy 1.9418235\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3980622 entropy 1.9351138\n",
      "kl 0.019966517\n",
      "completed in 0.3666048049926758 s\n",
      "game 252 completed in 6.657500982284546 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6370049 entropy 1.9820981\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6128845 entropy 1.9826719\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5749104 entropy 1.9848638\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5331042 entropy 1.9872113\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4926789 entropy 1.9885213\n",
      "kl 0.019493956\n",
      "completed in 0.33016324043273926 s\n",
      "game 253 completed in 9.225373268127441 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5680816 entropy 1.9410987\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.535222 entropy 1.9332023\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4881074 entropy 1.923144\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4401703 entropy 1.9157605\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.393218 entropy 1.9125223\n",
      "kl 0.027448991\n",
      "completed in 0.32628607749938965 s\n",
      "game 254 completed in 13.323940992355347 s 16 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5844057 entropy 1.9341373\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5670826 entropy 1.9399087\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5314212 entropy 1.947758\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4909563 entropy 1.954865\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4524238 entropy 1.9599819\n",
      "kl 0.020945027\n",
      "completed in 0.36162281036376953 s\n",
      "game 255 completed in 8.230180263519287 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6254337 entropy 1.9831996\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6083245 entropy 1.9817097\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5751987 entropy 1.9776034\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.535488 entropy 1.9720831\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4986367 entropy 1.9661019\n",
      "kl 0.019576278\n",
      "completed in 0.24690628051757812 s\n",
      "game 256 completed in 7.30202317237854 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6010618 entropy 1.9395198\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5755847 entropy 1.93146\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5331352 entropy 1.9209397\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4864953 entropy 1.9134072\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4387832 entropy 1.910811\n",
      "kl 0.02372118\n",
      "completed in 0.2941017150878906 s\n",
      "game 257 completed in 9.429245233535767 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6459532 entropy 1.9297434\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6225755 entropy 1.9407128\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5835786 entropy 1.9559423\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.540215 entropy 1.9704475\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5009184 entropy 1.980452\n",
      "kl 0.022087459\n",
      "completed in 0.29372096061706543 s\n",
      "game 258 completed in 5.7284979820251465 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5861187 entropy 2.0118754\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.560962 entropy 2.0053394\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5241163 entropy 1.9949143\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4841273 entropy 1.9853611\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4436526 entropy 1.979321\n",
      "kl 0.023393702\n",
      "completed in 0.32797980308532715 s\n",
      "game 259 completed in 8.172027111053467 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5916867 entropy 1.9469833\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5631998 entropy 1.9552472\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5204885 entropy 1.9644147\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.477614 entropy 1.9699483\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.437967 entropy 1.9683377\n",
      "kl 0.028769722\n",
      "completed in 0.33420872688293457 s\n",
      "game 260 completed in 10.911265850067139 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5573452 entropy 1.9676298\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5395036 entropy 1.9574318\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5119252 entropy 1.9489766\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4792347 entropy 1.9440925\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.444103 entropy 1.942458\n",
      "kl 0.017062373\n",
      "completed in 0.2812678813934326 s\n",
      "game 261 completed in 7.169620990753174 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5765755 entropy 1.9718196\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5525198 entropy 1.9719152\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5125325 entropy 1.9692464\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4675124 entropy 1.9653468\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.419675 entropy 1.9629418\n",
      "kl 0.015958894\n",
      "completed in 0.3162710666656494 s\n",
      "game 262 completed in 8.872753143310547 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5299687 entropy 1.8825369\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.506266 entropy 1.8834441\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.467659 entropy 1.8836255\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.423668 entropy 1.8810242\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3778133 entropy 1.8743118\n",
      "kl 0.018127367\n",
      "completed in 0.28435206413269043 s\n",
      "game 263 completed in 10.274619340896606 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.521211 entropy 1.8785393\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.497605 entropy 1.8774583\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4561627 entropy 1.8794744\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4102986 entropy 1.8825521\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3657603 entropy 1.8843333\n",
      "kl 0.018482765\n",
      "completed in 0.24555706977844238 s\n",
      "game 264 completed in 7.23853325843811 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6375966 entropy 1.9088693\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.61478 entropy 1.911574\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5792983 entropy 1.9161727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 3 lr_mult 0.4444444444444444 loss 2.53953 entropy 1.9228791\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4984815 entropy 1.9312816\n",
      "kl 0.019601978\n",
      "completed in 0.315079927444458 s\n",
      "game 265 completed in 10.281911134719849 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5863168 entropy 1.9154191\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.556981 entropy 1.9216721\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5183082 entropy 1.9263182\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.480029 entropy 1.9302284\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4379296 entropy 1.9341139\n",
      "kl 0.020311346\n",
      "completed in 0.3013641834259033 s\n",
      "game 266 completed in 7.306581020355225 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5754197 entropy 1.9466939\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5534055 entropy 1.9468771\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5138705 entropy 1.9438449\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4652803 entropy 1.9378266\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4278286 entropy 1.9296303\n",
      "kl 0.02074442\n",
      "completed in 0.3618502616882324 s\n",
      "game 267 completed in 8.848091125488281 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.571582 entropy 1.9069282\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5457652 entropy 1.9103402\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5035555 entropy 1.9222288\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4571848 entropy 1.9377774\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4151433 entropy 1.9517972\n",
      "kl 0.026718104\n",
      "completed in 0.27335309982299805 s\n",
      "game 268 completed in 6.063029050827026 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6275132 entropy 2.0244677\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5925043 entropy 2.0142884\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5434144 entropy 1.9942195\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5017107 entropy 1.9757843\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.45856 entropy 1.9671528\n",
      "kl 0.027018357\n",
      "completed in 0.2891578674316406 s\n",
      "game 269 completed in 9.164448022842407 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.551986 entropy 1.9291043\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5156555 entropy 1.9372933\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4786358 entropy 1.9451694\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4488416 entropy 1.9481165\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4162295 entropy 1.942605\n",
      "kl 0.025102798\n",
      "completed in 0.32160186767578125 s\n",
      "game 270 completed in 11.785247087478638 s 14 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5838785 entropy 1.9933525\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5647883 entropy 1.9778731\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5338433 entropy 1.9644439\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4978065 entropy 1.9563823\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4618075 entropy 1.9542614\n",
      "kl 0.016950723\n",
      "completed in 0.30406808853149414 s\n",
      "game 271 completed in 11.33383584022522 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6587749 entropy 1.9027735\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6376595 entropy 1.9138995\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.603517 entropy 1.9296014\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5654833 entropy 1.9450284\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5258398 entropy 1.9559299\n",
      "kl 0.026651554\n",
      "completed in 0.34784412384033203 s\n",
      "game 272 completed in 5.971284866333008 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.559966 entropy 1.9696618\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.544535 entropy 1.9711313\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5144188 entropy 1.9706533\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.479131 entropy 1.9681079\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4441473 entropy 1.9630497\n",
      "kl 0.011930689\n",
      "completed in 0.30843400955200195 s\n",
      "game 273 completed in 6.239887237548828 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5651305 entropy 1.897446\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5366561 entropy 1.8927917\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4956372 entropy 1.8885201\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4555027 entropy 1.8831962\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.417091 entropy 1.8767649\n",
      "kl 0.016445413\n",
      "completed in 0.3198277950286865 s\n",
      "game 274 completed in 8.19896388053894 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6414983 entropy 1.9220833\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6181746 entropy 1.9228178\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5766203 entropy 1.9295214\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5294478 entropy 1.9383781\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4867816 entropy 1.9448402\n",
      "kl 0.017292235\n",
      "completed in 0.29076695442199707 s\n",
      "game 275 completed in 6.822070837020874 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5760143 entropy 1.9501014\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5524116 entropy 1.946403\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5150156 entropy 1.9408871\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4725795 entropy 1.9366891\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4268599 entropy 1.935693\n",
      "kl 0.014690279\n",
      "completed in 0.32559895515441895 s\n",
      "game 276 completed in 9.186158895492554 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.620262 entropy 1.926381\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.589526 entropy 1.9329537\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5429194 entropy 1.9410118\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.501115 entropy 1.9474514\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4567502 entropy 1.9478145\n",
      "kl 0.01803809\n",
      "completed in 0.2633657455444336 s\n",
      "game 277 completed in 5.989199161529541 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5205963 entropy 1.9413129\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5004656 entropy 1.9292563\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4684534 entropy 1.9158189\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4285374 entropy 1.9044068\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.382273 entropy 1.8960786\n",
      "kl 0.021654163\n",
      "completed in 0.31469273567199707 s\n",
      "game 278 completed in 8.845241069793701 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5562117 entropy 1.9181461\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5389616 entropy 1.9227995\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5129857 entropy 1.93345\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4840822 entropy 1.9453124\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4549656 entropy 1.9538132\n",
      "kl 0.022954252\n",
      "completed in 0.2886629104614258 s\n",
      "game 279 completed in 13.771697044372559 s 17 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4580257 entropy 1.8881135\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4339514 entropy 1.8807924\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.398409 entropy 1.8672521\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3589656 entropy 1.8531678\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3174286 entropy 1.8424325\n",
      "kl 0.024919078\n",
      "completed in 0.3676869869232178 s\n",
      "game 280 completed in 9.3348228931427 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5172873 entropy 1.8954707\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4890547 entropy 1.8959982\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4408965 entropy 1.8991969\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.391626 entropy 1.9026182\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3498147 entropy 1.9044608\n",
      "kl 0.02130098\n",
      "completed in 0.296184778213501 s\n",
      "game 281 completed in 10.66840386390686 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.558905 entropy 1.880126\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5317297 entropy 1.8796968\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4948816 entropy 1.8806132\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4563096 entropy 1.8828804\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4146433 entropy 1.8862913\n",
      "kl 0.018836863\n",
      "completed in 0.2900099754333496 s\n",
      "game 282 completed in 7.974305868148804 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4965312 entropy 1.9314344\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4798307 entropy 1.9373267\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4529855 entropy 1.9439455\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4233732 entropy 1.9509265\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.390645 entropy 1.9568874\n",
      "kl 0.017657172\n",
      "completed in 0.2706418037414551 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 283 completed in 6.27696681022644 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5352228 entropy 1.9352939\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5128121 entropy 1.9387729\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4808578 entropy 1.9410349\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4459033 entropy 1.9406767\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4105213 entropy 1.9375012\n",
      "kl 0.01337751\n",
      "completed in 0.2978780269622803 s\n",
      "game 284 completed in 9.459536790847778 s 11 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.585432 entropy 1.9444861\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.560864 entropy 1.9337171\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5228136 entropy 1.9200335\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4820824 entropy 1.9076436\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.442019 entropy 1.8983816\n",
      "kl 0.016816754\n",
      "completed in 0.35178589820861816 s\n",
      "game 285 completed in 8.965224981307983 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5502698 entropy 1.8953774\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.527329 entropy 1.9001456\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.487625 entropy 1.91001\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4497342 entropy 1.9215424\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4173048 entropy 1.9302249\n",
      "kl 0.017564762\n",
      "completed in 0.33074092864990234 s\n",
      "game 286 completed in 6.310729026794434 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5647805 entropy 1.9256732\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5493376 entropy 1.9227884\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5183134 entropy 1.916579\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.479636 entropy 1.9104782\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.436298 entropy 1.906993\n",
      "kl 0.017141303\n",
      "completed in 0.337954044342041 s\n",
      "game 287 completed in 8.015484094619751 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5540404 entropy 1.9467688\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5312812 entropy 1.9435893\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4925501 entropy 1.9405003\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.450481 entropy 1.9373643\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4142158 entropy 1.9341294\n",
      "kl 0.015454944\n",
      "completed in 0.27771711349487305 s\n",
      "game 288 completed in 11.403702020645142 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4789977 entropy 1.8996649\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4580634 entropy 1.8974197\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4266849 entropy 1.8950987\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.3914852 entropy 1.8928747\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.354502 entropy 1.8903508\n",
      "kl 0.012955184\n",
      "completed in 0.2640831470489502 s\n",
      "game 289 completed in 11.2410249710083 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.561909 entropy 1.9242871\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5372624 entropy 1.9245744\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4995306 entropy 1.9259887\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4550233 entropy 1.9265913\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4080284 entropy 1.9249197\n",
      "kl 0.015543304\n",
      "completed in 0.33992981910705566 s\n",
      "game 290 completed in 10.94965410232544 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5287027 entropy 1.9043845\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.513039 entropy 1.9016858\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4833486 entropy 1.8989713\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4499767 entropy 1.8977222\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4175463 entropy 1.8982058\n",
      "kl 0.017088134\n",
      "completed in 0.3658268451690674 s\n",
      "game 291 completed in 6.852860927581787 s 8 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5601108 entropy 1.9406648\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5455575 entropy 1.9439845\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5181 entropy 1.9480283\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.484128 entropy 1.9529504\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4498293 entropy 1.9583844\n",
      "kl 0.020086635\n",
      "completed in 0.33196377754211426 s\n",
      "game 292 completed in 11.78708791732788 s 13 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.4910035 entropy 1.9104631\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.472818 entropy 1.9121782\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4423156 entropy 1.910354\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4055948 entropy 1.9063697\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3727272 entropy 1.9025141\n",
      "kl 0.01740437\n",
      "completed in 0.36977100372314453 s\n",
      "game 293 completed in 10.717975854873657 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.428396 entropy 1.9120874\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.4085166 entropy 1.9153256\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.3815677 entropy 1.9201083\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.352647 entropy 1.923778\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.3215458 entropy 1.9239616\n",
      "kl 0.02146675\n",
      "completed in 0.3302602767944336 s\n",
      "game 294 completed in 13.200330972671509 s 15 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6007717 entropy 1.9600357\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5748823 entropy 1.9505974\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5312696 entropy 1.9384054\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4868233 entropy 1.9263597\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4498816 entropy 1.9169459\n",
      "kl 0.020264514\n",
      "completed in 0.33110618591308594 s\n",
      "game 295 completed in 8.958340883255005 s 10 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.599693 entropy 1.9330983\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5825734 entropy 1.9329503\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5555847 entropy 1.9359279\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.525607 entropy 1.939872\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4927242 entropy 1.94322\n",
      "kl 0.017006645\n",
      "completed in 0.2875711917877197 s\n",
      "game 296 completed in 10.06836223602295 s 12 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.551362 entropy 1.9025764\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5306034 entropy 1.8977534\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.4974935 entropy 1.890945\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4574783 entropy 1.8863733\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4152434 entropy 1.8864127\n",
      "kl 0.018462121\n",
      "completed in 0.3212931156158447 s\n",
      "game 297 completed in 6.464503049850464 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6572473 entropy 1.9046595\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.6346383 entropy 1.915278\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5995648 entropy 1.9274752\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5600421 entropy 1.936575\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.5214436 entropy 1.9380288\n",
      "kl 0.025603829\n",
      "completed in 0.3739309310913086 s\n",
      "game 298 completed in 8.144206047058105 s 9 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.6324723 entropy 1.9267374\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.610861 entropy 1.9185642\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5737913 entropy 1.9076905\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.5317845 entropy 1.8967144\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.4914882 entropy 1.8880965\n",
      "kl 0.019232843\n",
      "completed in 0.3213620185852051 s\n",
      "prediction:\n",
      " [0.00166224 0.00231218 0.00289149 0.00371232 0.00253205 0.00164232\n",
      " 0.00132254 0.00232238 0.01351434 0.10820237 0.00702753 0.00299491\n",
      " 0.00416473 0.01829707 0.01347643 0.10678165 0.20380065 0.00422284\n",
      " 0.00563233 0.14825483 0.10472059 0.01303306 0.01185968 0.00440983\n",
      " 0.00285466 0.00990184 0.16613515 0.00877096 0.00356225 0.00208633\n",
      " 0.00168541 0.0035048  0.00491278 0.00335024 0.00327294 0.00117254] \n",
      " -0.3686744\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 2.49061327e-01 3.90488110e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.80225282e-01 1.80225282e-01\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 15\n",
      "board\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [7.92010105e-05 2.23632785e-04 2.05750795e-04 3.09665164e-04\n",
      " 2.07321995e-04 3.54435579e-05 1.44535050e-04 2.33662606e-04\n",
      " 1.10223619e-02 9.57463123e-03 6.22412264e-02 1.84398639e-04\n",
      " 2.63161538e-03 2.78942943e-01 1.39776230e-01 2.82882955e-02\n",
      " 3.26328503e-04 1.07403175e-04 1.18387572e-04 1.62552707e-04\n",
      " 7.60498717e-02 1.52958497e-01 1.72011659e-01 1.78557483e-03\n",
      " 1.30432032e-04 4.11440805e-02 1.23492815e-02 7.40110083e-03\n",
      " 1.42873498e-04 1.39760305e-04 4.21522454e-05 4.31203895e-04\n",
      " 1.50711916e-04 1.29972977e-04 2.72210804e-04 4.51135202e-05] \n",
      " 0.19668975\n",
      "p [[0.00125156 0.00250313 0.00125156 0.00250313 0.00125156 0.00125156]\n",
      " [0.00250313 0.00125156 0.14768461 0.07634543 0.00125156 0.00125156]\n",
      " [0.00125156 0.01126408 0.00375469 0.         0.30162703 0.00125156]\n",
      " [0.00375469 0.08385482 0.2290363  0.00375469 0.00750939 0.00125156]\n",
      " [0.00375469 0.00375469 0.08135169 0.00250313 0.00250313 0.00625782]\n",
      " [0.00125156 0.00250313 0.00250313 0.00250313 0.00125156 0.00125156]]\n",
      "move 16\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00146438 0.00845628 0.00147701 0.0059674  0.00371446 0.00064145\n",
      " 0.00929095 0.00126426 0.32516256 0.03550071 0.01724893 0.00622215\n",
      " 0.00951684 0.0036587  0.03439546 0.02551451 0.01649816 0.00317159\n",
      " 0.02605173 0.01767846 0.02017712 0.04664813 0.0018465  0.01143971\n",
      " 0.00475741 0.01667809 0.04913222 0.2527129  0.00101425 0.0136286\n",
      " 0.00276995 0.00434109 0.00641564 0.0009549  0.01325934 0.00132821] \n",
      " -0.51428264\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 3.75469337e-03 1.25156446e-03\n",
      "  1.00125156e-02 1.25156446e-13]\n",
      " [1.25156446e-13 1.61451815e-01 2.10262829e-01 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-02 4.25531915e-02\n",
      "  5.44430538e-01 1.25156446e-13]\n",
      " [1.25156446e-13 8.76095119e-03 3.75469337e-03 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 22\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [5.1530224e-04 2.1212166e-03 7.0655817e-04 4.2540748e-03 1.0783038e-03\n",
      " 1.6938211e-04 7.7836895e-03 2.8796233e-03 5.2214954e-02 4.1976746e-02\n",
      " 2.5360644e-02 5.5149238e-04 6.9331815e-03 2.8194757e-02 2.9503527e-01\n",
      " 8.3841473e-02 2.4117092e-03 2.7276040e-03 2.0146368e-03 2.0922513e-03\n",
      " 7.9196036e-02 1.9004558e-01 5.7998137e-03 2.5526020e-03 6.0876372e-04\n",
      " 2.1775836e-02 8.0834508e-02 3.2051079e-02 9.1663603e-04 1.0730607e-02\n",
      " 3.5448358e-04 1.4443150e-03 1.9759999e-03 1.2239041e-03 7.3607713e-03\n",
      " 2.6637712e-04] \n",
      " 0.1895867\n",
      "p [[0.00125156 0.00375469 0.00125156 0.00125156 0.00125156 0.00125156]\n",
      " [0.00500626 0.00125156 0.60450563 0.02377972 0.00500626 0.00125156]\n",
      " [0.00500626 0.00250313 0.03379224 0.         0.         0.00125156]\n",
      " [0.01126408 0.01001252 0.00876095 0.05381727 0.         0.00250313]\n",
      " [0.00125156 0.01877347 0.07259074 0.10638298 0.00125156 0.00500626]\n",
      " [0.00125156 0.00500626 0.00125156 0.00125156 0.00500626 0.00125156]]\n",
      "move 8\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00100504 0.00568949 0.01508221 0.00894357 0.00454416 0.00144219\n",
      " 0.00582758 0.00856528 0.03798776 0.23280755 0.0081473  0.00493794\n",
      " 0.0232304  0.00584823 0.01382967 0.0189322  0.00324981 0.00124545\n",
      " 0.00629353 0.00273031 0.01180213 0.01116189 0.00278247 0.02324507\n",
      " 0.00744687 0.01345505 0.45762512 0.01160903 0.00412828 0.00817966\n",
      " 0.00196762 0.00622224 0.01113275 0.01250092 0.00519609 0.00120524] \n",
      " -0.7010938\n",
      "p [[1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [3.75469337e-03 1.25156446e-13 0.00000000e+00 6.25782228e-03\n",
      "  3.75469337e-03 1.25156446e-13]\n",
      " [2.50312891e-03 6.25782228e-03 6.00750939e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 6.38297872e-02 7.97246558e-01\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 6.25782228e-03 3.25406758e-02 1.37672090e-02\n",
      "  1.25156446e-13 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-13\n",
      "  2.50312891e-03 1.25156446e-13]]\n",
      "move 21\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [1.6752366e-03 5.0640205e-04 9.1167027e-03 5.0384511e-04 7.9175300e-04\n",
      " 6.1592873e-05 1.6794100e-03 2.1253636e-02 1.0610438e-02 3.1728236e-04\n",
      " 4.7230637e-03 1.4579908e-03 2.9737699e-01 8.5217104e-04 4.6043136e-04\n",
      " 2.5532898e-02 1.0084892e-02 1.2246349e-03 1.1741006e-03 7.2489791e-03\n",
      " 1.9863717e-02 6.6050055e-04 4.1636534e-04 5.3528076e-01 1.6447534e-03\n",
      " 1.0076753e-02 2.3237749e-03 5.7391468e-03 5.7848436e-03 5.8018412e-03\n",
      " 8.8823414e-05 3.2699658e-03 4.6725501e-04 9.7373957e-03 1.7896963e-03\n",
      " 4.0208668e-04] \n",
      " 0.35938334\n",
      "p [[0.00125156 0.00125156 0.03254068 0.00625782 0.00125156 0.00125156]\n",
      " [0.00125156 0.03254068 0.         0.33667084 0.11013767 0.00125156]\n",
      " [0.02002503 0.00125156 0.01877347 0.         0.         0.00125156]\n",
      " [0.00250313 0.00125156 0.01126408 0.         0.         0.12640801]\n",
      " [0.00250313 0.00375469 0.19399249 0.00750939 0.00125156 0.00250313]\n",
      " [0.00125156 0.00500626 0.01501877 0.01251564 0.04505632 0.00125156]]\n",
      "move 9\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00152761 0.01071893 0.09395523 0.00631665 0.00716811 0.00240808\n",
      " 0.02924078 0.14871989 0.04436667 0.01597631 0.03933817 0.04049845\n",
      " 0.00354831 0.00291504 0.00848309 0.04167771 0.00325228 0.00142591\n",
      " 0.0044293  0.00121743 0.02414298 0.0187648  0.00198818 0.00459315\n",
      " 0.02503031 0.08082089 0.01534227 0.02515797 0.17147255 0.06376763\n",
      " 0.00234454 0.01258895 0.0027899  0.03348065 0.00959824 0.00093319] \n",
      " -0.84580445\n",
      "p [[1.25156446e-13 1.25156446e-13 6.25782228e-03 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.37672090e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [3.87984981e-02 1.25156446e-13 1.25156446e-13 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-13]\n",
      " [1.25156446e-13 9.51188986e-02 1.62703379e-02 0.00000000e+00\n",
      "  0.00000000e+00 7.93491865e-01]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 3.12891114e-02\n",
      "  1.25156446e-03 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 1.25156446e-13 1.25156446e-03\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 23\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0.  0.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [0.00563078 0.00382358 0.01367489 0.01026915 0.00544675 0.00137382\n",
      " 0.01516739 0.01423599 0.31511497 0.00040523 0.01677868 0.02264849\n",
      " 0.01577579 0.01246799 0.06074308 0.00114384 0.00094519 0.00661674\n",
      " 0.00135292 0.00101412 0.00287101 0.21148854 0.00784134 0.00464326\n",
      " 0.02040277 0.01996315 0.00083455 0.0867052  0.00687637 0.05151913\n",
      " 0.0013439  0.00691245 0.00351882 0.04450776 0.00348054 0.00246206] \n",
      " 0.23469576\n",
      "p [[0.00125156 0.00375469 0.03379224 0.00125156 0.00250313 0.00125156]\n",
      " [0.0175219  0.06007509 0.         0.         0.01376721 0.01376721]\n",
      " [0.00125156 0.00125156 0.00250313 0.         0.         0.00125156]\n",
      " [0.00125156 0.00125156 0.68335419 0.         0.         0.        ]\n",
      " [0.00876095 0.02878598 0.00500626 0.00876095 0.06257822 0.02252816]\n",
      " [0.00125156 0.00375469 0.00125156 0.01126408 0.00375469 0.00125156]]\n",
      "move 20\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "prediction:\n",
      " [4.5414848e-04 1.3269633e-03 4.0455571e-01 2.3842964e-03 2.4108193e-03\n",
      " 4.3070331e-04 2.3529120e-03 1.2055534e-02 1.9880233e-03 2.5241952e-02\n",
      " 2.3041250e-02 2.6597796e-02 8.0435205e-04 8.7949319e-04 4.5659998e-03\n",
      " 5.3527387e-04 1.1638725e-03 8.2610850e-04 2.6699260e-03 4.0235577e-04\n",
      " 3.0745377e-04 5.5234353e-03 5.6537293e-04 4.5964954e-04 1.5675783e-02\n",
      " 4.1968159e-02 1.1121579e-02 8.0170343e-04 1.1098460e-02 6.5384442e-03\n",
      " 2.3816577e-04 8.3776647e-03 1.5048593e-03 3.7982371e-01 1.1145629e-03\n",
      " 1.9350169e-04] \n",
      " 0.8326494\n",
      "p [[1.25156446e-03 1.25156446e-13 1.25156446e-03 1.25156446e-03\n",
      "  1.25156446e-03 1.25156446e-13]\n",
      " [1.25156446e-03 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 6.25782228e-03]\n",
      " [1.25156446e-03 1.25156446e-03 1.00125156e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 1.25156446e-03 1.25156446e-13 8.86107635e-01\n",
      "  1.25156446e-03 2.50312891e-02]\n",
      " [1.25156446e-13 1.25156446e-03 1.25156446e-13 5.50688360e-02\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 27\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:\n",
      " [1.1286080e-02 4.6176356e-03 1.4237895e-02 5.2516633e-01 4.0782723e-03\n",
      " 2.9515108e-04 1.2693401e-02 2.4021523e-02 8.7599625e-04 9.1740303e-03\n",
      " 1.7536843e-02 3.6905978e-02 6.8706772e-03 1.0182000e-03 5.7284045e-03\n",
      " 5.9645704e-04 1.8873625e-04 6.7370408e-03 1.7093483e-03 3.4274111e-04\n",
      " 3.0041841e-04 3.9468907e-02 1.6918298e-03 2.8018756e-03 1.7339194e-02\n",
      " 1.8989664e-02 7.1880617e-03 6.8380550e-04 8.8223265e-03 4.4224687e-02\n",
      " 2.7820247e-04 3.2792003e-03 1.4833458e-01 1.3608509e-02 6.6733230e-03\n",
      " 2.2347302e-03] \n",
      " 0.9901453\n",
      "p [[0.00125156 0.00125156 0.14768461 0.00125156 0.00125156 0.00125156]\n",
      " [0.00125156 0.03003755 0.         0.         0.04005006 0.0563204 ]\n",
      " [0.00125156 0.00125156 0.00125156 0.         0.         0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.         0.         0.        ]\n",
      " [0.00876095 0.01376721 0.02377972 0.         0.00500626 0.00125156]\n",
      " [0.00125156 0.00625782 0.00125156 0.64705882 0.00125156 0.00125156]]\n",
      "move 33\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.]]\n",
      "prediction:\n",
      " [0.0012726  0.00477813 0.14222959 0.00172695 0.01776391 0.00080436\n",
      " 0.00358786 0.02963064 0.0059749  0.05061813 0.04469808 0.14626473\n",
      " 0.00504566 0.00123447 0.02219363 0.00131641 0.00321172 0.00692407\n",
      " 0.01749326 0.00111917 0.00042589 0.03895326 0.00107837 0.00260691\n",
      " 0.06910126 0.0669297  0.01930367 0.0024631  0.02463037 0.01299032\n",
      " 0.00049294 0.04224842 0.00159268 0.20475218 0.00413885 0.00040391] \n",
      " 0.9236114\n",
      "p [[3.87984981e-02 1.25156446e-13 2.25281602e-02 7.38423029e-02\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.62703379e-02 2.25281602e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-03 2.75344180e-02]\n",
      " [1.25156446e-03 1.25156446e-13 1.25156446e-03 0.00000000e+00\n",
      "  0.00000000e+00 1.25156446e-03]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-03 1.25156446e-03 1.25156446e-03 0.00000000e+00\n",
      "  2.75344180e-02 2.12765957e-02]\n",
      " [1.25156446e-13 1.25156446e-13 7.39674593e-01 0.00000000e+00\n",
      "  1.25156446e-03 1.25156446e-13]]\n",
      "move 32\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1.  0.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [0.01335052 0.00897108 0.0210146  0.06970312 0.00758829 0.00085185\n",
      " 0.04281224 0.0324394  0.01311464 0.03648206 0.03340391 0.07128034\n",
      " 0.0181063  0.02899193 0.01161305 0.01436024 0.00087345 0.03414657\n",
      " 0.0079839  0.00148152 0.01367425 0.0861388  0.02409945 0.00411407\n",
      " 0.03625456 0.03061474 0.04096658 0.00570064 0.01659808 0.17004752\n",
      " 0.00032162 0.01171571 0.03065693 0.04619942 0.01195912 0.00236983] \n",
      " 0.99666893\n",
      "p [[0.00125156 0.00125156 0.10638298 0.00125156 0.01877347 0.00125156]\n",
      " [0.00125156 0.13516896 0.         0.         0.04130163 0.13642053]\n",
      " [0.00125156 0.00125156 0.00750939 0.         0.         0.33416771]\n",
      " [0.03629537 0.00125156 0.         0.         0.         0.        ]\n",
      " [0.03003755 0.05256571 0.02628285 0.         0.02753442 0.00375469]\n",
      " [0.00125156 0.02878598 0.         0.         0.00250313 0.00125156]]\n",
      "move 17\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [0.00158594 0.00449267 0.05606668 0.00156975 0.01045534 0.00094762\n",
      " 0.00069947 0.0122651  0.00625722 0.08642511 0.07162408 0.05743575\n",
      " 0.01566177 0.00367564 0.06248853 0.00468689 0.00464365 0.00690212\n",
      " 0.02174779 0.00240701 0.00077246 0.12580165 0.00340725 0.00214759\n",
      " 0.03218883 0.06377347 0.07875562 0.00202854 0.0115612  0.00414419\n",
      " 0.00060592 0.02660019 0.00386137 0.2087435  0.00267166 0.0008987 ] \n",
      " 0.8609732\n",
      "p [[0.05882353 0.00125156 0.03254068 0.07259074 0.00125156 0.00125156]\n",
      " [0.13642053 0.08635795 0.         0.         0.08010013 0.05882353]\n",
      " [0.04005006 0.07634543 0.01126408 0.         0.         0.        ]\n",
      " [0.00125156 0.00125156 0.         0.         0.         0.        ]\n",
      " [0.05006258 0.02878598 0.03379224 0.         0.06007509 0.077597  ]\n",
      " [0.00125156 0.05006258 0.         0.         0.03754693 0.00125156]]\n",
      "move 6\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  1. -1. -1.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [0.0240093  0.01738592 0.04351182 0.08226977 0.01957578 0.00139214\n",
      " 0.03144455 0.00608123 0.00274371 0.05546936 0.01908809 0.09485962\n",
      " 0.01161497 0.012706   0.00028309 0.02903632 0.00500386 0.03951556\n",
      " 0.0177744  0.00774718 0.01097995 0.00107454 0.00709242 0.00341048\n",
      " 0.05100719 0.0115579  0.09113469 0.00137124 0.00332724 0.11174181\n",
      " 0.00055198 0.02627846 0.03354242 0.09612161 0.02503272 0.00426302] \n",
      " 0.9876898\n",
      "p [[0.00125156 0.00125156 0.09136421 0.00125156 0.00125156 0.00125156]\n",
      " [0.         0.00125156 0.         0.         0.11514393 0.00750939]\n",
      " [0.00125156 0.00125156 0.69962453 0.         0.         0.        ]\n",
      " [0.00125156 0.00125156 0.         0.         0.         0.        ]\n",
      " [0.01251564 0.00876095 0.04505632 0.         0.00125156 0.00125156]\n",
      " [0.00125156 0.00125156 0.         0.         0.00125156 0.00125156]]\n",
      "move 14\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1. -1. -1.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [1.9692790e-04 2.3820293e-03 2.2741956e-01 2.0224706e-04 5.6352122e-03\n",
      " 6.8924783e-05 3.8159909e-05 3.1843232e-03 1.2007216e-03 6.7826986e-02\n",
      " 9.3288498e-04 4.4140751e-03 2.3903797e-04 8.8057663e-05 5.9076486e-04\n",
      " 5.0100926e-03 2.3559106e-03 2.1236404e-03 4.3490180e-03 7.3740748e-04\n",
      " 6.9998408e-04 2.5203032e-03 8.3667059e-05 5.2985040e-05 2.5759980e-03\n",
      " 5.7636091e-04 5.5845790e-02 2.9277685e-04 1.6421932e-03 3.9511535e-04\n",
      " 1.1571838e-04 9.3536116e-03 5.6454941e-04 5.9502965e-01 1.0495612e-03\n",
      " 2.0578415e-04] \n",
      " 0.9999993\n",
      "p [[0.03379224 0.02503129 0.08385482 0.11889862 0.02753442 0.00125156]\n",
      " [0.         0.00876095 0.         0.         0.02753442 0.13767209]\n",
      " [0.01627034 0.0175219  0.         0.         0.         0.        ]\n",
      " [0.02503129 0.01001252 0.         0.         0.         0.        ]\n",
      " [0.0738423  0.01627034 0.13141427 0.         0.00375469 0.16145181]\n",
      " [0.00125156 0.03754693 0.         0.         0.03629537 0.00500626]]\n",
      "move 29\n",
      "board\n",
      " [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1. -1. -1.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "prediction:\n",
      " [0.01404936 0.04302951 0.01242496 0.11427499 0.01659672 0.00333866\n",
      " 0.00789426 0.04748693 0.00721879 0.03700885 0.01096464 0.12859221\n",
      " 0.02005443 0.00898789 0.00017464 0.02775594 0.0026105  0.09348323\n",
      " 0.05830059 0.0009427  0.00681116 0.00044211 0.00518672 0.0024734\n",
      " 0.04518032 0.0079362  0.02174707 0.00281983 0.02452829 0.01541661\n",
      " 0.00108847 0.04102722 0.04360812 0.02338786 0.10141448 0.00174238] \n",
      " 0.9898003\n",
      "p [[1.25156446e-13 1.25156446e-13 8.02252816e-01 1.25156446e-13\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [0.00000000e+00 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-13 1.96495620e-01 0.00000000e+00\n",
      "  1.25156446e-13 0.00000000e+00]\n",
      " [1.25156446e-13 1.25156446e-03 0.00000000e+00 0.00000000e+00\n",
      "  1.25156446e-13 1.25156446e-13]]\n",
      "move 2\n",
      "board\n",
      " [[ 0.  0. -1.  0.  0.  0.]\n",
      " [ 1.  0. -1. -1.  0.  0.]\n",
      " [ 0.  0. -1.  1. -1. -1.]\n",
      " [ 0.  0. -1.  1.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  1. -1.  0.  0.]]\n",
      "-1 won\n",
      "game 299 completed in 32.48992466926575 s 7 steps\n",
      "training 0 lr_mult 0.4444444444444444 loss 2.5858328 entropy 1.9212983\n",
      "training 1 lr_mult 0.4444444444444444 loss 2.5699806 entropy 1.9200947\n",
      "training 2 lr_mult 0.4444444444444444 loss 2.5392053 entropy 1.9222232\n",
      "training 3 lr_mult 0.4444444444444444 loss 2.4997141 entropy 1.9268574\n",
      "training 4 lr_mult 0.4444444444444444 loss 2.461801 entropy 1.9320214\n",
      "kl 0.01878473\n",
      "completed in 0.30188989639282227 s\n",
      "training pipeline completed in 3122.2656257152557 s\n"
     ]
    }
   ],
   "source": [
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "826c1c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:18: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:22: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:26: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:31: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:40: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:44: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:51: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:54: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
      "2022-01-20 15:17:25.046704: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-20 15:17:25.046730: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-20 15:17:25.053247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 600.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:17:25.138559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-20 15:17:25.166886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) INVALID_ARGUMENT: Input to reshape is a tensor with 72 values, but the requested shape requires a multiple of 144\n\t [[node Reshape\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:36)\n]]\n\t [[dense_2/Tanh/_105]]\n  (1) INVALID_ARGUMENT: Input to reshape is a tensor with 72 values, but the requested shape requires a multiple of 144\n\t [[node Reshape\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:36)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Reshape:\nIn[0] conv2d_3/Relu (defined at /Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional.py:273)\t\nIn[1] Reshape/shape:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\", line 36, in __init__\n>>>     self.action_conv_flat = tf.reshape(\n>>> \n\nInput Source operations connected to node Reshape:\nIn[0] conv2d_3/Relu (defined at /Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional.py:273)\t\nIn[1] Reshape/shape:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\", line 36, in __init__\n>>>     self.action_conv_flat = tf.reshape(\n>>> \n\nOriginal stack trace for 'Reshape':\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n    result = self._run_cell(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n    return runner(coro)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\", line 1, in <module>\n    pv = PVNet2(6, 6)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\", line 36, in __init__\n    self.action_conv_flat = tf.reshape(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1096, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 197, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8546, in reshape\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1456\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) INVALID_ARGUMENT: Input to reshape is a tensor with 72 values, but the requested shape requires a multiple of 144\n\t [[{{node Reshape}}]]\n\t [[dense_2/Tanh/_105]]\n  (1) INVALID_ARGUMENT: Input to reshape is a tensor with 72 values, but the requested shape requires a multiple of 144\n\t [[{{node Reshape}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'600.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state, v)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#state.get_state().reshape(-1, 1, 8, 8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         log_act_probs, value = self.session.run(\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_fc2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                            run_metadata)\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1397\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1399\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) INVALID_ARGUMENT: Input to reshape is a tensor with 72 values, but the requested shape requires a multiple of 144\n\t [[node Reshape\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:36)\n]]\n\t [[dense_2/Tanh/_105]]\n  (1) INVALID_ARGUMENT: Input to reshape is a tensor with 72 values, but the requested shape requires a multiple of 144\n\t [[node Reshape\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py:36)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Reshape:\nIn[0] conv2d_3/Relu (defined at /Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional.py:273)\t\nIn[1] Reshape/shape:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\", line 36, in __init__\n>>>     self.action_conv_flat = tf.reshape(\n>>> \n\nInput Source operations connected to node Reshape:\nIn[0] conv2d_3/Relu (defined at /Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional.py:273)\t\nIn[1] Reshape/shape:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\", line 36, in __init__\n>>>     self.action_conv_flat = tf.reshape(\n>>> \n\nOriginal stack trace for 'Reshape':\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n    result = self._run_cell(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n    return runner(coro)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/2299691555.py\", line 1, in <module>\n    pv = PVNet2(6, 6)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/3538894304.py\", line 36, in __init__\n    self.action_conv_flat = tf.reshape(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1096, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 197, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8546, in reshape\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "pv = PVNet2(6, 6)\n",
    "pv.restore('600.model')\n",
    "b = Board(6, 4)\n",
    "pv.predict(b.get_state().reshape(-1, 4, 6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2e82661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.3689392e-07, 3.1376342e-07, 5.0886496e-07, 5.1594026e-07,\n",
       "        2.7964430e-07, 4.7143509e-08, 6.6497114e-07, 4.2883763e-05,\n",
       "        3.7276754e-04, 3.1938957e-04, 4.5294495e-05, 2.6526584e-07,\n",
       "        9.0949135e-07, 6.0766219e-04, 2.2480451e-01, 2.7523169e-01,\n",
       "        4.1038700e-04, 1.2267570e-06, 5.6432191e-07, 3.1323172e-04,\n",
       "        2.8378546e-01, 2.1240395e-01, 6.2836619e-04, 3.8217266e-07,\n",
       "        1.8744321e-07, 3.6152513e-05, 3.4512402e-04, 6.0383789e-04,\n",
       "        4.0508086e-05, 4.0719797e-07, 5.1515578e-08, 3.5078295e-07,\n",
       "        4.2418924e-07, 6.6745918e-07, 7.9944306e-07, 1.5953768e-07],\n",
       "       dtype=float32),\n",
       " 0.3153984)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pv_net.predict(b.get_state().reshape(-1, 4, 6, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61faab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:17: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv1 = tf.layers.conv2d(inputs=self.input_state,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:21: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv2 = tf.layers.conv2d(inputs=self.conv1, filters=64,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:25: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.conv3 = tf.layers.conv2d(inputs=self.conv2, filters=128,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:30: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.action_conv = tf.layers.conv2d(inputs=self.conv3, filters=4,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:39: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.action_fc = tf.layers.dense(inputs=self.action_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:43: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  self.evaluation_conv = tf.layers.conv2d(inputs=self.conv3, filters=2,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:50: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc1 = tf.layers.dense(inputs=self.evaluation_conv_flat,\n",
      "/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:53: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  self.evaluation_fc2 = tf.layers.dense(inputs=self.evaluation_fc1,\n",
      "2022-01-20 15:08:15.385581: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-20 15:08:15.385609: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-20 15:08:15.498202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 900.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 15:08:16.327502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-20 15:08:16.594658: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at save_restore_v2_ops.cc:207 : NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[node save_6/RestoreV2\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:92)\n]]\n\t [[save_6/RestoreV2/_17]]\n  (1) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[node save_6/RestoreV2\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:92)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save_6/RestoreV2:\nIn[0] save_6/Const:\t\nIn[1] save_6/RestoreV2/tensor_names:\t\nIn[2] save_6/RestoreV2/shape_and_slices:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n>>>     self.saver = tf.train.Saver()\n>>> \n\nInput Source operations connected to node save_6/RestoreV2:\nIn[0] save_6/Const:\t\nIn[1] save_6/RestoreV2/tensor_names:\t\nIn[2] save_6/RestoreV2/shape_and_slices:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n>>>     self.saver = tf.train.Saver()\n>>> \n\nOriginal stack trace for 'save_6/RestoreV2':\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n    result = self._run_cell(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n    return runner(coro)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n    pv = PVNet2(6, 6)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n    self.saver = tf.train.Saver()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 923, in __init__\n    self.build()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 935, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 963, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 533, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 353, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 601, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1501, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1364\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1456\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[{{node save_6/RestoreV2}}]]\n\t [[save_6/RestoreV2/_17]]\n  (1) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[{{node save_6/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m         sess.run(self.saver_def.restore_op_name,\n\u001b[0m\u001b[1;32m   1405\u001b[0m                  {self.saver_def.filename_tensor_name: save_path})\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    971\u001b[0m                          run_metadata_ptr)\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                              feed_dict_tensor, options, run_metadata)\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1374\u001b[0m                            run_metadata)\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1399\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[node save_6/RestoreV2\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:92)\n]]\n\t [[save_6/RestoreV2/_17]]\n  (1) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[node save_6/RestoreV2\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:92)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save_6/RestoreV2:\nIn[0] save_6/Const:\t\nIn[1] save_6/RestoreV2/tensor_names:\t\nIn[2] save_6/RestoreV2/shape_and_slices:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n>>>     self.saver = tf.train.Saver()\n>>> \n\nInput Source operations connected to node save_6/RestoreV2:\nIn[0] save_6/Const:\t\nIn[1] save_6/RestoreV2/tensor_names:\t\nIn[2] save_6/RestoreV2/shape_and_slices:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n>>>     self.saver = tf.train.Saver()\n>>> \n\nOriginal stack trace for 'save_6/RestoreV2':\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n    result = self._run_cell(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n    return runner(coro)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n    pv = PVNet2(6, 6)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n    self.saver = tf.train.Saver()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 923, in __init__\n    self.build()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 935, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 963, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 533, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 353, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 601, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1501, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     return CheckpointReader.CheckpointReader_GetTensor(\n\u001b[0m\u001b[1;32m     71\u001b[0m         self, compat.as_bytes(tensor_str))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1735\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPVNet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'900.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;31m# is a graph mismatch. Re-raise the original error with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         raise _wrap_restore_error_with_msg(\n\u001b[0m\u001b[1;32m   1421\u001b[0m             err, \"a Variable name or other graph key that is missing\")\n\u001b[1;32m   1422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[node save_6/RestoreV2\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:92)\n]]\n\t [[save_6/RestoreV2/_17]]\n  (1) NOT_FOUND: Key batch_normalization/beta/Adam_10 not found in checkpoint\n\t [[node save_6/RestoreV2\n (defined at /var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py:92)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node save_6/RestoreV2:\nIn[0] save_6/Const:\t\nIn[1] save_6/RestoreV2/tensor_names:\t\nIn[2] save_6/RestoreV2/shape_and_slices:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n>>>     self.saver = tf.train.Saver()\n>>> \n\nInput Source operations connected to node save_6/RestoreV2:\nIn[0] save_6/Const:\t\nIn[1] save_6/RestoreV2/tensor_names:\t\nIn[2] save_6/RestoreV2/shape_and_slices:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n>>>     pv = PVNet2(6, 6)\n>>> \n>>>   File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n>>>     self.saver = tf.train.Saver()\n>>> \n\nOriginal stack trace for 'save_6/RestoreV2':\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n    self.io_loop.start()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n    self._run_once()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n    handle._run()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n    await self.process_one()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n    await dispatch(*args)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n    await result\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n    reply_content = await reply_content\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n    result = self._run_cell(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n    return runner(coro)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/391105635.py\", line 1, in <module>\n    pv = PVNet2(6, 6)\n  File \"/var/folders/_3/stf971r13njfhfsz80m7bqwc0000gn/T/ipykernel_60583/1549856815.py\", line 92, in __init__\n    self.saver = tf.train.Saver()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 923, in __init__\n    self.build()\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 935, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 963, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 533, in _build_internal\n    restore_op = self._AddRestoreOps(filename_tensor, saveables,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 353, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/training/saver.py\", line 601, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1501, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3697, in _create_op_internal\n    ret = Operation(\n  File \"/Users/fanrongqi/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "pv = PVNet2(6, 6)\n",
    "pv.restore('900.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838bf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8df6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae89986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b3bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49755ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input\n",
    "weight_decay=1e-4\n",
    "input = Input((4, 8, 8))\n",
    "x = input\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(4, 8, 8))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "x = BatchNormalization()(x)\n",
    "print(x.shape, input.shape)\n",
    "p = Conv2D(2, (1,1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "p = BatchNormalization()(p)\n",
    "p = Flatten()(p)\n",
    "p = Dense(8 * 8, activation='softmax')(p)\n",
    "print(p.shape)\n",
    "v = Conv2D(2, (1,1), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "v = BatchNormalization()(v)\n",
    "v = Flatten()(v)\n",
    "v = Dense(8 * 8, activation='relu')(v)\n",
    "v = Dense(1, activation='tanh')(v)\n",
    "print(v.shape)\n",
    "model = Model(inputs=input, outputs=[p, v])\n",
    "model.compile(optimizer=Adam(), loss=['categorical_crossentropy', 'mean_squared_error'])\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
